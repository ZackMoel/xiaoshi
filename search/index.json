[{"content":"如何部署python的代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 既然是运维，运维，部署，维护 一个完整的产品、 前端开发工程师(前端代码 html,css,js) + 后端工程师（编写和数据库交互的逻辑代码） 前端、后端源码，打包，发给运维，部署到linux服务器上 1.如果是web产品，需要运维，部署如nginx这样的web服务器，提供域名，端口，防火墙，等允许网站在公网中的可访问。 2. 如果是控制汽车运行的智能算法系统，仅仅要求在linux上运行。基本都要提供基于http协议的一个访问服务。 3. 单纯的计算服务，在系统上，确保可以运行即可,不提供socket(ip:port)让客户端去访问。 不同的公司，使用的技术栈不一样，基本是根据企业的技术沉淀有关，以及招聘来的技术老大有关。决定你开发技术栈，架构，用什么形式的。 早期的，老旧的技术栈，单体应用， 前后端不分离开发模式。（前端、后端代码，糅杂在一起，后端代码，也包括前端代码） 后端代码文件，里面还能看到html这样的标签。。。 具体部署形式，比较简单，整个代码，跑起来，甩给nginx去反向代理即可。，如，经典的wordpress，用的是php后端。 如果你去其他公司，如360这样公司，大量使用php，那么你的日常维护，部署工作，基本是围绕着LNMP来打转。。 ------------------------- 如果你是去了一些新型的互联网公司，某单位，技术栈，用的都是比较新的，复杂的。 看主流，常见的部署技术栈 php + html + css + js = wordpress python + vue = jumpserver 借助浏览器插件： Wappalyzer 可以很方便的看到网站，是基于什么技术开发的 现在大多数网站，前端都是基于vue开发 后端，编程语言选择性很多 数据库，基本是mysql javascript框架，就知道，这是前端的服务器框架 python框架，就知道后端用的是python bilibili.com 前端 服务器是 运行着 vue.js进程的服务器 后端服务器 是运行着 golang 进程的服务器 数据库服务器，运行着mysql进程的服务器 前后端分离和不分离 在部署 Web 应用时，Nginx 可以用于支持前后端分离和不分离的架构。以下是这两种部署方式的区别和示例配置：\n前后端分离 概念 前端：通常使用框架如 Vue.js、React 等，构建成静态文件（HTML、CSS、JS）。 后端：使用 Node.js、Django、Spring 等提供 API 服务。 部署方式 前端：Nginx 负责托管静态文件。 后端：Nginx 通过反向代理将 API 请求转发到后端服务。 Nginx 配置示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 server { listen 80; server_name example.com; location / { root /path/to/frontend/dist; try_files $uri $uri/ /index.html; } location /api/ { proxy_pass http://localhost:3000; # Node.js 服务 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 前后端不分离 概念 集成：前后端代码在同一个项目中开发和部署。 模板渲染：后端使用模板引擎（如 EJS、Thymeleaf）直接渲染 HTML。 部署方式 Nginx 主要作为反向代理，所有请求都转发到后端服务。 后端服务负责提供完整的页面和 API。 Nginx 配置示例 1 2 3 4 5 6 7 8 9 10 11 server { listen 80; server_name example.com; location / { proxy_pass http://localhost:3000; # 后端服务 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 总结 前后端分离：更灵活，前端和后端可以独立开发、部署和扩展。 前后端不分离：更简单的项目架构，适合小型应用或快速开发。 选择合适的架构和部署方式根据项目需求、团队结构和技术栈而定。\n补充，nginx和vue和node.js的关系\nNginx、Vue.js 和 Node.js 在现代 web 开发中常常一起使用，形成一个完整的前后端架构。以下是它们之间的关系和协作方式：\nVue.js 前端框架：用于构建用户界面的 JavaScript 框架，特别适合单页应用（SPA）。 开发工具：使用 Vue CLI 等工具进行开发、组件化和状态管理。 Node.js 后端运行环境：基于 Chrome V8 引擎的 JavaScript 运行时，用于构建快速、可扩展的网络应用。 API 服务：通常用于构建后端 RESTful API，以支持前端应用的数据交互。 构建工具：Node.js 也用于前端构建工具（如 Webpack、Vite）来打包和优化 Vue.js 应用。 Nginx Web 服务器：用于托管静态文件（如 Vue.js 构建后的文件）和反向代理请求。 负载均衡：可以将请求分发到多个 Node.js 实例，提高应用的可用性和性能。 缓存：支持静态内容缓存，提高访问速度。 协同工作流程 前端开发： 使用 Vue.js 开发应用，Node.js 作为构建工具运行开发服务器。 构建和打包： 使用 Node.js 中的工具（如 Webpack、Vite）将 Vue.js 应用打包成静态文件。 部署： Nginx：托管打包后的静态文件。 Node.js：运行后端服务，处理 API 请求。 Nginx 配置示例： 1 2 3 4 5 6 7 8 9 10 11 12 13 server { listen 80; server_name yourdomain.com; location / { root /path/to/your/dist; try_files $uri $uri/ /index.html; } location /api/ { proxy_pass http://localhost:3000; } } 典型架构 用户请求：通过浏览器访问 Vue.js 应用。 静态文件：Nginx 提供静态文件（HTML、CSS、JavaScript）。 API 请求：Nginx 将 API 请求转发到 后端。 数据处理：后端 处理请求并与数据库交互，返回数据给前端。 这种架构充分利用了各个组件的优势，Nginx 提供高效的静态内容服务和反向代理功能，Vue.js 提供灵活的前端开发体验\n部署堡垒机jumpserver(python+vue+golang) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 生产级别，较为复杂的项目部署。 前后端分离的如何部署： 独立的前端vue项目部署 独立的python项目部署 独立的mysql、redis数据库 独立的golang项目 运维开发，就是去写python，维护jumpserver源码 招运维，就是去给客户，部署jumpserver，以及运行过程中，出现问题，运维做技术支持，解决客户的问题。。 为什么要使用堡垒机 跳板机和堡垒机 1 2 3 4 5 为了细粒度的，监控运维，任意登录服务器操作的行为 可以责任制，防止无端背黑锅 也保证了服务器的安全 jumpserver基于ansible远程执行命令 安装部署 - JumpServer 文档\n项目架构图（组件版本要求） 这些每一个组件，当你部署好，运行好进程后， 需要整合起来，整合为一个可访问的统一入口\n这个整合的和事佬是，是nginx。\n请看nginx统一架构图，也是用户访问jumpserver的核心请求逻辑图。\n完整部署笔记 大项目，都是一个工程化开发结构，还是狠复杂的。\n服务器准备 1 2 3 4 5 6 7 准备好你的master-61机器，至少给它4G内存，因为 这里部署形式，是让前端，和后端在一台机器上，先不拆了。 如果是你的官网应用，基于前后端分离开发模式，一定要分开多台机器的 master-61 运行堡垒机所有组件，5大组件 db-51 部署数据库mysql，和redis mysql、redis（db-51，数据库机器） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 重要，友情提醒 友情提示：mysql数据库密码请使用 \u0026#34;字母+数字\u0026#34; 可以和老师配置的一样 用\u0026#34;lijin666\u0026#34; 数据库密码连接，读取的是字符串类型 如果你的数据库密码是 \u0026#34;123456\u0026#34;这样的纯数字， 在config.yml里面填入的DB_PASSWORD: \u0026#34;123456\u0026#34; 需要像这样，添加引号，否则报错。 1. 密码，复杂一点，数字+字母 2， 给大家准备的堡垒机 v2.12版本，要求mysql版本大于等于5.7 # 具体部署笔记 yum -y localinstall http://mirrors.ustc.edu.cn/mysql-repo/mysql57-community-release-el7.rpm sed -i \u0026#39;/gpgcheck=1/c gpgcheck=0\u0026#39; /etc/yum.repos.d/mysql-community* yum clean all yum install -y mysql-community-server 初始化mysql数据 shell命令，修改mysql的启动脚本 mysql5.7之后，默认初始化启动，会随机给你生成密码，你得去配置文件中找这个随机密码。 用如下命令，修改配置文件，可以让他默认别生成随机密码。 if [ ! \u0026#34;$(cat /usr/bin/mysqld_pre_systemd | grep -v ^\\# | grep initialize-insecure )\u0026#34; ]; then sed -i \u0026#34;s@--initialize @--initialize-insecure @g\u0026#34; /usr/bin/mysqld_pre_systemd fi 启动 systemctl enable mysqld systemctl start mysqld 检查进程，端口 [root@db-51 ~]# [root@db-51 ~]#netstat -tunlp|grep mysql tcp6 0 0 :::3306 :::* LISTEN 2450/mysqld [root@db-51 ~]# [root@db-51 ~]# [root@db-51 ~]# [root@db-51 ~]#ps -ef|grep mysql mysql 2450 1 1 11:32 ? 00:00:00 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid root 2484 1659 0 11:33 pts/0 00:00:00 grep --color=auto mysql 尝试连接mysql，然后设置一个远程连接的用户，因为master-61机器需要用 [root@db-51 ~]#mysql Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.38 MySQL Community Server (GPL) Copyright (c) 2000, 2022, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; mysql\u0026gt; # 创建数据库，用于堡垒机写入数据表信息 mysql\u0026gt; create database jumpserver default charset \u0026#39;utf8\u0026#39;; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; # 设置弱密码参数，默认密码难度限制较大，数字，字母，特殊符号。 mysql\u0026gt; set global validate_password_policy=LOW; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; # 创建用户，jumpserver 以及密码，待会用于远程连接 mysql\u0026gt; create user \u0026#39;jumpserver\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;linux0224\u0026#39;; Query OK, 0 rows affected (0.00 sec) # 用户授予远程连接权限 mysql\u0026gt; grant all on jumpserver.* to \u0026#39;jumpserver\u0026#39;@\u0026#39;%\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec) 到这里，数据库mysql5.7就配置完毕了 redis内存型数据库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 mysql 磁盘性数据库存储网站的 冷数据，读取不频繁的 redis 数据存内存里。存储网站热数据，如用户信息等，用户的session身份保持信息等。 组件连接的信息等 要求版本大于6.0 编译安装，准备编译环境，以及redis源码 yum -y install epel-release wget make gcc-c++ # 6.2.4版本 cd /opt ; wget https://download.redis.io/releases/redis-6.2.4.tar.gz [root@db-51 /opt]#tar -xf redis-6.2.4.tar.gz 进入源代码目录，编译安装即可，注意可以指定安装的路径参数 cd redis-6.2.4 make \u0026amp;\u0026amp; make install PREFIX=/usr/local/redis 检查你的redis安装情况 [root@db-51 /opt/redis-6.2.4]#cd /usr/local/redis/ [root@db-51 /usr/local/redis]#ls bin [root@db-51 /usr/local/redis]#ls bin redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-sentinel redis-server 需要你自己添加PATH变量，方可直接使用。 [root@db-51 /opt/redis-6.2.4]#tail -2 /etc/profile export PATH=$PATH:/usr/local/redis/bin/ 修改配置文件的参数，设定redis数据库的连接信息，以及密码 # 拷贝配置文件 cp redis.conf /etc/redis.conf # 允许redis在任意地址可访问 sed -i \u0026#34;s/bind 127.0.0.1/bind 0.0.0.0/g\u0026#34; /etc/redis.conf # 让redis以守护进程，在后台运行 sed -i \u0026#34;s/daemonize no/daemonize yes/g\u0026#34; /etc/redis.conf # 设置redis的内存性参数，内存缓存算法 sed -i \u0026#34;561i maxmemory-policy allkeys-lru\u0026#34; /etc/redis.conf # 设置redis的连接密码requirepass设置密码的，后面写密码 sed -i \u0026#34;481i requirepass linux0224\u0026#34; /etc/redis.conf 验证你的配置，是否生效 grep -Ev \u0026#39;^#|^$\u0026#39; /etc/redis.conf 验证你的修改操作 [root@db-51 /opt/redis-6.2.4]#grep -Ev \u0026#39;^#|^$\u0026#39; /etc/redis.conf | grep -E \u0026#39;(bind|require|daemonize)\u0026#39; bind 0.0.0.0 -::1 daemonize yes requirepass linux0224 由于是编译安装，默认没有systemctl的管理脚本，可以自己写一个即可 cat \u0026gt;/etc/systemd/system/redis.service \u0026lt;\u0026lt;EOF [Unit] Description=Redis persistent key-value database After=network.target After=network-online.target Wants=network-online.target [Service] Type=forking PIDFile=/var/run/redis_6379.pid ExecStart=/usr/local/redis/bin/redis-server /etc/redis.conf ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID [Install] WantedBy=multi-user.target EOF 可以用systemctl去管理了 # 启动redis systemctl enable redis systemctl start redis 确保redis运行中 [root@db-51 /opt/redis-6.2.4]#ps -ef|grep redis root 7009 1 0 11:50 ? 00:00:00 /usr/local/redis/bin/redis-server 0.0.0.0:6379 root 7015 1659 0 11:50 pts/0 00:00:00 grep --color=auto redis [root@db-51 /opt/redis-6.2.4]# [root@db-51 /opt/redis-6.2.4]# [root@db-51 /opt/redis-6.2.4]# [root@db-51 /opt/redis-6.2.4]# [root@db-51 /opt/redis-6.2.4]#netstat -tunlp|grep redis tcp 0 0 0.0.0.0:6379 0.0.0.0:* LISTEN 7009/redis-server 0 tcp6 0 0 ::1:6379 :::* LISTEN 7009/redis-server 0 本地连接redis测试，查看密码是否好用 [root@db-51 /opt/redis-6.2.4]#redis-cli 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; ping (error) NOAUTH Authentication required. 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; auth linux0224 OK 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; ping PONG 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; exit [root@db-51 /opt/redis-6.2.4]# [root@db-51 /opt/redis-6.2.4]# [root@db-51 /opt/redis-6.2.4]## master-61去远程连接redis [root@db-51 /opt/redis-6.2.4]# [root@db-51 /opt/redis-6.2.4]#redis-cli -h 172.16.1.51 172.16.1.51:6379\u0026gt; 172.16.1.51:6379\u0026gt; 172.16.1.51:6379\u0026gt; ping (error) NOAUTH Authentication required. 172.16.1.51:6379\u0026gt; 172.16.1.51:6379\u0026gt; 172.16.1.51:6379\u0026gt; auth linunx0224 (error) WRONGPASS invalid username-password pair or user is disabled. 172.16.1.51:6379\u0026gt; 172.16.1.51:6379\u0026gt; 172.16.1.51:6379\u0026gt; auth linux0224 OK 172.16.1.51:6379\u0026gt; 172.16.1.51:6379\u0026gt; ping PONG 172.16.1.51:6379\u0026gt; exit [root@db-51 /opt/redis-6.2.4]# [root@db-51 /opt/redis-6.2.4]## 本地连接，远程连接，密码认证，ping pong通了 [root@db-51 /opt/redis-6.2.4]# [root@db-51 /opt/redis-6.2.4]# core(核心堡垒机后端服务)（内存至少4G，其他服务起不来） 光jumpserver核心core程序，至少用到2G内存。\n基础环境安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 先确保环境正确，基础环境部署。 先恢复master61机器，注意，做好快照。 从端口来看，这个机器是干净的。 [root@master-61 ~]#netstat -tunlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 893/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1151/master tcp6 0 0 :::22 :::* LISTEN 893/sshd tcp6 0 0 ::1:25 :::* LISTEN 1151/master [root@master-61 ~]# 检查防火墙 yum源，基础环境部署 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo # 一是，安装基础软件 yum install -y bash-completion vim lrzsz wget expect net-tools nc nmap tree dos2unix htop iftop iotop unzip telnet sl psmisc nethogs glances bc ntpdate openldap-devel 2.第一个里程：需要部署跳板机依赖软件，重要 # 二是，安装python程序，必须的一些基础依赖。 yum -y install git python-pip gcc automake autoconf python-devel vim sshpass lrzsz readline-devel zlib zlib-devel openssl openssl-devel 设置master-61机器的系统编码环境，支持中文 localedef -c -f UTF-8 -i zh_CN zh_CN.UTF-8 # 设置操作系统所有的语言环境，改为中文utf8编码 export LC_ALL=zh_CN.UTF-8 查看编码情况 使用locale命令，查看系统本地所有编码的变量 需要你切换系统的中英文支持。 [root@master-61 ~]#locale LANG=en_US.UTF-8 LC_CTYPE=\u0026#34;zh_CN.UTF-8\u0026#34; LC_NUMERIC=\u0026#34;zh_CN.UTF-8\u0026#34; LC_TIME=\u0026#34;zh_CN.UTF-8\u0026#34; LC_COLLATE=\u0026#34;zh_CN.UTF-8\u0026#34; LC_MONETARY=\u0026#34;zh_CN.UTF-8\u0026#34; LC_MESSAGES=\u0026#34;zh_CN.UTF-8\u0026#34; LC_PAPER=\u0026#34;zh_CN.UTF-8\u0026#34; LC_NAME=\u0026#34;zh_CN.UTF-8\u0026#34; LC_ADDRESS=\u0026#34;zh_CN.UTF-8\u0026#34; LC_TELEPHONE=\u0026#34;zh_CN.UTF-8\u0026#34; LC_MEASUREMENT=\u0026#34;zh_CN.UTF-8\u0026#34; LC_IDENTIFICATION=\u0026#34;zh_CN.UTF-8\u0026#34; LC_ALL=zh_CN.UTF-8 # 这是一个python3开发的源代码，jumpserver，因此需要配置python3环境，咱们是编译安装，因为有版本要求。 # 编译安装，python是可以处理ssl加密，因此你的底层需要安装openssl基础环境 # 下载安装python3源代码，部署python这一块，会需要用到一些python的环境知识，认真听，稍微有点难度。 # 1. 下载jumpserver后端核心源码 mkdir /opt/jumpserver-v2.12.0 wget -O /opt/jumpserver-v2.12.0.tar.gz https://github.com/jumpserver/jumpserver/archive/refs/tags/v2.12.0.tar.gz # 2. 解压缩源代码，安装后端源码，运行所需的linux环境依赖，rpm包，人家给提供好了 # --strip-components 1 参数意思是， cd /opt ; tar -xf jumpserver-v2.12.0.tar.gz -C /opt/jumpserver-v2.12.0 --strip-components 1 --------------------------------------------------------------------------------- # 3.检查解压的源码（这就是python的web框架，django的一堆源代码，都是py文件） # 其实就是一堆py代码，和sh脚本，这个源码是飞致云的运维开发，写的程序 # 纯开发，纯后端开发，是写业务代码，如电商后台，员工管理系统后台，医疗系统后台 # 管理的纯业务的员工数据，商业数据。 ------------------------------------------------------------------------ # 运维开发，写代码，写平台，数据库管理的是机器的信息，如资产管理平台， 代码发布平台，容器管理平台 # ansible自动化调度平台。运维开发，通过运维技术+开发技术，管理服务器，等资产信息。 # --------------------------------------------------------------------------------- [root@master-61 /opt/jumpserver-v2.12.0]#ls apps data docs jms logs README.md run_server.py utils config_example.yml Dockerfile entrypoint.sh LICENSE README_EN.md requirements tmp Vagrantfile # 3. jumpserver源码，给你提供了一堆rpm包，需要你去安装方可运行， yum install -y $(cat /opt/jumpserver-v2.12.0/requirements/rpm_requirements.txt) python3.6开发环境安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 当你以后去维护python的产品 目前市面上有2个版本 1. python2的版本，以及不再维护了，但是有老企业在用(linux系统默认很多工具用的是python2，如yum工具) [root@master-61 /opt/jumpserver-v2.12.0]#python -V Python 2.7.5 2. python3的版本，主流版本 3. 要注意的是，同时保留python2，和python3，不要乱改。 添加到PATH，让2个版本共存即可。 4. 先安装python3的编译环境，注意整理python的包，是不带3这个数字的！！ yum install gcc patch libffi-devel python-devel zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel -y 5. 下载python3源码，编译且安装 # 使用自建的yum仓库即可。 # 确保你的编译过程，没有errorr，看好日志 # python语言是由C语言开发而来。。。它也叫做Cpython。。没想到吧。。 cd /opt \u0026amp;\u0026amp; wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tgz tar -zxf Python-3.6.9.tgz cd Python-3.6.9/ ./configure --prefix=/opt/python369/ make \u0026amp;\u0026amp; make install 6.看到如下日志，你的python3才是正常的 Collecting setuptools Collecting pip Installing collected packages: setuptools, pip Successfully installed pip-18.1 setuptools-40.6.2 检查python3的环境如下，添加到PATH变量中 [root@master-61 /opt/python369/bin]#tail -2 /etc/profile # 添加python3的PATH export PATH=$PATH:/opt/python369/bin [root@master-61 /opt/python369/bin]#source /etc/profile 7.检查，确保如下2个命令可以正确执行，你的python3环境才是对的 # 这个是python3的解释器，用于执行*.py代码的。 [root@master-61 ~]#python3 -V Python 3.6.9 [root@master-61 ~]# [root@master-61 ~]# # 这是管理python程序的模块依赖包的 # 这么去理解 # yum是给centos安装rpm包依赖的。 # pip3命令是给python3，给python项目，安装项目所需的依赖的。 # 它俩是2个 东西 [root@master-61 ~]#pip3 -V pip 18.1 from /opt/python369/lib/python3.6/site-packages/pip (python 3.6) 补充：设置pip3的下载源，豆瓣源，加速模块下载 1 2 3 4 5 6 7 8 9 10 11 # 在用户家目录下，生成一个全局的 .pip.conf配置文件而已。 # 就是生成一个文件而已。然后pip3 install xxx模块的时候，会使用如下这个地址 # 就和你配置yum源一个意思。。。 # 创建文件夹 mkdir ~/.pip # 创建配置文件 (venv_py3) [root@master-61 ~]#cat ~/.pip/pip.conf [global] index-url=https://pypi.douban.com/simple python3的虚拟环境安装（虚拟环境原理就是在修改PATH变量） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 当前机器上，存在一个python3的环境，绝对路径在 [root@master-61 ~]#which python3 /opt/python369/bin/python3 # 具体的演示如下 1. 创建虚拟环境（其实就是又下载了一个python3解释器，而已，你理解是本体解释器的一个分身即可。） # 基于python3命令 指定用venv这个模块功能，下载安装一个解释器路径到 /opt/venv_py3 cd /opt \u0026amp;\u0026amp; python3 -m venv /opt/venv_py3 2. 演示，物理解释器的环境信息，以及虚拟环境的解释器信息 ------------------------------------------------------------ 查看【物理解释器】本体的模块信息 [root@master-61 /opt]#which pip3 /opt/python369/bin/pip3 查看模块列表 [root@master-61 /opt]#pip3 list Package Version ---------- ------- pip 18.1 setuptools 40.6.2 随便装一个模块，再查看模块列表 [root@master-61 /opt]#pip3 install requests ￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥ [root@master-61 /opt]#pip3 list Package Version ------------------ ----------- certifi 2022.5.18.1 charset-normalizer 2.0.12 idna 3.3 pip 18.1 requests 2.27.1 setuptools 40.6.2 urllib3 1.26.9 ￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥ ------------------------------------------------------------ 3. 激活虚拟环境，安装jumpserver后端所需的python依赖 [root@master-61 /opt]#source /opt/venv_py3/bin/activate (venv_py3) [root@master-61 /opt]# (venv_py3) [root@master-61 /opt]# (venv_py3) [root@master-61 /opt]# (venv_py3) [root@master-61 /opt]# (venv_py3) [root@master-61 /opt]# (venv_py3) [root@master-61 /opt]# (venv_py3) [root@master-61 /opt]# (venv_py3) [root@master-61 /opt]# (venv_py3) [root@master-61 /opt]#which pip3 /opt/venv_py3/bin/pip3 (venv_py3) [root@master-61 /opt]# 查看当前python3解释器的模块列表 ￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥ (venv_py3) [root@master-61 /opt]#pip3 list Package Version ---------- ------- pip 18.1 setuptools 40.6.2 ￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥ 能看明白，此时基于虚拟环境，管理了一个新的解释器模块依赖 和物理解释器的模块信息，是分开的， 说到这里，就是已经装好了一个虚拟环境\n1 /opt/venv_py3/ 这个路径的解释器 为什么激活虚拟环境后，解释器用which查看的路径就变了。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 很简单，因为它帮你修改了PATH PATH有加载顺序，从左到右。 1. 查看虚拟环境下的PATH信息 (venv_py3) [root@master-61 /opt]#echo $PATH /opt/venv_py3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/opt/python369/bin (venv_py3) [root@master-61 /opt]# 2. 退出虚拟环境后再看 (venv_py3) [root@master-61 /opt]#deactivate [root@master-61 /opt]# [root@master-61 /opt]# [root@master-61 /opt]#echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/opt/python369/bin [root@master-61 /opt]# [root@master-61 /opt]#which pip3 /opt/python369/bin/pip3 安装jumpserver后端所需的python依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 1.确保要激活虚拟环境 2. 找到项目中的，项目依赖文件，这是每一个python开发者，必然会设置的一个文件，方便运维去部署这些依赖模块。 (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0/requirements]#ls /opt/jumpserver-v2.12.0/requirements/requirements.txt /opt/jumpserver-v2.12.0/requirements/requirements.txt 先查看当前的虚拟环境下的依赖列表 (venv_py3) [root@master-61 ~]#pip3 list Package Version ---------- ------- pip 18.1 setuptools 40.6.2 You are using pip version 18.1, however version 21.3.1 is available. You should consider upgrading via the \u0026#39;pip install --upgrade pip\u0026#39; command. 3. 安装这些模块依赖（注意，使用豆瓣源去下载，否则让你怀疑人生） (venv_py3) [root@master-61 ~]#pip3 install -r /opt/jumpserver-v2.12.0/requirements/requirements.txt 这个python模块，要么全部成功，要么全部会失败。 注意别报错即可。 别出现error，否则pip3命令会立即终止的，然后看报错，解决报错即可。 4. 查看模块依赖（依然是虚拟环境下的模块依赖） 差不多有198行模块 (venv_py3) [root@master-61 ~]#pip3 list |wc -l 198 5. 可以退出虚拟环境，对比着物理环境理解下，看下区别。 再次确认，物理环境，和虚拟环境的区别 解决pip版本太低的问题，升级即可 1 2 3 4 5 6 7 8 9 10 (venv_py3) [root@master-61 ~]#pip install --upgrade pip Looking in indexes: https://pypi.douban.com/simple Collecting pip Downloading https://pypi.doubanio.com/packages/a4/6d/6463d49a933f547439d6b5b98b46af8742cc03ae83543e4d7688c2420f8b/pip-21.3.1-py3-none-any.whl (1.7MB) 100% |████████████████████████████████| 1.7MB 26.9MB/s Installing collected packages: pip Found existing installation: pip 18.1 Uninstalling pip-18.1: Successfully uninstalled pip-18.1 Successfully installed pip-21.3.1 下一步，python3环境好了之后，可以运行项目了 修改jumpserver代码的配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 1. 提示，你在部署core服务，后端python服务的时候，确保全程激活虚拟环境 2.拷贝配置文件，修改配置文件如下 (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]#cp config_example.yml config.yml (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]# (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]# (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]#ls config.yml config.yml 3. 修改如下 jumpserver整个架构的所有组件，相互之间的通信，都是基于一个密钥来加密的。 基于如下命令，生成2个密钥。 先打印这2个变量看有没有 echo $SECRET_KEY echo $BOOTSTRAP_TOKEN # 生成如下2个变量的随机值，待会配置文件得用 if [ \u0026#34;$SECRET_KEY\u0026#34; = \u0026#34;\u0026#34; ]; then SECRET_KEY=`cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 50`; echo \u0026#34;SECRET_KEY=$SECRET_KEY\u0026#34; \u0026gt;\u0026gt; ~/.bashrc; echo $SECRET_KEY; else echo $SECRET_KEY; fi if [ \u0026#34;$BOOTSTRAP_TOKEN\u0026#34; = \u0026#34;\u0026#34; ]; then BOOTSTRAP_TOKEN=`cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 16`; echo \u0026#34;BOOTSTRAP_TOKEN=$BOOTSTRAP_TOKEN\u0026#34; \u0026gt;\u0026gt; ~/.bashrc; echo $BOOTSTRAP_TOKEN; else echo $BOOTSTRAP_TOKEN; fi 4. 修改jumpserver后台的配置文件【请注意，这个文件是yaml语法，空格语法很严格】 大家，照着我这个修改即可， SECRET_KEY: \u0026#34;$SECRET_KEY\u0026#34; BOOTSTRAP_TOKEN: \u0026#34;$BOOTSTRAP_TOKEN\u0026#34; DEBUG: true # 开发建议打开 DEBUG, 生产环境应该关闭 LOG_LEVEL: DEBUG # 开发建议设置 DEBUG, 生产环境推荐使用 ERROR SESSION_EXPIRE_AT_BROWSER_CLOSE: true # 浏览器关闭 session 过期 DB_ENGINE: mysql\t# 数据库引擎是mysql DB_HOST: 10.0.0.51 # 自行配置 数据库相关 DB_PORT: 3306\t# 数据库端口 DB_USER: jumpserver\t# 数据库远程连接的用户 DB_PASSWORD: linux0224\t# mysql密码 DB_NAME: jumpserver\t# mysql存储的库名 HTTP_BIND_HOST: 0.0.0.0 # core服务运行的地址 HTTP_LISTEN_PORT: 8080\t# core服务运行的端口 WS_LISTEN_PORT: 8070\t# 后端websocket协议的端口 REDIS_HOST: 10.0.0.51 # 自行配置 Redis 相关 REDIS_PORT: 6379 REDIS_PASSWORD: linux0224\t# 自定义的redis密码 因此最终的配置如下 (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]#cat config.yml SECRET_KEY: \u0026#34;$SECRET_KEY\u0026#34; BOOTSTRAP_TOKEN: \u0026#34;$BOOTSTRAP_TOKEN\u0026#34; DEBUG: true LOG_LEVEL: DEBUG SESSION_EXPIRE_AT_BROWSER_CLOSE: true DB_ENGINE: mysql DB_HOST: 10.0.0.51 DB_PORT: 3306 DB_USER: jumpserver DB_PASSWORD: linux0224 DB_NAME: jumpserver HTTP_BIND_HOST: 0.0.0.0 HTTP_LISTEN_PORT: 8080 WS_LISTEN_PORT: 8070 REDIS_HOST: 10.0.0.51 REDIS_PORT: 6379 REDIS_PASSWORD: linux0224 数据库迁移 1 2 3 4 5 6 7 8 9 10 11 12 通过python3命令，生成jumpserver的核心数据库，数据表内容，会写入到mysql 都是python开发的知识。。。运维会部署也得会。。 (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0/apps]#python3 ./manage.py makemigrations 此步骤，会写入mysql数据库的jumpserver 库中的数据表 发现生成了97张数据表 (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0/apps]#python3 ./manage.py migrate 有了数据之后，可以启动后端了 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 进入到jumpserver源码目录中，它提供好了启动脚本。 一键执行python的启动服务脚本，运行后端所有程序 并且是后台运行，不会占用你的窗口，xshell关了，也不会断开。 (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]# (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]#ls /opt/jumpserver-v2.12.0/jms /opt/jumpserver-v2.12.0/jms (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]# (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]# (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]#./jms start all -d 检查所有的组件，状态，确保有进程id号，才是对的。 (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]#./jms status gunicorn is running: 2977 flower is running: 2992 daphne is running: 3152 celery_ansible is running: 3347 celery_default is running: 3448 beat is running: 3587 确保这6个进程的pid，都存在，即正确。 以及，查看该进程的 端口，注意是端口。 (venv_py3) [root@master-61 /opt/jumpserver-v2.12.0]#netstat -tunlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:8070 0.0.0.0:* LISTEN 3152/python3 tcp 0 0 0.0.0.0:8080 0.0.0.0:* LISTEN 2977/python3 tcp 0 0 0.0.0.0:5555 0.0.0.0:* LISTEN 2992/python3 tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 958/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1127/master tcp6 0 0 :::5555 :::* LISTEN 2992/python3 tcp6 0 0 :::22 :::* LISTEN 958/sshd tcp6 0 0 ::1:25 :::* LISTEN 1127/master 直接告诉大家，后端core服务，运行的http端口是 8080 因此你可以试着访问试试。 首次访问，登录，修改密码 首次是可以访问，它会让你修改密码，下一次，人家代码中限制，你就没法直接访问后台了，。必须通过前端lina服务器，才能访问到后台。\n1 2 3 4 5 admin admin 首次修改密码为，lijin666 lina前端(可视化前端页面) 部署前端lina全流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 1. 下载前端源代码，下载源码，解压缩。 # 这里由于网络问题，我是去windows下载 mkdir -p /opt/lina-v2.12.0 wget -O /opt/lina-v2.12.0.tar.gz https://github.com/jumpserver/lina/archive/refs/tags/v2.12.0.tar.gz cd /opt/lina-v2.12.0 tar -xf lina-v2.12.0.tar.gz -C /opt/lina-v2.12.0 --strip-components 1 # 注意，源代码放入到指定的目录中 # 确保代码如下即可。 [root@master-61 /opt]#ls /opt/lina-v2.12.0 alias.config.js dump.rdb mock public utils babel.config.js jest.config.js nginx.conf README.md vue.config.js build jsconfig.json package.json src yarn.lock Dockerfile LICENSE postcss.config.js tests 2. 部署nodejs （学到现在，你已经部署了 php编程语言，python语言，nodejs前端开发的语言） # node.js和python，php一样，是一个编程语言，专门运行*.js程序的。 # 部署php后端是 2个步骤 一是下载*.php源码，安装php7解释器执行这个代码 # 部署 python后端 2个步骤 一是下载*.py，编译python3去执行代码 # 部署nodejs是因为，前端源代码是一堆*.js文件，需要用node.js解释器去运行 # 程序员大牛，必备技能ctrl +c ctrl +v mkdir -p /opt/node-v10.24.1 \u0026amp;\u0026amp; cd /opt/node-v10.24.1 \u0026amp;\u0026amp; wget https://nodejs.org/dist/v10.24.1/node-v10.24.1-linux-x64.tar.gz # 这里下载，解压缩的node.js解释器，是一个二进制的命令，无须安装了，配置PATH即可使用 tar -xf node-v10.24.1-linux-x64.tar.gz -C /opt/node-v10.24.1 --strip-components 1 tail -1 /etc/profile export PATH=$PATH:/opt/python369/bin/:/opt/node-v10.24.1/bin # 你最终，确保node.js的运行目录如下即可。 [root@master-61 /opt/node-v10.24.1/bin]#ls /opt/node-v10.24.1/bin node npm npx # 配置PATH，确保和我一样 [root@master-61 /opt/node-v10.24.1/bin]#tail -2 /etc/profile # 添加python3的PATH export PATH=$PATH:/opt/python369/bin:/opt/node-v10.24.1/bin [root@master-61 /opt/node-v10.24.1/bin]# [root@master-61 /opt/node-v10.24.1/bin]#node -v v10.24.1 [root@master-61 /opt/node-v10.24.1/bin]# [root@master-61 /opt/node-v10.24.1/bin]# [root@master-61 /opt/node-v10.24.1/bin]#npm -v 6.14.12 [root@master-61 /opt/node-v10.24.1/bin]## 确保node解释器可以用，以及npm命令可以用 [root@master-61 /opt/node-v10.24.1/bin]# [root@master-61 /opt/node-v10.24.1/bin]##npm 命令又是管理 node.js项目的依赖工具，装前端依赖模块的。。 到这里，前端的node.js开发环境，就已经部署好了 配置前端npm的下载加速源 1 2 3 4 执行如下命令即可 npm config set registry https://registry.npm.taobao.org npm config get registry 理解npm和node的关系（对比pip和python的关系） 安装前端源代码的依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 1.配置加速源 [root@master-61 /opt/lina-v2.12.0]# [root@master-61 /opt/lina-v2.12.0]#cd /opt/lina-v2.12.0/ 配置淘宝的下载加速源 [root@master-61 /opt/lina-v2.12.0]#npm config set registry https://registry.npm.taobao.org [root@master-61 /opt/lina-v2.12.0]#npm config get registry https://registry.npm.taobao.org/ # 2.进入源代码目录，执行命令，安装即可、 先安装yarn工具，为了安装前端vue的依赖，跟着操作就行，都是前端开发的知识。 公司里会有前端工程师，配合你，给你文档，你跟着操作就行。 [root@master-61 /opt/lina-v2.12.0]#npm install -g yarn # 3.通过如下命令，安装前端的依赖 [root@master-61 /opt/lina-v2.12.0]#yarn install # 4.你只需要确保，能理解这些步骤，是在部署前端代码，下载前端的项目依赖，确保命令正确执行就OK 只要别跟着笔记操作，一个命令8个报错就行。。。。 # 装前端依赖，装十次，得报错8次，没办法，和前端工程协同工作，报错直接发给他，让他看。 # 多玩几次，就熟练了， # 一般的错误，你作为一个高级运维，你还是得自己先看一看报错，试着解决， # 疑难杂症，得让前端配合你。。 # 生产环境下的部署，需要有前端、后端的接口、参数、调试配合，如果没有自动化的话，一天时间，能跑起来。 剩下的复杂的接口，其他程序，数据能调通，慢慢来了。。 最终，确保如下安装结果，才是对的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@master-61 /opt/lina-v2.12.0]# [root@master-61 /opt/lina-v2.12.0]#yarn install yarn install v1.22.19 [1/5] Validating package.json... [2/5] Resolving packages... [3/5] Fetching packages... [############################################-----------------------------------------------------------------[############################################-----------------------------------------------------------------[############################################-----------------------------------------------------------------[#############################################--------------------------------------------------------------- warning url-loader@1.1.2: Invalid bin field for \u0026#34;url-loader\u0026#34;. [#########################################################################-----------------------] 1284/1681 [4/5] Linking dependencies... warning \u0026#34; \u0026gt; less-loader@5.0.0\u0026#34; has unmet peer dependency \u0026#34;webpack@^2.0.0 || ^3.0.0 || ^4.0.0\u0026#34;. warning \u0026#34; \u0026gt; html-webpack-plugin@3.2.0\u0026#34; has unmet peer dependency \u0026#34;webpack@^1.0.0 || ^2.0.0 || ^3.0.0 || ^4.0.0\u0026#34;. warning \u0026#34; \u0026gt; compression-webpack-plugin@6.1.1\u0026#34; has unmet peer dependency \u0026#34;webpack@^4.0.0 || ^5.0.0\u0026#34;. warning \u0026#34; \u0026gt; sass-loader@7.3.1\u0026#34; has unmet peer dependency \u0026#34;webpack@^3.0.0 || ^4.0.0\u0026#34;. warning \u0026#34; \u0026gt; script-ext-html-webpack-plugin@2.1.3\u0026#34; has unmet peer dependency \u0026#34;webpack@^1.0.0 || ^2.0.0 || ^3.0.0 || ^4.0.0\u0026#34;. [5/5] Building fresh packages... success Saved lockfile. Done in 259.36s. 修改前端的js文件，设置一些运行参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 [root@master-61 /opt/lina-v2.12.0]#cat .env.development # 全局环境变量 请勿随意改动 ENV = \u0026#39;development\u0026#39; # base api VUE_APP_BASE_API = \u0026#39;\u0026#39; VUE_APP_PUBLIC_PATH = \u0026#39;/ui/\u0026#39; # vue-cli uses the VUE_CLI_BABEL_TRANSPILE_MODULES environment variable, # to control whether the babel-plugin-dynamic-import-node plugin is enabled. # It only does one thing by converting all import() to require(). # This configuration can significantly increase the speed of hot updates, # when you have a large number of pages. # Detail: https://github.com/vuejs/vue-cli/blob/dev/packages/@vue/babel-preset-app/index.js VUE_CLI_BABEL_TRANSPILE_MODULES = true # External auth VUE_APP_LOGIN_PATH = \u0026#39;/core/auth/login/\u0026#39; VUE_APP_LOGOUT_PATH = \u0026#39;/core/auth/logout/\u0026#39; # Dev server for core proxy VUE_APP_CORE_HOST = \u0026#39;http://localhost:8080\u0026#39; VUE_APP_ENV = \u0026#39;development\u0026#39; # 我们这里是测试，前端的lina项目和后端的core项目运行在同一台机器，因此 这里用 # 前端后端在一起的用法。 # 还记得，我们刚才去访问 core的堡垒机登录页面，确认后端端口是8080 所这里啥也没改。 运行lina前端项目 1 2 3 4 5 6 7 8 9 10 执行如下命令，让lina在后台运行即可。 [root@master-61 /opt/lina-v2.12.0]#nohup yarn serve \u0026amp; [root@master-61 /opt/lina-v2.12.0]## 确保如下端口存在，前端的lina进程就已经运行了，前端端口是 9528 [root@master-61 /opt/lina-v2.12.0]# [root@master-61 /opt/lina-v2.12.0]# [root@master-61 /opt/lina-v2.12.0]#netstat -tunlp|grep 9528 tcp 0 0 0.0.0.0:9528 0.0.0.0:* LISTEN 5385/node 测试访问前端 至此，你已经可以基于如下的通信请求，正确访问堡垒机了。\n但是，还缺少\nnginx做端口代理 其他基础组件。 测试访问，能确保正确看到堡垒机后台，就OK\n1 2 3 访问的地址入口是前端 http://10.0.0.61:9528/ 前端lina、后端core的架构图 1 2 3 4 5 6 目前完成的任务 1. db-51的 mysql，redis组件 2. master-61 core后台组件 lina前端组件 luna前端（网页版命令行） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 lina项目，是堡垒机的前端项目，咱们目前是运行了一个前端进程 10.0.0.61:9528 对的吧。 在生产环境下的部署，会有前端工程师配合你，将所有的前端的代码，编译 执行前端的 build命令，生成 纯静态文件。 得前端代码中，填写后端的接口地址（负载均衡的地址） 这个得你清晰部署流程。 还有一个luna组件，提供网页版命令行的，这个功能也是是基于 vue前端开发的页面 + 和后端进行数据交互，提供的网页版命令行。 web开发的知识。。大家不用过多琢磨。。 学会如何部署即可。。 1. 部署node环境，因为需要运行 luna的前端代码。 [root@master-61 /opt/lina-v2.12.0]# [root@master-61 /opt/lina-v2.12.0]#node -v v10.24.1 [root@master-61 /opt/lina-v2.12.0]# [root@master-61 /opt/lina-v2.12.0]#npm -v 6.14.12 2.下载luna的前端源代码 mkdir -p /opt/luna-v2.12.0 wget -O /opt/luna-v2.12.0.tar.gz https://github.com/jumpserver/luna/archive/refs/tags/v2.12.0.tar.gz tar -xf luna-v2.12.0.tar.gz -C /opt/luna-v2.12.0 --strip-components 1 最后确保如下代码一样即可。 [root@master-61 /opt]#ls /opt/luna-v2.12.0 angular.json Dockerfile e2e LICENSE nginx.conf package-lock.json proxy.conf.json src tslint.json deploy docs karma.conf.js mock.py package.json protractor.conf.js README.md tsconfig.json utils 3.安装luna项目的前端依赖，安装依赖的时候，发现缺少如下gcc工具，跟着操作，安装即可。踩坑之后的文档。 yum -y install gcc gcc-c++ 4. 安装前端的依赖，很棘手，很容易出现问题。 执行如下2条命令。 命令一，安装依赖，直接执行这个命令即可，会自动寻找目录下的 package.json文件，安装前端依赖信息 [root@master-61 /opt/luna-v2.12.0]#pwd /opt/luna-v2.12.0 [root@master-61 /opt/luna-v2.12.0]# [root@master-61 /opt/luna-v2.12.0]#npm install 老师的机器安装了如下1477个依赖包。 added 1477 packages from 1909 contributors in 244.312s 11 packages are looking for funding run `npm fund` for details 命令二： # 必须安装对应版本的 node-sass依赖，否则又是一堆报错。 # 这个命令是单独的，安装一个组件，限定了版本，这是我踩坑的解决办法，你跟着操作就行。 # 你根据这个教程，部署的是v2.12.0 luna源代码，因此这个前端项目，依赖的模块，有指定的版本。 # 如果是其他的luna源码版本你或许不需要装这个操作。。理解即可。。 SASS_BINARY_SITE=https://npm.taobao.org/mirrors/node-sass/ npm install node-sass@4.13.0 如果想加速下载，可以设置linux的全局http_proxy代理。走你的梯子即可。\nhttp,https的数据请求。\n搞个梯子，设置全局http代理，\n【机器请求 \u0026gt; 梯子】 \u0026gt; 发给目标机器\n称之为正向代理，还是反向代理？\n正向代理。\n修改luna 的配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 由于luna和 core服务部署在一台机器，因此这里的地址，不用用localhost 如果luna和core服务，分开在不同得机器，你得填写 core机器的ip 因此这里，啥也不写即可 [root@master-61 /opt/luna-v2.12.0]#cat proxy.conf.json { \u0026#34;/koko\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;http://localhost:5000\u0026#34;, \u0026#34;secure\u0026#34;: false, \u0026#34;ws\u0026#34;: true }, \u0026#34;/media/\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;http://localhost:8080\u0026#34;, \u0026#34;secure\u0026#34;: false, \u0026#34;changeOrigin\u0026#34;: true }, \u0026#34;/api/\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;http://localhost:8080\u0026#34;, \u0026#34;secure\u0026#34;: false, \u0026#34;changeOrigin\u0026#34;: true }, \u0026#34;/core\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;http://localhost:8080\u0026#34;, \u0026#34;secure\u0026#34;: false, \u0026#34;changeOrigin\u0026#34;: true }, \u0026#34;/static\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;http://localhost:8080\u0026#34;, \u0026#34;secure\u0026#34;: false, \u0026#34;changeOrigin\u0026#34;: true }, \u0026#34;/lion\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;http://localhost:9529\u0026#34;, \u0026#34;secure\u0026#34;: false, \u0026#34;pathRewrite\u0026#34;: { \u0026#34;^/lion/monitor\u0026#34;: \u0026#34;/monitor\u0026#34; }, \u0026#34;ws\u0026#34;: true, \u0026#34;changeOrigin\u0026#34;: true } } [root@master-61 /opt/luna-v2.12.0]# 启动luna 需要安装ng命令\n你要运行luna这个项目，需要安装ng命令，为了执行，ng server 运行luna进程 ，\n这是前端的命令工具。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # 安装ng命令，用于启动前端服务器，注意，必须是这个版本（再次吐槽，官网文档，就不能用心点写吗？一堆烂坑） # 安装这个ng命令，使用这条命令，添加--unsafe-perm参数，提权，让node的权限大一点 npm install -g @angular/cli@1.3.2 --unsafe-perm # 确保ng命令能装好,执行如下命令即可。 [root@master-61 /opt/luna-v2.12.0]#ng --version _ _ ____ _ ___ / \\ _ __ __ _ _ _| | __ _ _ __ / ___| | |_ _| / △ \\ | \u0026#39;_ \\ / _` | | | | |/ _` | \u0026#39;__| | | | | | | / ___ \\| | | | (_| | |_| | | (_| | | | |___| |___ | | /_/ \\_\\_| |_|\\__, |\\__,_|_|\\__,_|_| \\____|_____|___| |___/ Angular CLI: 7.3.9 Node: 10.24.1 OS: linux x64 Angular: 7.2.15 ... animations, common, compiler, compiler-cli, core, forms ... http, language-service, platform-browser ... platform-browser-dynamic, router Package Version ----------------------------------------------------------- @angular-devkit/architect 0.13.9 @angular-devkit/build-angular 0.13.9 @angular-devkit/build-optimizer 0.13.9 @angular-devkit/build-webpack 0.13.9 @angular-devkit/core 7.3.9 (cli-only) @angular-devkit/schematics 7.3.9 (cli-only) @angular/cdk 7.3.7 @angular/cli 7.3.9 @angular/flex-layout 7.0.0-beta.24 @angular/material 7.3.7 @ngtools/webpack 7.3.9 @schematics/angular 7.3.9 @schematics/update 0.13.9 rxjs 6.3.3 typescript 3.2.4 webpack 4.29.0 # 后台运行命令如下，必须运行在0.0.0.0地址上，否则不通。 # 必须执行这个命令。 # 当前是没有luna的端口的 [root@master-61 /opt/luna-v2.12.0]#netstat -tunlp|grep 4200 # 执行命令，运行luna进程 [root@master-61 /opt/luna-v2.12.0]#nohup ng serve --proxy-config proxy.conf.json --host 0.0.0.0 \u0026amp; # 检查端口 [root@master-61 /opt/luna-v2.12.0]#netstat -tunlp|grep 4200 tcp 0 0 0.0.0.0:4200 0.0.0.0:* LISTEN 7244/@angular/cli # 至此，luna就OK了，可以访问网页版linux命令行了。 测试访问luna 由于这个luna版本，有点问题，v2.12.0，总是需要前端工程师配合，才能精确的调通。\n这里的部署，有点bug，需要指定luna的端口才可以访问到 网页版命令行。\n以及luna需要去连接koko服务，才能实现远程网页，执行linux命令。\n你先确保可以看到luna的页面。\nkoko后端（命令行版堡垒机） 早期的命令行堡垒机，是基于coco服务，是飞致云公司，基于python开发的工具。\n1 部署python的环境，运行coco代码。 后来代码升级，基于golang重构了，换为了koko。\n1 需要提供golang的开发环境，才能运行koko Koko 是 Go 版本的 coco，重构了 coco 的 SSH/SFTP 服务和 Web Terminal 服务。\nKoko组件用于基于ssh的跳板机登录，统一管理。\n1 jumpserver是一个 跳板机（koko）的升级版，添加了很多4A功能，完成了整个的堡垒机产品。 部署koko 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 1. 下载koko代码，由于是基于golang开发，可以直接打包二进制，你无须安装了，下载即用。 mkdir /opt/koko-v2.12.0 cd /opt ; wget https://github.com/jumpserver/koko/releases/download/v2.12.0/koko-v2.12.0-linux-amd64.tar.gz tar -xf koko-v2.12.0-linux-amd64.tar.gz -C /opt/koko-v2.12.0 --strip-components 1 2. 确保如下目录存在即可 [root@master-61 /opt]#ls /opt/koko-v2.12.0 config_example.yml init-kubectl.sh koko kubectl locale static templates 3.配置golang的环境，也是下载即可，然后配置环境变量就可以用了 直接下载二进制版本 wget https://golang.google.cn/dl/go1.15.linux-amd64.tar.gz tar -xf go1.15.linux-amd64.tar.gz 添加path [root@master-61 /opt/go/bin]#tail -2 /etc/profile # 添加python3的PATH export PATH=$PATH:/opt/python369/bin:/opt/node-v10.24.1/bin:/opt/go/bin 确认版本 [root@master-61 /opt/go/bin]#source /etc/profile [root@master-61 /opt/go/bin]# [root@master-61 /opt/go/bin]# [root@master-61 /opt/go/bin]#go version go version go1.15 linux/amd64 至此golang开发环境，go编译器已经装好 启动koko 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 1.先修改配置文件 [root@master-61 /opt/koko-v2.12.0]#cp config_example.yml config.yml [root@master-61 /opt/koko-v2.12.0]# [root@master-61 /opt/koko-v2.12.0]# [root@master-61 /opt/koko-v2.12.0]#ls config_example.yml config.yml init-kubectl.sh koko kubectl locale static templates 2. 修改如下即可 CORE_HOST: http://127.0.0.1:8080 # Core 的地址 # 第一次运行的时候，koko会用这个值，注册当前机器的信息到jumpserver中，证明这个机器是当做了跳板机，安全验证 # 第二次运行，这个参数就给删除即可，否则会反复注册，如果说你运行koko出了问题，找老师，你估计解决不了。 BOOTSTRAP_TOKEN: \u0026#34;$BOOTSTRAP_TOKEN\u0026#34; BIND_HOST: 0.0.0.0 # koko服务绑定运行在0.0.0.0上，表示可以基于10.0.0.61访问 # 表示你可以基于ssh 协议，连接koko， 用法是 ssh root@10.0.0.61 -p 2222 # 连接22端口是 sshd进程， 连接2222是koko进程 SSHD_PORT: 2222 # 使用 0.0.0.0:2222, HTTPD_PORT: 5000 # 使用 0.0.0.0:5000 LOG_LEVEL: DEBUG # 开发建议设置 DEBUG, 生产环境推荐使用 ERROR 3.具体配置如下，和我一样即可 [root@master-61 /opt/koko-v2.12.0]#cat config.yml CORE_HOST: http://127.0.0.1:8080 BOOTSTRAP_TOKEN: \u0026#34;$BOOTSTRAP_TOKEN\u0026#34; BIND_HOST: 0.0.0.0 SSHD_PORT: 2222 HTTPD_PORT: 5000 LOG_LEVEL: DEBUG 4.运行koko服务，首次会注册到堡垒机中，以及确保2222，和5000端口都运行了，koko才是正常运行。 [root@master-61 /opt/koko-v2.12.0]#ls config_example.yml config.yml init-kubectl.sh koko kubectl locale static templates [root@master-61 /opt/koko-v2.12.0]# [root@master-61 /opt/koko-v2.12.0]# [root@master-61 /opt/koko-v2.12.0]#./koko -f config.yml -d 5.验证koko的运行 [root@master-61 /opt/koko-v2.12.0]#netstat -tunlp|grep -E \u0026#39;(5000|2222)\u0026#39; tcp6 0 0 :::5000 :::* LISTEN 7613/./koko tcp6 0 0 :::2222 :::* LISTEN 7613/./koko 6.至此，koko已经运行成功了 此时你可以试试，跳板机的实际用法了，1.访问luna的网页命令行 由于还没在堡垒机中，添加你的服务器资产数据，所以说看不到服务器列表，下节课，添加资产列表就可以管理你的机器了。\n为了验证luna和koko结合，点击文件管理功能即可。\n以及试试，基于ssh协议连接koko 确保如下操作，正常即可，说明你的koko，跳板机以及可以使用，使用的是jumpserver的用户信息\n1 2 3 账户 admin 密码lijin666 ssh admin@10.0.0.61 -p 2222 说明你的koko，命令行，跳板机已经可以用了。\n部署lion（提供vnc远程桌面功能） 体验下，阿里云服务器的两种登录方式。\n无法基于ssh连接的话，基于vnc连接去解决机器的故障。\n下一步，部署jumpserver也提供给你的lion服务\n先装一个工具叫做 guacamole，远程桌面依赖的一个前端框架 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 mkdir /opt/guacamole-v2.12.0 cd /opt/guacamole-v2.12.0 wget http://download.jumpserver.org/public/guacamole-server-1.3.0.tar.gz tar -xzf guacamole-server-1.3.0.tar.gz cd guacamole-server-1.3.0/ 注意，需要安装centos的依赖环境，才可以使用这个VNC远程桌面协议。 # 踩坑了 yum -y install cairo-devel libjpeg-devel libpng-devel uuid-devel # 粘贴如下代码即可 ./configure --with-init-dir=/etc/init.d make \u0026amp;\u0026amp; make install # 让你的linux，更新底层的驱动，加载远程桌面 guacamole协议 ldconfig 安装lion程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 cd /opt wget https://github.com/jumpserver/lion-release/releases/download/v2.12.0/lion-v2.12.0-linux-amd64.tar.gz tar -xf lion-v2.12.0-linux-amd64.tar.gz cd lion-v2.12.0-linux-amd64 最终看到如下数据即可 [root@master-61 /opt]#tar -xf lion-v2.12.0-linux-amd64_\\(1\\).tar.gz [root@master-61 /opt]# [root@master-61 /opt]# [root@master-61 /opt]#cd lion-v2.12.0-linux-amd64/ [root@master-61 /opt/lion-v2.12.0-linux-amd64]# [root@master-61 /opt/lion-v2.12.0-linux-amd64]# [root@master-61 /opt/lion-v2.12.0-linux-amd64]#ls config_example.yml lion ui 拷贝配置文件 [root@master-61 /opt/lion-v2.12.0-linux-amd64]#cp config_example.yml config.yml 修改配置文件，参考如下写法 # 项目名称, 会用来向Jumpserver注册, 识别而已, 不能重复 # NAME: # Jumpserver项目的url, api请求注册会使用 CORE_HOST: http://127.0.0.1:8080 # Core 的地址 # Bootstrap Token, 预共享秘钥, 用来注册使用的service account和terminal # 请和jumpserver 配置文件中保持一致，注册完成后可以删除 BOOTSTRAP_TOKEN: \u0026#34;$BOOTSTRAP_TOKEN\u0026#34; # 启动时绑定的ip, 默认 0.0.0.0 BIND_HOST: 0.0.0.0 # 监听的HTTP/WS端口号，默认8081 HTTPD_PORT: 8081 # 设置日志级别 [DEBUG, INFO, WARN, ERROR, FATAL, CRITICAL] LOG_LEVEL: DEBUG # 开发建议设置 DEBUG, 生产环境推荐使用 ERROR # Guacamole Server ip， 默认127.0.0.1 # GUA_HOST: 127.0.0.1 # Guacamole Server 端口号，默认4822 # GUA_PORT: 4822 # 会话共享使用的类型 [local, redis], 默认local # SHARE_ROOM_TYPE: local # Redis配置 # REDIS_HOST: 127.0.0.1 # REDIS_PORT: 6379 # REDIS_PASSWORD: # REDIS_DB_ROOM: 启动guacd程序 都是官网提供的教程，学会操作，确保操作正确即可。\n1 2 3 4 5 /etc/init.d/guacd start [root@master-61 /opt/lion-v2.12.0-linux-amd64]#/etc/init.d/guacd start Starting guacd: guacd[13422]: INFO:\tGuacamole proxy daemon (guacd) version 1.3.0 started SUCCESS 启动lion进程 1 2 [root@master-61 /opt/lion-v2.12.0-linux-amd64]#nohup ./lion -f config.yml \u0026amp; [3] 13435 部署nginx（整合所有组件，提供统一的七层反向代理） 部署nginx的配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 1. 确保nginx安装，在大于 1.18版本即可 [nginx-stable] name=nginx stable repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=1 enabled=1 gpgkey=https://nginx.org/keys/nginx_signing.key 2. 安装nginx yum install nginx -y 3. 配置nginx虚拟主机文件，实现整合所有jumpserver的组件，统一访问入口，如 jumpserver.linux0224.cc 默认80端口即可。 4.具体配置文件如下 [root@master-61 /etc/yum.repos.d]#cd /etc/nginx/conf.d/ [root@master-61 /etc/nginx/conf.d]#ls default.conf [root@master-61 /etc/nginx/conf.d]# [root@master-61 /etc/nginx/conf.d]# [root@master-61 /etc/nginx/conf.d]#rm -f default.conf [root@master-61 /etc/nginx/conf.d]# server { listen 80; # 不做域名解析，基于ip:port直接访问 # server_name www.lijinit.cn; client_max_body_size 5000m; # Luna 配置 # 经过实测，这个v12版本，只能http://10.0.0.61:4200/luna/这样去访问，前端这里有点难处理。 location /luna/ { proxy_pass http://luna:4200; } # Core data 静态资源 location /media/replay/ { add_header Content-Encoding gzip; root /opt/jumpserver-v2.12.0/data/; } location /media/ { root /opt/jumpserver-v2.12.0/data/; } location /static/ { root /opt/jumpserver-v2.12.0/data/; } # KoKo Lion 配置 location /koko/ { proxy_pass http://koko:5000; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_buffering off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; } # lion 配置 location /lion/ { proxy_pass http://lion:8081; proxy_buffering off; proxy_request_buffering off; proxy_http_version 1.1; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; proxy_ignore_client_abort on; proxy_connect_timeout 600; proxy_send_timeout 600; proxy_read_timeout 600; send_timeout 6000; } # Core 配置 location /ws/ { proxy_pass http://core:8070; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_buffering off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; } location /api/ { proxy_pass http://core:8080; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location /core/ { proxy_pass http://core:8080; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # 前端 Lina location /ui/ { proxy_pass http://lina:9528; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location / { rewrite ^/(.*)$ /ui/$1 last; } } 图解nginx配置 注意，配置文件中用的都是测试域名，你要在master-61上做好hosts解析 最后，启动nginx，访问入口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [root@master-61 /etc/nginx/conf.d]# [root@master-61 /etc/nginx/conf.d]#nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful [root@master-61 /etc/nginx/conf.d]# [root@master-61 /etc/nginx/conf.d]#nginx [root@master-61 /etc/nginx/conf.d]# [root@master-61 /etc/nginx/conf.d]# [root@master-61 /etc/nginx/conf.d]#ps -ef|grep nginx root 13675 1 0 19:01 ? 00:00:00 nginx: master process nginx nginx 13676 13675 0 19:01 ? 00:00:00 nginx: worker process nginx 13677 13675 0 19:01 ? 00:00:00 nginx: worker process nginx 13678 13675 0 19:01 ? 00:00:00 nginx: worker process nginx 13679 13675 0 19:01 ? 00:00:00 nginx: worker process root 13681 1333 0 19:01 pts/0 00:00:00 grep --color=auto nginx [root@master-61 /etc/nginx/conf.d]# [root@master-61 /etc/nginx/conf.d]# 注意，客户端，windows也做好域名解析 1 不用域名解析了。 最终访问，访问堡垒机官网 这里，不能用域名去测试了，用ip去访问即可，所有的后端进程，它还不认识你这个域名。\n1 2 3 访问入口是 http://10.0.0.61:80 确保可以正确登录，整个实验就没问题了。 堡垒机大盘页面 个人信息页面 总之，你在页面上，确保点点点，各种链接，访问都是正常的 你的这个堡垒机才是正确的部署完毕。\n以最终看到，个人页面为结束 ","date":"2025-04-14T16:58:32+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/%E9%83%A8%E7%BD%B2python%E7%BD%91%E7%AB%99/","title":"部署python网站"},{"content":"项目部署实战 单体项目架构 服务架构 代码架构 常见技术名词，和他所属的服务器关系。\n‍\n项目简介 技术选型 开发环境 后端\n1 2 3 4 5 6 7 8 9 10 11 12 1、系统环境 Java EE 8 Servlet 3.0 Apache Maven 3 2、主框架 Spring Boot 2.2.x Spring Framework 5.2.x Apache Shiro 1.7 3、持久层 Apache MyBatis 3.5.x Hibernate Validation 6.0.x Alibaba Druid 1.2.x 前端\n1 2 3 Vue 2.6.x Axios 0.21.x Element 2.15.x 部署环境 JDK（JVM） \u0026gt;= 1.8\nMySQL \u0026gt;= 5.7\nMaven（java项目源代码编译） \u0026gt;= 3.0\n打包：war​、​jar​​\n如果未打包：mvn clean package​→ war | jar\nNode（类nginx） \u0026gt;= 12\n打包：​dist​​ 未打包：npm install​ \u0026amp;​ npm run build​ Redis \u0026gt;= 3\n资源 ruoyi.zip\n项目部署思路 安装环境 部署实战 项目打包 前端\n前端程序员负责。\n后端\n后端程序员负责。\n部署 上传资源包 规划项目目录\n1 2 /opt/app/web # 前端 /opt/app/java # 后端 数据库 安装MySQL、Redis。\n查看数据库相关配置\n数据库database名字 密码 java项目：application-xxx.yml​、xxxx.properties​\n创建database\nmysql -uroot -padmins -e \u0026quot;create database ry_vue;\u0026quot;​\n初始化sql文件\n1 2 mysql -uroot -padmins ry_vue \u0026lt; ./db/ry_20240629.sql mysql -uroot -padmins ry_vue \u0026lt; ./db/quartz.sql 应用程序Java 安装JDK\n安装Tomcat(略)\nMySQL配置\n1 2 3 url: jdbc:mysql://192.168.32.30:3306/ry_vue?useUnicode=true\u0026amp;characterEncoding=utf8\u0026amp;zeroDateTimeBehavior=convertToNull\u0026amp;useSSL=true\u0026amp;serverTimezone=GMT%2B8 username: root password: admins Redis配置\n1 2 3 4 5 6 7 8 9 10 11 12 # redis 配置 redis: # 地址 host: 192.168.32.30 # 端口，默认为6379 port: 6379 # 数据库索引 database: 0 # 密码 password: # 连接超时时间 timeout: 10s 设置文件上传路径\n1 profile: /home/ruoyi/uploadPath 启动项目\njava -jar xxx.jar --spring.config.location=/xx/xx/xx.yml​\n1 java -jar ruoyi-admin.jar --spring.config.location=./java_config/application.yml 前端 安装nginx\n准备web项目资源\n配置nginx.config\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 server { listen 80; server_name www.mall.vip; # 主机地址，或者域名。 charset utf-8; # access_log 访问日志 access_log /var/log/nginx/mall_access.log main; # error_log 错误日志 error_log /var/log/nginx/mall_error.log warn; location / { root /opt/app/web/dist/; # 网站资源根目录 index /index.html; try_files $uri $uri/ /index.html; # 如果找不到网页，则选择/index.html显示 } location /prod-api/ { proxy_set_header Host $http_host; # 将http_host主机域名www.crm.vip 写入Host请求，避免nginx的host覆盖 proxy_set_header X-Real-IP $remote_addr; # 将$remote_addr客户端真实ip，写入x-real-ip真实ip，再请求后端，防止nginx的ip地址覆盖 proxy_pass http://192.168.199.20:8080/; # 将/prod-api请求路径，转发给后台java的服务器地址。 } } 启动加载配置文件\n访问\n在访问主机配置域名hosts\nnginxip www.ruoyi.vip​\n访问\nhttp://www.ruoyi.vip​\n默认超管用户名密码\n用户：admin\n密码：admin123\n后端项目规范 自测试启动\n1 java -jar ruoyi-admin.jar --spring.config.location=./java_config/application.yml 内部测试\n1 2 3 4 java -jar ruoyi-admin.jar --spring.config.location=./java_config/application.yml \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 # /dev/null 是一个输出黑洞，类似垃圾桶，写入不需要输出的东西 # 2\u0026gt;\u0026amp;1 将错误输出，重定向到控制台输出，这样错误也会写入/dev/null 正式启动记录日志\nnohup​：以守护进程方式启动，脱离当前shell，关闭shell，也不会挂断该命令的程序。 \u0026amp;​ ：后台启动，不在前台输出日志。 1 2 3 4 # 创建日志目录 mkdir /var/log #如果有就不用创建 # 启动 nohup java -jar ruoyi-admin.jar --spring.config.location=./java_config/application.yml \u0026gt; /var/log/ruoyi-admin.log 2\u0026gt;\u0026amp;1 \u0026amp; ‍运维工作内容 工作职责 项目部署：将代码，部署服务器上，供测试，供预发布(灰度发布)，正式上线。\nLinux系统运维：磁盘管理、网络管理监控、防火墙管理、系统进程监控管理\n监控告警：监控项目状态，如果有问题，告警，预警。\n系统资源监控、服务状态监控、故障监控。\n数据备份：\nmysql数据*.ibd文件,库表数据：mysqldump，xbk。 Redis持久化数据：备份。 日志文件： 代码： 配置文件 日志分析：\nnginx日志分析：危险IP，分析DDOS，nginx访问压力，页面路径的访问压力分析。 mysql的lowlog：sql调优，优化mysql配置。 xxxx所有服务程序：日志都需要分析。 代码日志：分析程序的执行日志，找出bug异常，转开发人员。 系统优化：\nLinux系统优化：swap设置 网络优化 服务器组件：Redis、MySQL。 自动化\n自动化工具Ansible+Shell+Python+Zabbix+Kubernets\n‍\n工作日常 作为工作经历/实习经历，工作内容。\n一、公司内部维护 对SVN、git(代码的，代码地址)每日备份，编写shell自动定期对SVN的账号进行密码更新，并且发送邮件通知。开发数据库和测试数据库的每日按库表备份。 使用markdown(Typora)，建立小型的wiki(知识库)，编写公司内部的信息文档，避免重复、无用、过期的信息交换。 测试环境编写Dockerfile，进行构建Docker镜像，用于测试代码的发布，避免环境混乱，易于管理。 建立公司内部连接客户服务器的VPN通道，方便故障时调试处理。(远程操作，外部访问公司内部服务器)(花生壳,内网穿透,todesk) 编写脚本监控预发布环境与生产环境的数据库结构差异，避免发布的代码缺少字段或表。 编写Dockercompose，提供环境给实施部门培训测试。 二、云端服务器的维护 使用zabbix监控云端服务器与mysql数据库，到阈值时进行钉钉通知。 提供云端全部项目的日志展示，方便研发与值班人员查到定位问题。（ELK） 编写了shell脚本，监控进程或者API，进行故障时的重启拉起。 部署了haproxy+nginx的负载均衡，对大流量项目访问进行分发负载。 部署了redis 3+3集群，提供缓存负载。 建立mysql多源同步，使用mysql proxy与mycat（不同的项目）进行读写分离。 建立rsync服务器，定时在服务器之间进行数据的互相备份，并且最终汇总到一台备用服务器上，统一拉回公司服务器上进行归档。 编写shell采集全部客户服务器信息，包含：CPU、内存、硬盘、nginx、php、redis、部署的服务等。超过阈值则进行短信、邮件与钉钉通知。 编写shell脚本监控云端的mysql多源同步情况，故障时进行邮件与钉钉通知。 监控云端服务器到期时间，进行监控通知。 三、客户侧的维护 进行编写脚本，自动进行一些工作：\n自动更新本地的维护脚本、自动定期修改密码、自动更新软件包与配置、自动更新mysql配置、自动刷新文件权限、rsync配置更新 通过shell脚本监控本地程序进程与API的保活：包含Mysql（包含同步监控）、redis、nginx、OpenVpn、php-fpm、Rsync、Tomcat等等。故障非忙时自动重启，并且进行钉钉与邮件通知。 每日的日志切割，归档：mysql的gerenalLog、nginx日志、tomcat日志。 客户侧监控，包含：shell脚本监控（生成信息由云端的shell脚本进行采集，进行钉钉、短信、邮件的通知）、atop（主要记录进程的变化，日志保留7天）、prometheus（node_exporter）、硬盘坏道检查定期检查（结果进行钉钉通知）、自定义的node_exporter 定期备份数据库，并且加密压缩包，密码由云端的脚本提供，每日随机生成。定期自动修复数据库中的信息变化，比如本地IP发送变化，apikey发送了变化。 有主从服务器的环境，进行互相的数据备份，包含用户文件、日志、数据库备份等。并且每日自动同步云端服务器上，最小化避免客户服务器故障时数据丢失。 建立keepalived，主服务器故障时，IP偏移至备用服务器。 一套日志服务，可通过公司内部的DNS，进行访问客户服务器查看日志。（web日志系统，账号管理，公网）。 所有的shell与python脚本，执行的内容都会进行日志保存，可追溯之前执行脚本的情况。 技能列表 在简历中体现你的技能模块。\n格式 技能列表\n熟悉（熟练掌握）xxxx技术，AAAA、BBBB、技术点、技术亮点、技术难点、面试重点。 掌握xxxx 了解xxx 熟悉linux系统，文件管理机制、磁盘和逻辑卷、网络管理、firewalld防火墙、系统服务进程管理、系统权限、软件管理rpm、tar、yum，病毒程序的防护和处理，定时任务crontab。 vscode windows idea notepad++ 注意 简历技能列表，就是你给面试官画的面试范围。 不要在语言中兑水：虚词。 技术名词不要写错，注意大小写。 如果技术内容太多，合并，删除不太重要技术。 写自己会的，不会不要写，可以写了解。 总结 掌握Linux操作系统：文件管理机制、磁盘和逻辑卷、网络管理、firewalld防火墙、系统服务进程管理、系统权限、Linux软件管理rpm、tar、yum，病毒程序的防护和处理，定时任务crontab。 掌握MySQL数据库：MySQL架构组成、存储引擎、ibd文件系统底层、B+索引和存储机制、慢查询和SQL调优、MySQL优化配置、逻辑备份mdp、物理备份xbk、5大日志系统、optimize磁盘优化、库表设计。 **数据库架构设计：**​高可用Altas，主从复制，读写分离Mycat。 掌握Shell编程：系统资源监控、nginx日志分析、监控告警、MySQL数据备份脚本，正则表达式、文本分析命令 awk、sed、egrep、xargs。 掌握服务器运维工具：nfs文件共享，rsync文件同步，logrotate日志轮转。 掌握服务器部署：Nginx服务器组成，location匹配规则，反向代理，日志系统。Tomcat和JDK部署配置，前后端分离项目部署。 掌握NoSQL数据库： Redis内存机制，常用数据类型，压测和监控，持久化机制AOF、RDB和混合模式，AOF重写。 项目经验 项目名\n写法1: 项目是什么xxxx，供xxxx使用，包含xxx功能。 写法2：为了保证项目测试，进行项目部署，以及数据备份和日志系，确保系统的稳定运行，监控系统运行状态，通过优化提高系统并发能力和性能。 个人职责\n规范：使用了xxxx技术，解决了xxx问题 参数项目的技术研讨会，并负责项目库表设计，和MySQL优化和初始化配置。 对项目部署环境进行初始化配置，磁盘分区和逻辑卷设置，防火墙设置，保证项目运行环境稳定和安全。 负责项目的完整部署，包含nginx、springjar、redis、MySQL，提供测试环境和预发布的项目部署 使用xbk物理备份和定时任务，对MySQL数据做每日数据备份。 编写shell脚本，对项目的访问日志，做分析PV、UV。 使用logrotate对nginx、javajar、mysql的日志，做按日轮转切割。并做NFS的异地同步和归档。 ‍\n","date":"2025-04-14T16:56:07+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/nginx%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2/","title":"Nginx前后端分类项目部署"},{"content":"基于ip地址的访问限制 官网：Module ngx_http_access_module (nginx.org)\n1 2 3 4 5 6 7 8 9 句法: allow address | CRID | unix:| all 默认： - 语境: http,server,location,limit_except 允许访问指定的网络或地址,如果指定了特殊值unix:(1.5.1),则允许访问所有unix域套接字 句法:deny address | CRID | unix:| all 默认： - 语境: http,server,location,limit_except 拒绝访问指定的网络或地址,如果指定了特殊值unix:(1.5.1),则拒绝访问所有unix域套接字 1 2 3 allow和的放置顺序: allow xxxxx; deny xxxx; 第一题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 第一题 限制只允许10.0.0.0~10.0.0.255范围的IP访问（禁止其他网段的访问） 创建虚拟主机，完成该功能 [root@web-8 /etc/nginx/conf.d]#cat deny-allow.conf server { listen 22334; server_name _; location / { allow 10.0.0.0/24; deny all; root /www/deny-allow; index index.html; } } 创建测试数据，查看访问情况 [root@web-8 /etc/nginx/conf.d]#mkdir -p /www/deny-allow [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#echo \u0026#39;I am web-8 , test deny and allow !!!!!!!!\u0026#39; \u0026gt; /www/deny-allow/index.html [root@web-8 /etc/nginx/conf.d]#systemctl restart nginx [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#netstat -tunlp|grep 22334 tcp 0 0 0.0.0.0:22334 0.0.0.0:* LISTEN 7402/nginx: master 1. 用win去访问，可以吗？ 可以的 http://10.0.0.8:22334/ 2. 用61机器去访问， # 网卡的流量，网段是对应起来的 eth0 10.0.0.61 eth1 172.16.1.61 curl 10.0.0.8:22334 # 从61机器的10.0.0.61发出 curl 172.16.1.8:22334\t# 从61机器的172.16.1.61发出 提示\n1 只写一个allow的话，等于没有任何意义，必须做好deny限制，才有实际意义。 第二题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 - 限制只允许172.16.1.0 ~ 172.16.1.255 范围的IP访问，禁止其他任意的地址访问。 [root@web-8 /etc/nginx/conf.d]#cat deny-allow.conf server { listen 22334; server_name _; location / { #allow 10.0.0.0/24; allow 172.16.1.0/24; deny all; # 拒绝客户端访问该网页根目录下的资源，返回403权限不足 root /www/deny-allow; index index.html; } } 你发现，处于同一个内网环境下的 ，有172网段的机器是通的， 第三题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 - 限制只允许windows访问（禁止其他机器访问，比如任意的 10.0.0.61 任意的172.16.1.52） [root@web-8 /etc/nginx/conf.d]#cat deny-allow.conf server { listen 22334; server_name _; location / { # allow 10.0.0.0/24; # allow 172.16.1.0/24; allow 10.0.0.1; deny all; # 拒绝客户端访问该网页根目录下的资源，返回403权限不足 root /www/deny-allow; index index.html; } } # 待会试试，用不同网段的客户端ip，访问，查看权限 # 测试几个客户端 10.0.0.1 通 ，只有这一个ip地址是通的. 10.0.0.61 不通 172.16.1.52 不通 第四题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 - 限制拒绝10.0.0.0~10.0.0.255范围的IP访问（得允许其他网段访问） (这个ip限制规则，自上而下的匹配，匹配到规则后，就不会继续向后匹配了) 此时只能通过内网的172网卡去访问这个机器了 # 配置如下 [root@web-8 /etc/nginx/conf.d]#cat deny-allow.conf server { listen 22334; server_name _; location / { deny 10.0.0.0/24; root /www/deny-allow; index index.html; } } # 通过如下这几个客户端试试，先用10网段的试试 发现10网段全部被拒绝 发现172网段是允许被访问的 第五题 基于ip，判断出目标机器是windows吗？\n通过目标机器的user-agent去判断，判断的浏览器客户端，是windows等情况，拒绝\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 限制只拒绝windows访问。其他人都允许访问 [root@web-8 /etc/nginx/conf.d]#cat deny-allow.conf server { listen 22334; server_name _; location / { deny 10.0.0.1; root /www/deny-allow; index index.html; } } 10.0.0.1 只有它不能访问 测试 1 2 3 4 5 window访问 172.16.1.8:22334 windows(vmnet8 10.0.0.1，) 172网段（vmware提供的LAN网段，纯局域网，） 基于用户认证的访问限制 有时候，我们一些站点内容想要进行授权查看，只能输入账号密码之后才能访问，例如一些重要的内网平台，CRM,CMDB,企业内部WIK等等。\n语法 https://nginx.org/en/docs/http/ngx_http_auth_basic_module.html\n1 2 3 4 5 6 7 8 9 10 11 12 句法：auth_basie string I off; 默认 auth_basie 关闭; 语境：http,server,location,1imit_except 启用使用“HTTP基本身份验证”协议验证用户名和密码。 指定的参数用作realm.多数值可以包含变量(1.3.10,1.2.7)。 特殊值off取消了auth_basic从先前配置级别继承的指令的效果。 句法：auth_basic_user_file file; 默认： - 语境：http,server,location,limit_except 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 给虚拟主机，加上密码验证 1. 创建密码，密码不是一个简单的纯文本文件，得基于密码数据库的存储 有工具帮你完成htpasswd这个工具去创建密码文件 yum -y install httpd-tools 创建密码文件 # -b 免交互，输入账号密码即可 # -c 设置密码写入到什么文件 htpasswd -b -c /etc/nginx/auth_passwd lijin01 lijin666 [root@web-8 /etc/nginx/conf.d]#cat /etc/nginx/auth_passwd lijin01:$apr1$.D27Ssim$P9KebeNNrgXWUIbo1fZs40 2. 让nginx 的虚拟主机，支持该功能，并且由于是内网文档，让他只在内网下可访问 [root@web-8 /etc/nginx/conf.d]#nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#cat auth_basic.conf server { listen 172.16.1.8:33334; charset utf-8; server_name _; location / { auth_basic \u0026#34;please input your account password\u0026#34;; auth_basic_user_file /etc/nginx/auth_passwd; root /www/auth-html; index index.html; } } 3.创建测试数据 [root@web-8 ~]#mkdir -p /www/auth-html [root@web-8 ~]# [root@web-8 ~]#echo \u0026#39;我是用于验证账户密码的，你不输入密码，别想看到我！！！\u0026#39; \u0026gt; /www/auth-html/index.html 4.启动测试访问 用win去测试 10.0.0.8:33334 ，这一次都不是权限之类的问题，而是tcp/ip都没有建立。直接提示网络连接失败 这里由于我们是学习环境，linux虚拟机的网段，都是vmware提供的纯局域网 在企业里，也会有内网环境，但是有网工给你配置好了所有的环境 你的办公电脑，会有该内网的ip，可以访问到该内网下的资料（需要进行一系列的网络转发设置） 只能在内网环境下，去访问了 172，只能是linux下的访问 # 咱们临时测试，还是先用windows去访问该站点 # 理解了nginx虚拟主机，绑定网段即可， # 还是改为，允许让windows也可以访问，修改监听的地址，放置到10网段 [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#netstat -tunlp|grep 33334 tcp 0 0 10.0.0.8:33334 0.0.0.0:* LISTEN 7765/nginx: master [root@web-8 /etc/nginx/conf.d]#cat auth_basic.conf server { #listen 172.16.1.8:33334; listen 10.0.0.8:33334; charset utf-8; server_name _; location / { auth_basic \u0026#34;please input your account password\u0026#34;; auth_basic_user_file /etc/nginx/auth_passwd; root /www/auth-html; index index.html; } } [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#netstat -tunlp|grep 33334 tcp 0 0 10.0.0.8:33334 0.0.0.0:* LISTEN 7765/nginx: master # 此时你就可以基于10网段去访问了 基于ie浏览器可以看到你的提示信息，看不到也无所谓\nnginx限流模块 1.知道用法即可，生产下的限流，更多的是后端框架中限制，nginx这里一般不做，可能导致请求出错。知道用法，以后看到企业里在用，会维护即可。\n2.以及理解限流的概念。\n1 2 3 4 5 6 7 8 9 10 11 12 计算机程序，会给网站带来极大的恶意流量，导致服务器压力多大，以及网站所有的负载都会很大 例如： www.taobao.com 服务端 nginx 解析这用户的请求 tcp/ip连接 大量的客户端，大量的ip，去访问服务器，导致服务器建立的大量的tcp连接 (这些大量的ip都是恶意ip，肉鸡一类的机器，而非正常用户的ip) 默认情况下，服务器可建立的连接时65535个tcp连接 具体nginx限流的配置 1 针对客户端ip判断的，以及针对请求访问速率的限制模块 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1.定义一个限述规则 定义限速区域，保持在10字节的区域one。该区域的平均处理请求每秒不能超过1个。 $binary_remote_addr变量的大小始终为4个字节，在64位机器上始终占用64字节 limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; limit_req_zone $binary_remote_addr zone=two:10m rate=1r/s; 参数解释 limit_req_zone 常用限速模块 binary_remote_addr 判定条件，远程的客户端Ip zone 定义限道区域名称，内存大小· rate 限速规则，1秒只能1个请求 2.引用限速规则 limit_reg zone=two burst=5; limit_reg #用哪一个限速区域 burst=5 #令牌桶，平均每秒不超过1个请求。并且突发不超过5个请求。 nodelay #如果不希望排队堆积的请求过多，可以用这个参数。 实际配置\n限速规则是1秒一个请求\n提供3个VIP特殊请求\nnodelay参数作用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 定制虚拟主机文件 [root@web-8 /etc/nginx/conf.d]#cat limit_req.conf limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server { listen 33555; server_name _; charset utf-8; access_log /var/log/nginx/limit_req.log; limit_req zone=one burst=3 nodelay; location / { root /www/limit-req; index index.html index.htm; } } # 创建测试数据目录 [root@web-8 /etc/nginx/conf.d]#mkdir -p /www/limit-req [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#echo \u0026#39;我是限速模块，你别太快，太快不好\u0026#39; \u0026gt; /www/limit-req/index.html [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#systemctl restart nginx 查看限速，以及3个VIP名的作用\nnodelay参数作用 用法1，不加nodelay参数\n这个nginx的意思是，该虚拟主机，限制客户端 1秒内只能有5个请求，其他请求全部延迟排队。这个参数有麻烦，别用，可能导致出现大问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@web-8 ~]#cat /etc/nginx/conf.d/limit_req.conf limit_req_zone $binary_remote_addr zone=one:10m rate=5r/s; server { listen 33555; server_name _; charset utf-8; access_log /var/log/nginx/limit_req.log; limit_req zone=one burst=3 ; location / { root /www/limit-req; index index.html index.htm; } } 用法2，添加nodelay参数\n请求不排队，限速是几个就几个，超过就直接503拒绝，以及设置了burst特殊请求。\n内置变量 官方网址：Alphabetical index of variables (nginx.org)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 [root@master-61 ~]#cat vars.txt echo $args echo $query_string echo $arg_NAME echo $is_args echo $uri echo $document_uri echo $document_root echo $host echo $hostname echo $https echo $binary_remote_addr echo $body_bytes_sent echo $bytes_sent echo $connection echo $connection_requests echo $content_length echo $content_type echo $cookie_name echo $limit_rate echo $msec echo $nginx_version echo $pid echo $pipe echo $proxy_protocol_addr echo $realpath_root echo $remote_addr echo $remote_port echo $remote_user echo $request echo $request_body echo $request_body_file echo $request_completion echo $request_filename echo $request_length echo $request_method echo $request_time echo $request_uri echo $scheme echo $server_addr echo $server_name echo $server_port echo $server_protocol echo $status echo $time_iso8601 echo $time_local echo $cookie_NAME echo $http_NAME echo $http_cookie echo $http_post echo $http_referer echo $http_user_agent echo $http_x_forwarded_for echo $sent_http_NAME echo $sent_http_cache_control echo $sent_http_connection echo $sent_http_content_type echo $sent_http_keep_alive echo $sent_http_last_modified echo $sent_http_location echo $sent_http_transfer_encoding nginx开启第三方模块 1 2 3 4 5 1.nginx装好之后，想添加额外的模块，只能重新编译，添加这个模块。 2. nginx的第三方模块 echo模块，用于打印nginx中所有变量的信息。 先看看一个不支持echo模块的，使用该语法什么样 编译安装nginx，添加第三方模块 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 # 1.重新下载安装nginx，设置新的 nginx命令 yum -y install gcc-c++ yum -y install pcre pcre-devel yum -y install zlib zlib-devel yum -y install openssl openssl-devel # 3.准备好nginx编译环境 yum install pcre pcre-devel openssl openssl-devel zlib zlib-devel gzip gcc gcc-c++ make wget httpd-tools vim -y # 降低nginx运行时的权限，但是也要注意，你的网页根目录，是否给该用户设置了读写权限。 groupadd www -g 666 useradd www -u 666 -g 666 -M -s /sbin/nologin # 4.开始下载echo模块源码，然后编译且安装，添加给nginx # 下载源码nginx，进行编译，添加第三方模块的代码即可 cd /opt/ wget http://nginx.org/download/nginx-1.19.0.tar.gz tar -zxf nginx-1.19.0.tar.gz [root@web-8 /opt]#cd nginx-1.19.0/ [root@web-8 /opt/nginx-1.19.0]# [root@web-8 /opt/nginx-1.19.0]#ls auto CHANGES CHANGES.ru conf configure contrib html LICENSE man README src # 5.此时可以编译安装这个nginx了，重点就在这 #通过编译参数 --add-module添加第三方的模块，给nginx [root@web-8 /opt]#cd /opt/nginx-1.19.0/ [root@web-8 /opt/nginx-1.19.0]# [root@web-8 /opt/nginx-1.19.0]# # 编译三部曲，第一曲，设置编译参数 [root@web-8 /opt/nginx-1.19.0]#ls auto CHANGES CHANGES.ru conf configure contrib html LICENSE man README src [root@web-8 /opt/nginx-1.19.0]# ./configure \\ --user=www \\ --group=www \\ --prefix=/opt/nginx-1-19-0 \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-pcre \\ --add-module=/opt/echo-nginx-module # 第二曲，第三曲 make \u0026amp;\u0026amp; make install # 你必须吧上面的linux基础编译依赖环境给装好，否则这里可能会出错。。 # 编译结束后，查看生成的二进制命令，是否支持了echo模块 # 编译结束后，nginx的源码目录就可以删除了。 # 查看最终的nginx安装目录 [root@web-8 /opt/nginx-1-19-0]#./sbin/nginx -v nginx version: nginx/1.19.0 [root@web-8 /opt/nginx-1-19-0]# [root@web-8 /opt/nginx-1-19-0]# [root@web-8 /opt/nginx-1-19-0]#./sbin/nginx -V nginx version: nginx/1.19.0 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --user=www --group=www --prefix=/opt/nginx-1-19-0 --with-http_stub_status_module --with-http_ssl_module --with-pcre --add-module=/opt/echo-nginx-module # 发现该nginx是支持echo模块的 # 下载echo模块的源代码 # 通过个git命令，去下载github代码仓库中的源码目录 yum install git -y # cd /opt/ # 由于某些不可描述的因素，代码可能下载不了。。 # 去windows中下好了，发给linux git clone https://github.com/openresty/echo-nginx-module.git 下载完毕 [root@web-8 /opt]#git clone https://github.com/openresty/echo-nginx-module.git Cloning into \u0026#39;echo-nginx-module\u0026#39;... remote: Enumerating objects: 3039, done. remote: Counting objects: 100% (21/21), done. remote: Compressing objects: 100% (16/16), done. remote: Total 3039 (delta 7), reused 15 (delta 5), pack-reused 3018 Receiving objects: 100% (3039/3039), 1.17 MiB | 1.44 MiB/s, done. Resolving deltas: 100% (1631/1631), done. 查看echo模块的源代码内容 [root@web-8 /opt]#ls /opt/echo-nginx-module/ config LICENSE README.markdown src t util valgrind.suppress 使用该echo模块，可以打印，调试nginx的变量等信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 创建虚拟主机了，给你编译的nginx创建配置文件了 优化默认的配置文件，去除无用的内容 利用include语法，导入自定义的配置文件 [root@web-8 /opt/nginx-1-19-0/conf]#cat nginx.conf worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # 自定义配置文件优化 include /opt/nginx-1-19-0/conf/extra/*.conf; } # 创建子配置文件 [root@web-8 /opt/nginx-1-19-0/conf]#mkdir extra [root@web-8 /opt/nginx-1-19-0/conf]# [root@web-8 /opt/nginx-1-19-0/conf]#cd extra/ [root@web-8 /opt/nginx-1-19-0/conf/extra]# [root@web-8 /opt/nginx-1-19-0/conf/extra]#vim test-echo.conf [root@web-8 /opt/nginx-1-19-0/conf/extra]# [root@web-8 /opt/nginx-1-19-0/conf/extra]# [root@web-8 /opt/nginx-1-19-0/conf/extra]# [root@web-8 /opt/nginx-1-19-0/conf/extra]#cat test-echo.conf server { listen 11444; server_name localhost; charset utf-8; location / { echo \u0026#34;lijinit.cn welcome you!\u0026#34;; echo $uri; echo $document_uri; echo $remote_addr; echo $remote_port; echo $http_user_agent; } } # 验证配置是否正确，启动nginx [root@web-8 /opt/nginx-1-19-0/conf/extra]#/opt/nginx-1-19-0/sbin/nginx -t nginx: the configuration file /opt/nginx-1-19-0/conf/nginx.conf syntax is ok nginx: configuration file /opt/nginx-1-19-0/conf/nginx.conf test is successful [root@web-8 /opt/nginx-1-19-0/conf/extra]# [root@web-8 /opt/nginx-1-19-0/conf/extra]# [root@web-8 /opt/nginx-1-19-0/conf/extra]#/opt/nginx-1-19-0/sbin/nginx [root@web-8 /opt/nginx-1-19-0/conf/extra]# [root@web-8 /opt/nginx-1-19-0/conf/extra]#netstat -tunlp|grep 11444 tcp 0 0 0.0.0.0:11444 0.0.0.0:* LISTEN 11945/nginx: master [root@web-8 /opt/nginx-1-19-0/conf/extra]# 测试访问，该echo模块是否正确\n1 你如果用浏览器去访问，nginx默认不会解析这个echo打印的内容，会提供下载功能，让你查看这些字符串 1 2 3 在linux客户端中，查看这个echo打印的内置变量的信息 至此也证明了，我们编译现状的nginx，支持echo模块。了。。 location 实战 location是nginx的核心重要功能,可以设置网站的访问路径,一个web server会有多个路径,那么location就得设置多个。\nNginx的locaiton作用是根据用户请求的URl不同,来执行不同的应用。\n针对用户请求的网站URL进行匹配,匹配成功后进行对应的操作。\n官方文档 Module ngx_http_core_module (nginx.org)\n.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 1. 先学懂语法，清晰locaiton的匹配规则 Syntax:\tlocation [ = | ~ | ~* | ^~ ] uri { ... } location @name { ... } Default:\t— Context:\tserver, location Syntax: location [ = | ~ | ~* | ^~ ] uri { ... } location @name { ... } Default: — Context: server, location 官网用法 location = / { [ configuration A ] } location / { [ configuration B ] } location /documents/ { [ configuration C ] } location ^~ /images/ { [ configuration D ] } location ~* \\.(gif|jpg|jpeg)$ { [ configuration E ] } 测试用法，如果定义了如上的5个location，则 http://lijinit.cn/ 匹配A http://lijinit.cn/hello 匹配B http://lijinit.cn/documents/hello 匹配C http://lijinit.cn/images/葫芦娃.gif 匹配D http://lijinit.cn/documents/德玛西亚.gif 匹配E 2. 在后续的php网站部署，python网站，java网站部署实践配置中，反复用到location语法，即可加深理解。 2.location语法优先级 优先级从高到低\n有符号的，才有优先级，\n否则都往后排\n匹配符 匹配规则 优先级 = 定义 URI 和位置的精确匹配。 1 ^~ 以某个字符串开头，不检查正则(，区分大小写) 2 ~ 区分大小写的正则匹配 （认识正则，区分url大小写） 3 ~* 不区分大小写的正则匹配（认识正则，不区分url大小写） 4 四个规则\n生成具体location的匹配规则 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # 配置文件如下 server { listen 22333; server_name _; # 最低级匹配，不符合其他locaiton就来这 # 属于通用url规则 location / { return 200 \u0026#34;location / \\n\u0026#34;; } # 优先级最高，等于号后面可以指定url location = / { return 200 \u0026#34;location = / \\n\u0026#34;; } #以/documents/开头的url，来这里，如符合其他locaiton，则以其他优先 location /documents/ { return 200 \u0026#34;location /documents/ \\n\u0026#34;; } #匹配任何以/images/开头的请求，不匹配正则 location ^~ /images/ { return 200 \u0026#34;location ^~ /images/ \\n\u0026#34;; } #匹配任何以.gif结尾的请求，支持正则 location ~* \\.(gif|jpg|jpeg)$ { return 200 \u0026#34;location ~* \\.(gif|jpg|jpeg) \\n\u0026#34;; } access_log off; } 进行url的设置访问，查看结果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 [root@master-61 ~]## 精确匹配 [root@master-61 ~]#curl 10.0.0.8:22333 location = / [root@master-61 ~]#curl 10.0.0.8:22333/ location = / [root@master-61 ~]## 最低级匹配，没有location匹配上，就找默认的 location / {} [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/xixixixixixi location / [root@master-61 ~]#curl 10.0.0.8:22333/hehehehehe location / [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/jinitaimei location / [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/律师函我是跑不掉了 location / [root@master-61 ~]## 指定url的匹配 [root@master-61 ~]# [root@master-61 ~]## 指定url的匹配，指定以/documents/开头的url [root@master-61 ~]# [root@master-61 ~]## 得你客户端url，以/documnets/开头才行 [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/documents location / [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]## 你写的这个url，拿到的是 $url /documents [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]## 你写的这个url，拿到的是 $url /documents 必须是 /documents/才行， [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/documents/ location /documents/ [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/documents/xixixixi location /documents/ [root@master-61 ~]#curl 10.0.0.8:22333/documents/xixixihahahahahah location /documents/ [root@master-61 ~]#curl 10.0.0.8:22333/documents/xixixihahahahahah基尼太美 location /documents/ [root@master-61 ~]# # 匹配，第二优先级的 location ^~ 匹配指定的url是 /images/ [root@master-61 ~]## 继续指定url，也等于精确匹配字符串 ，必须是以 /images/ [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/images/ location ^~ /images/ [root@master-61 ~]#curl 10.0.0.8:22333/IMAGES/ location / [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/images/ location ^~ /images/ [root@master-61 ~]#curl 10.0.0.8:22333/images/xixixix location ^~ /images/ [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/images/xixixixhahahaha location ^~ /images/ [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/image/xixixixhahahaha location / [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]## 如何证明它的高优先级，排第二 [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/images/两年半练习生.jpg location ^~ /images/ [root@master-61 ~]#curl 10.0.0.8:22333/asdasdasdasdasdasd/asdasdasd/caixukun.jpg location ~* \\.(gif|jpg|jpeg) [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]## $url /asdasdasdasdasdasd/asdasdasd/caixukun.jpg [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/asdasdasdasdasdasd/asdasdasd/caixukun.jpg location ~* \\.(gif|jpg|jpeg) [root@master-61 ~]# [root@master-61 ~]## 测试不区分大小写 [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/asdasdasdasdasdasd/asdasdasd/caixukun.JPG location ~* \\.(gif|jpg|jpeg) [root@master-61 ~]#curl 10.0.0.8:22333/asdasdasdasdasdasd/asdasdasd/caixukun.gif location ~* \\.(gif|jpg|jpeg) [root@master-61 ~]#curl 10.0.0.8:22333/asdasdasdasdasdasd/asdasdasd/caixukun.GIf location ~* \\.(gif|jpg|jpeg) [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/asdasdasdasdasdasd/asdasdasd/caixukun.jpeg location ~* \\.(gif|jpg|jpeg) [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/asdasdasdasdasdasd/asdasdasd/caixukun.jpeG location ~* \\.(gif|jpg|jpeg) [root@master-61 ~]#curl 10.0.0.8:22333/asdasdasdasdasdasd/asdasdasd/caixukun.jpEG location ~* \\.(gif|jpg|jpeg) [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]#curl 10.0.0.8:22333/asxixixixixix/asdasd/caixukun.jpEG location ~* \\.(gif|jpg|jpeg) [root@master-61 ~]# [root@master-61 ~]# [root@master-61 ~]## 看到这，理解 不区分大小写，以jpg,gif,jpeg结尾的url # ~* 排在老四，优先级算低， 1 2 3 4 5 6 ]## 1. = 2. ^~ 不检查正则，且区分大小写的url匹配 [root@web-8 /opt/nginx-1-19-0/conf/extra]# [root@web-8 /opt/nginx-1-19-0/conf/extra]## 3. ~ 区分大小写的正则匹配 [root@web-8 /opt/nginx-1-19-0/conf/extra]# [root@web-8 /opt/nginx-1-19-0/conf/extra]## 4. ~* 不区分大小写的正则匹配 [root@web-8 /opt/nginx-1-19-0/conf/extra]# 实际工作应用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 实际工作中，会有至少3个匹配规则如下，需要同学们学习了nginx负载均衡即可理解。以及具体的网站部署实践。 1.必选规则，设置反向代理，官网也推荐该用法，可以加速处理，因为首页会频繁被访问 location一般直接设置反向代理，转发给后端应用服务器，或者是静态页： locatlon =/ { proxy_pass http://lijinit.cn; } 2.静态文件处理。nginx强项 两个模式。二选一即可 这个表示当用户请求是http://lijinit.cn/static/hello.css这样的请求时 进入/ew日录下，寻我itatie文件夹。也就是/www/static/hello.css文件 location ^~ /static/( root /www/; } #这个表示请求是以如下静志资源结尾的。进入到/www/下寻找该文件 匹配任何以.gif结尾的请求。支持正则 location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ { root /www/; } 3.还有就是通用规则，用子处理未定义的url.默认四配 一般网站除了静态文件的请求。默认就是动态请求。因此直接转发给后端 location / { proxy_pass http://my_tomcat:8080/; } location中的root和alias实战 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 1.明确了location是根据用户访问的具体url来决定做什么事。 2. 要做的事是 返回一些静态数据给用户看 （问题在于，你通过什么语句，把nginx机器上的数据，返回给用户） 已知的语法是 server { listen 33555; server_name _; # 你现在需要设置 # 需要访问 10.0.0.8:33555/static/caixukun.jpg # 你有什么写法，可以返回这个数据，给用户看到呢？ # 当前有一个代码目录，叫做 /huya/ 要求静态数据放在这个目录下 # 已知有一个静态图片，放在如下的目录中 /huya/static/caixukun.jpg # 要求，要进行静态请求匹配，匹配/static/ url开头 # 等于匹配用户访问的url形式是 10.0.0.8:33555/static/caixukun.jpg location ^~ /static/ { # 两种写法第一个，写root，root特点是会将该url(/static)填充到网页根目录下，认为它也是一个目录 # 测一测是否能让你访问到 caixukun.jpg root /huya/static/; # 第二种写法，alias别名用法 } } 不正确的写法1, 为了让你理解root的参数含义\n正确写法（root参数） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 1.你还是必须要明确，用户要访问的url，是如下 http://10.0.0.8:33555/static/caixukun.jpg 2. 正确的配置文件应该是如下 [root@web-8 /huya/static]#cat /opt/nginx-1-19-0/conf/extra/test-root-alias.conf server { listen 33555; server_name _; # 你现在需要设置 # 需要访问 10.0.0.8:33555/static/caixukun.jpg # 你有什么写法，可以返回这个数据，给用户看到呢？ # 当前有一个代码目录，叫做 /huya/ 要求静态数据放在这个目录下 # 已知有一个静态图片，放在如下的目录中 /huya/static/caixukun.jpg # 要求，要进行静态请求匹配，匹配/static/ url开头 # 等于匹配用户访问的url形式是 10.0.0.8:33555/static/caixukun.jpg location ^~ /static/ { # 两种写法第一个，写root，root特点是会将该url(/static)填充到网页根目录下，认为它也是一个目录 # 应该正确写法如下 root /huya/; # 第二种写法，alias别名用法 } } 重启服务 3.按照这个写法的话，该资源文件应该是防止在什么位置？ （这里的路径，意识是，该caixukun.jpg资源放在服务器上的什么路径下！！） 才能正确的访问 http://10.0.0.8:33555/static/caixukun.jpg 所以说，你要确保，这个静态资源存放的绝对路径是如下\n1 /huya/static/caixukun.jpg alias参数用法 #alias的作用是，别名，将该location匹配的url($uri变量提取的字符串信息)替换为如下alias设置的目录\n1 2 3 4 5 1.还拿这个url来做实验，用户需要访问的url依然是 http://10.0.0.8:33555/static/caixukun.jpg 2. 修改nginx的配置文件 nginx location的root参数，和alias参数如上解释，自己根据location的匹配规则，结合root，alias参数，去找静态文件试试。\n","date":"2025-04-14T16:53:41+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/nginx%E9%AB%98%E7%BA%A7%E7%AF%872/","title":"Nginx高级篇2"},{"content":"nginx高级篇 在nginx最核心的功能，虚拟主机会用之后，下一步就是学习nginx的各种高级功能，用于应对工作里对网站部署的各种需求。\nnginx访客日志切割 为什么要进行日志切割 1.为了业务方便提取 2.防止单个日志文件过大，切割后，容易做备份\n切割理念（先纯手动的去切割日志，备份日志） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 1. 给nginx进程发送信号，让nginx重新生成一个新日志文件，这就是一个日志切割根本 /var/log/nginx/access.log.bak # 1.备份原本日志文件 nginx reload reopen信号 # 配置文件中定义的日志文件名，是这个 2. /var/log/nginx/access.log # 重新生成新日志文件，让新日志往这里去写 # 手动切割，修改日志 #1.准备好旧的日志文件，测试写入大量的日志记录，先用第一种办法，for循环 [root@web-8 ~]#for num in {1..10000};do curl 10.0.0.8 ; done #2.使用支持多进程，并发写入的工具，如ab命令 apache提供的性能压测命令，给网站发送支持并发的大量的http请求。 [root@web-8 ~]#yum install httpd-tools -y # 发送10000个http请求，且招来100个人同时发请求 ab -c 100 -n 10000 http://10.0.0.8/ # 3.当前日志数量 [root@web-8 /var/log/nginx]#cat all-server-accesss.log |wc -l 20000 # 4.让你有一个已经记录了大量日志的文件，得进行日志切割了 切割思路就是，1.先重命名，等于备份() 2. 重新记录nginx日志 (/var/log/nginx/access.log) 按天记录日志 （每天夜里的 整点分进行日志备份，日志） 按天，生成一个新的日志文件 # 备份旧日志（模拟是前一天的旧日志） cd /var/log/nginx \u0026amp;\u0026amp; mv all-server-accesss.log all-server-accesss.log.$(date \u0026#39;+%F\u0026#39;) # 还得生成新日志，得继续记录 给nginx进程发送reopen信号，重新生成新日志 # 用这种方式，可以最精确的提取进程id号。 kill -USR1 $(ps -ef|grep nginx |grep master | awk \u0026#39;{print $2}\u0026#39;) 此时会生成新的日志 [root@web-8 /var/log/nginx]#ll total 6084 -rw-r--r-- 1 www root 0 May 23 10:10 all-server-accesss.log -rw-r--r-- 1 root root 4160000 May 23 10:08 all-server-accesss.log.2022-05-23---10:04:17 -rw-r--r-- 1 www root 700 May 23 10:10 error.log 此时新日志，就会记录到这个新的日志文件中了 ==\u0026gt; all-server-accesss.log \u0026lt;== /index.html 10.0.0.8 - - [23/May/2022:10:10:56 +0800] \u0026#34;GET / HTTP/1.1\u0026#34; 200 6 \u0026#34;-\u0026#34; \u0026#34;curl/7.29.0\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [23/May/2022:10:10:57 +0800] \u0026#34;GET / HTTP/1.1\u0026#34; 200 6 \u0026#34;-\u0026#34; \u0026#34;curl/7.29.0\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [23/May/2022:10:10:58 +0800] \u0026#34;GET / HTTP/1.1\u0026#34; 200 6 \u0026#34;-\u0026#34; \u0026#34;curl/7.29.0\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [23/May/2022:10:10:58 +0800] \u0026#34;GET / HTTP/1.1\u0026#34; 200 6 \u0026#34;-\u0026#34; \u0026#34;curl/7.29.0\u0026#34; \u0026#34;-\u0026#34; 对于旧的日志 你最好 创建文件夹去分类管理他们 shell脚本形式 .你得先有解决问题的思路，然后将思路转变为linux命令，再优化为shell脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #!/bin/bash # 源日志目录 logs_path=\u0026#34;/var/log/nginx\u0026#34; # 备份日志目录 back_logs_path=\u0026#34;${logs_path}/$(date -d \u0026#39;yesterday\u0026#39; +\u0026#39;%F\u0026#39;)\u0026#34; # 创建备份目录，以日期命名，注意，每天零点整切割，开始记录新的一天的日志，备份目录应该是昨天 mkdir -p ${back_logs_path} # 重命名旧日志名，注意日期 cd ${logs_path} \u0026amp;\u0026amp; find . -type f |xargs -i mv {} {}.$(date -d \u0026#39;yesterday\u0026#39; +\u0026#39;%F\u0026#39;) # 移动旧日志文件到该目录下 cd ${logs_path} \u0026amp;\u0026amp; find . -type f |xargs -i mv {} ${back_logs_path} # 重新生成新日志 kill -USR1 `ps -ef|grep nginx |grep master|awk \u0026#39;{print $2}\u0026#39;` 脚本写完了，先手动试试，脚本对不对\n下一步就是，将这个脚本，添加到定时任务即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 crontab -e 0 0 * * * /bin/bash /my_shell/back_nginx.sh # 测试修改日期，查看日志的备份是否正确 [root@web-8 /var/log/nginx]#ll /var/log/nginx/ total 0 drwxr-xr-x 2 root root 75 May 24 00:00 2022-05-23 -rw-r--r-- 1 www root 0 May 24 00:00 all-server-accesss.log -rw-r--r-- 1 www root 0 May 24 00:00 error.log [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]#tail -5 all-server-accesss.log /index.html 10.0.0.8 - - [24/May/2022:00:00:28 +0800] \u0026#34;GET / HTTP/1.0\u0026#34; 200 0 \u0026#34;-\u0026#34; \u0026#34;ApacheBench/2.3\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [24/May/2022:00:00:28 +0800] \u0026#34;GET / HTTP/1.0\u0026#34; 200 0 \u0026#34;-\u0026#34; \u0026#34;ApacheBench/2.3\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [24/May/2022:00:00:28 +0800] \u0026#34;GET / HTTP/1.0\u0026#34; 200 0 \u0026#34;-\u0026#34; \u0026#34;ApacheBench/2.3\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [24/May/2022:00:00:28 +0800] \u0026#34;GET / HTTP/1.0\u0026#34; 200 0 \u0026#34;-\u0026#34; \u0026#34;ApacheBench/2.3\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [24/May/2022:00:00:28 +0800] \u0026#34;GET / HTTP/1.0\u0026#34; 200 0 \u0026#34;-\u0026#34; \u0026#34;ApacheBench/2.3\u0026#34; \u0026#34;-\u0026#34; [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]#ll total 5076 drwxr-xr-x 2 root root 75 May 24 00:00 2022-05-23 -rw-r--r-- 1 www root 5193864 May 24 00:00 all-server-accesss.log -rw-r--r-- 1 www root 0 May 24 00:00 error.log [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]#tail -5 2022-05-23/ all-server-accesss.log.2022-05-23 error.log.2022-05-23 [root@web-8 /var/log/nginx]#tail -5 2022-05-23/all-server-accesss.log.2022-05-23 /index.html 10.0.0.8 - - [23/May/2022:10:44:08 +0800] \u0026#34;GET / HTTP/1.0\u0026#34; 200 6 \u0026#34;-\u0026#34; \u0026#34;ApacheBench/2.3\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [23/May/2022:10:44:08 +0800] \u0026#34;GET / HTTP/1.0\u0026#34; 200 6 \u0026#34;-\u0026#34; \u0026#34;ApacheBench/2.3\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [23/May/2022:10:44:08 +0800] \u0026#34;GET / HTTP/1.0\u0026#34; 200 6 \u0026#34;-\u0026#34; \u0026#34;ApacheBench/2.3\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [23/May/2022:10:44:08 +0800] \u0026#34;GET / HTTP/1.0\u0026#34; 200 6 \u0026#34;-\u0026#34; \u0026#34;ApacheBench/2.3\u0026#34; \u0026#34;-\u0026#34; /index.html 10.0.0.8 - - [23/May/2022:10:44:08 +0800] \u0026#34;GET / HTTP1.0\u0026#34; 200 6 \u0026#34;-\u0026#34; \u0026#34;ApacheBench/2.3\u0026#34; \u0026#34;-\u0026#34; logrotate工具切割形式 比shell脚本手动切割日志更方便的工具\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 # 看看该日志切割工具，支持哪些软件 # 默认改工具，对nginx的支持. # 这里的写法，是针对你的yum安装的nginx，实现日志切割 [root@web-8 /var/log/nginx]#cat /etc/logrotate.d/nginx /var/log/nginx/*.log { daily # 每天切割 missingok # 忽略错误 rotate 52 # 最多保留多少个存档 compress # 切割后且压缩 delaycompress # 延迟压缩动作在下一次切割 notifempty # 日志为空就不切割 create 640 nginx adm # 切割的文件权限 sharedscripts # 共享脚本，结果为空 postrotate # 收尾动作，重新生成nginx日志 if [ -f /var/run/nginx.pid ]; then kill -USR1 `cat /var/run/nginx.pid` fi endscript # 结束动作 } 看具体的效果，是否理解 先清理你刚才的shell的定时任务 重新生成nginx日志环境，然后测试工具 [root@web-8 /var/log/nginx]#crontab -e crontab: installing new crontab [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]#ntpdate -u ntp.aliyun.com 23 May 10:59:03 ntpdate[4346]: step time server 203.107.6.88 offset -47699.063535 sec [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]# [root@web-8 /var/log/nginx]#date Mon May 23 10:59:14 CST 2022 应该先修改时间，作为测试 测试logrotate工具是否实现日志切割 手动实现日志切割，执行该工具 logrotate -f /etc/logrotate.d/nginx 被切割后的日志 [root@web-8 /var/log/nginx]#ll -h total 21M -rw-r----- 1 www adm 10M May 24 00:01 all-server-accesss.log -rw-r--r-- 1 root root 5.0M May 23 10:59 all-server-accesss.log.1 -rw-r----- 1 www adm 0 May 24 00:01 error.log -rw-r--r-- 1 root root 700 May 24 00:01 error.log.1 logrotate工具，本身会压缩备份的日志文件，是因为，压缩工作，被延迟到了下一次切割 logrotate -f /etc/logrotate.d/nginx 等于实现了第二次切割动作，本次会进行日志压缩了 logrotate 的定时任务 logrotate 的定时任务通常由系统的 cron 服务自动管理。具体来说，logrotate 的定时任务配置文件位于 /etc/cron.daily/ 目录中。 检查 cron.daily 目录 你可以查看 /etc/cron.daily/ 目录中的内容： ls /etc/cron.daily/ 你应该会看到一个名为 logrotate 的脚本文件。这个脚本会每天运行一次，执行所有配置在 /etc/logrotate.d/ 目录中的 logrotate 任务。 总结 通过 yum 安装的 Nginx 的 logrotate 配置文件通常位于 /etc/logrotate.d/nginx。logrotate 的定时任务由系统的 cron 服务管理，通常配置在 /etc/cron.daily/ 目录中。你可以查看和编辑这些配置文件，确保日志轮转按照你的需求进行。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 如果说你要用这个logrotate工具对你的编译安装的淘宝nginx实现日志切割，你还会写吗？ # 区别是1.确定日志目录 /opt/ngx/logs/ ； 2.给nginx主进程发送USR1信号（tengine是生成了nginx.pid文件，还是没有） # 生成切割脚本 # 针对你编译安装的 淘宝nginx，实现自动的日志切割 cat \u0026gt; /etc/logrotate.d/tengine \u0026lt;\u0026lt;EOF /opt/ngx/logs/*.log { daily # 每天切割 missingok # 忽略错误 rotate 52 # 最多保留多少个存档 compress # 切割后且压缩 delaycompress # 延迟压缩动作在下一次切割 notifempty # 日志为空就不切割 create 640 nginx adm # 切割的文件权限 sharedscripts # 共享脚本，结果为空 postrotate # 收尾动作，重新生成nginx日志 if [ -f /opt/ngx/sbin/tengine.pid ]; then kill -USR1 `cat /opt/ngx/sbin/tengine.pid` fi endscript # 结束动作 } 目录索引、下载服务 实现一个类似于ftp工具的功能\n1.先准备好一个用于共享的数据目录\n2.部署server虚拟主机，然后去展示这些数据，完事\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 1. 准备一个 rpm包的 目录 2. 提供该rpm包目录的展示 mkdir /0224rpms [root@web-8 /0224rpms]#yum install python3 python3-devel --downloadonly --downloaddir=/0224rpms 3.创建nginx的虚拟主机 [root@web-8 /0224rpms]#cat /etc/nginx/conf.d/autoindex.conf server { listen 11111; server_name _; location / { autoindex on; autoindex_localtime on; autoindex_exact_size off; root /0224rpms; } } 4.重启nginx实现该目录索引功能 [root@web-8 /0224rpms]#systemctl reload nginx 如何明确，该虚拟主机是否可用 [root@web-8 /0224rpms]#netstat -tunlp |grep 11111 tcp 0 0 0.0.0.0:11111 0.0.0.0:* LISTEN 4361/nginx: master 5.测试访问即可 此时这个虚拟主机就提供了基于http请求的文件下载功能 6.利用wget下载 wget http://10.0.0.8:11111/python3-3.6.8-18.el7.x86_64.rpm 连接数监控 web协议篇\ntcp/ip\nhttp 请求，与响应\nnginx服务器， client浏览器，curl，等都是封装了，以http协议规范发出的请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 http://www.linux0224.com/奥力给.jpg 这是一个完整的url，你要能看懂每一个符号的含义 默认nginx不支持这个功能，你要看一看你装的nginx是否有这个模块 创建nginx的虚拟主机文件，单独的去测试这个statsu状态功能即可 如果你的nginx默认不支持这个status功能， 重新编译nginx二进制命令，把这个模块添加进去 # 创建虚拟主机文件，查看status功能 [root@web-8 /etc/nginx/conf.d]#cat status.conf # 作用就是让你访问 ip:9999可以精确定位到这个虚拟主机 server{ listen 9999; server_name _; stub_status on; access_log off; # 因为它不是一个基于http请求响应的网站，仅仅是展示连接的信息，都不需要写location。 } 重新读取 [root@web-8 /etc/nginx/conf.d]#cat status.conf server{ listen 9999; server_name localhost; stub_status on; access_log off; } [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#systemctl reload nginx 测试访问 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 参数解释： Active connections 当前活动客户编连按数,包括wating连按数。 accepts 接受的客户端连接总数。 handled 处理的连接总数。 accepts通常,险非己达到某些资源限制(例如,worker_connections限制),否则该参数值相同 reguests 客户端请求的总数, Reading nginx正在读取请求标头的当前选按数 writing nginx 将响应写回客户编的当前连接数。 waiting 当前等待请求的空闲客户端连接数。 #注意 一个tcp连接,可以发起多个http请求 可以通过修改保持连接参数修改 keepalive_timeout 0;表示关闭长连接 1 2 3 4 5 6 因为你restart nginx 等于重新生成master进程，这些数据就没了，重新计算了。 关于nginx连接信息的，动态玩法 ab命令测试 这里的关于连接的详细信息，需要从web协议篇去理解，从tcp，http的理解 利用ab命令测试\n1 ab -c 100 -n 100000 http://10.0.0.8/ 为什么激活数是2 ","date":"2025-04-14T16:53:36+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/nginx%E9%AB%98%E7%BA%A7%E7%AF%871/","title":"Nginx高级篇1"},{"content":"nginx的日志 nginx的功能都是基于插件（模块）来的\nnginx的所有核心功能\n1 2 3 4 5 6 https://nginx.org/en/docs/ 例如老板让你在windows下部署nginx网站， https://nginx.org/en/docs/windows.html 找到windows配置教程 nginx日志变量的格式，作用 1 2 3 4 https://nginx.org/en/docs/ https://nginx.org/en/docs/http/ngx_http_core_module.html#var_remote_addr 当你的nginx访客日志，需要记录更多的client请求信息，你可以来这里找，添加更多的变量，加入到如下的日志格式化参数中 访客日志 处理日志模块的官网教程\nhttps://nginx.org/en/docs/http/ngx_http_log_module.html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 nginx.conf中有关访客日志定义如下 #a log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log logs/access.log main; 参数解释 # 看到这个请求是从什么IP发来的。 remote_addr $remote_addr ：记录访问网站的客户端IP地址 $remote_user ：记录远程客户端用户名称 $time_local ：记录访问时间与时区 $request ：记录用户的 http 请求起始行信息（请求方法，http协议） $status ：记录 http 状态码，即请求返回的状态，例如 200 、404 、502 等 $body_bytes_sent ：记录服务器发送给客户端的响应 body 字节数 $http_referer ：记录此次请求是从哪个链接访问过来的，可以根据 referer 进行防盗链设置 $http_user_agent ：记录客户端访问信息，如浏览器、手机客户端等 $http_x_forwarded_for ：当前端有代理服务器时，设置 Web 节点记录客户端地址的配置，此参数生效的前提是代理服务器上也进行了相关的 x_forwarded_for 设置 备注 $remote_addr 可能拿到的是反向代理IP地址 $http_x_forwarded_for 可以获取客户端真实IP地址 生产环境下的日志实践经验 开启，关闭日志功能（先看默认的日志功能怎么用） 逐步分析，主配置文件nginx.con\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 [root@web-8 /etc/nginx]#cat /etc/nginx/nginx.conf user www; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 重启nginx服务，查看默认的日志功能 systemctl restart nginx 检测日志 1 tail -f /var/log/nginx/access.log 1 2 3 4 所有的子域名的日志都被统一记录到了一个文件中 http://dnf.linux0224.cc/ http://huoying.linux0224.cc/ 关闭日志功能 有时候在代理服务器上，转发服务器上，nginx日志可能不用记录，节省磁盘IO的资源。\n1 2 3 4 5 6 7 8 9 10 http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #access_log /var/log/nginx/access.log main; access_log off; 修改nginx访客日志的格式 自己添加，可以捕获更多的客户端的信息\n1 2 3 4 5 6 7 8 9 https://nginx.org/en/docs/ https://nginx.org/en/docs/http/ngx_http_core_module.html#var_remote_addr 当你的nginx访客日志，需要记录更多的client请求信息，你可以来这里找，添加更多的变量，加入到如下的日志格式化参数中 log_format main \u0026#39;$document_uri $remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; 单个虚拟主机，记录日志 针对每一个网站，单独的记录日志文件，便于分类管理。\n1 2 3 4 5 6 此时的各个虚拟主机配置文件，并未使用日志功能 [root@web-8 /etc/nginx]#cd conf.d/ [root@web-8 /etc/nginx/conf.d]#ls 88.conf dnf.linux0224.conf huoying.linux0224.conf lol.linux0224.conf port.conf [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#grep \u0026#39;access_log\u0026#39; ./* 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 语法就是，将日志格式的配置参数，别写在http{}花括号中，而是写在各自的server{}虚拟主机中即可。： # 语法要求，log_format 格式化的日志的名字，还不得重复 1.去掉nginx.conf中的日志配置 # http{}区域中 nginx.conf中关闭日志 # log_format参数依然得写在http{}区域中 ，可以利用include语法实现 http { access_log off; include /etc/nginx/mime.types; default_type application/octet-stream; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 2.针对每一个虚拟主机，添加日志格式参数，主要的是，分别写入到不同的日志文件中 [root@web-8 /etc/nginx/conf.d]#cat dnf.linux0224.conf # 这个参数和server{}平级 log_format main \u0026#39;$document_uri $remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; server { # 开启日志功能，以及存放路径，参数写在server{}内 access_log /var/log/nginx/dnf.linux0224.cc.access.log main; listen 80; server_name dnf.linux0224.cc; # 这里写的是域名 charset utf-8; location / { root /www/dnf/; index index.html; } } 3. 单独记录lol域名业务的访客日志 [root@web-8 /etc/nginx/conf.d]#cat lol.linux0224.conf log_format main2 \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; server { access_log /var/log/nginx/lol.linux0224.cc.access.log main2; listen 80; server_name lol.linux0224.cc; charset utf-8; location / { root /www/lol/; index index.html; } } 4.注意，开启access_log日志的参数，可以写在server{}区域里，但是日志格式化的参数，只能写在http{}区域中 测试不同虚拟主机的日志记录 现在有2个虚拟主机，单独记录了日志\ndnf页面的访问情况，与日志记录 其他虚拟主机的日志记录情况 解读日志的写入顺序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 看你如何设计了，你是继续针对每一个虚拟主机，添加日志 遵循上述讲解的语法 1. 给dnf和lol这两个三级域名，子业务的网站，单独记录访客日志 -rw-r--r-- 1 root root 3310 May 19 14:55 dnf.linux0224.cc.access.log -rw-r--r-- 1 root root 2341 May 19 14:55 lol.linux0224.cc.access.log 2. 剩余其他的虚拟主机日志，全部统一记录到 /var/log/nginx/all-server-accesss.log 如下写法，就会去记录，除了你单独指定的虚拟主机的日志，剩下的日志，都会写入到这个all-server-accesss.log 文件中 nginx.conf 主配置如下 # 定义一个全局的设置 http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main3 \u0026#39;$document_uri $remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/all-server-accesss.log main3; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } # 单独的虚拟主机，单独设置即可。。 # 检测所有的日志 [root@web-8 /var/log/nginx]#tail -f /var/log/nginx/* # nginx的配置，存在虚拟主机的匹配，匹配到谁，就读取谁的配置。 # 只要是ip符合，port符合，并且有优先级加载顺序，就能匹配上 10.0.0.8:80 这个ip 你只要构造符合条件的 请求即可。 第一种虚拟主机，符合 10.0.0.8:80 第二种虚拟主机。符合，修改了端口的 10.0.0.8:81 10.0.0.8:82 第三种虚拟主机，符合修改了ip的 10.0.0.88:80 练习的目的，在于搞懂，你有几个虚拟主机，以及你的请求，与哪一个虚拟主机匹配上了。 # 单独给 lol.linux0224.cc 设置了日志 # 单独给 dnf.linux0224.cc 设置了日志 # 其他的虚拟主机，就会默认匹配 http{ 设置的全局 日志参数了} 只有针对单个的网站业务，记录的日志，才有提取，分析的意义。\nnginx提供的日志 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 记录用户访问记录的 ，access_log 记录nginx运行错误的日志 error_log 关于该参数的官网文档，以及具体的用法 https://nginx.org/en/docs/ngx_core_module.html#error_log 和access_log用法一样去以及 http{} server{} 区域里面 Syntax:\terror_log file [level]; Default:\terror_log logs/error.log error; Context:\tmain, http, mail, stream, server, location 具体的level是指，日志记录的详细程度 有这些值让你填写 debug, info, notice, warn, error, crit, alert 从左到右，详细程度分别是 从 大 \u0026gt;\u0026gt;\u0026gt; 小 debug 会记录超级详细的信息，没必要，占用大量的磁盘空间 crit 表示nginx以及出现严重错误，以及崩溃了，才记录日志。。记录的内容太少 一般用的，以及默认的就是error日志级别，能够记录基本的，常见错误。 错误日志 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 1. 如何开启error级别的错误日志。 # 单独给的lol虚拟主机网址，设置错误日志，eroor级别 ，配置如下 # 支持写入http{} server{} [root@web-8 /etc/nginx/conf.d]#cat lol.linux0224.conf log_format main2 \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; server { access_log /var/log/nginx/lol.linux0224.cc.access.log main2; error_log /var/log/nginx/lol-error.log error; listen 80; server_name lol.linux0224.cc; charset utf-8; location / { root /www/lol/; index index.html; } } 重启服务 [root@web-8 /etc/nginx/conf.d]#systemctl restart nginx 检查日志 [root@web-8 /etc/nginx/conf.d]#tail -f /var/log/nginx/lol-error.log 错误日志的，特点是记录，访问时的出错信息 404页面优化 error_page模块 错误页面优化，nginx，默认访问出错后，会返回不同的错误页面\n如 -\n40x系列的页面 404 not found 服务器上找不到该资源 403 Forbidden 禁止访问（权限不够，找权限的问题） 如50x系列的页面 学nginx反向代理 但是默认的都太丑，对其优化 http://nginx.org/cn/docs/http/ngx_http_core_module.html\n1 2 3 4 给全局设置、给虚拟主机设置。 1. 如何单独设置40x错误的页面优化 2. 如何设置50x系列的错误页面 淘宝的错误页面 语法 1 2 3 4 # error_page 响应状态码 相对路径的html文件/ 填入url ; error_page 404 /404.html; error_page 500 502 503 504 /50x.html; 优化错误页面，指向本地的html文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 针对lol的虚拟主机设置 [root@web-8 ~]#cat /etc/nginx/conf.d/lol.linux0224.conf log_format main2 \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; # 当404错误时，返回当前机器上的my404.html # 当403错误时，跳转到淘宝这个错误页面上 server { access_log /var/log/nginx/lol.linux0224.cc.access.log main2; error_log /var/log/nginx/lol-error.log error; error_page 404 /my404.html; error_page 403 https://error.taobao.com/app/tbhome/common/error.html; listen 80; server_name lol.linux0224.cc; charset utf-8; location / { root /www/lol/; index index.html; } } # 创建404错误页面 echo \u0026#34;我是美丽的404错误页面，你访问的资源不存在该服务器上！！！请检查你的URL\u0026#34; \u0026gt; /www/lol/my404.html [root@web-8 ~]#nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful [root@web-8 ~]# [root@web-8 ~]# [root@web-8 ~]#systemctl restart nginx 再次测试错误页面，针对lol这个虚拟主机 404错误页面 从网站优化，用户体验角度设置的功能\n403错误的设置 1 指定跳转到另一个url， 403指定跳转到当前机器的一个文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [root@web-8 /etc/nginx/conf.d]#cat lol.linux0224.conf log_format main2 \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; server { access_log /var/log/nginx/lol.linux0224.cc.access.log main2; error_log /var/log/nginx/lol-error.log error; error_page 404 /my404.html; error_page 403 /my403.html; listen 80; server_name lol.linux0224.cc; charset utf-8; location / { root /www/lol/; index index.html; } } 最后的测试。403，和404页面优化 .\n内容回顾 web协议篇\ntcp/ip协议的，三次握手，四次挥手\nclient和server、之间会收发的数据包，wireshare去抓包看实际效果 发送的数据包的次数 以及数据包它的格式（tcp中对数据包设置的flag标志位） SYN建立连接的标志（对数据包的标记flag，表示本次数据包的作用） ACK 对上一次请求的确认回复。 FIN，发出一个终止tcp连接的请求的数据包 OSI七层模型，背诵出来（这个网络知识，前期你不会用到太多，基本的ip地址概念有就行，机器之间的网络通信概念，你需要找时间，课外时间，找点书看看。。）\n网络中的数据传递，是端对端的传递，机器A要基于OSI模型的数据发出，机器B也要基于OSI模型的数据接收\n从最底层的硬件，到mac地址，网线，到传输，应用层\n1.物理层\n硬件网卡，对电信号的字节流，进行接收，传递的。。 2.链路层，二层交换机，网桥（端对端的数据传递）\n网卡物理地址，mac地址，是全球唯一的网卡的唯一标号 3.网络层，IP地址就在这定义的，路由的指定（数据从A点传到B点的路线，路由，路由有下一跳的关键字）\n关键字，IP地址（局域网，私有网段，192.168.0.xx） 路由器（自动的寻找，设定路线，数据源从哪发，要发到那里去，中间这个路线怎么定义） 淮安的快递，寄到苏州 路由，淮安到苏州的路线（高德地图去看看） 淮安 \u0026gt; 扬州 \u0026gt; 南京 \u0026gt; 南通 \u0026gt; 昆山 \u0026gt; 苏州 （下一跳，下一跳的理念） 数据包的传输，从数据源发出，到下一跳（路由器），再到下一跳（路由器） 。。。（N个路由器），到达目的地 前三层，定义了网络的物理环境，网络硬件+网络地址环境\n从3.网络层建立连接后，后续的就是基于网络协议的数据传输了（协议就是控制数据包的传递格式，抓包工具可以看到这个数据包，被添加了很多字段，还都是有意义的）\n（简单理解就是你发的那个快递， 上面贴了一堆标签，严格定义，只能往哪个城市发，往哪个快递点发，发给那个小区，的谁。。数据包的封装）\n数据可以基于协议发送了，（传输层，用于建立tcp/ip的连接，并且是socket形式的连接，ip:port的端对端的数据交互）， 会话层（数据包的传递，本身是没有身份验证的，cookie技术，记录会话身份的） 表示层（基于复杂的逻辑处理， 图片的二进制数据的编码） 应用层（丰富的各种软件，工作在这一层，以HTTP为代表） 基于web协议通信的软件实践（nginx技术） server和client的web数据交互\nnginx的核心功能 nginx.conf最核心的几大块\n每一条语句结尾必须是分号结束\n以区段形式的配置参数，需要有闭合的花括号 {}\n不同作用域的配置参数，不能瞎嵌套\nserver{}是用于定义nginx的 http核心模块功能的子配置，必须防止在http{}括号中 写在http{}外层，与其同级，语法报错 include配置参数\n导入外部的配置文件，优化，简化主配置文件的格式 http{}利用include导入外部的 server{}配置 include得写在http{}花括号内，才表示给这个区域导入外部的配置文件 只针对http{}区域生效。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # /etc/nginx/nginx.conf # 导入外部的虚拟主机 http{ xxxxx; xxxxx; include /etc/nginx/extra/*.conf; } # 后续你就可以去创建单独的虚拟主机文件了 vim /etc/nginx/extra/my_blog.conf #写入虚拟主机配置 server { # 端口号 listen 80; # 域名匹配 server_name _; #不做域名匹配，只根据虚拟主机内的port去匹配 # 基于URL的匹配，在定位到具体的虚拟主机后，去哪找数据 # nginx强大的基于url处理用户请求吗，就是基于location来的 location / { # 定义网站根目录 root /www/myblog/; # 定义首页文件 index index.html; } } # 我们会有多个虚拟主机配置文件 vim /etc/nginx/extra/crm.conf server { # 端口号，端口一般不变，浏览器默认是80，用户都得主动添加这个端口 listen 80; # 域名匹配 server_name crm.linux0224.com; } nginx.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 user www; http{ 数据传输性能相关的参数; server{} 区域中主要定义 单个的网站的处理 网站的根目录，静态数据存放的地方 server{ 端口 域名匹配 URL处理 } 网站1 server{} 网站2 server{} 网站3 } 定义全局的一些关于http请求响应处理的参数 nginx支持多种日志\n访客日志\nclient给server发出请求，基于访问某一个URL来的 client请求报文发来了，包含了client的具体信息，服务端如何提取这些信息，以及后续的处理 nginx支持了大量的内置变量，提取这些请求报文中的数据。然后后续的处理。 错误日志 ","date":"2025-04-14T16:49:05+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/nginx%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%BB%BC%E5%90%88%E5%AE%9E%E6%88%98/","title":"Nginx虚拟主机综合实战"},{"content":"nginx虚拟主机，部署网站 为什么配置虚拟主机 一些草根流量站长,常会搭建个人站点进行资源分享交流,并且可能有多个不同业务的站点,如果每台服务器只运行一个网站,那么将造成资源浪费,成本浪费。\n利用虚拟主机的功能,就不用为了运行一个网站而单独配置一个Nginx服务器,或是单独再运行一组Nginx进程。\n虚拟主机可以在一台服务器,同一个Nginx进程上运行多个网站。 nginx.conf住配置文件中,最简单的一段虚拟主机配置如下\n单虚拟主机 只需要在http{}区域中，设置一个 server{}标签即可。\n1 2 3 4 5 6 7 8 9 10 11 12 部署一个 huoying.linux0224.cc 看到 /www/huoying/index.html 降低运行权限 [root@web-8 ~]#groupadd www -g 666 [root@web-8 ~]#useradd www -u 666 -g 666 -M -s /sbin/nologin [root@web-8 ~]#id www uid=666(www) gid=666(www) groups=666(www) 修改nginx.conf nginx.conf入口配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 user www;\t# 设置运行用户 worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; # include导入该目录下的*.conf配置文件 } 创建虚拟主机子配置文件 只需要写server{}标签即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # huoying.linux0224.cc # 吧数据放在 /www/huoying/index.html vim /etc/nginx/conf.d/huoying.linux0224.conf # 写入如下信息 server { listen 80; # nginx会匹配 http://huoying.linux0224.cc:80 server_name huoying.linux0224.cc; # 支持中文的参数 charset utf-8; location / { # 根据root参数，填写网页根目录信息 # 表示当你访问 http://huoying.linux0224.cc:80 ，自动来这个目录下找数据 root /www/huoying/; # 默认找 /www/huoying/ 的名字叫做index.html的文件 index index.html; } } # 创建网页静态文件，index.html 鸣人.jpg 鸣人与佐助的秘密.txt # 你部署一个静态网站，最基本的提供，html，jpg，txt等静态数据 # nginx都可以帮你去返回，解析请求 # mkdir -p /www/huoying cat \u0026gt; /www/huoying/index.html \u0026lt;\u0026lt;EOF \u0026lt;meta charset=utf-8\u0026gt; 我是火影页面，老六你好。 EOF cd /www/huoying ; wget -O 鸣人.jpg https://pics0.baidu.com/feed/d62a6059252dd42a57f830e3671230b2c8eab8b1.jpeg?token=df950341a2fc3467a01012e87e868f08 cd /www/huoying ; echo \u0026#39;佐助其实打不过鸣人\u0026#39; \u0026gt; 鸣人与佐助的秘密.txt # 修改静态文件的属主，属组 [root@web-8 /www/huoying]#chown -R www.www /www/ 测试nginx配置文件语法，然后启动 1 2 3 4 5 [root@web-8 /www/huoying]#nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful [root@web-8 /www/huoying]#systemctl restart nginx 根据域名访问该虚拟主机 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 你的本地添加好dns域名解析 分别添加二级域名，三级域名，hosts解析 10.0.0.8 huoying.linux0224.cc linux0224.cc 你可以先访问ip试试，通不通 [C:\\~]$ ping huoying.linux0224.cc 正在 Ping huoying.linux0224.cc [10.0.0.8] 具有 32 字节的数据: 来自 10.0.0.8 的回复: 字节=32 时间\u0026lt;1ms TTL=64 来自 10.0.0.8 的回复: 字节=32 时间\u0026lt;1ms TTL=64 来自 10.0.0.8 的回复: 字节=32 时间\u0026lt;1ms TTL=64 来自 10.0.0.8 的回复: 字节=32 时间\u0026lt;1ms TTL=64 10.0.0.8 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)， 往返行程的估计时间(以毫秒为单位): 最短 = 0ms，最长 = 0ms，平均 = 0ms 该测试域名是没问题，浏览器直接访问即可， 有时候如果出现故障，检查你本地是否设置了代理。关闭即可。。、 html文件资源 图片资源 普通txt文件资源 如果是其他类型的文件，nginx默认不解析，直接下载 1 2 3 4 直接生成静态数据，不用重启nginx，这就是磁盘上的一些静态数据 nginx的server{}虚拟主机，以及设置了，去这个目录下搜索资料 nginx默认不识别这个test.ttt格式的文件，因此直接下载了 nginx识别的文件类型都在这个文件里定义好了 1 2 3 [root@web-8 /www/huoying]#cat /etc/nginx/mime.types 只有这个文件中定义的文件类型，nginx默认可以识别处理 nginx多个server同时监听同一端口号 1 当出现这种情况时，nginx首先会按照server_name来选择对应的server，然后会按照nginx.conf中http{}中server{}的定义先后顺序来决定哪个server， IP多虚拟主机 1 2 3 给指定的网卡，绑定多个ip地址 # 这个命令是临时添加一个ip ip addr add 10.0.0.88/24 dev eth0 修改虚拟主机，绑定多个ip 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 vim /etc/nginx/conf.d/88.conf # 指定绑定ip地址的配置文件 [root@web-8 /etc/nginx/conf.d]#nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration fil e /etc/nginx/nginx.conf test is successful [root@web-8 /etc/nginx/conf.d]#ls 88.conf huoying.linux0224.conf [root@web-8 /etc/nginx/conf.d]#cat 88.conf server { listen 10.0.0.88:80; server_name _; location / { root /www/80/; index index.html; } } # 创建测试数据 [root@web-8 /etc/nginx/conf.d]#mkdir -p /www/80/ [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#echo \u0026#39;I am 10.0.0.88 server. welcome my linux\u0026#39; \u0026gt; /www/80/index.html [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]# [root@web-8 /etc/nginx/conf.d]#systemctl restart nginx 测试基于ip的虚拟主机 1 2 3 4 1. 当你访问 10.0.0.8 或者 huoying.linux2004.cc 看到的是/etc/nginx/conf.d/huoying.linux0224.conf这个虚拟主机的内容 2. 当你访问，基于指定ip访问，看到的/etc/nginx/conf.d/88.conf的内容 给这个指定的IP，绑定一个测试域名 1 2 3 4 5 修改本地hosts 10.0.0.88 88.linux0224.cc 访问该域名也是可以通的，因为依然是基于绑定的socket地址匹配的该虚拟主机文件 http://88.linux0224.cc/ 多域名虚拟主机 1 2 3 4 5 6 dnf.linux0224.cc /www/lol/index.html lol.linux0224.cc /www/lol/index.html 俩域名，就得分俩配置文件更合适些，表示是2个站点 创建各自的配置文件 dnf.linux0224.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@web-8 /etc/nginx/conf.d]#touch dnf.linux0224.conf 分别写入配置 ，基于域名的虚拟主机，这样写 server { listen 80; server_name dnf.linux0224.cc; # 这里写的是域名 charset utf-8; location / { root /www/dnf/; index index.html; } } lol.linux0224.conf\n1 2 3 4 5 6 7 8 9 10 11 server { listen 80; server_name lol.linux0224.cc; charset utf-8; location / { root /www/lol/; index index.html; } } 创建两个数据目录即可\n1 2 3 4 5 6 7 8 9 mkdir -p /www/{lol,dnf} # 分别创建测试数据 echo \u0026#39;人在塔在，人在linux在\u0026#39; \u0026gt; /www/lol/index.html echo \u0026#39;勇士，好好学习linux，你就是最帅的\u0026#39; \u0026gt; /www/dnf/index.html [root@web-8 /etc/nginx/conf.d]#systemctl restart nginx 重启nginx，查看各自的网站 1 2 3 4 5 6 7 8 9 10 还差什么步骤吗？ 还差客户端机器上的 域名解析 10.0.0.8 huoying.linux0224.cc linux0224.cc lol.linux0224.cc dnf.linux0224.cc http://lol.linux0224.cc/ http://dnf.linux0224.cc/ 多端口虚拟主机 1 2 3 4 除了支持 - 绑定域名 - 绑定ip - 绑定多个端口，的虚拟主机 配置文件如下\n在一个配置文件中，定义多个虚拟主机\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 vim /etc/nginx/conf.d/port.conf # 平级 server { listen 10.0.0.8:81; server_name _; charset utf-8; location / { root /www/data81/; index index.html; } } # 平级 server { listen 10.0.0.8:82; server_name _; charset utf-8; location / { root /www/data82/; index index.html; } } # 创建测试数据， mkdir -p /www/{data81,data82} cd /www/data81 ; echo \u0026#34;我是81，你是老六\u0026#34; \u0026gt; /www/data81/index.html cd /www/data82 ; echo \u0026#34;我是82，你是秘制小汉堡\u0026#34; \u0026gt; /www/data82/index.html 验证整个配置文件，和数据目录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@web-8 /www/data82]#tree -N /www/ /www/ ├── 80 │ └── index.html ├── data81 │ └── index.html ├── data82 │ └── index.html └── huoying ├── index.html ├── test.ttt ├── 鸣人.jpg └── 鸣人与佐助的秘密.txt 配置文件 [root@web-8 /www/data82]#tree -NF /etc/nginx/conf.d/ /etc/nginx/conf.d/ ├── 88.conf ├── huoying.linux0224.conf └── port.conf 重启服务，查看是否生效\n1 2 3 4 5 6 7 [root@web-8 /www/data82]#systemctl restart nginx [root@web-8 /www/data82]#netstat -tunlp |grep nginx tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 4563/nginx: master tcp 0 0 10.0.0.8:81 0.0.0.0:* LISTEN 4563/nginx: master tcp 0 0 10.0.0.8:82 0.0.0.0:* LISTEN 4563/nginx: master 测试访问81和82页面 反向代理，负载均衡，就有用了，可以基于虚拟主机，实现多台服务器运行的多个网站\n1 2 3 4 指定端口号才行 http://10.0.0.8:82/ http://10.0.0.8:81/ ","date":"2025-04-14T16:48:59+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/nginx%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA/","title":"Nginx虚拟主机"},{"content":"web服务器介绍 Web服务器常指的是(world wide web,www)服务器、也是HTTP服务器，主要用于提供网上信息测览。我们大部分人接触互联网，都基本上是通过浏览器访问互联网中各种资源。\nWeb网络服务是一种被动访问的服务程序，即只有接收到互联网中其他主机发出的请求后才会响应，最终用于提供服务程序的Web服务器会通过HTTP(超文本传输协议)或HTTPS(安全超文本传输协议)把请求的内容传送给用户\nUnix和Linux平台下的常用Web服务器常见有：\nApache Nginx Lighttpd Tomcat IBM WebSphere 其中最为广泛的是Nginx,在Windows平台上最常用的是微软的IS(Internet Information Server,互联网信息服务)是Windows系统中默认的Web服务程序。\nnginx 介绍 Nginx是俄罗斯人lgor Sysoev(伊戈尔·塞索耶夫)开发的一款高性能的HTTP和反向代理服务器。\nNginx以高效的epoll,kqueue,eventport作为网络IO模型，在高并发场景下，Nginx能够轻松支持5w并发连接数的响应，并且消耗的服务器内存、CPU等系统资源消耗却很低，运行非常稳定。\n1 2 3 4 5 6 7 8 9 10 11 当前想让nginx支持5万并发，甚至百万级的并发，都是可以的，但需要做很多的优化工作，如 想至少支持5万并发的基本调优 1.服务器内存、CPU硬件支持，如8核16线程、32G内存的服务器 2.磁盘使用SSD、或者购买至少15000转的SAS企业级硬盘，做成RAID 0 3.安装光纤网口 4.使用Linux系绕，如centos7,优化内核参数，对TCP连接的设置 5.优化nginx.conf中井发相关的参数，如： worker_processes 16 worker_connections 50000; 6. ...... 国内著名站点，新浪博客、网易、淘宝、豆瓣、迅雷等大型网站都在使用Nginx作为Web服务器或是反向代理服务器\n在线自动生成nginx配置文件 https://www.digitalocean.com/community/tools/nginx?global.app.lang=zhCN\n可以自由选择所需的应用，生成nginx配置作为参考。\n1 根据你的业务需求，自动生成复杂的nginx配置文件，提供你作为参考，非常好用 nginx企业用它干啥 1 2 3 4 5 1.提供静态页面展示，网页服务 2.提供多个网站、多个域名的网页服务 3.提供反向代理服务（结合动态应用程序） 4.提供简单资源下载服务（密码认证） ftp服务 5.用户行为分析（日志功能） nginx的运行架构 nginx是多进程架构，当启动nginx会使用root创建master进程，由master进程创建多个Worker进程\n1 2 3 4 5 6 7 8 9 10 11 nginx运行后，是多进程，调用多个cpu去解析用户的请求 在linux中进行多进程开发，开辟多个进程，调用多个cpu，当然也会消耗更多的机器资源，内存，cpu资源，给服务器带来更大的压力 - 不是说进程越多，干活越快，合理的分配，才能达到最高效的处理效率 ===== 有一个屋子要装修，请1个工人干活，还是请5个工人干活，请500个工人干活 哪一个效率是最高的呢？ 最合适的？ ===== 关于nginx的优化设置，nginx默认应该启动多少个进程去工作呢？ 默认就是根据cpu的核数去设置进程数即可。 master进程 包工头进程，管理nginx的数据，创建worker工作进程。\n1 2 3 4 5 1.启动时检查nginx.conf是否正确，语法错误； 2.根据配置文件的参数创建、且监控worker进程的数量和状态； 3.监听socket，接收client发起的请求，然后worker竞争抢夺链接，获胜的可以处理且响应请求。 4.接收运维人员发送的管理nginx进程的信号，并且将信号通知到worker进程。 5.如果运维人员发送了reload命令，则读取新配置文件，创建新的worker进程，结束旧的worker进程。 简单测试：reload重新加载进程，worker-pid会变化吗\nworker进程 1 2 3 4 5 1.实际处理client网络请求的是worker 2.master根据nginx.conf决定worker的数量 3.有client用户请求到达时，worker之间进程竞争。获胜者和client建立连接且处理用户请求： 4.接收用户请求后，若需要代理转发给后端，则后端处理完毕后接收处理结果，再响应给用户 5.接收并处理master发来的进程信号，如启动、重启、重载、停止 nginx进程通信 ![屏幕截图 2024-09-26 085527](assets/屏幕截图 2024-09-26 085527.png)\nnginx处理http请求流程 nginx模块介绍 1 利用nginx -V 命令可以看到当前操作的这个命令二进制命令，详细的信息，包括支持了哪些模块 nginx安装实践 nginx的安装形式 源代码编译安装，优点\nBuilding nginx from Sources 版本，可以获取官网最新的软件包，甚至最新测试版，都可以直接编译安装 还有稳定版本 自由定义，安装路径自由定义， 自由定义第三方插件 缺点，安装步骤繁琐，耗时太长，看你要装多少个模块，编译添加的模块多，安装的就更久 rpm安装\n得提前准备好nginx本身的rpm包，以及相关依赖的rpm包 用于离线安装nginx的环境 yum安装\n阿里云第三方仓库（centos-base.repo,epel.repo） 这个其实都不靠谱。 自建yum仓库（得提前准备好nginx本身的rpm包，以及相关依赖的rpm包） nginx官网仓库（获取官网最新稳定版的yum源仓库） yum一键安装，省心省事，版本也是有一定的保障的，rpm的安全性也是有保障的 yum安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 1. 配置官网yum源，一键安装即可 cat \u0026gt; /etc/yum.repos.d/nginx.repo \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; [nginx-stable] name=nginx stable repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=1 enabled=1 gpgkey=https://nginx.org/keys/nginx_signing.key EOF 2.清空yum源，安装最新版nginx [root@web-8 /etc/yum.repos.d]#yum clean all [root@web-8 /etc/yum.repos.d]#yum install nginx -y 3.查看PATH变量 [root@web-8 /etc/yum.repos.d]#which nginx /usr/sbin/nginx [root@web-8 /etc/yum.repos.d]#ll /usr/sbin/nginx -rwxr-xr-x 1 root root 1377720 Nov 16 2021 /usr/sbin/nginx [root@web-8 /etc/yum.repos.d]#nginx -V nginx version: nginx/1.20.2 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt=\u0026#39;-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC\u0026#39; --with-ld-opt=\u0026#39;-Wl,-z,relro -Wl,-z,now -pie\u0026#39; nginx管理命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 nginx -t # 检测nginx.conf语法 nginx -s reload # 重新读取nginx.conf nginx -s stop # 停止nginx kill -15 nginx nginx # 默认是直接运行，前提是当前机器没运行nginx #你通过yum安装的nginx请你用systemctl去管理 # 不能多次执行nginx二进制命令 [root@web-8 ~]# [root@web-8 ~]#nginx [root@web-8 ~]#nginx # 会报错 # nginx -s reload ,会发生什么 nginx -s reload是给master进程发信号，重新读取配置信息，导致worker重新生成，因此worker-pid发生了变化 但是master进程id不带变化的（包工头，一直没变，更换了手底下的干活的工人） ================================ 配置文件变化，就好比 合同变化了（包工头还是他，但是工人更换了一批） =========== 只有你restart的时候，包工头，也会被更换 你只能先停止， 再重启 nginx -s stop ============================== 如果出现如下错误，如何解决，其实是通过pid，管理nginx的进程 ~]#nginx -s stop nginx: [error] invalid PID number \u0026#34;\u0026#34; in \u0026#34;/var/run/nginx.pid\u0026#34; [root@web-8 ~]#cat /var/run/nginx.pid [root@web-8 ~]#ps -ef |grep nginx root 3599 1 0 16:10 ? 00:00:00 nginx: master process nginx nginx 3628 3599 0 16:12 ? 00:00:00 nginx: worker process root 3677 3434 0 16:19 pts/0 00:00:00 grep --color=auto nginx [root@web-8 ~]#echo 3599 \u0026gt; /var/run/nginx.pid [root@web-8 ~]#nginx -s stop [root@web-8 ~]#!ps ps -ef |grep nginx root 3686 3434 0 16:19 pts/0 00:00:00 grep --color=auto nginx [root@web-8 ~]# # 明确，现在用systemctl去管理nginx了 [root@web-8 ~]#systemctl start nginx 查看状态，reload， restart nginx，查看进程id号 [root@web-8 ~]#systemctl status nginx [root@web-8 ~]#systemctl reload nginx # worker变化，master不变 [root@web-8 ~]#systemctl restart nginx # 整个nginx进程变化 # 总结：用什么命令启动的，就用什么方式去管理该进程 nginx配置文件详解 1 2 3 安装完了之后，后续nginx的所有功能，都是围绕着修改nginx配置文件生效了 看懂配置文件，运维来说，达到手写nginx配置文件，才是合格的。 通过官网yum仓库默认安装的nginx.conf 位置在/etc/nginx/nginx.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } ~ ","date":"2025-04-14T16:48:49+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/nginx%E5%9F%BA%E7%A1%80%E7%AF%87/","title":"Nginx基础篇"},{"content":"正式进入网站部署的学习 web通信流程 在开始学web服务器之前，需要先理解web通信协议，才能够更好的吸收其中精华。\n我们平时浏览网页的时候，会打开浏览器，输入网址后按下回车键，然后就会显示出你想要浏览的内容。在这个看似简单的用户行为背后，到底隐藏了些什么呢?\n浏览器本身是一个客户端，当你输入URL的时候，首先浏览器会去请求DNS服务器，通过DNS获取相应的域名对应的IP 然后通过IP地址找到IP对应的服务器后，要求建立TCP连接 等浏览器发送完HTTP Request(请求)包后，服务器接收到请求包之后才开始处理请求包 服务器调用自身服务，返回HTTP Response(响应)包； 客户端收到来自服务器的响应后开始渲染这个Response包里的主体(body),等收到全部的内容随后断开与该服务器之间的TCP连接。 web服务器工作原理 Web服务器的工作原理可以简单地归纳为：\n客户端通过TCP/IP协议建立到服务器的TCP连接 客户端向服务器发送HTTP协议请求包，请求服务器里的资源文档 服务器向客户端发送HTTP协议应答包，如果请求的资源包含有动态语言的内容，那么服务器会调用动态语言的解释引擎负责处理“动态内容”,并将处理得到的数据返回给客户端 客户端与服务器断开。由客户端解释HTML文档，在客户端屏幕上渲染图形结果 客户端请求到达服务端流程 当客户端拿到服务端域名对应的ip后，浏览器会以一个随机端口(1024\u0026lt;随机端口\u0026lt;65535)向服务器的web程序(nginx,apache)的80端口发起tcp连接请求。 该请求经过复杂的网络环境后到达服务端，进入到服务器的对应的网卡，再进入到Linux内核的tcp/ip协议栈，一层一层的解开数据包，甚至经过防火墙，最终到达nginx程序，确认tcp/ip连接。 确认tcp连接之后，客户端继续发起http请求，如常见的get,post请求方法。 TCP/IP协议 传输控制协议(TCP,Transmission Control Protocol)是一种面向连接的，可靠的、基于字节流的传输层通信协议。\n简单说就是TCP协议就是控制数据包在传过过程中的规范格式。 IP是Internet Protocol(网际互连协议)的缩写，是TCP/IP体系中的网络层协议。\n设计IP的目的是捉高网络的可扩展性：一是解决互联网问题，实现大规模、异构网络的互联互通；二是分割顶层网络应用和底层网络技术之间的耦合关系，以利于两者的独立发展。 根据端到端的设计原则，IP只为主机提供一种无连接、不可靠的、尽力而为的数据包传输服务。\nTCP（传输控制协议）和 IP（网际协议）是互联网协议套件（通常称为 TCP/IP 套件）的两个核心组件，它们各自承担不同的职责，但紧密合作以实现网络通信。以下是它们的关系和各自的功能：\nIP 协议 功能：\n寻址和路由： IP 协议负责将数据包从源地址传送到目标地址。它使用 IP 地址来标识网络上的设备，并通过路由器在不同网络之间转发数据包。 数据封装： 在 IP 层，数据被封装成 IP 数据包，包含源和目标 IP 地址以及其他控制信息。 无连接服务： IP 提供无连接的数据传输服务，即每个数据包独立传输，路由器对每个数据包进行独立处理，数据包可能通过不同路径到达目的地。 特点：\n不可靠传输： IP 不保证数据包的交付顺序、完整性或可靠性。数据包可能丢失、重复或乱序到达。 最佳传送： IP 尽力而为地传送数据，但不提供错误恢复机制。 TCP 协议 功能：\n可靠传输： TCP 提供可靠的数据传输服务，通过确认机制和重传机制确保数据包按顺序、无误地到达目的地。 流量控制： TCP 使用流量控制机制（如滑动窗口）来调整发送方的发送速率，防止接收方的缓冲区溢出。 拥塞控制： TCP 实现拥塞控制算法（如慢启动和拥塞避免）来防止网络拥塞。 数据分段和重组： TCP 将应用层数据分割成适当大小的段（segment），并在接收方重组这些段以恢复原始数据流。 面向连接： TCP 是面向连接的协议，在传输数据之前，需要建立一个 TCP 连接（三次握手），传输结束后需要断开连接（四次挥手）。 特点：\n可靠性： TCP 保证数据的可靠传输，提供错误检测和纠正机制。 顺序性： TCP 保证数据按发送顺序到达接收方。 TCP 和 IP 的关系 层次关系：\nIP 协议 位于网络层，负责数据包的路由和传输。 TCP 协议 位于传输层，建立在 IP 之上，提供可靠的端到端通信。 封装关系：\n在发送数据时，应用层数据首先通过 TCP 封装成 TCP 段，然后再通过 IP 封装成 IP 数据包。最终，数据包通过链路层协议（如 Ethernet）传输。 在接收数据时，链路层首先解封装成 IP 数据包，然后 IP 层解封装成 TCP 段，最后传递给应用层。 协同工作：\nIP 负责将数据包从一个网络节点传送到另一个网络节点，不关心数据的内容和可靠性。 TCP 负责确保数据在两个端点之间可靠传输，处理数据的分段、重组、错误检测和纠正。 举例说明 假设你在浏览器中访问一个网页：\n应用层（HTTP）：浏览器发送一个 HTTP 请求。 传输层（TCP）：HTTP 请求被 TCP 封装成 TCP 段，TCP 负责建立连接、保证数据可靠传输。 网络层（IP）：TCP 段被 IP 封装成 IP 数据包，IP 负责将数据包路由到目标服务器。 链路层（Ethernet 等）：IP 数据包被进一步封装并通过物理网络传输。 在目标服务器上，这个过程逆向进行，最终将 HTTP 响应传递回浏览器。\n总结 TCP 和 IP 协议各自承担不同的职责，IP 负责基本的网络数据传输和路由，而 TCP 在 IP 之上提供可靠的端到端通信服务。它们共同构成了互联网通信的基础，确保数据能够在全球范围内高效、安全地传输。\nTCP/IP协议指的不仅仅是top、和ip这两个协议。\n而是由FTP、SMTP、TCP、UDP、IP等各种协议组成的协议簇，但是TCP/IP最最具有代表性，因此俗称TCP/IP协议。\nOSI七层网络模型 OSI（开放系统互连）模型是一个抽象的网络通信参考模型，由国际标准化组织（ISO）制定，用于描述网络系统之间通信的标准框架。OSI 模型将网络通信过程分为七个层次，每一层都有特定的功能和职责。以下是对 OSI 七层模型的详细描述：\n1. 物理层（Physical Layer） 功能：\n负责在物理媒体上传输原始的比特流（0 和 1）。 定义硬件设备的电气、机械、功能和规程特性，如电缆类型、信号电压、电缆连接器、传输速率等。 示例：\n网络接口卡（NIC）、集线器（Hub）、电缆（如光纤、电缆）。 2. 数据链路层（Data Link Layer） 功能：\n负责节点间的可靠数据传输，处理物理层上可能出现的传输错误。 将数据帧（Frame）传输到相邻节点，并进行帧的同步、流量控制和错误检测与纠正。 分为两个子层：逻辑链路控制（LLC）和媒体访问控制（MAC）。 示例：\n以太网（Ethernet）、Wi-Fi、交换机（Switch）。 3. 网络层（Network Layer） 功能：\n负责数据包（Packet）的路由和转发，决定数据包从源到目的地的最佳路径。 处理网络地址转换和逻辑地址（IP 地址）分配。 示例：\nIP（Internet Protocol）、路由器（Router）。 4. 传输层（Transport Layer） 功能：\n提供端到端的通信服务，确保数据的完整性和可靠传输。 负责数据分段、重组、流量控制和错误恢复。 提供面向连接（TCP）和无连接（UDP）的服务。 示例：\nTCP（Transmission Control Protocol）、UDP（User Datagram Protocol）。 5. 会话层（Session Layer） 功能：\n管理和控制应用程序之间的会话，建立、维护和终止会话连接。 负责会话的同步和恢复，管理对话控制。 示例：\nRPC（Remote Procedure Call）、SIP（Session Initiation Protocol）。 6. 表示层（Presentation Layer） 功能：\n负责数据的格式化、加密和解密、压缩和解压缩。 确保数据的语法和语义能够被接收方正确理解。 示例：\nSSL/TLS（用于加密）、JPEG（图像格式）、MPEG（视频格式）。 7. 应用层（Application Layer） 功能：\n提供网络服务和应用程序接口，直接为用户或应用程序提供服务。 处理特定的网络应用协议，如电子邮件、文件传输和远程登录等。 示例：\nHTTP（HyperText Transfer Protocol）、FTP（File Transfer Protocol）、SMTP（Simple Mail Transfer Protocol）、DNS（Domain Name System）。 OSI 模型的作用 标准化： 提供了一个通用的参考框架，帮助不同厂商和开发者创建兼容的网络设备和协议。 模块化： 各层次独立且互相协作，便于理解和实现复杂的网络通信功能。 故障排除： 分层模型有助于定位和解决网络问题，明确问题出现在哪一层。 互操作性： 促进不同网络和设备之间的互操作性和兼容性。 抓包工具，查看TCP/IP的三次握手 经典的问题，你了解TCP/IP的三次握手、四次挥手吗？\n具体数据包的报文格式，暂时不用过多去琢磨；\n什么时候需要琢磨数据包的序列号，只有当你在生产环境下，遇见的及其棘手的问题，比如一些数据不同步，交易数据丢失等极端情况，需要去抓取数据包，逐个分析，数据包的完整性，序列号。\n目前只需要大致了解数据包的类型，以及作用即可；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1. 抓取ssh登录的数据包，查看 tcp/ip协议基础之上的 SSH应用层协议 登录web-7机器 windows(192.168.xx.xx) ↓ vmnet8(nat虚拟网卡，10.0.0.1) ↓ web-7(nat 10.0.0.7) 两个ip:port的数据包交互 10.0.0.1:随机端口 \u0026gt; 10.0.0.7:22 wireshark大鲨鱼抓包工具查看ssh登录数据包收发情况 在window去登录 web-7 ssh远程连接，也是建立的tcp/ip的三次握手之上 1 2 3 4 5 6 7 8 9 10 2. 查看网站访问的数据包，基于 tcp/ip 基础之上的 HTTP应用层协议 由于捕捉的是 vmnet8的网卡流量，检测http协议，只能给这个网段内的机器，发http请求 这里需要注意，如果你多次访问nginx，你可能会抓不到默认的tcp三次握手 tcp三次握手，是用于首次连接的 访问nginx页面的请求，第一次以及建立好连接，默认会有一个保持连接 你后续的请求，。就不会再继续tcp三次握手，而是直接发送http请求 你和nginx服务器已经建立好tcp连接了。 使用firefox另一个浏览器，重新去建立tcp连接 总结\n抓包工具，查看四次挥手 1 先建立ssh连接，然后退出ssh会话，查看是否发出tcp/ip 的四次挥手，四个数据包 ![img](file:///C:\\Users\\Administrator\\Documents\\Tencent Files\\1599185635\\Image\\C2C\\3437f8bb7ab6c36f7a003767933167d9.jpg)\n1、MSL是什么\nMSL是Maximum Segment Lifetime的英文缩写，可译为“最长报文段寿命”，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。\n2、为何等待2MSL\n（1）为了保证客户端发送的最后一个ACK报文段能够到达服务器。\n因为这个ACK有可能丢失，从而导致处在 LAST-ACK 状态的服务器收不到对 FIN-ACK 的确认报文。服务器会超时重传这个FIN-ACK，接着客户端再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。即：保证客户端发送的最后一个ACK报文段能够到达服务端。\n这个ACK报文段有可能丢失，使得处于 LAST-ACK 状态的B收不到对已发送的 FIN+ACK 报文段的确认，服务端超时重传 FIN+ACK 报文段，而客户端能在2MSL时间内收到这个重传的FIN+ACK 报文段，接着客户端重传一次确认，重新启动2MSL计时器，最后客户端和服务端都进入到 CLOSED 状态，若客户端在 TIME-WAIT 状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到服务端重传的 FIN+ACK 报文段，所以不会再发送一次确认报文段，则服务端无法正常进入到 CLOSED 状态。\n（2）防止“已失效的连接请求报文段”出现在本连接中。\n客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生 的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。\nTCP连接状态报文 面试时候拿出来背诵即可\n1 CLOSE没有任何连接状态\n2 LISTEN监听状志，等待来自TCP的连接请求\n3 SYN-5ENT发送连接请求后，等待对方确认\n4 SYN-RECEIVED收到、发送一个连接请求后，等待对方确认\n5 ESTABLISHED代表传输连接已经建立，双方进入数据传输状态\n6 FIN-HAIT-1主动关闭1,主机己发送关闭连接请求，等特对方确认\n7FIN-HAIT-2主动关闭2,主机己收到对方关闭传输连接的确认，等待对方发送关闭传输连接请求\n8 TINE-WAIT完成双向传输连接关闭，等待服务端最终确认\n9 CLO5E-WAIT被动关闭连接。收到对方发来的关闭连接请求，且己经确认。\n10 LAST-ACK被动关闭，等待最后一个关闭传输连接的确认。\n11 CLOSE双方同时确认了关闭传输连接\n常见端口号 常用的熟知端口号 应用程序 FTP TFTP TELNET SMTP DNS HTTP SSH MYSQL 熟知端口 21,20 69 23 25 53 80 22 3306 传输层协议 TCP UDP TCP TCP UDP TCP TCP TCP 什么是socket套接字 1 2 3 4 5 6 7 8 任何，两个机器的连接，指的是tcp/ip协议的连接，本质上是两个socket的通信 socket套接字就是 ip+port的具象化 比如部署nginx服务，运行在 10.0.0.7:80 端口，这就是一个socket 通过本地去访问这个socket，浏览器随机指定的端口，发出请求 10.0.0.1:61145 这个也是一个socket 网络套接字 套接字存在的意义，在于让两端进行数据交互，数据传输，部署LNMP，这是不同机器之间的远程访问，就是远程socket\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 比如 http协议的交互 10.0.0.1:61145 \u0026gt; 10.0.0.7:80 马上学习nginx反向代理，远程部署 lb-5 10.0.0.5:80 ↓ web-7 10.0.0.7:9000 (php-fpm) 叫做远程的socket通信 简单说就是你部署 10.0.0.5:80 这个服务，还会和远程的另一个服务通过网络通信 10.0.0.7:9000 两端进行数据交互，专业名词就叫做socket通信 本地套接字 比如单机LNMP，应用程序在机器内部内存之间数据交互\n1 2 3 4 5 6 7 8 9 10 11 12 另一个形式是，也就是文件形式的本地socket （因为本地内存文件socket形式，比网络socket传输效率更高，） 在后面高级部分，我教大家企业常用的python后端部署 socket的都是具象化证明服务的确运行了，可以对外提供访问了，可以交互了 mysql运行在 /tmp/mysql.sock 这个文件存在，则表示mysql运行 你可以通过这个/tmp/mysql.sock去登录mysql数据库 咱们暂时部署形式都是 网络socket形式，将程序部署在 ip：port的形式。 HTTP协议工作原理 这些内容，都是你部署网站，后续的nginx高级知识点，必备的内容\n无状态（stateless）和cookie http默认不会记住每一次连接的状态信息，下一次都会认为是一个新的客户端连接\n1 2 3 4 5 6 7 8 比如你去找到禁用浏览器的cookie功能， 1.你去禁用这个功能后 2. 你每次登录淘宝网， 再打开一页面，网站又提示你需要登录 。。 cookie功能这是网站为了解决无状态实现的技术 这种无状态设计是为了保证HTTP可以处理大量的请求响应\n请求方法 定义client发给server的请求，是什么类型\n序号 方法 描述 1 GET 从服务器获取资源。用于请求数据而不对数据进行更改。例如，从服务器获取网页、图片等。 2 POST 向服务器发送数据以创建新资源。常用于提交表单数据或上传文件。发送的数据包含在请求体中。 3 PUT 向服务器发送数据以更新现有资源。如果资源不存在，则创建新的资源。与 POST 不同，PUT 通常是幂等的，即多次执行相同的 PUT 请求不会产生不同的结果。 4 DELETE 从服务器删除指定的资源。请求中包含要删除的资源标识符。 5 PATCH 对资源进行部分修改。与 PUT 类似，但 PATCH 只更改部分数据而不是替换整个资源。 6 HEAD 类似于 GET，但服务器只返回响应的头部，不返回实际数据。用于检查资源的元数据（例如，检查资源是否存在，查看响应的头部信息）。 7 OPTIONS 返回服务器支持的 HTTP 方法。用于检查服务器支持哪些请求方法，通常用于跨域资源共享（CORS）的预检请求。 8 TRACE 回显服务器收到的请求，主要用于诊断。客户端可以查看请求在服务器中的处理路径。 9 CONNECT 建立一个到服务器的隧道，通常用于 HTTPS 连接。客户端可以通过该隧道发送加密的数据。 请求、响应报文查看 通过F12即可查看，也可以通过抓包工具查看\n响应状态码 1 2 3 4 5 6 1. 当你client 发出 get请求 获取一个图片信息 ，发出requests 2. server 响应结果，nginx找到这个图片，返回给用户， response 响应信息，是有对应的状态码的 学习nginx会遇见的内容 20x系列，表示请求，响应正常解析 30x系列，表示本次请求，被转发到另一个服务器上了。。 40x系列，表示client客户端访问的url有问题，该资源不存在 50x系列，表示网站的服务端出错了（php-fpm）没有运行 \u0026hellip;\u0026hellip; 总结梳理 面试拿出来背即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 1.dns篇 用户访问域名www.bzit.cn ↓ 浏览器跳转 ↓ 浏览器缓存（disk cache） ↓ Hosts文件 ↓ 本地DNS服务器（递归查询 \u0026gt; 迭代查询） ↓ client 向 server发起查询（递归查询） server 向 server发起查询（迭代查询） 2.TCP/IP协议篇（三次握手） client \u0026gt; SYN报文，请求连接 server \u0026gt; SYN，ACK报文 响应client client \u0026gt; ACK，建立连接 3.客户端发起http请求 - 请求方法是什么、get、post、delete - 请求主机是什么、www.bzit.cn - 请求资源是什么 、 http://bzit.cn:8090/upload/2022/05/Xnip2022-05-01_16-32-30-b82235c9b62c42af8ea25e0313ca42f7.jpg - 请求端口是什么、默认http是80、https是443 - 请求参数是什么、请求头部信息（资源类型、是否压缩、cookie、浏览器客户端等） - 请求信息最后的换行 4.服务端响应的内容 - server信息（web服务器软件类型） - 响应文件类型 - 响应头部信息（是否压缩，语言编码，是否保持连接等） 5.客户端发起TCP四次挥手断开连接。 client \u0026gt; 发起断开请求 FIN=1 server \u0026gt; 响应断开 FIN、ACK server \u0026gt; 发起断开请求 FIN=1 client \u0026gt; 确认断开连接 ACK ","date":"2025-04-14T16:48:29+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/web%E5%9F%BA%E7%A1%80%E5%8D%8F%E8%AE%AE/","title":"Web基础协议"},{"content":"role的官网介绍 Roles — Ansible Community Documentation\n为什么用role 1 2 3 4 5 6 7 8 9 10 11 12 把单个的大剧本，拆分为小剧本，便于维护，修改、使用 完成解耦、结构更清晰、调试更方便 如果是小部署， 还是剧本更方便 大型项目，必须通过role管理 在实际的工作当中，一个完整的项目实际上是很多功能体的组合，如果将所有的功能写在一个playbook中会存在如代码耦合程度高、playbook长而维护成本大、灵活性低等一系列的问题。 使用roles能巧妙的解决这一系列的问题。 roles是ansible1.2版本后加入的新功能，适合于大项目playbook的编排架构。 具体role的用法 role（角色）用于层次化、结构化的组织多个playbook. role主要的作用是可以单独的通过一个有组织的结构，通过单独的目录管理如变量、文件、任务、模块等，并且可以通过include导入使用这些目录。 roles主要依赖于目录的命名和摆放，默认tasks/main.yml是所有任务的入口，使用roles的过程也可以认为是目录规范化命名的过程 roles每个目录下均由main.yml定义该功能的任务集，tasks/main.yml默认执行所有定义的任务； roles目录建议放在ansible.cfg中\u0026quot;roles_path\u0026quot;定义的目录下. 使用role的好处： 1 2 3 4 5 6 7 1.难度会大大降低 role理念就是把你以前部署的playbook进行拆分，拆成固定的目录格式 2. 你来了新任务，直接基于role去部署 等于 ad-hoc 临时命令 再去写成palybook 创建role的规范目录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 1.定义好role存放路径 [root@master-61 ~]#vim /etc/ansible/ansible.cfg [root@master-61 /etc/ansible]#grep \u0026#39;^role\u0026#39; /etc/ansible/ansible.cfg roles_path = /etc/ansible/roles [root@master-61 ~]#mkdir -p /etc/ansible/roles 2. 创建role的固定目录 # baizhi.com ansible-role site.yml # role入口 nfs_servers.yml # role入口 rsync_servers.yml # role入口 roles/ # role规范目录结构 nfs_servers/ # role具体名字 tasks/ # 剧本任务 handlers/ # 剧本里存放的handlers files/ # 如压缩文件，如需要拷贝的文件 templates/ # 存放配置文件 vars/ # 存放变量文件 rsync_servers/ tasks/ handlers/ files/ templates/ vars/ 3. 这里定义的文件名，必须和roles目录下的每一个任务目录同名 [root@master-61 ~]#touch /etc/ansible/{site.yml,nfs_servers.yml,rsync_servers.yml} 4. 创建关于rsync_servers的目录 [root@master-61 ~]#mkdir -p /etc/ansible/roles/rsync_servers/{tasks,handlers,files,templates,vars} 5.检查创建好的目录结构 [root@master-61 /etc/ansible]#tree /etc/ansible/ /etc/ansible/ ├── ansible.cfg ├── hosts ├── nfs_servers.yml ├── roles │ └── rsync_servers │ ├── files # 指的是目录中，存放剧本运行需要用到的文件 │ ├── handlers │ ├── tasks │ ├── templates │ └── vars ├── rsync_servers.yml └── site.yml 部署rsyncd服务的role角色 1.准备写装rsync服务的role\n2.创建好对应的目录结构\n3.写好playbook模式\n4.拆开即可\n先写好纯playbook形式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 - hosts: backup vars: user_id: \u0026#39;666\u0026#39; rsync_user: \u0026#39;www\u0026#39; tasks: # 1.创建www用户和组 - name: 01_create_group group: name: \u0026#34;{{ rsync_user }}\u0026#34; gid: \u0026#34;{{ user_id }}\u0026#34; # 2.创建www用户 - name: 02_create_user user: name: \u0026#34;{{ rsync_user }}\u0026#34; gid: \u0026#34;{{ user_id }}\u0026#34; group: \u0026#34;{{ rsync_user}}\u0026#34; create_home: no shell: /sbin/nologin # 3.创建数据目录且授权 - name: 03_createUdata file: path: \u0026#34;{{ item }}\u0026#34; state: direcotry owner: \u0026#34;{{ rsync_user }}\u0026#34; group: \u0026#34;{{ rsync_user}}\u0026#34; mode: \u0026#34;755\u0026#34; loop: - /data - /backup # 4.安装rsync软件 - name: 04_install_rsync yum: name: rsync state: latest # 5.复制配置文件与密码文件 - name: 05_copy_config copy: src: \u0026#34;{{ item.src }}\u0026#34; dest: /etc/ mode: \u0026#34;{{ item.mode }}\u0026#34; notify: - restart_rsyncd loop: - { src:/script/rsyncd.conf,mode:\u0026#39;644\u0026#39;} - { src:/script/rsync.passwd,mode:\u0026#39;600\u0026#39;} # 6.启动服务 - name: 06_start_rsync systemd: name: rsyncd state: started enabled: yes # 7.重启服务 handlers: - name: restart_rsyncd systemd: name: rsyncd state: restarted 将剧本拆为role的形式 1 2 3 1.如何拆，先看你的剧本中，有多少个部分，是符合role的目录规范的（有多少部分需要拆） 2.对配置文件，解析完毕后，可以去逐步的拆了 拆tasks（任务） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 1.创建tasks/main.yml [root@master-61 /script]#touch /etc/ansible/roles/rsync_servers/tasks/main.yml 2.往tasks的主体文件中，写入拆分出来的任务列表 只需要复制原本的剧本中的 tasks任务列表，无须携带tasks这个key了，复制粘贴如下的任务列表即可，写入到该 tasks/main.yml 剧本中，依然会调用 变量信息，但是不写在这个tasks/main.yml中了 而是，role角色会自动的去 vars/main.yml 寻找这个变量 {{rsync_user}} # 1.创建www组 - name: 01_create_group group: name: \u0026#34;{{rsync_user}}\u0026#34; gid: \u0026#34;{{user_id}}\u0026#34; # 2.创建www用户 - name: 02_create_user user: name: \u0026#34;{{rsync_user}}\u0026#34; uid: \u0026#34;{{user_id}}\u0026#34; group: \u0026#34;{{rsync_user}}\u0026#34; create_home: no shell: /sbin/nologin # 3.创建数据目录并更改授权 - name: 03_create_data file: path: \u0026#34;{{item}}\u0026#34; state: directory owner: \u0026#34;{{rsync_user}}\u0026#34; group: \u0026#34;{{rsync_user}}\u0026#34; mode: \u0026#39;755\u0026#39; loop: - /data - /backup/ # 4.安装rsync软件 - name: 04_install_rsync yum: name: rsync state: latest # 5.复制文件 - name: 05-copy config copy: src: \u0026#34;{{item.src}}\u0026#34; dest: /etc mode: \u0026#34;{{item.mode}}\u0026#34; notify: - restart_rsyncd loop: - {src: rsyncd.conf,mode: \u0026#39;644\u0026#39;} - {src: rsync.passwd,mode: \u0026#39;600\u0026#39;} # 6. 启动服务 - name: start service systemd: name: rsyncd state: started enabled: yes 拆 vars/main.yml 1 2 3 4 5 6 7 8 1.写入 剧本需要用到的变量即可，也是一样，不需要添加 vars: 这个脑袋了 roles判断，只要在 vars/main.yml 就识别这是一个变量yml文件 2.创建 vars/main.yml 写入如下信息，无须缩进： user_id: \u0026#39;666\u0026#39; rsync_user: \u0026#39;www\u0026#39; 拆配置文件 1 2 3 4 5 6 1. 找到你原本的配置文件所在地儿，复制到 roles的 files目录下即可 2.创建文件如下 [root@master-61 /etc/ansible/roles/rsync_servers]#cp /script/rsync* /etc/ansible/roles/rsync_servers/files/ [root@master-61 /etc/ansible/roles/rsync_servers]#ls files/ rsyncd.conf rsync.passwd 拆handlers 1 2 3 4 5 6 创建handlers文件 [root@master-61 /etc/ansible/roles/rsync_servers]#cat handlers/main.yml - name: restart_rsyncd systemd: name: rsyncd state: restarted 创建启动文件 1 2 3 4 5 6 7 8 9 10 注意：该启动文件，入口在 和 roles这个目录，平级的地方，且写入需要操作的主机组，以及定义角色的名字（和角色文件夹对应即可） 1.修改这个role的启动剧本 ，正确的入口文件，语法如下 [root@master-61 /etc/ansible]#cat /etc/ansible/rsync_servers.yml - hosts: backup roles: - rsync_servers 2.调试该启动剧本是否可以运行，语法是否正确 [root@master-61 /etc/ansible]#ansible-playbook -C rsync_servers.yml 正式运行该rsync角色 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 1.准备好新机器，rsync-41机器测试 2. 运行角色程序 [root@master-61 /etc/ansible]#ansible-playbook rsync_servers.yml PLAY [backup] ************************************************************************************************************** TASK [Gathering Facts] ***************************************************************************************************** ok: [172.16.1.41] TASK [rsync_servers : 01_create_group] ************************************************************************************* ok: [172.16.1.41] TASK [rsync_servers : 02_create_user] ************************************************************************************** ok: [172.16.1.41] TASK [rsync_servers : 03_create_data] ************************************************************************************** ok: [172.16.1.41] =\u0026gt; (item=/data) ok: [172.16.1.41] =\u0026gt; (item=/backup/) TASK [rsync_servers : 04_install_rsync] ************************************************************************************ ok: [172.16.1.41] TASK [rsync_servers : 05-copy config] ************************************************************************************** ok: [172.16.1.41] =\u0026gt; (item={u\u0026#39;src\u0026#39;: u\u0026#39;rsyncd.conf\u0026#39;, u\u0026#39;mode\u0026#39;: u\u0026#39;644\u0026#39;}) ok: [172.16.1.41] =\u0026gt; (item={u\u0026#39;src\u0026#39;: u\u0026#39;rsync.passwd\u0026#39;, u\u0026#39;mode\u0026#39;: u\u0026#39;600\u0026#39;}) TASK [rsync_servers : start service] *************************************************************************************** changed: [172.16.1.41] PLAY RECAP ***************************************************************************************************************** 172.16.1.41 : ok=7 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 测试handlers的执行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 1.需要修改配置文件，触发notify，然后handlers才会执行 需要修改 roles目录下的 files目录，里面的配置文件 [root@master-61 /etc/ansible]#ansible-playbook rsync_servers.yml PLAY [backup] ************************************************************************************************************** TASK [Gathering Facts] ***************************************************************************************************** ok: [172.16.1.41] TASK [rsync_servers : 01_create_group] ************************************************************************************* ok: [172.16.1.41] TASK [rsync_servers : 02_create_user] ************************************************************************************** ok: [172.16.1.41] TASK [rsync_servers : 03_create_data] ************************************************************************************** ok: [172.16.1.41] =\u0026gt; (item=/data) ok: [172.16.1.41] =\u0026gt; (item=/backup/) TASK [rsync_servers : 04_install_rsync] ************************************************************************************ ok: [172.16.1.41] TASK [rsync_servers : 05-copy config] ************************************************************************************** changed: [172.16.1.41] =\u0026gt; (item={u\u0026#39;src\u0026#39;: u\u0026#39;rsyncd.conf\u0026#39;, u\u0026#39;mode\u0026#39;: u\u0026#39;644\u0026#39;}) ok: [172.16.1.41] =\u0026gt; (item={u\u0026#39;src\u0026#39;: u\u0026#39;rsync.passwd\u0026#39;, u\u0026#39;mode\u0026#39;: u\u0026#39;600\u0026#39;}) TASK [rsync_servers : start service] *************************************************************************************** ok: [172.16.1.41] RUNNING HANDLER [rsync_servers : restart_rsyncd] *************************************************************************** changed: [172.16.1.41] PLAY RECAP ***************************************************************************************************************** 172.16.1.41 : ok=8 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 template（模板）模块 1 2 3 作用是专门用于动态替换配置文件中的值，需要学习jinja2这个模板语言（内容太多，支持循环语句，条件判断，以后有机会再学。。） 这里学习它的 创建，使用规则；以及变量替换功能；实现配置文件的变量替换； 改为变量形式的配置文件 一个纯普通的文本文件，是没法识别这样的变量的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 rsyncd.conf uid = www gid = www port = 873 fake super = yes use chroot = no max connections = 200 timeout = 600 ignore errors read only = false list = false auth users = rsync_bakcup secrets file = /etc/rsync.passwd log file = /var/log/rsyncd.log [backup] comment = chaoge rsync backup! path = /backup [data] comment = baizhi.com rsync! path = /data 使用template模板替换配置文件的思路 因此ansible提供了一个jinja2模板语言，要求如下\n第一件事，改造配置文件为 j2类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 1.创建配置文件，但是后缀必须是 j2格式的 rsyncd.j2 该j2文件写入配置: uid = www gid = www port = 873 fake super = yes use chroot = no max connections = 200 timeout = 600 ignore errors read only = false list = false auth users = {{ rsync_auth_user }} secrets file = /etc/rsync.passwd log file = /var/log/rsyncd.log [backup] comment = chaoge rsync backup! path = /backup [data] comment = baizhi.com rsync! path = /data 第二件事，修改vars变量文件，去替换j2文件中的变量值\n只需要在vars/main.yml中写入变量即可\n1 rsync_auth_user: \u0026#34;rsync_backup\u0026#34; 第三件事，修改tasks任务yaml文件\n还得修改tasks任务yaml文件，指定配置文件路径，为j2模板形式\n以部署sshd服务为演示（role角色） 1.创建sshd_server角色目录 1 2 3 4 5 6 7 8 9 10 11 12 [root@master-61 /etc/ansible]#mkdir -p /etc/ansible/roles/sshd_server/{files,handlers,tasks,vars,templates} 检查 [root@master-61 /etc/ansible]#tree /etc/ansible/roles/sshd_server/ /etc/ansible/roles/sshd_server/ ├── files ├── handlers ├── tasks ├── templates └── vars 5 directories, 0 files 2.需要创建role目录下的每一个目录资料 直接写roles剧本了\ntasks\nvars\ntemplates\n先创建部署sshd的tasks任务文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 1. 创建tasks/main.yml vim tasks/main.yml # 2. 写入剧本语法 [root@master-61 /etc/ansible/roles/sshd_server]#cat tasks/main.yaml # 1.复制文件 - name: 01_copy_sshd template: src: sshd_config.j2 dest: /etc/ssh/sshd_config mode: \u0026#39;600\u0026#39; backup: yes notify: - restart sshd # 2.启动服务 - name: start sshd service systemd: name: sshd state: started enabled: yes 3.创建template信息 创建模板配置文件，设置变量用于替换配置文件的值\n1 2 3 4 5 6 7 8 9 10 11 12 1.你要准备好 sshd_config的配置文件 [root@master-61 /etc/ansible/roles/sshd_server]#cp /etc/ssh/sshd_config /etc/ansible/roles/sshd_server/templates/sshd_config.j2 [root@master-61 /etc/ansible/roles/sshd_server]#ls templates/ sshd_config.j2 2.修改这个sshd_config.j2文件，修改需要用变量替换的参数 修改端口 禁止公钥登录 Port {{ sshd_port }} PubkeyAuthentication {{ pubkey_yes_no }} 4.创建变量文件 1 2 3 4 1.创建文件 [root@master-61 /etc/ansible/roles/sshd_server]#cat vars/main.yml sshd_port: \u0026#34;2999\u0026#34; pubkey_yes_no: \u0026#34;no\u0026#34; 5.创建handlers文件，用于重启sshd 1 2 3 4 5 [root@master-61 /etc/ansible/roles/sshd_server]#cat handlers/main.yml - name: restart sshd systemd: name: sshd state: restarted 6.检查当前服务的roles目录信息 1 2 3 4 5 6 7 8 9 10 11 12 13 [root@master-61 /etc/ansible/roles/sshd_server]#tree . ├── files ├── handlers │ └── main.yml ├── tasks │ └── main.yml ├── templates │ └── sshd_config.j2 └── vars └── main.yml 5 directories, 4 files 7.创建启动文件就完事 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 1.必须和roles同级 2.roles角色定义的工作目录名，必须和roles/文件夹名字对应的上 # 先进入/etc/ansible目录，创建启动文件 [root@master-61 /etc/ansible]#cat start_sshd.yml - hosts: backup roles: - sshd_server 3.测试剧本运行 [root@master-61 /etc/ansible/roles/sshd_server]#ansible-playbook /etc/ansible/start_sshd.yml PLAY [backup] ************************************************************************************************************* TASK [Gathering Facts] **************************************************************************************************** ok: [172.16.1.41] TASK [sshd_server : 01_copy_sshd] ***************************************************************************************** changed: [172.16.1.41] TASK [sshd_server : start sshd service] *********************************************************************************** ok: [172.16.1.41] RUNNING HANDLER [sshd_server : restart sshd] ****************************************************************************** changed: [172.16.1.41] PLAY RECAP **************************************************************************************************************** 172.16.1.41 : ok=4 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 ","date":"2025-04-14T16:39:02+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/ansible%E8%A7%92%E8%89%B2/","title":"Ansible角色"},{"content":"剧本学习目标 1.剧本主题内容\n剧本就是两部分大知识点\nansible的模块（模块的参数） yaml语法 2.json语法（网站数据传输，数据传输的最主流的格式）\n3.工作之后 维护公司的剧本\n看剧本，看懂了，维护，修改 修改各种参数，文件路径，文件名字，服务的端口名字（就是该ansible各种模块，参数的值） 剧本是什么 1 2 3 4 5 6 7 8 9 10 11 影名 演员 场景 时间 事件 台词 道具 ansible剧本，一系列的任务，按照我们期望的结果編排在一起 hosts: 定义主机角色 tasks: 具体执行的任务 yaml学习 yaml详细介绍\n全称 (YAML Ain\u0026rsquo;t Markup Language)，一种数据序列化格式\n优点：\n容易阅读\n容易与脚本语言交互\n以数据为核心，重数据轻格式\nYAML文件扩展名\n.yml（主流）\n.yaml\nyaml语法规则\n大小写敏感\n属性层级关系使用多行描述，每行结尾使用冒号结束\n使用缩进表示层级关系，同层级左侧对齐，只允许使用空格（不允许使用Tab键）\n属性值前面添加空格（属性名与属性值之间使用冒号+空格作为分隔）\n# 表示注释\nyaml这个语法中，只有三个数据类型\n字典类型，特点就是 key : value形式\n列表形式，特点是 通过 短横线定义\n纯变量形式（字面值）\n字面值表示方式\n1 2 3 4 5 6 7 8 boolean: TRUE #TRUE,true,True,FALSE,false，False均可 float: 3.14 #6.8523015e+5 #支持科学计数法 int: 123 #0b1010_0111_0100_1010_1110 #支持二进制、八进制、十六进制 null: ~ #使用~表示null string: HelloWorld #字符串可以直接书写 string2: \u0026#34;Hello World\u0026#34; #可以使用双引号包裹特殊字符 date: 2018-02-17 #日期必须使用yyyy-MM-dd格式 datetime: 2018-02-17T15:02:31+08:00 #时间和日期之间使用T连接，最后使用+代表时区 数组表示方式 1 2 3 4 5 6 7 8 9 10 11 12 13 subject: - Java - 前端 - 大数据 enterprise: #字典形式 name: itcast age: 16 subject: - Java - 前端 - 大数据 likes: [王者荣耀,刺激战场] #数组书写缩略格式 1 2 3 4 5 6 7 8 9 10 11 12 13 users: #对象数组格式 - name: Tom age: 4 - name: Jerry age: 5 users: #对象数组格式二 - name: Tom age: 4 - name: Jerry age: 5 users2: [ { name:Tom , age:4 } , { name:Jerry , age:5 } ] #对象数组缩略格式 json学习 JSON在线解析及格式化验证 - JSON.cn\n语法\n1 2 3 4 5 6 7 8 9 JSON 语法是 JavaScript 对象表示语法的子集。 数据在名称/值对中 数据由逗号分隔 大括号 {} 保存字典 中括号 [] 保存列表，列表可以包含多个对象 JSON 值可以是：\n数字（整数或浮点数） 字符串（在双引号中） 逻辑值（true 或 false） 数组（在中括号中） 对象（在大括号中） null json的语法示例 1 2 3 4 5 6 7 8 9 10 { \u0026#34;students\u0026#34;:null, \u0026#34;age\u0026#34;:18, \u0026#34;male\u0026#34;:true, \u0026#34;手机号\u0026#34;:[ 152100000000, 16800000000 ], \u0026#34;你快乐吗\u0026#34;:\u0026#34;我很快乐\u0026#34; } jq命令学习 提取json的数据：\n1 2 3 4 5 6 7 根据key，提取value 前端通过js代码提取 后端 通过python代码提取 运维通过jq命令提取 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 1. 安装jq命令 [root@master-61 ~]#yum install jq -y 2.简单json数据提取 提取名字的值，价格 [root@master-61 ~]#echo \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;德玛西亚\u0026#34;,\u0026#34;price\u0026#34;:6888}\u0026#39; | jq 使用jq命令的过滤器提取某个value，语法是 通过 `.` 提取，比如 jq \u0026#39;.name,.price\u0026#39; [root@master-61 ~]#echo \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;德玛西亚\u0026#34;,\u0026#34;price\u0026#34;:6888}\u0026#39; | jq \u0026#39;.name\u0026#39; [root@master-61 ~]#echo \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;德玛西亚\u0026#34;,\u0026#34;price\u0026#34;:6888}\u0026#39; | jq \u0026#39;.price\u0026#39; [root@master-61 ~]#echo \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;德玛西亚\u0026#34;,\u0026#34;price\u0026#34;:6888}\u0026#39; | jq \u0026#39;.price,.name\u0026#39; 3.串行执行，提取复杂的json数据，数据可能会有列表嵌套 [root@master-61 ~]#echo \u0026#39;{\u0026#34;students\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;zhangsan\u0026#34;,\u0026#34;age\u0026#34;:18},{\u0026#34;name\u0026#34;:\u0026#34;lisi\u0026#34;,\u0026#34;age\u0026#34;:20},{\u0026#34;name\u0026#34;:\u0026#34;wangwu\u0026#34;,\u0026#34;age\u0026#34;:22}]}\u0026#39; | jq [root@master-61 ~]#echo \u0026#39;{\u0026#34;students\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;zhangsan\u0026#34;,\u0026#34;age\u0026#34;:18},{\u0026#34;name\u0026#34;:\u0026#34;lisi\u0026#34;,\u0026#34;age\u0026#34;:20},{\u0026#34;name\u0026#34;:\u0026#34;wangwu\u0026#34;,\u0026#34;age\u0026#34;:22}]}\u0026#39; | jq \u0026#39;.students\u0026#39; [root@master-61 ~]#echo \u0026#39;{\u0026#34;students\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;zhangsan\u0026#34;,\u0026#34;age\u0026#34;:18},{\u0026#34;name\u0026#34;:\u0026#34;lisi\u0026#34;,\u0026#34;age\u0026#34;:20},{\u0026#34;name\u0026#34;:\u0026#34;wangwu\u0026#34;,\u0026#34;age\u0026#34;:22}]}\u0026#39; | jq \u0026#39;.students | .[]\u0026#39; [root@master-61 ~]#echo \u0026#39;{\u0026#34;students\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;zhangsan\u0026#34;,\u0026#34;age\u0026#34;:18},{\u0026#34;name\u0026#34;:\u0026#34;lisi\u0026#34;,\u0026#34;age\u0026#34;:20},{\u0026#34;name\u0026#34;:\u0026#34;wangwu\u0026#34;,\u0026#34;age\u0026#34;:22}]}\u0026#39; | jq \u0026#39;.students | .[0]\u0026#39; [root@master-61 ~]#echo \u0026#39;{\u0026#34;students\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;zhangsan\u0026#34;,\u0026#34;age\u0026#34;:18},{\u0026#34;name\u0026#34;:\u0026#34;lisi\u0026#34;,\u0026#34;age\u0026#34;:20},{\u0026#34;name\u0026#34;:\u0026#34;wangwu\u0026#34;,\u0026#34;age\u0026#34;:22}]}\u0026#39; | jq \u0026#39;.students | .[2] | .name\u0026#39; 取头不取尾 [root@master-61 ~]#echo \u0026#39;{\u0026#34;students\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;zhangsan\u0026#34;,\u0026#34;age\u0026#34;:18},{\u0026#34;name\u0026#34;:\u0026#34;lisi\u0026#34;,\u0026#34;age\u0026#34;:20},{\u0026#34;name\u0026#34;:\u0026#34;wangwu\u0026#34;,\u0026#34;age\u0026#34;:22}]}\u0026#39; | jq \u0026#39;.students | .[0:2]\u0026#39; [root@master-61 ~]#echo \u0026#39;{\u0026#34;students\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;zhangsan\u0026#34;,\u0026#34;age\u0026#34;:18},{\u0026#34;name\u0026#34;:\u0026#34;lisi\u0026#34;,\u0026#34;age\u0026#34;:20},{\u0026#34;name\u0026#34;:\u0026#34;wangwu\u0026#34;,\u0026#34;age\u0026#34;:22}]}\u0026#39; | jq \u0026#39;.students | .[] | .name\u0026#39; jq处理文件中的json 打开以下链接或从文本框中复制：\nv1.yiketianqi.com/api?version=v9\u0026amp;appid=23035354\u0026amp;appsecret=8YvlPNrz\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 { \u0026#34;cityid\u0026#34;: \u0026#34;101030100\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;天津\u0026#34;, \u0026#34;cityEn\u0026#34;: \u0026#34;tianjin\u0026#34;, \u0026#34;country\u0026#34;: \u0026#34;中国\u0026#34;, \u0026#34;countryEn\u0026#34;: \u0026#34;China\u0026#34;, \u0026#34;update_time\u0026#34;: \u0026#34;2024-05-16 17:06:00\u0026#34;, \u0026#34;data\u0026#34;: [ { \u0026#34;day\u0026#34;: \u0026#34;16日（星期四）\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2024-05-16\u0026#34;, \u0026#34;week\u0026#34;: \u0026#34;星期四\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;wea_day\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_day_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;wea_night\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_night_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;29.1\u0026#34;, \u0026#34;tem1\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;tem2\u0026#34;: \u0026#34;19\u0026#34;, \u0026#34;humidity\u0026#34;: \u0026#34;25%\u0026#34;, \u0026#34;visibility\u0026#34;: \u0026#34;28km\u0026#34;, \u0026#34;pressure\u0026#34;: \u0026#34;1002\u0026#34;, \u0026#34;win\u0026#34;: [ \u0026#34;西南风\u0026#34;, \u0026#34;南风\u0026#34; ], \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34;, \u0026#34;win_meter\u0026#34;: \u0026#34;11km/h\u0026#34;, \u0026#34;sunrise\u0026#34;: \u0026#34;04:56\u0026#34;, \u0026#34;sunset\u0026#34;: \u0026#34;19:18\u0026#34;, \u0026#34;air\u0026#34;: \u0026#34;92\u0026#34;, \u0026#34;air_level\u0026#34;: \u0026#34;良\u0026#34;, \u0026#34;air_tips\u0026#34;: \u0026#34;空气质量可接受，但某些污染物可能对极少数异常敏感人群健康有较弱影响。\u0026#34;, \u0026#34;alarm\u0026#34;: { \u0026#34;alarm_type\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_level\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_content\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;hours\u0026#34;: [ { \u0026#34;hours\u0026#34;: \u0026#34;08时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;阴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yin\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;09时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;阴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yin\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;10时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;11时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;26\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;12时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;26\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;13时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;27\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;14时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;27\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;15时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;28\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;16时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;29\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;17时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;29\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;18时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;28\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;19时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;27\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;20时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;25\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;21时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;22时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;23时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;23\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;00时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;01时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;02时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;03时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;04时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;05时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;19\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;06时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;19\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;07时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; } ], \u0026#34;index\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;紫外线指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;强\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;涂擦SPF大于15、PA+防晒护肤品。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;减肥指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;天气较好，尽情感受运动的快乐吧。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;血糖指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较易发\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;外出需远离过敏源，适当采取防护措施。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;穿衣指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;热\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;适合穿T恤、短薄外套等夏季服装。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;洗车指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;天气较好，适合擦洗汽车。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;空气污染扩散指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;中\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;易感人群应适当减少室外活动。\u0026#34; } ], \u0026#34;uvIndex\u0026#34;: \u0026#34;7\u0026#34;, \u0026#34;uvDescription\u0026#34;: \u0026#34;强\u0026#34; }, { \u0026#34;day\u0026#34;: \u0026#34;17日（星期五）\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2024-05-17\u0026#34;, \u0026#34;week\u0026#34;: \u0026#34;星期五\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;wea_day\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_day_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;wea_night\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_night_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;32\u0026#34;, \u0026#34;tem1\u0026#34;: \u0026#34;32\u0026#34;, \u0026#34;tem2\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;humidity\u0026#34;: \u0026#34;44%\u0026#34;, \u0026#34;visibility\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pressure\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;win\u0026#34;: [ \u0026#34;东风\u0026#34;, \u0026#34;东南风\u0026#34; ], \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34;, \u0026#34;win_meter\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;sunrise\u0026#34;: \u0026#34;04:56\u0026#34;, \u0026#34;sunset\u0026#34;: \u0026#34;19:19\u0026#34;, \u0026#34;air\u0026#34;: \u0026#34;113\u0026#34;, \u0026#34;air_level\u0026#34;: \u0026#34;轻度污染\u0026#34;, \u0026#34;air_tips\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm\u0026#34;: { \u0026#34;alarm_type\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_level\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_content\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;hours\u0026#34;: [ { \u0026#34;hours\u0026#34;: \u0026#34;08时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;09时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;10时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;27\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;11时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东北风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;12时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;13时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;14时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;31\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;15时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;31\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;16时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;31\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;17时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;31\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;18时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;29\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;19时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;28\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;20时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;26\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;21时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;25\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;22时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;23时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;00时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;23\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;01时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;23\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;02时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东北风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;03时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东北风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;04时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东北风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;05时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东北风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;06时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东北风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;07时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;23\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; } ], \u0026#34;index\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;紫外线指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;很强\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;涂擦SPF20以上，PA++护肤品，避强光。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;减肥指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;请适当减少运动时间，降低运动强度。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;血糖指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较易发\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;外出需远离过敏源，适当采取防护措施。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;穿衣指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;炎热\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;建议穿短衫、短裤等清凉夏季服装。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;洗车指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;天气较好，适合擦洗汽车。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;空气污染扩散指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;中\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;易感人群应适当减少室外活动。\u0026#34; } ], \u0026#34;uvIndex\u0026#34;: \u0026#34;9\u0026#34;, \u0026#34;uvDescription\u0026#34;: \u0026#34;很强\u0026#34; }, { \u0026#34;day\u0026#34;: \u0026#34;18日（星期六）\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2024-05-18\u0026#34;, \u0026#34;week\u0026#34;: \u0026#34;星期六\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;wea_day\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_day_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;wea_night\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_night_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;31\u0026#34;, \u0026#34;tem1\u0026#34;: \u0026#34;31\u0026#34;, \u0026#34;tem2\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;humidity\u0026#34;: \u0026#34;51%\u0026#34;, \u0026#34;visibility\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pressure\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;win\u0026#34;: [ \u0026#34;东风\u0026#34;, \u0026#34;东风\u0026#34; ], \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34;, \u0026#34;win_meter\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;sunrise\u0026#34;: \u0026#34;04:55\u0026#34;, \u0026#34;sunset\u0026#34;: \u0026#34;19:19\u0026#34;, \u0026#34;air\u0026#34;: \u0026#34;120\u0026#34;, \u0026#34;air_level\u0026#34;: \u0026#34;轻度污染\u0026#34;, \u0026#34;air_tips\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm\u0026#34;: { \u0026#34;alarm_type\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_level\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_content\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;hours\u0026#34;: [ { \u0026#34;hours\u0026#34;: \u0026#34;08时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;09时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;25\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;10时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;26\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;3-4级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;11时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;28\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;12时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;29\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;13时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;14时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;31\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;15时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;16时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;29\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;17时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;28\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;18时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;26\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;19时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;25\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;20时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;23\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;21时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;23\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;22时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;23时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;00时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;01时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;02时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;03时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;04时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;05时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;06时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;23\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;07时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;25\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; } ], \u0026#34;index\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;紫外线指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;中等\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;涂擦SPF大于15、PA+防晒护肤品。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;减肥指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;请适当降低运动强度并注意户外防风。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;血糖指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较易发\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;外出需远离过敏源，适当采取防护措施。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;穿衣指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;炎热\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;建议穿短衫、短裤等清凉夏季服装。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;洗车指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较不宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;风力较大，洗车后会蒙上灰尘。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;空气污染扩散指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;良\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;气象条件有利于空气污染物扩散。\u0026#34; } ], \u0026#34;uvIndex\u0026#34;: \u0026#34;9\u0026#34;, \u0026#34;uvDescription\u0026#34;: \u0026#34;很强\u0026#34; }, { \u0026#34;day\u0026#34;: \u0026#34;19日（星期日）\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2024-05-19\u0026#34;, \u0026#34;week\u0026#34;: \u0026#34;星期日\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;wea_day\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_day_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;wea_night\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_night_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;32\u0026#34;, \u0026#34;tem1\u0026#34;: \u0026#34;32\u0026#34;, \u0026#34;tem2\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;humidity\u0026#34;: \u0026#34;52%\u0026#34;, \u0026#34;visibility\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pressure\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;win\u0026#34;: [ \u0026#34;东风\u0026#34;, \u0026#34;东风\u0026#34; ], \u0026#34;win_speed\u0026#34;: \u0026#34;3-4级转\u0026lt;3级\u0026#34;, \u0026#34;win_meter\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;sunrise\u0026#34;: \u0026#34;04:54\u0026#34;, \u0026#34;sunset\u0026#34;: \u0026#34;19:20\u0026#34;, \u0026#34;air\u0026#34;: \u0026#34;111\u0026#34;, \u0026#34;air_level\u0026#34;: \u0026#34;轻度污染\u0026#34;, \u0026#34;air_tips\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm\u0026#34;: { \u0026#34;alarm_type\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_level\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_content\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;hours\u0026#34;: [ { \u0026#34;hours\u0026#34;: \u0026#34;08时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;26\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;11时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;28\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;4-5级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;14时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;3-4级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;17时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;27\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;3-4级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;20时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东北风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;3-4级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;23时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东北风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;3-4级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;02时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东北风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;05时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东北风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; } ], \u0026#34;index\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;紫外线指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;很强\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;涂擦SPF20以上，PA++护肤品，避强光。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;减肥指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;请适当降低运动强度并注意户外防风。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;血糖指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较易发\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;外出需远离过敏源，适当采取防护措施。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;穿衣指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;炎热\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;建议穿短衫、短裤等清凉夏季服装。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;洗车指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较不宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;风力较大，洗车后会蒙上灰尘。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;空气污染扩散指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;良\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;气象条件有利于空气污染物扩散。\u0026#34; } ], \u0026#34;uvIndex\u0026#34;: \u0026#34;6\u0026#34;, \u0026#34;uvDescription\u0026#34;: \u0026#34;强\u0026#34; }, { \u0026#34;day\u0026#34;: \u0026#34;20日（星期一）\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2024-05-20\u0026#34;, \u0026#34;week\u0026#34;: \u0026#34;星期一\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云转晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;wea_day\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_day_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;wea_night\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_night_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;29\u0026#34;, \u0026#34;tem1\u0026#34;: \u0026#34;29\u0026#34;, \u0026#34;tem2\u0026#34;: \u0026#34;19\u0026#34;, \u0026#34;humidity\u0026#34;: \u0026#34;65%\u0026#34;, \u0026#34;visibility\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pressure\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;win\u0026#34;: [ \u0026#34;东风\u0026#34;, \u0026#34;东风\u0026#34; ], \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34;, \u0026#34;win_meter\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;sunrise\u0026#34;: \u0026#34;04:53\u0026#34;, \u0026#34;sunset\u0026#34;: \u0026#34;19:21\u0026#34;, \u0026#34;air\u0026#34;: \u0026#34;101\u0026#34;, \u0026#34;air_level\u0026#34;: \u0026#34;轻度污染\u0026#34;, \u0026#34;air_tips\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm\u0026#34;: { \u0026#34;alarm_type\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_level\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_content\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;hours\u0026#34;: [ { \u0026#34;hours\u0026#34;: \u0026#34;08时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;11时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;14时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;27\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;17时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;多云\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;yun\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;26\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;20时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;25\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;23时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;02时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;19\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;05时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;19\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; } ], \u0026#34;index\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;紫外线指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;很强\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;涂擦SPF20以上，PA++护肤品，避强光。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;减肥指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;请适当降低运动强度，并及时补充水分。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;血糖指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较易发\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;外出需远离过敏源，适当采取防护措施。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;穿衣指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;热\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;适合穿T恤、短薄外套等夏季服装。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;洗车指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;天气较好，适合擦洗汽车。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;空气污染扩散指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;中\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;易感人群应适当减少室外活动。\u0026#34; } ], \u0026#34;uvIndex\u0026#34;: \u0026#34;8\u0026#34;, \u0026#34;uvDescription\u0026#34;: \u0026#34;很强\u0026#34; }, { \u0026#34;day\u0026#34;: \u0026#34;21日（星期二）\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2024-05-21\u0026#34;, \u0026#34;week\u0026#34;: \u0026#34;星期二\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;wea_day\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_day_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;wea_night\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_night_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;32\u0026#34;, \u0026#34;tem1\u0026#34;: \u0026#34;32\u0026#34;, \u0026#34;tem2\u0026#34;: \u0026#34;19\u0026#34;, \u0026#34;humidity\u0026#34;: \u0026#34;49%\u0026#34;, \u0026#34;visibility\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pressure\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;win\u0026#34;: [ \u0026#34;东南风\u0026#34;, \u0026#34;西南风\u0026#34; ], \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34;, \u0026#34;win_meter\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;sunrise\u0026#34;: \u0026#34;04:53\u0026#34;, \u0026#34;sunset\u0026#34;: \u0026#34;19:22\u0026#34;, \u0026#34;air\u0026#34;: \u0026#34;76\u0026#34;, \u0026#34;air_level\u0026#34;: \u0026#34;良\u0026#34;, \u0026#34;air_tips\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm\u0026#34;: { \u0026#34;alarm_type\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_level\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_content\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;hours\u0026#34;: [ { \u0026#34;hours\u0026#34;: \u0026#34;08时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;19\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;11时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;14时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;29\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;17时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;27\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;20时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;23时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;23\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;02时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;05时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;东南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; } ], \u0026#34;index\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;紫外线指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;很强\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;涂擦SPF20以上，PA++护肤品，避强光。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;减肥指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;请适当减少运动时间，降低运动强度。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;血糖指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较易发\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;外出需远离过敏源，适当采取防护措施。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;穿衣指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;炎热\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;建议穿短衫、短裤等清凉夏季服装。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;洗车指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;天气较好，适合擦洗汽车。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;空气污染扩散指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;中\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;易感人群应适当减少室外活动。\u0026#34; } ], \u0026#34;uvIndex\u0026#34;: \u0026#34;9\u0026#34;, \u0026#34;uvDescription\u0026#34;: \u0026#34;很强\u0026#34; }, { \u0026#34;day\u0026#34;: \u0026#34;22日（星期三）\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2024-05-22\u0026#34;, \u0026#34;week\u0026#34;: \u0026#34;星期三\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;wea_day\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_day_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;wea_night\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_night_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;34\u0026#34;, \u0026#34;tem1\u0026#34;: \u0026#34;34\u0026#34;, \u0026#34;tem2\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;humidity\u0026#34;: \u0026#34;36%\u0026#34;, \u0026#34;visibility\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pressure\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;win\u0026#34;: [ \u0026#34;南风\u0026#34;, \u0026#34;西南风\u0026#34; ], \u0026#34;win_speed\u0026#34;: \u0026#34;3-4级\u0026#34;, \u0026#34;win_meter\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;sunrise\u0026#34;: \u0026#34;04:52\u0026#34;, \u0026#34;sunset\u0026#34;: \u0026#34;19:23\u0026#34;, \u0026#34;air\u0026#34;: \u0026#34;116\u0026#34;, \u0026#34;air_level\u0026#34;: \u0026#34;轻度污染\u0026#34;, \u0026#34;air_tips\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm\u0026#34;: { \u0026#34;alarm_type\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_level\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;alarm_content\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;hours\u0026#34;: [ { \u0026#34;hours\u0026#34;: \u0026#34;08时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;11时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;27\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;14时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;32\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;17时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;31\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;20时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;29\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;23时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;25\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;02时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; }, { \u0026#34;hours\u0026#34;: \u0026#34;05时\u0026#34;, \u0026#34;wea\u0026#34;: \u0026#34;晴\u0026#34;, \u0026#34;wea_img\u0026#34;: \u0026#34;qing\u0026#34;, \u0026#34;tem\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;win\u0026#34;: \u0026#34;西南风\u0026#34;, \u0026#34;win_speed\u0026#34;: \u0026#34;\u0026lt;3级\u0026#34; } ], \u0026#34;index\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;紫外线指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;很强\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;涂擦SPF20以上，PA++护肤品，避强光。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;减肥指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较适宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;请适当降低运动强度并注意户外防风。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;血糖指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较易发\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;外出需远离过敏源，适当采取防护措施。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;穿衣指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;炎热\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;建议穿短衫、短裤等清凉夏季服装。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;洗车指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;较不宜\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;风力较大，洗车后会蒙上灰尘。\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;空气污染扩散指数\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;良\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;气象条件有利于空气污染物扩散。\u0026#34; } ], \u0026#34;uvIndex\u0026#34;: \u0026#34;9\u0026#34;, \u0026#34;uvDescription\u0026#34;: \u0026#34;很强\u0026#34; } ], \u0026#34;aqi\u0026#34;: { \u0026#34;update_time\u0026#34;: \u0026#34;17:08\u0026#34;, \u0026#34;cityid\u0026#34;: \u0026#34;101030100\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;天津市\u0026#34;, \u0026#34;cityEn\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;country\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;countryEn\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;air\u0026#34;: \u0026#34;79\u0026#34;, \u0026#34;air_level\u0026#34;: \u0026#34;良\u0026#34;, \u0026#34;air_tips\u0026#34;: \u0026#34;空气质量可接受，但某些污染物可能对极少数异常敏感人群健康有较弱影响。\u0026#34;, \u0026#34;pm25\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;pm25_desc\u0026#34;: \u0026#34;优\u0026#34;, \u0026#34;pm10\u0026#34;: \u0026#34;62\u0026#34;, \u0026#34;pm10_desc\u0026#34;: \u0026#34;良\u0026#34;, \u0026#34;o3\u0026#34;: \u0026#34;183\u0026#34;, \u0026#34;o3_desc\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;no2\u0026#34;: \u0026#34;16\u0026#34;, \u0026#34;no2_desc\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;so2\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;so2_desc\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;co\u0026#34;: \u0026#34;0.5\u0026#34;, \u0026#34;co_desc\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;kouzhao\u0026#34;: \u0026#34;不用佩戴口罩\u0026#34;, \u0026#34;yundong\u0026#34;: \u0026#34;适宜运动\u0026#34;, \u0026#34;waichu\u0026#34;: \u0026#34;适宜外出\u0026#34;, \u0026#34;kaichuang\u0026#34;: \u0026#34;适宜开窗\u0026#34;, \u0026#34;jinghuaqi\u0026#34;: \u0026#34;不需要打开\u0026#34; } } 1 2 3 4 [root@master-61 ~]#vim weather.json 粘贴上述json串 [root@master-61 ~]#cat weather.json | jq \u0026#39;.city,.country\u0026#39; 拿yaml转json测试，查看效果\n1 https://www.bejson.com/json/json2yaml/ 补充：修改ansible的输出结果为json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 json 数据转换格式，专有的语法，可以在网络中传输 json的作用就是定义了一堆 键值对的数据格式,根据key就可以拿到value { \u0026#34;key\u0026#34;: \u0026#34;value\u0026#34; } 读作字典形式 发给后端 python （python的数据类型，去解析json的数据格式，处理） 也可以发给前端 （js， js解析json的数据格式，然后处理） 运维可以通过jq命令处理json，即获取到json数据后，提取json的数据，步骤如下: 1.修改ansible的配置文件，让它输出的结果是一个json [root@master-61 /opt]#vim /etc/ansible/ansible.cfg [defaults] stdout_callback = json bin_ansible_callbacks = True 2.可以看到，此时ansible的命令输出结果，全部变为了json的格式 ad-hoc命令模式复习 1 2 3 4 5 6 7 8 9 10 11 12 ansible中有两种模式，分别是ad-hoc模式和playbook模式 ad-hoc简而言之，就是\u0026#34;临时命令\u0026#34; - 临时的看下远程机器的内存信息 - 临时的批量分发一个配置文件 特别小的需求，临时命令就解决 大需求，部署软件，这样的复杂需求，就写剧本 https://docs.ansible.com/ansible/latest/user_guide/intro_adhoc.html Ansible ad hoc 命令使用/usr/bin/ansible命令行工具在一个或多个托管节点上自动执行单个任务。ad hoc 命令既快速又简单，但它们不可重复使用 剧本语法 ansible-playbook，所必须的yaml语法\n1 2 3 4 5 6 - hosts： 需要执行的机器（nfs） tasks: -任务1: 安装nfs 动作：yum install nfs -任务2: 创建数据目录 动作：mkdir -p xxxx 拿安装nginx的yaml举例 原写法：\n1 2 ansible web -m yum -a \u0026#34;name=nginx state=installed\u0026#34; ansible web -m systemd -a \u0026#34;name=nginx state=started 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 第二种yaml风格 字典参数格式 1.先写好yaml [root@master-61 ~]#cat install_nginx.yml --- - name: 这是一个安装nginx的剧本 hosts: nfs tasks: - name: 01 安装nginx yum: name: nginx state: installed - name: 02 启动nginx systemd: name: nginx state: started 2.可以用ansible-playbook命令去验证yaml语法是否正确（不会真正执行） [root@master-61 ~]#ansible-playbook -C install_nginx.yml 写name字段，是表示定义剧本的注释，这一次任务的名称\nyaml中定义hosts的信息语法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 方式一：定义所管理的主机IP地址 - hosts: 192.168.178.111 tasks: 动作... # 方式二：定义所管理主机的名字 - hosts: backup01 tasks: 动作... # 方式三：定义管理主机 - hosts: 192.168.178.111, rsync01 tasks: 动作... # 方式四：管理所有主机 - hosts: all tasks: 动作... 关于剧本的tasks任务部分 tasks任务部分，就是决定用什么模块，做什么事，以及模块对应的参数的风格 字典风格的模块参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 [root@master-61 /opt]#cat install_nginx.yml --- - name: 这是一个安装nginx的剧本 hosts: 172.16.1.7,172.16.1.8,nfs tasks: - name: 01 安装nginx yum: name: nginx state: installed - name: 02 启动nginx systemd: name: nginx state: started 变量风格的模块参数\n1 2 3 4 5 6 7 8 9 10 11 [root@master-61 /opt]#cat vars_install_nginx.yml --- - name: 这是一个安装nginx的剧本 hosts: 172.16.1.7,172.16.1.8,nfs tasks: - name: 01 安装nginx yum: name=nginx state=installed - name: 02 启动nginx systemd: name=nginx state=started - name: 03 设置nginx开机自启 systemd: name=nginx enabled=yes 总结 ​\t先写ad-hoc命令，转换为剧本\n剧本的高级特性 剧本高级特性是完全遵循python的循环结构来的 编程语言特有的逻辑控制语句 变量 循环 等等 你的剧本，可以考虑用高级特性，也可以不用\n高级特性是为了简化剧本\n循环 1 2 3 4 5 6 7 8 9 10 务必记住，对比理解 ad-hoc命令模式 转化为 yaml剧本模式 最新用法，循环的内置关键字是用loop定义循环变量 item关键字，去提取loop每次循环出来的值 简答理解为shell的for循环就行 不用循环，去批量的创建，删除用户 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [root@master-61 ~/my_scripts]#cat create_user.yml - name: create user test1~5 hosts: backup tasks: - name: create test1 user: name: test1 state: present - name: create test2 user: name: test2 state: present - name: create test3 user: name: test3 state: present - name: create tes4 user: name: test4 state: present - name: create test5 user: name: test5 state: present [root@master-61 ~/my_scripts]#sed -i \u0026#39;s#present#absent#g\u0026#39; create_user.yml 关于loop循环参数的语法 创建多个系统用户 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [root@master-61 ~/my_scripts]#cat create_user.yml --- - name: create test1~5 hosts: backup tasks: - name: create test1~5 user: name: \u0026#34;{{ item }}\u0026#34; state: present loop: - test1 - test2 - test3 - test4 - test5 - name: set password shell: echo \u0026#39;123123\u0026#39; |passwd --stdin \u0026#34;{{item}}\u0026#34; loop: - test1 - test2 - test3 - test4 - test5 执行剧本 [root@master-61 ~]#ansible-playbook create_user.yml 删除多个用户 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@master-61 ~/my_scripts]#cat delete_user.yml --- - name: delete test1~5 hosts: backup tasks: - name: delete user01 user: name: \u0026#34;{{ item }}\u0026#34; state: absent loop: - test1 - test2 - test3 - test4 - test5 vars关键字定义循环变量 上面会发现已然有重复的变量，还可以再简化\n通过vars关键字定义用户列表，变量一般定义在任务开始之前 通过item关键字提取loop中每次循环的数据 借助vars关键字循环创建用户且设置密码 通过vars关键字，定义好用户列表变量user_list\n然后通过loop去循环变量\n通过item去提取每次循环的值\n这是在通过loop提取列表的值。\nloop还可以循环字典的值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 --- - name: create user hosts: backup vars: users_list: - test1 - test2 - test3 tasks: - name: create user user: name: \u0026#34;{{ item }}\u0026#34; state: present loop: \u0026#34;{{ users_list }}\u0026#34; - name: set password shell: echo \u0026#39;123123\u0026#39; | passwd --stdin \u0026#34;{{ item }}\u0026#34; loop: \u0026#34;{{ users_list }}\u0026#34; loop结合vars循环提取字典的值 循环创建用户，且设置用户uid\n结合变量，循环，字典数据，创建用户信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 --- - name: create user hosts: backup vars: users_info: - {user: \u0026#39;t1\u0026#39;, uid: \u0026#39;2000\u0026#39;} - {user: \u0026#39;t2\u0026#39;, uid: \u0026#39;2001\u0026#39;} - {user: \u0026#39;t3\u0026#39;, uid: \u0026#39;2002\u0026#39;} - {user: \u0026#39;t4\u0026#39;, uid: \u0026#39;2003\u0026#39;} tasks: - name: create user and uid user: name: \u0026#34;{{ item.user }}\u0026#34; uid: \u0026#34;{{ item.uid }}\u0026#34; loop: \u0026#34;{{users_info}}\u0026#34; rsync创建备份文件夹 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 比如部署nfs、rsync、nginx的综合剧本； 1.要安装多个软件 nfs-utils rpcbind nginx wget net-tools vim （定义为列表，循环去提取列表中的值，） loop循环的知识用在 yum安装多个软件 2.创建多个目录rsynd.conf设置了多个备份目录， ad-hoc临时命令模式 file 创建文件夹 file 创建文件夹 file 创建文件夹 loop循环的知识用在 file创建多个文件 3.复制多个目录 loop循环的知识用在 copy拷贝多个文件 4.每个文件的权限都不一样 繁琐的写法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 - hosts: backup tasks: - name: 01安装rsync yum: name: rsync state: installed - name: 02 发送配置文件模板 copy: src: /script/rsyncd.conf dest: /etc/rsyncd.conf - name: 02 发送密码文件 copy: src: /script/rsync.passwd dest: /etc/rsync.passwd mode: \u0026#39;600\u0026#39; - name: 03 创建www用户组 group: name: www gid: 1000 - name: 04 创建www用户 user: name: www uid: 1000 group: www create_home: no shell: /sbin/nologin - name: 05 备份目录创建与授权/data file: path: /data state: directory owner: www group: www mode: \u0026#39;755\u0026#39; - name: 06 备份目录创建与授权/backup file: path: /backup state: directory owner: www group: www mode: \u0026#39;755\u0026#39; - name: 07 启动服务 systemd: name: rsyncd state: started enabled: yes 循环优化写法（利用loop循环的知识点，简化一些操作）\n前提条件是，原本的动作是重复的，不是重复，就无法使用loop\n以权限设置为例，如下yaml剧本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 - name: setMode hosts: backup tasks: - name: create_data file: path: \u0026#34;{{ item.file_path }}\u0026#34; state: directory owner: www group: www mode: \u0026#34;{{ item.mode }}\u0026#34; loop: - { file_path:\u0026#39;/data\u0026#39; ,mode:\u0026#39;755\u0026#39; } - { file_path:\u0026#39;/backup\u0026#39; ,mode:\u0026#39;755\u0026#39; } 变量定义 vars自定义变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 - hosts: backup vars: data_path: /data dest_path: /etc config_path: /etc/rsync.passwd tasks: - name: 01 mkdir data dir file: path: \u0026#34;{{ data_path }}\u0026#34; state: directory - name: 02 copy config file copy: src: \u0026#34;{{ config_path }}\u0026#34; dest: \u0026#34;{{ dest_path }}\u0026#34; ansible内置变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 1.ansible默认提供了一个模块，setup模块， master-61在通过ssh远程连接，操作目标机器的时候 ansible会默认收集这个机器的所有信息，放入到一个setup模块中 包括这个机器的 主机名，ip地址，mac地址，磁盘数量，是否是虚拟化，cpu核数等静态数据 将结果放入到了json数据中，存储为键值对形式 [root@master-61 ~]#ansible backup -m setup 2.内置变量使用实战： 语法如下 [root@master-61 ~]#cat get_ip.yaml - hosts: backup tasks: - name: 01 get ip address debug: msg=\u0026#34;该web组机器，ip是 {{ ansible_all_ipv4_addresses }}\u0026#34; - name: 02 get hostname debug: msg=\u0026#34;该web组，主机名是 {{ ansible_hostname }}\u0026#34; - name: 03 单ip debug: msg=\u0026#34;{{ansible_default_ipv4.address }}\u0026#34; - name: 04 eth0 ip地址是 debug: msg=\u0026#34;{{ansible_facts.eth0.ipv4.address}}\u0026#34; - name: 05 eth1 ip地址是 debug: msg=\u0026#34;{{ansible_facts.eth1.ipv4.address}}\u0026#34; 注意:如果自定义变量名与内置变量名相同，则获取优先级为：自定义变量 \u0026gt; 内置变量 主机清单文件的变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@master-61 ~]#cat /etc/ansible/hosts [all:vars] ansible_port=22999 ansible_password=\u0026#39;123123\u0026#39; [web] 172.16.1.[7:9] [nfs] 172.16.1.31 [backup] 172.16.1.41 ansible_port=22 ansible_password=\u0026#39;123123\u0026#39; loop循环使用变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [root@master-61 ~/my_scripts]#cat loop_install_rsync.yaml - hosts: backup vars: my_files: - { file_path: \u0026#39;/data\u0026#39; ,mode: \u0026#39;755\u0026#39; } - { file_path: \u0026#39;/backup\u0026#39; ,mode: \u0026#39;755\u0026#39; } tasks: - name: create_data file: path: \u0026#34;{{ item.file_path }}\u0026#34; state: directory owner: www group: www mode: \u0026#34;{{ item.mode }}\u0026#34; loop: \u0026#34;{{ my_files }}\u0026#34; register注册变量 1 2 3 4 5 6 7 8 9 10 11 12 官网文档 讲解了 register模块的用法 https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#registering-variables 查看示例用法 关于命令执行结果的返回值信息提取 关于ansible中的返回值提供了哪些参数 比如解释了 msg: \u0026#34;{{ about_ip_log.stdout_lines }}\u0026#34; 这个stdout_lines提取返回值的结果的用法 https://docs.ansible.com/ansible/latest/reference_appendices/common_return_values.html 获取内置变量的信息，写入到文件，然后读取该文件\n1 2 3 4 5 6 7 8 9 10 11 12 - hosts: backup tasks: - name: echo ip address shell: \u0026#34;echo {{ ansible_default_ipv4.address }} \u0026gt;\u0026gt; /tmp/ip.log\u0026#34; - name: cat ip.log shell: \u0026#34;cat /tmp/ip.log\u0026#34; register: about_ip_log - name: debug about_ip_log debug: msg: \u0026#34;{{ about_ip_log.stdout_lines }}\u0026#34; 1 2 3 4 5 1. 执行了个命令，默认有返回值 2. 通过register提取该返回值，写入到变量 3. 通过debug模块，msg参数 ，打印了这个变量的信息 注册多个变量 执行多个命令，并且注册多个变量，提取多个返回值，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 [root@master-61 ~/my_scripts]#cat test2_register.yml - hosts: backup tasks: - name: 01 get ip shell: \u0026#34;echo {{ ansible_default_ipv4.address }} \u0026gt; /tmp/ip.log\u0026#34; - name: 02 get hostname shell: \u0026#34;echo {{ ansible_hostname }} \u0026gt; /tmp/hostname.log\u0026#34; - name: 03 echo hostname shell: \u0026#34;cat /tmp/hostname.log\u0026#34; register: hostname_log - name: 04 echo ip shell: \u0026#34;cat /tmp/ip.log\u0026#34; register: ip_log - name: 05 show mount info shell: \u0026#34;showmount -e 172.16.1.41\u0026#34; register: showmount_log - debug: msg: \u0026#34;{{item}}\u0026#34; loop: - \u0026#34;{{ showmount_log.stdout_lines}}\u0026#34; - \u0026#34;{{ ip_log.stdout_lines}}\u0026#34; - \u0026#34;{{ hostname_log.stdout_lines}}\u0026#34; 总结:\n1 2 3 4 5 6 7 register注册变量 1. 获取命令的执行结果（返回值） 2. 这个返回值被注册为变量之后，可以交给后续的任务去使用 3. 这个注册变量（命令的返回值），还提供了很多的功能去使用 4.想知道关于注册变量的返回值，可以用哪些方法，看这个官网即可 https://docs.ansible.com/ansible/latest/reference_appendices/common_return_values.html 关于命令的返回结果，可以使用的所有方法 when条件语句 官网文档\n1 2 文档 https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html register+when 假设需要一个剧本，作用是判断当配置文件变化后，就重启服务\n1 2 3 4 5 6 7 8 9 10 register和when都是针对tasks任务列表下，某一个任务设置的 - name: 01 修改配置文件 register - name: 02 重启服务 作用分别是 1.获取某任务的命令执行结果（返回值） register 2.利用when条件判断，针对返回值的不同状态（决定做什么事） ，ansible进阶篇，都是在大量使用编程语言的特性，以及语法了 我们重启配置服务的标准是，修改了配置文件，否则无须重启\n例如，判断rsyncd.conf文件状态发生变化后，就重启服务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 - hosts: backup tasks: - name: 01 copy rsyncd.conf copy: src=/root/rsyncd.conf dest=/etc/ register: conf_status - name: 02 start rsyncd.service systemd: name=rsyncd state=started enabled=yes - name: 03 restart rsyncd.service systemd: name: rsyncd state: restarted when: conf_status.changed 当nfs配置文件存在，就显示其内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 - name: baizhi.com hosts: backup vars: nfs_file: /etc/exports tasks: - name: 01 check nfs config shell: \u0026#34;cat {{nfs_file}}\u0026#34; register: nfs_result ignore_errors: true - name: 02 debug nfs config debug: msg: \u0026#34;{{ansible_hostname}} has {{nfs_file}},file content is : {{nfs_result.stdout}}\u0026#34; when: nfs_result is success - name: 03 debug nfs not exists debug: msg=\u0026#34;{{nfs_file}} is not exists.\u0026#34; when: nfs_result is failed handler特性 1 2 官网文档 https://docs.ansible.com/ansible/latest/user_guide/playbooks_handlers.html 想要实现配置文件变化就重启rsync\n1 2 3 4 5 6 7 8 9 10 11 12 13 [root@master-61 ~]#cat restart_rsync.yaml - name: baizhi.com hosts: backup remote_user: root tasks: - name: copy rsyncd.conf copy: src=/root/rsyncd.conf dest=/etc/ - name: restart rsyncd.service systemd: name=rsyncd state=restarted 上述剧本中，重启rsync的操作会默认执行\n可以通过handler+ notify 这两个关键字，来组合定义一个新的剧本：\n1 2 3 4 5 6 1. handler关键字必须写在剧本结尾 2. handler是定义事件列表，可以定义多个要执行的事件，给每一个事件起好名字 如何调用这个事件，通过notify关键字。notify是写在tasks任务列表里的 （当某一个任务，的确执行了，发生了change更改状态，就会触发notify的执行，执行notify指定的名称的 handler事件） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 - name: baizhi.com hosts: backup remote_user: root tasks: - name: 01 copy rsyncd.conf copy: src=/root/rsyncd.conf dest=/etc/ notify: - restart rsyncd.service handlers: - name: restart rsyncd.service systemd: name: rsyncd state: restarted tag标签 作用为选择性的执行某些任务\n给部署nfs-server的任务添加标签 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 - name: baizhi.com hosts: nfs tasks: - name: 01 安装nfs-utils 服务 yum: name=nfs-utils state=installed tags: 01_install_nfs_service - name: 02 安装rpcbind 服务 yum: name=rpcbind state=installed tags: 02_install_rpcbind_service - name: 03 创建组 group: name=www gid=666 tags: 03_add_group - name: 04 创建用户 user: name=www uid=666 group=www create_home=no shell=/sbin/nologin tags: 04_add_user - name: 05 创建共享目录 file: path=/data owner=www group=www state=directory tags: 05_create_data_dir - name: 06 拷贝配置文件 copy: src=/script/exports dest=/etc/exports tags: 06_copy_nfs_exports - name: 07 创建关于rsync密码文件 copy: content=\u0026#39;123123\u0026#39; dest=/etc/rsync.passwd mode=600 tags: 07_create_rsync_passwd - name: 08 启动rpcbind service: name=rpcbind state=started enabled=yes tags: 08_start_rpcbind - name: 09 启动nfs systemd: name=nfs state=started enabled=yes tags: 09_start_nfs 列出查看当前剧本有没有标签可用 1 2 3 4 5 6 [root@master-61 ~/my_scripts]#ansible-playbook --list-tags install_nfs.yaml playbook: install_nfs.yaml play #1 (nfs): baizhi.com\tTAGS: [] TASK TAGS: [01_install_nfs_service, 02_install_rpcbind_service, 03_add_group, 04_add_user, 05_create_data_dir, 06_copy_nfs_exports, 07_create_rsync_passwd, 08_start_rpcbind, 09_start_nfs] 选择运行某个标签 1 [root@master-61 ~/my_scripts]#ansible-playbook -t 01_install_nfs_service install_nfs.yaml 跳过某些个标签 跳过，5 6 7 标签指定的任务了，执行了 1 2 3 4 8 9\n1 [root@master-61 ~/my_scripts]#ansible-playbook --skip-tags 05_create_data_dir,06_copy_nfs_exports,07_create_rsync_passwd install_nfs.yaml 选择tasks执行 1.列出当前剧本有多少个任务（查看任务列表） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 --list-tasks list all tasks that would be executed 查看有多少个任务需要执行，以及该任务是否有tag标签 [root@master-61 ~/my_scripts]#ansible-playbook --list-tasks install_nfs.yaml playbook: install_nfs.yaml play #1 (backup): baizhi.com\tTAGS: [] tasks: 01 安装nfs-utils 服务\tTAGS: [01_install_nfs_service] 02 安装rpcbind 服务\tTAGS: [02_install_rpcbind_service] 03 创建组\tTAGS: [03_add_group] 04 创建用户\tTAGS: [04_add_user] 05 创建共享目录\tTAGS: [05_create_data_dir] 06 拷贝配置文件\tTAGS: [06_copy_nfs_exports] 07 创建关于rsync密码文件\tTAGS: [07_create_rsync_passwd] 08 启动rpcbind\tTAGS: [08_start_rpcbind] 09 启动nfs\tTAGS: [09_start_nfs] 2.指定从哪个tasks开始运行 1 2 3 --start-at-task START_AT_TASK [root@master-61 ~/my_scripts]#ansible-playbook --start-at-task \u0026#34;07 创建关于rsync密码文件\u0026#34; install_nfs.yaml ","date":"2025-04-14T16:38:54+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/ansible%E5%89%A7%E6%9C%AC/","title":"Ansible剧本"},{"content":"前言 学ansible，基础篇就是一件事\n学各种模块的语法，参数 由于模块较多，参数较多，需要做好笔记，以及一定的背诵，敲打建议记忆 基础篇学习路线\n1.主机清单语法，学会如何批量管理服务器组，配置服务器认证，服务器变量 2.学习常见的模块，语法，参数，用法 3.改造shell脚本为ansible模块 自动化运维好处 提高工作效率，减少重复性工作 大大减少人为出错的可能性 数据化管理、数据化汇报、问题可追溯 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ansible saltstack 这俩自动化运维工具均为python编写 例如： master-61机器，管理了100台目标机器 如果使用shell脚本，就需要结合for循环处理这100个机器，存在的问题如下： free -m \u0026gt; xxx.file cpuinfo shell，命令导出的数据就是一堆普通的文本字符串，难以加工处理；但有时希望能导出为数据交换格式，如json、如yaml、如xml等，就可以很轻松的发给各种编程语言，实现数据加工，格式化处理，发给前端去做网页展示 使用ansible几条命令就可以实现了 并且ansible导出的服务器信息，如内存，磁盘，网卡，等等一堆信息，可以直接导出为json数据，而json数据就可以直接发给前端，前端就可以展示出服务器的信息 综上，这就是运维开发做的事 后端python+ansible获取数据，导出json，发给前端 前端写html，js，对json数据展示 一个运维平台就搭建出来了 如何学习ansible 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1.打开ansible官网，查看所有最新的功能，不要看其他的文档，可能已经很陈旧了，python3也已经更新了很多，导致用法变化等。 最新官网文档： https://zackmoel.github.io/hugo-dev/ shell脚本（nfs服务、rsync服务），堆砌了各种部署的命令 ↓ 把这个脚本，所有的操作，全部替换为ansible的模块 2.你可能要执行的各种命令，ansible都提供了模块，如文件拷贝，如软件安装，服务重启等； 3.你使用ansible，必须严格按照ansible提供的语法来，否则只有报错 4.先学语法，语法基本功扎实后，面对千变万化的需求，才能游刃有余 5.多动手，ansible需要记忆的操作比较多 初识ansible命令： 命令语法：\n1 ansible 主机组 -m 模块名 [模块参数] 1、ansible安装部署 在master-61管理机安装 1 2 3 4 5 6 7 8 9 10 11 12 [root@master-61 ~]#yum install epel-release ansible libselinux-python -y 前提你配置好了阿里云的epel源可以直接安装 [root@master-61 ~]#yum install ansible -y [root@master-61 ~]#ansible --version ansible 2.9.27 config file = /etc/ansible/ansible.cfg configured module search path = [u\u0026#39;/root/.ansible/plugins/modules\u0026#39;, u\u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, Apr 11 2018, 07:36:10) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)] 其他被管理的机器 准备\n1 2 3 4 5 web-7 web-8 web-9 nfs-31 rsync-41 全部初始化，还原sshd原本的配置即可\n安装ansible\n用于学习ansible的主机连接配置参数\n主机清单文件（主机分组） https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#inventory-basics-formats-hosts-and-groups\n把综合架构需要用到的机器，进行分组\n主机清单配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 [root@master-61 ~]#vim /etc/ansible/hosts [web] 172.16.1.7 172.16.1.8 172.16.1.9 [nfs] 172.16.1.31 [backup]\t172.16.1.41 主机分组后，执行命令测试，批量管理一组机器、\n管理所有的机器，使用特殊主机组，all\n1 2 3 让所有的主机，远程执行hostname，返回主机名信息 [root@master-61 ~]#ansible all -m shell -a \u0026#34;hostname\u0026#34; 但是默认没配置认证方式，权限被拒绝： 2、ansible主机登录认证 Ansible批量管理主机有两种方式：\n传统的密码认证 公钥认证 ansible基于公私钥认证 1.将master61机器的公钥，分发给想免密登录的机器\n2.后续在对该机器操作，就直接进行ssh的公钥认证了，可以免密码，直接远程执行\n1 2 3 4 5 6 7 8 9 10 11 1.配置好master-61免密登录31机器 [root@master-61 ~]#ssh-keygen [root@master-61 ~]#ssh-copy-id root@172.16.1.31 2.后续可以免密执行ansible的各种模块了 [root@master-61 ~]#ansible nfs -m command -a \u0026#34;hostname\u0026#34; 你可以配置所有机器的公钥一键分发，就可以实现all所有主机的远程命令执行 [root@master-61 ~]#ansible all -m shell \u0026#34;hostname\u0026#34; # 返回结果给master-61机器 基于密码认证 在你的客户端机器、修改了ssh默认端口、以及密码需要修改主机清单文件才可以正确连接。 注意你得配置允许密码登录才能进行如下测试，可以再开一个web-9机器。 ansible主机清单配置文件语法（重要） 官网地址：\nhttps://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#connecting-to-hosts-behavioral-inventory-parameters\n可选参数：\n参数 参数类型 参数说明 ansible_host 主机地址 远程主机ip ansible_port 主机端口 设置SSH连接端口，默认22 ansible_user 主机用户 默认SSH远程连接的用户身份，默认root ansible_password 用户密码 指定SSH远程主机密码 给rsync机器，进行密码认证 1 2 3 4 5 6 7 8 9 10 11 12 编辑主机清单文件 [root@master-61 ~]#vim /etc/ansible/hosts 1.给rsync机器，添加密码，端口等信息 [backup] 172.16.1.41 ansible_port=22 ansible_password=\u0026#39;123123\u0026#39; 2.如果目标机器的ssh信息都被改了，这里也得改 [root@rsync-41 ~]#vi /etc/ssh/sshd_config [backup] 172.16.1.41 ansible_port=22999 ansible_password=\u0026#39;123123\u0026#39; 测试执行\n1 2 3 4 5 6 7 8 [root@master-61 ~]#ansible backup -m ping 172.16.1.41 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 添加web机器组的信息 1 2 3 4 5 6 7 8 9 10 11 [root@master-61 ~]#vim /etc/ansible/hosts [web] 172.16.1.7 ansible_port=22999 ansible_user=root ansible_password=123123 172.16.1.8 ansible_port=22999 ansible_user=root ansible_password=123123 [nfs] 172.16.1.31 [backup] 172.16.1.41 ansible_ssh_port=22999 ansible_ssh_user=root ansible_ssh_pass=123123 测试执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@master-61 ~]#ansible web -m ping 172.16.1.8 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 172.16.1.7 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 拿web机器测试（单独操作某主机） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 1.先配置主机组的参数 [web] 172.16.1.7 ansible_port=22999 ansible_password=\u0026#39;123123\u0026#39; 172.16.1.8 ansible_port=22999 ansible_password=\u0026#39;123123\u0026#39; 172.16.1.9 ansible_port=22999 ansible_password=\u0026#39;123123\u0026#39; 2.执行ping模块，看下是否和远程主机通信 [root@master-61 ~]#ansible web -m ping 172.16.1.7 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 172.16.1.9 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 172.16.1.8 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 指纹故障解决 你可能会遇见如下问题，关于新机器的指纹确认问题。\n解决办法1，手动ssh连接，进行指纹确认，写入到本机的\n1 [root@master-61 ~]#cat ~/.ssh/known_hosts 解决办法2，ansible配置文件中忽略指纹确认\n1 2 [root@master-61 ~]#grep \u0026#39;host_key_checking\u0026#39; /etc/ansible/ansible.cfg host_key_checking = False 问题以及解决，可以正确操作web-9机器\n1 2 3 4 5 6 7 8 [root@master-61 ~]#ansible 172.16.1.9 -m ping 172.16.1.9 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 踩坑记录(ansible缓存) 由于ansible在对远程主机操作之前，默认会先通过setup模块获取机器的facts（静态属性），并且会生成缓存，便于加速远程主机的操作；\n但缓存也会导致一些奇怪的现象，比如客户端的机器信息更新了，服务端依旧使用的是旧数据，那就不准确了，因此可以删除缓存。\n1 2 3 4 5 关于缓存导致bug的文章，https://serverfault.com/questions/630253/ansible-stuck-on-gathering-facts 清理ansible的缓存目录即可 [root@master-61 ~]#rm -rf ~/.ansible/cp/* 同一组连续的ip 可以修改主机清单文件如下，前提是该些主机的配置一致\n1 2 [web] 172.16.1.[7:9] 公共变量 当主机清单里，很多主机组，有相同的变量属性，可以写成公共变量\n这部分配置是针对web主机组，抽象的变量\n1 2 3 4 5 6 7 8 9 10 11 [root@master-61 ~]#grep -vE \u0026#39;^#|^$\u0026#39; /etc/ansible/hosts [web:vars] ansible_ssh_port=22999 ansible_ssh_user=root ansible_ssh_pass=123123 [web] 172.16.1.[7:9] [nfs] 172.16.1.31 ansible_ssh_port=22999 [backup] 172.16.1.41 ansible_ssh_port=22999 ansible_ssh_user=root ansible_ssh_pass=123123 测试web组和backup组是否可用 1 2 3 4 5 [root@master-61 ~]#ansible web -m ping [root@master-61 ~]#ansible backup -m shell -a \u0026#34;ls /opt/\u0026#34; [root@master-61 ~]#ansible web -m shell -a hostname 所有主机都生效的变量【了解】 指定主机组名all，即可针对所有主机生效，前提是，你要确保这个信息是所有主机通用的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@master-61 ~]#grep -vE \u0026#39;^#|^$\u0026#39; /etc/ansible/hosts [all:vars] ansible_port=22999 #ansible_user=root #ansible_password=123456 [web] 172.16.1.7 172.16.1.8 172.16.1.9 [nfs] 172.16.1.31 [backup] 172.16.1.41 远程执行命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@master-61 ~]#rm -rf ~/.ansible/cp/* [root@master-61 ~]# [root@master-61 ~]#ansible all -m shell -a hostname [root@master-61 ~]#ansible all -m shell -a hostname 172.16.1.31 | CHANGED | rc=0 \u0026gt;\u0026gt; nfs-31 172.16.1.8 | CHANGED | rc=0 \u0026gt;\u0026gt; web-8 172.16.1.41 | CHANGED | rc=0 \u0026gt;\u0026gt; rsync-41 172.16.1.7 | CHANGED | rc=0 \u0026gt;\u0026gt; web-7 172.16.1.9 | CHANGED | rc=0 \u0026gt;\u0026gt; web-9 3、ansible命令执行方式 Ansible实现批量管理主机的模式主要有俩：\n利用ansible命令实现批量管理（ad-hoc）模式 利用ansible剧本实现批量管理（playbook）模式 Ad-hoc和playbook的关系就好比shell命令与shell scripts的关系\nad-hoc模式 Ansible的ad-hoc模式也就是ansible的命令行模式，该模式通常用来临时处理一些任务。例如\n临时批量查看所有被管控机器的内存、负载、磁盘 临时批量分发某个特定文件 Playbook模式 Ansible的playbook模式就是针对特定的具体较大的任务，事先写好执行剧本，然后在其他机器上批量执行相同的任务，属于定制化的批量执行任务，例如\n一键安装Rsync 一键搭建LNMP集群等 ansible-doc命令 列出ansible所有支持的模块，这就是ansible这个万能工具箱所有的零件了。\n1 2 3 4 5 6 7 8 9 10 11 12 [root@master-61 ~]#ansible-doc -l |grep ^ping ping Try to connect to host, verify a usable python and re... pingdom Pause/unpause Pingdom alerts [root@master-61 ~]#ansible-doc -l |grep ^shell shell 当前ansible支持3387个模块 [root@master-61 ~]#ansible-doc -l |wc -l 3387 当前ansible支持的模块数量\n1 2 [root@master-61 ~]#ansible-doc -l |wc -l 3387 查看某个模块的具体用法\n1 2 3 [root@master-61 ~]#ansible-doc -s shell [root@master-61 ~]#ansible-doc -s ping 4、ansible核心内容（模块学习） ansible执行命令结果（状态颜色） 你后续使用各种模块操作，会有不同的颜色结果，都是有意义的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 运维远程执行命令，有2个方式 shell脚本，远程执行 ansible模块，远程执行 shell脚本不够智能，不会记录上一次的执行状态，以及修改的状态，因此导致，傻瓜式的，重复性执行。效率是极其低下的，不做状态记录 例如安装软件： shell yum install rsync; mkdir -p; 而ansible的模块，yum模块会记录执行的状态 第一次执行,装完之后，的确对目标机器产生了修改的状态，会给master-61返回一个命令的执行结果，执行状态，存储下来 ansible web -m yum -a \u0026#34;name=rsync state=installed\u0026#34; ansible会检测目标机器，对比这个状态，如果状态没变，ansible就不会再执行该命令，因此效率很高 ansible web -m yum -a \u0026#34;name=rsync state=installed\u0026#34; ansible的状态，就是如下的颜色区分，看到不同的状态\n1 2 3 4 5 6 7 8 9 绿色：命令以用户期望的执行了，但是状态没有发生改变； 黄色：命令以用户期望的执行了，并且状态发生了改变； 紫色：警告信息，说明ansible提示你有更合适的用法；出现了warning警告 红色：命令错误，执行失败； 蓝色：详细的执行过程； 官网文档 网址：Ansible.Builtin — Ansible Community Documentation\nAnsible自动化软件的核心功能就在于其众多的模块，可以说学习Ansible就是学习模块的使用。\n剩余的是对Ansible剧本编写的熟练度。\n4.1 ping测试连通性 1 2 3 通过master-61查看目标机器是否运行 ansible all -m ping https://docs.ansible.com/ansible/latest/collections/ansible/builtin/ping_module.html#ansible-collections-ansible-builtin-ping-module\n查看模块解释\n1 2 3 4 5 6 [root@master-61 ~]#ansible-doc -s ping - name: Try to connect to host, verify a usable python and return `pong\u0026#39; on success ping: data: # Data to return for the `ping\u0026#39; return value. If this parameter is set to `crash\u0026#39;, the module will cause an exception. [root@master-61 ~]# 执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [root@master-61 ~]#ansible web -m ping 172.16.1.8 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 172.16.1.9 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 172.16.1.7 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 4.2 command 简单命令模块 https://docs.ansible.com/ansible/latest/collections/ansible/builtin/command_module.html#ansible-collections-ansible-builtin-command-module\n语法\n1 2 3 [root@master-61 ~]#ansible-doc -s command ansible 主机组 -m command -a \u0026#34;需要批量执行的命令\u0026#34; 该模块作用：在远程节点上执行一个命令\ncommand模块是ansible默认的模块，也就是默认就指定了 -m command 只支持简单命令命令执行，比如你想远程看下服务器的资源信息，普通的linux命令 command模块是ansible命令基本模块，无法使用复杂的linux命令\n使用command模块执行远程命令，命令不得用变量（$HOME）\n不得出现特殊符号\n1 \u0026lt; 、\u0026gt;、|、；、\u0026amp; 远程查看主机名 1 2 3 4 [root@master-61 ~]#ansible web -m command -a \u0026#34;hostname\u0026#34; 简写： [root@master-61 ~]#ansible web -a \u0026#34;hostname\u0026#34; 查看远程主机内存 1 [root@master-61 ~]#ansible web -a \u0026#34;free -m\u0026#34; 远程创建文件、查看文件 1 2 3 [root@master-61 ~]#ansible web -m command -a \u0026#34;touch /opt/bbb.log\u0026#34; [root@master-61 ~]#ansible web -m command -a \u0026#34;cat /opt/bbb.log\u0026#34; 远程获取机器负载 1 2 3 4 5 6 7 [root@master-61 ~]#ansible web -a \u0026#34;uptime\u0026#34; 172.16.1.9 | CHANGED | rc=0 \u0026gt;\u0026gt; 11:35:36 up 3 days, 5:09, 2 users, load average: 0.00, 0.01, 0.05 172.16.1.7 | CHANGED | rc=0 \u0026gt;\u0026gt; 11:35:36 up 2:56, 2 users, load average: 0.00, 0.01, 0.02 172.16.1.8 | CHANGED | rc=0 \u0026gt;\u0026gt; 11:35:36 up 2:26, 2 users, load average: 0.00, 0.01, 0.03 关闭告警信息 1 2 3 4 [root@master-61 ~]#ansible web -m command -a \u0026#34;touch /opt/ccc.log warn=false\u0026#34; 172.16.1.9 | CHANGED | rc=0 \u0026gt;\u0026gt; 172.16.1.8 | CHANGED | rc=0 \u0026gt;\u0026gt; 172.16.1.7 | CHANGED | rc=0 \u0026gt;\u0026gt; 在所有机器上，创建baizhi01用户 1 [root@master-61 ~]#ansible web -m command -a \u0026#34;useradd baizhi01\u0026#34; 使用command提供的专有命令 这些命令用于编写ansible-playbook，完成服务器部署的各种复杂条件限定。\n选项参数 选项说明 chdir 在执行命令执行，通过cd命令进入指定目录 creates 定义一个文件是否存在，若不存在，则运行相应命令；存在则跳过 free_form（必须） 参数信息中可以输入任何系统命令，实现远程管理 removes 定义一个文件是否存在，如果存在，则运行相应命令；如果不存在则跳过 备份/var/log日志目录，需要先进入根目录 cd / \u0026amp;\u0026amp; tar -zcvf /opt/log.tgz /var/log\n注意你备份文件存放的文件夹是否存在\n1 2 3 [root@master-61 ~]#ansible web -m command -a \u0026#34;tar -zcf /opt/log.tgz /var/log chdir=/\u0026#34; [root@master-61 ~]#ansible web -a \u0026#34;ls -l /opt\u0026#34; 在/opt下创建baizhi666.log 1 2 3 4 原写法： [root@master-61 ~]#ansible web -a \u0026#34;touch /opt/chaoge666.log\u0026#34; [root@master-61 ~]#ansible web -a \u0026#34;touch chaoge666.log chdir=/opt\u0026#34; 备份/etc所有配置文件到 /backup_config/etc.tgz 。 1 2 [root@master-61 ~]#ansible web -a \u0026#34;tar -zcf /backup_config/etc.tgz etc chdir=/\u0026#34; 目标目录不存在则会报错 removes命令 1 2 3 4 5 6 7 8 9 10 11 1.这里就得提前考虑 /backup_config文件夹是否存在，必须先有文件夹，才能执行该备份命令 2.判断如果该文件夹不存在，则不执行备份 目标文件夹不存在，这个命令不会对目标机器产生任何修改，因此绿色结果 ansible web -a \u0026#34;tar -zcf /backup_config/etc.tgz etc chdir=/ removes=/backup_config\u0026#34; 3.你必须先创建该文件夹 ansible web -a \u0026#34;mkdir -p /backup_config\u0026#34; 4.再次执行该命令 ansible web -a \u0026#34;tar -zcf /backup_config/etc.tgz etc chdir=/ removes=/backup_config\u0026#34; 测试creates命令，如果目标目录已经存在了，就别创建该目录了 1 2 3 [root@master-61 ~]#ansible backup -m command -a \u0026#39;mkdir /opt creates=/opt\u0026#39; 172.16.1.41 | SUCCESS | rc=0 \u0026gt;\u0026gt; skipped, since /opt exists 4.3 shell模块（万能模块） shell模块功能：在远程节点上执行命令（复杂的命令）\nhttps://docs.ansible.com/ansible/latest/collections/ansible/builtin/shell_module.html#ansible-collections-ansible-builtin-shell-module\n也就是等于你在linux上直接执行任何复杂的命令都可以\n但是ansible的使用理念是，人家提供了几千个模块，并且有很复杂的功能，你在用shell模块之前，先查一查是否有对应的模块。\n你如果想使用ansible提供的状态功能，记录你每次执行命令的结果，你就必须得使用专有的模块，否则无法使用该功能\nshell模块可以识别特殊符号，就等于远程执行命令了\n远程过滤ssh进程信息 1 [root@master-61 ~]#ansible all -m shell -a \u0026#34;ps -ef|grep ssh\u0026#34; 使用重定向符号，创建文件 1 2 3 4 5 6 7 8 9 10 11 12 # 远程获取时间信息，且写入到文件中，但command不认识重定向 [root@master-61 ~]#ansible web -m command -a \u0026#34;date \u0026gt; /tmp/date.log\u0026#34; [root@master-61 ~]#ansible web -m shell -a \u0026#34;date \u0026#39;+%F %T\u0026#39; \u0026gt; /tmp/date.log\u0026#34; #等价操作date “+%Y-%m-%d %H:%M:%S” [root@master-61 ~]#ansible web -m shell -a \u0026#39;cat /tmp/date.log\u0026#39; 172.16.1.8 | CHANGED | rc=0 \u0026gt;\u0026gt; 2022-05-06 12:06:23 172.16.1.9 | CHANGED | rc=0 \u0026gt;\u0026gt; 2022-05-06 12:06:23 172.16.1.7 | CHANGED | rc=0 \u0026gt;\u0026gt; 2022-05-06 12:06:23 远程执行复杂linux命令\n创建文件夹 生成sh脚本文件(查看主机名) 赋予脚本可执行权限 执行脚本 忽略warning信息 这个命令就无法在command中执行\n通过一条命令，做如下事情\n1 [root@master-61 ~]#ansible web -m shell -a \u0026#34;mkdir /0224/;echo \u0026#39;hostname\u0026#39; \u0026gt; /0224/hostname.sh;chmod +x /0224/hostname.sh;/0224/hostname.sh; warn=false\u0026#34; shell命令别过度依赖，那就等于用ansible远程帮你执行了个普通的shell命令；\n4.4 copy拷贝文件 copy模块是远程推送数据模块，只能把数据推送给远程主机节点，无法拉取数据到本地。\n既然是文件拷贝，可用参数也就是围绕文件属性。\n参数名 是否 必须 默 认 值 选项 说明 src no 用于定位ansible执行的机器上的文件，需要绝对路径。如果拷贝的是文件夹，那么文件夹会整体拷贝，如果结 尾是\u0026quot; / \u0026ldquo;,那么只有文件夹内的东西被拷过去。(类似于rsync) content no 用来替代src,用于将指定文件的内容，拷贝到远程文件内 dest yes 用于定位远程节点上的文件，需要绝对路径。如果src指向的是文件夹，这个参数也必须是指向文件夹 backup no no yes/no 备份远程节点上的原始文件，在拷贝之前。如果发生什么意外，原始文件还能使用。 directory_mode no 这个参数只能用于拷贝文件夹时候，这个设定后，文件夹内新建的文件会被拷贝。而老旧的不会被拷贝 follow no no yes/no 当拷贝的文件夹内有link存在的时候，那么拷贝过去的也会有link force no yes yes/no 默认为yes,会覆盖远程的内容不一样的文件(可能文件名一样)。如果是no,就不会拷贝文件，如果远程有这 个文件 group no 设定一个群组拥有拷贝到远程节点的文件权限 mode no 等同于chmod,参数可以为\u0026quot;u+rwx or u=rw,g=r,o=r\u0026rdquo; owner no 设定一个用户拥有拷贝到远程节点的文件权限 copy语法 1 ansible 主机组 -m copy -a \u0026#34;参数\u0026#34; 简单发送文件 1 [root@master-61 ~]#ansible web -m copy -a \u0026#34;src=/tmp/61-dnf.log dest=/tmp/web-dnf.log\u0026#34; 并且ansible的模块记录了文件属性，文件的md5值，得到了文件的唯一校验值，判断文件内容是否变化，如果未变化，不做处理，提升批量管理的效率\n发送文件且指定文件属性 1 2 3 61 ↓ web机器组(属性变化，baizhi001，600) 权限改为600、修改为baizhi001用户（要求目标机器存在该用户）\n1 2 3 4 5 6 7 8 创建baizhi001用户 ansible web -m shell -a \u0026#34;useradd baizhi001\u0026#34; 远程拷贝文件，且修改权限，为600 [root@master-61 ~]#ansible web -m copy -a \u0026#34;src=/tmp/61-dnf.log dest=/opt/web-dnf.log group=baizhi001 owner=baizhi001 mode=600 \u0026#34; 远程检查文件信息 [root@master-61 ~]#ansible web -m shell -a \u0026#34;ls -l /opt/web-dnf.log\u0026#34; 发送文件且先做好备份 使用backup参数，防止覆盖远程文件，丢失备份，提前备份该目标机器的数据\n1 2 3 4 5 6 7 8 1.检查目标机器的文件 [root@master-61 ~]#ansible web -m shell -a \u0026#34;ls -l /opt/web-dnf.log\u0026#34; 2.远程拷贝文件，且做好备份 [root@master-61 ~]#ansible web -m copy -a \u0026#34;src=/tmp/61-dnf.log dest=/opt/web-dnf.log backup=yes\u0026#34; 3.发现ansible帮你做好了备份 [root@master-61 ~]#ansible web -m shell -a \u0026#34;ls -l /opt/web*\u0026#34;\t· 指定数据写入到远程文件中 向rsyncd.conf中填入账号密码，覆盖其原有的文件内容\ncontent参数\n1 [root@master-61 ~]# 注意像这样的覆盖操作，还是添加备份参数更合适\n1 [root@master-61 ~]#ansible web -m copy -a \u0026#34;content=\u0026#39;byebye LINUX\u0026#39; dest=/opt/web-dnf.log backup=yes \u0026#34; 复制文件夹 注意结尾斜杠\n1 2 3 4 5 远程拷贝/opt/ 下的所有内容到目标机器 [root@master-61 ~]#ansible web -m copy -a \u0026#34;src=/opt/ dest=/tmp/\u0026#34; 远程拷贝/opt 整个目录到目标机器 [root@master-61 ~]#ansible web -m copy -a \u0026#34;src=/opt dest=/tmp/\u0026#34; 4.5 file文件操作模块 需要和copy区别开，file模块主要是对文件属性各种操作的，用于创建文件、目录数据，以及对现有的文件、目录权限进行修改\n1 2 3 4 5 copy模块，src(管理机器上 ) dest(目标机器上) file专门用于在远程机器上，关于文件的所有操作 file src(目标机器上的文件) dest(目标机器上的文件) 官网：https://docs.ansible.com/ansible/latest/modules/file_module.html#file-module\n1 2 或者看命令帮助 [root@master-61 ~]#ansible-doc -s file 远程创建文件 ansible每次命令的执行，都会记录下当前的状态\nstate参数、path参数\n1 2 3 4 5 6 7 远程在web服务器组中，创建一个文本， hello_ansible.log [root@master-61 ~]# ansible web -m file -a \u0026#34;path=/opt/hello_ansible.log state=touch\u0026#34; [root@master-61 ~]# ansible web -m shell -a \u0026#34;ls -ld /opt/hello*\u0026#34; 172.16.1.7 | CHANGED | rc=0 \u0026gt;\u0026gt; drwxr-xr-x 2 root root 6 May 6 14:56 /opt/hello_ansible -rw-r--r-- 1 root root 0 May 6 14:54 /opt/hello_ansible.log 创建文件夹 state参数、path参数\n1 [root@master-61 ~]#ansible web -m file -a \u0026#34;path=/opt/hello_ansible state=directory\u0026#34; 创建文件且设定权限 state参数、path参数、owner参数、group参数\npath=/opt/hello-linux.log\n1 [root@master-61 ~]#ansible web -m file -a \u0026#34;path=/opt/hello-linux.log state=touch owner=baizhi001 group=baizhi001\u0026#34; 远程修改文件属性 1 [root@master-61 ~]#ansible web -m file -a \u0026#34;path=/opt/hello-linux.log state=touch owner=baizhi001 group=baizhi001 mode=777\u0026#34; 创建软连接文件 软连接，也就是在目标机器上，指定源文件，创建软连接\nsrc、dest、state\n给web服务器组的 /etc/hosts文件，添加软连接到/opt/hosts文件\n1 [root@master-61 ~]# ansible web -m file -a \u0026#34;src=/etc/hosts dest=/opt/hosts state=link\u0026#34; 强制性创建文件（软连接） 1 2 意义不大，查看force参数的作用 [root@master-61 ~]#ansible web -m file -a \u0026#34;src=/etc/hostsss dest=/opt/hosts state=link force=yes \u0026#34;\t修改已存在文件/文件夹的属性 1 2 3 4 5 修改文件 Path、mode [root@master-61 ~]#ansible 172.16.1.7 -m file -a \u0026#34;path=/opt/chaoge666.log owner=baizhi001 group=baizhi001 mode=666\u0026#34; 修改文件夹 Path、mode owner,group [root@master-61 ~]#ansible 172.16.1.7 -m file -a \u0026#34;path=/opt/hello_ansible owner=baizhi001 group=baizhi001\u0026#34; 关于file模块的所有参数作用 1 https://docs.ansible.com/ansible/latest/collections/ansible/builtin/file_module.html#parameters 关于file模块的实例用法 playbook剧本的写法，yaml写法\n1 https://docs.ansible.com/ansible/latest/collections/ansible/builtin/file_module.html#examples 4.6 script脚本模块 1 2 3 一键部署rsync，nfs，nginx等，两种做法: 1.把脚本发到目标机器上执行， 2.远程执行，目标机器上不需要存在这个脚本 官网\n1 https://docs.ansible.com/ansible/latest/collections/ansible/builtin/script_module.html#ansible-collections-ansible-builtin-script-module scripts模块功能：把本地脚本传输到远程节点上并运行脚本\n为什么需要用scripts模块，是因为比起shell模块，script模块功能更强大，管理机本地有一份脚本，就可以在所有机器上运行，斌且script模块可以反复执行命令、远程执行脚本\nscripts模块的功能参数 选项参数 选项说明 creates 定义一个文件是否存在，若不存在，则运行相应命令；存在则跳过 free_form（必须） 参数信息中可以输入任何系统命令，实现远程管理 removes 定义一个文件是否存在，如果存在，则运行相应命令；如果不存在则跳过 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1.管理机创建测试脚本 master-61创建该脚本 [root@master-61 ~]#vim echo_server_info.sh [root@master-61 ~]#cat echo_server_info.sh echo \u0026#34;$(hostname -I)\u0026#34; \u0026gt;\u0026gt; /tmp/server_info.log echo \u0026#34;$(uptime)\u0026#34; \u0026gt;\u0026gt; /tmp/server_info.log echo \u0026#34;$(free -m)\u0026#34; \u0026gt;\u0026gt; /tmp/server_info.log 2.添加执行权限 [root@master-61 ~]#chmod +x echo_server_info.sh 3.远程执行 发给nfs机器去执行 [root@master-61 ~]#ansible nfs -m script -a \u0026#34;/root/echo_server_info.sh\u0026#34; 4.检查结果 [root@master-61 ~]#ansible nfs -m shell -a \u0026#34;cat /tmp/server_info.log\u0026#34; 远程在目标机器执行脚本 1 2 3 4 5 6 7 远程安装nginx脚本 [root@master-61 ~]#cat install_nginx.sh #yum install nginx -y #yum remove nginx -y echo \u0026#34;nginx操作完毕\u0026#34; [root@master-61 ~]#ansible nfs -m script -a \u0026#34;/root/install_nginx.sh\u0026#34; 查看命令执行详细过程 显示命令执行的详细过程，开启了debug日志模式，-vvvvv参数显示详细过程，v越多，越详细\n1 [root@master-61 ~]#ansible nfs -vvvv -m shell -a \u0026#34;cat /tmp/server_info.log\u0026#34; 4.7 cron定时任务模块 cron模块用于管理定时任务的记录，编写任务\n1 2 官网文档 https://docs.ansible.com/ansible/latest/modules/cron_module.html#cron-module 对比ansible的cron模块以及crontab 常见的参数如此，使用ansible编写定时任务，和直接编写是没有什么区别的\n添加ntpdate定时任务 添加每5分钟执行一次和阿里云时间同步\nname、job、minute参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 cron模块创建定时任务 [root@master-61 ~]#ansible nfs -m cron -a \u0026#34;name=\u0026#39;ntp aliyun\u0026#39; minute=*/5 job=\u0026#39;ntpdate -u ntp.aliyun.com\u0026#39;\u0026#34; 172.16.1.31 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;envs\u0026#34;: [], \u0026#34;jobs\u0026#34;: [ \u0026#34;ntp aliyun\u0026#34; ] } 查看远程机器的crontab记录 [root@master-61 ~]#ansible nfs -m shell -a \u0026#34;crontab -l\u0026#34; 172.16.1.31 | CHANGED | rc=0 \u0026gt;\u0026gt; * * * * * /usr/sbin/ntpdate time1.aliyun.com \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 #Ansible: ntp aliyun */5 * * * * ntpdate -u ntp.aliyun.com 删除定时任务 只能基于cron模块指定名字的修改\nname参数，state参数\n1 2 3 4 5 cron模块用法 ansible nfs -m cron -a \u0026#34;name=\u0026#39;ntp aliyun\u0026#39; state=absent \u0026#34; shell模块用法 [root@master-61 ~]#ansible nfs -m shell -a \u0026#34;crontab -r\u0026#34; 创建每分钟执行的任务 不指定任何时间规则，默认是每分钟\n1 2 3 [root@master-61 ~]#ansible nfs -m cron -a \u0026#34;name=\u0026#39;一句话\u0026#39; job=\u0026#39;echo \u0026#34;hellolinux\u0026#34; \u0026gt;\u0026gt;/tmp/hello.log \u0026#39;\u0026#34; [root@master-61 ~]#ansible nfs -m shell -a \u0026#34;crontab -l\u0026#34; 修改指定名称的定时任务 1 2 3 [root@master-61 ~]#ansible nfs -m cron -a \u0026#34;name=\u0026#39;一句话\u0026#39; minute=30 hour=23 job=\u0026#39;echo hellolinux \u0026gt;\u0026gt;/tmp/hello.log\u0026#39; \u0026#34; [root@master-61 ~]#ansible nfs -m shell -a \u0026#34;crontab -l\u0026#34; 4.8 group模块 管理系统用户组的模块\n1 2 官网文档 https://docs.ansible.com/ansible/latest/modules/group_module.html#group- 语法:\n模块参数 参数描述 name 创建指定的组名 gid 组的GID state absent，移除远程主机的组 present，创建远端主机的组 创建baizhi_ops组，gid=1234 name、gid\n1 [root@master-61 ~]#ansible nfs -m group -a \u0026#34;name=baizhi_ops gid=1234\u0026#34; 删除组 name、gid、state\n1 [root@master-61 ~]#ansible nfs -m group -a \u0026#34;name=baizhi_ops gid=1234 state=absent\u0026#34; 4.9 user用户模块 用户管理，也就是关于用户的\nuid 用户名 用户主组 用户附加组 创建用户 删除用户 创建关于用户的公私钥 用户过期时间 用户密码过期时间 1 2 官网文档 https://docs.ansible.com/ansible/latest/modules/user_module.html#user-module 语法参数 1 2 实例用法 https://docs.ansible.com/ansible/latest/collections/ansible/builtin/user_module.html#examples 模块参数 参数描述 create_home 创建家目录，设置no则不创建家目录 group 创建用户组 name 创建用户的名字 password 创建用户的密码 uid 创建用户的UID shell 用户登录解释器 state Absent（删除用户）present（默认参数，创建） expires 账户过期时间 创建baizhi001用户，uid为8888 1 [root@master-61 ~]#ansible nfs -m user -a \u0026#34;name=baizhi001 uid=8888\u0026#34; 创建用户cc01 uid、gid为1777 没有家目录、不允许登录 1 2 3 4 5 6 7 8 9 注意该用户组是否存在，否则报错 group、name、gid [root@master-61 ~]#ansible nfs -m group -a \u0026#34;name=cc01 gid=1777\u0026#34; 创建用户，设置权限 user、name、uid、group、create_home、shell [root@master-61 ~]#ansible nfs -m user -a \u0026#34;name=cc01 uid=1777 group=1777 create_home=no shell=/sbin/nologin \u0026#34; 检查用户 4.10 yum安装软件 yum模块明显就是一个专门用于管理软件的模块。yum模块其实就是在远程节点上，执行yum命令，你可以快速登录到目标机器，查看进程\n官网文档示例用法 1 https://docs.ansible.com/ansible/latest/collections/ansible/builtin/yum_module.html#examples 安装net-tools最新版本 latest参数也用于升级软件包\n1 [root@master-61 ~]#ansible backup -m yum -a \u0026#34;name=net-tools state=latest\u0026#34; 卸载net-tools软件 1 [root@master-61 ~]#ansible backup -m yum -a \u0026#34;name=net-tools state=absent\u0026#34; 安装rsync服务 1 2 3 4 [root@master-61 ~]#ansible backup -m yum -a \u0026#34;name=rsync state=installed\u0026#34; 检查rsync [root@master-61 ~]#ansible backup -m shell -a \u0026#34;rpm -qa rsync\u0026#34; 卸载rsync服务 1 [root@master-61 ~]#ansible backup -m yum -a \u0026#34;name=rsync state=removed\u0026#34; 4.11 service/systemd模块 该模块作用是针对yum包管理\nservice适用于centos6前的系统\nsystemd命令应用于centos7系统\n要注意的是service模块依旧对centos7有效，但是建议大家使用systemd模块\nsystemd模块用于控制远程主机的systemd服务，说白了，就是Linux下的systemd命令。需要远程主机支持systemd 用法和service模块基本相同 systemd模块参数 1 2 3 4 5 6 7 8 9 10 如果使用systemctl 管理程序的话，可以使用systemd模块，systemctl 可以 控制程序启/停，reload，开机启动，观察程序状态（status）等，掌握使用后管理就更方便了 主要参数 daemon_reload：在执行任何其他操作之前运行守护进程重新加载，以确保systemd已经读取其他更改 enabled：服务是否开机自动启动yes|no。enabled和state至少要有一个被定义 masked：是否将服务设置为masked状态，被mask的服务是无法启动的 name：必选项，服务名称 no_block(2.3后新增)：不要同步等待操作请求完成 state：对当前服务执行启动，停止、重启、重新加载等操作（started,stopped,restarted,reloaded） user：使用服务的调用者运行systemctl，而不是系统的服务管理者 安装、启动nginx服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 1.安装nginx服务 [root@master-61 ~]#ansible web -m yum -a \u0026#34;name=nginx state=installed\u0026#34; 2.启动服务 [root@master-61 ~]#ansible web -m systemd -a \u0026#34;name=nginx state=started\u0026#34; 3.查询状态，这里ansible未直接提供status参数，你可以借助command模块即可 [root@master-61 ~]#ansible web -a \u0026#34;systemctl status nginx\u0026#34; 4.停止nginx服务 [root@master-61 ~]#ansible web -m systemd -a \u0026#34;name=nginx state=stopped\u0026#34; 5.设置nginx开机自启 [root@master-61 ~]#ansible web -m systemd -a \u0026#34;name=nginx state=started enabled=yes\u0026#34; 6.检查nginx状态 [root@master-61 ~]#ansible web -a \u0026#34;systemctl is-enabled nginx\u0026#34; [root@master-61 ~]#ansible web -a \u0026#34;systemctl status nginx\u0026#34; 7.关闭开机自启、且停止服务 [root@master-61 ~]#ansible web -m systemd -a \u0026#34;name=nginx state=stopped enabled=no\u0026#34; 8.再次检查状态 [root@master-61 ~]#ansible web -m shell -a \u0026#34;systemctl is-enabled nginx;systemctl status nginx\u0026#34; 4.12 mount挂载模块 1 2 官网 https://docs.ansible.com/ansible/latest/collections/ansible/posix/mount_module.html#mount- 在nfs-31机器准备nfs 1 2 3 4 5 6 7 8 9 10 [root@nfs-31 ~]#yum install nfs-utils rpcbind -y [root@nfs-31 ~]#mkdir /nfs-data [root@nfs-31 ~]#vim /etc/exports /nfs-data 172.16.1.0/24(rw) [root@nfs-31 ~]#systemctl restart nfs [root@nfs-31 ~]#showmount -e 127.0.0.1 给web-7机器挂载nfs目录（只写入/etc/fstab而不立即挂载） 1 2 3 4 5 [root@master-61 ~]#ansible 172.16.1.7 -m mount -a \u0026#34;src=\u0026#39;172.16.1.31:/nfs-data\u0026#39; path=\u0026#39;/test-nfs\u0026#39; state=present fstype=nfs \u0026#34; 查看挂载状态 [root@master-61 ~]#ansible 172.16.1.7 -m shell -a \u0026#34;cat /etc/fstab\u0026#34; [root@master-61 ~]#ansible 172.16.1.7 -a \u0026#34;df -h\u0026#34; 给web-7机器挂载nfs目录（立即挂载且写入/etc/fstab） 1 2 3 4 5 [root@master-61 ~]#ansible 172.16.1.7 -m mount -a \u0026#34;src=\u0026#39;172.16.1.31:/nfs-data\u0026#39; path=\u0026#39;/test-nfs\u0026#39; state=mounted fstype=nfs \u0026#34; 检查 [root@master-61 ~]#ansible 172.16.1.7 -a \u0026#34;df -h\u0026#34; [root@master-61 ~]#ansible 172.16.1.7 -a \u0026#34;cat /etc/fstab\u0026#34; 取消挂载，以及删除fstab记录 1 2 3 4 5 [root@master-61 ~]#ansible 172.16.1.7 -m mount -a \u0026#34;src=\u0026#39;172.16.1.31:/nfs-data\u0026#39; path=\u0026#39;/test-nfs\u0026#39; state=absent fstype=nfs \u0026#34; 验证 [root@master-61 ~]#ansible 172.16.1.7 -a \u0026#34;df -h\u0026#34; [root@master-61 ~]#ansible 172.16.1.7 -a \u0026#34;cat /etc/fstab\u0026#34; 取消挂载，不删除fstab记录 1 [root@master-61 ~]#ansible 172.16.1.7 -m mount -a \u0026#34;src=\u0026#39;172.16.1.31:/nfs-data\u0026#39; path=\u0026#39;/test-nfs\u0026#39; state=unmounted fstype=nfs \u0026#34; state总结参数 1 2 3 4 5 mounted 挂载设备且写入fstab present 仅写入fstab 不挂载 absent 卸载且删除fstab记录 umounted 只卸载不删除fstab记录 remounted 重新挂载这个设备 4.13 archive压缩模块 1 2 3 4 官网文档 https://docs.ansible.com/ansible/latest/collections/community/general/archive_module.html 用法文档 https://docs.ansible.com/ansible/latest/collections/community/general/archive_module.html#examples 支持压缩类型 1 2 3 4 5 bz2 gz ← (default) tar xz zip 压缩/etc配置文件到指定路径 1 2 3 4 5 [root@master-61 ~]#ansible web -m archive -a \u0026#34;path=/etc dest=/opt/etc.tgz\u0026#34; [root@master-61 ~]#ansible web -a \u0026#34;ls /opt -l\u0026#34; [root@master-61 ~]#ansible web -a \u0026#34;file /opt/etc.tgz\u0026#34; 压缩/var/log为zip类型到指定路径 1 2 3 [root@master-61 ~]#ansible web -m archive -a \u0026#34;path=/var/log dest=/opt/log.zip format=zip\u0026#34; [root@master-61 ~]#ansible web -a \u0026#34;file /opt/log.zip\u0026#34; 4.14 unarchive解压缩模块 注意了，你现在是远程解压缩，而不是在本机直接解压缩\n1 https://docs.ansible.com/ansible/latest/collections/ansible/builtin/unarchive_module.html#examples 解压缩etc.tgz到指定目录（远程解压） remote_src远程数据源\n1 2 3 4 5 6 7 8 指定目录必须存在 [root@master-61 ~]#ansible web -m file -a \u0026#34;path=/opt/etc_file state=directory\u0026#34; 解压缩 [root@master-61 ~]#ansible web -m unarchive -a \u0026#34;src=/opt/etc.tgz dest=/opt/etc_file/ remote_src=yes\u0026#34; 查看 [root@master-61 ~]#ansible web -a \u0026#34;ls /opt/etc_file/etc/\u0026#34; 将管理机的压缩包，解压到远程机器上 将master-61的压缩文件，解压到web-7机器上\n1 2 3 4 5 6 7 8 1.生成etc.tgz数据 [root@master-61 ~]#cd / \u0026amp;\u0026amp; tar -zcf /opt/etc.tgz etc 2.远程解压到web-7机器上 [root@master-61 /]#ansible web -m unarchive -a \u0026#34;src=/opt/etc.tgz dest=/tmp/\u0026#34; 3.检查 [root@master-61 /]#ansible web -a \u0026#34;ls /tmp/etc/\u0026#34; ","date":"2025-04-14T16:38:41+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/ansible%E5%9F%BA%E7%A1%80/","title":"Ansible基础"},{"content":"1.为什么要学物理备份？ 一个合格的运维工程师或者dba工程师,如果有从事数据库方面的话,首先需要做的就是备份,如果没有备份,出现问题的话,你的业务就会出问题,你的工作甚至会丢掉\n所以备份是重要的,但光有备份还不行,备份后如果出现问题,你还得使用备份数据来恢复,但恢复数据的时间一般都是很长的,不符合业务需求,所以回复效率较高的物理备份也会被使用。\n就像前文给大家看的微盟数据库被删。,最后是腾讯云的工程师协助进行数据恢复\n但是单纯的物理备份会有以下问题：\n存储引擎依赖：\n物理备份通常与特定的存储引擎实现密切相关。不同版本的 MySQL 可能会对存储引擎的内部数据结构（如 InnoDB 的 redo 和 undo 日志）进行更改，从而导致兼容性问题。 版本变化：\nMySQL 的不同版本之间，数据文件格式可能会发生变化。物理备份直接复制数据文件，这些变化可能导致备份在不同版本之间不兼容。 平台依赖：\n物理备份可能依赖于特定的操作系统和文件系统特性。例如，文件锁定和文件系统快照在不同操作系统上可能表现不同。 事务日志：\nredo 和 undo 日志用于恢复和回滚事务。它们的格式和管理方式在不同版本中可能会有所变化，影响备份的可移植性。 为了解决以上问题，所以一个快速备份与恢复的软件就很有必要。\nxtrabackup工具 Percona-xtrabackup是Percona公司开发的一个用于MySQL数据库物理热备的备份工具,支持MySQL、Percona server和MariaDB,开源免费,是目前较为受欢迎的主流备份工具\nxtrabackup只能备份innoDB和xtraDB两种数据引擎的表,而不能备份MyiSAM数据表。\n特点\n物理备份工具,拷贝数据文件 备份和恢复数据的速度非常快,安全可靠 在备份期间执行的事务不会间断,备份innodb数据不影响业务 备份期间不增加太多数据库的性能压力 支持对备份的数据自动校验 运行全量,增量,压缩备份及流备份 支持在线迁移表以及快速创建新的从库 运行几乎所有版本的mysql和maridb 什么是物理备份 查看如下物理备份方式\n1 2 3 4 5 6 7 8 9 10 11 12 1. 基于逻辑备份的全量备份，导入执行，前提是数据库能正常启动 2. 直接恢复物理文件数据 - tar对mysql数据打包压缩，做了个备份 - 删数据 - 解压恢复数据 - 数据库重启还是可以继续用 但是这种方式太粗暴，有更专门的工具，通过这种直接操作数据文件的，备份，恢复方案，且对数据库做很多的校验工作。 一些主流的物理备份工具，例如xtrabackup工具 数据文件扩张名 文件类型 作用 .idb文件 以独立表空间存储的InnoDB引擎类型的数据文件扩展名 .ibdata文件 以共享表空间存储的InnoDB引擎类型的数据文件扩展名 .frm文件 存放于表相关的元数据(meta)信息及表结构的定义信息 .MYD文件 存放MyISAM引擎表的数据文件扩展名 .MYI文件 存放MyISAM引擎表的索引信息文件扩展名 看看mysql的数据是什么 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [root@tech-db-51 /linux0224/mysql_3306/test_backup]#ll total 112 -rw-r----- 1 mysql mysql 67 Aug 10 12:15 db.opt -rw-r----- 1 mysql mysql 8556 Aug 10 12:15 test_table.frm -rw-r----- 1 mysql mysql 98304 Aug 10 12:32 test_table.ibd 所以数据库引擎，就是帮你 1. 分析SQL语法 2. 执行SQL 3. 修改库，表数据 4. 提供了如事务的特性，能回滚，等，。 mysql\u0026gt; show engines; 查看当前机器是什么引擎 mysql\u0026gt; show variables like \u0026#39;%storage%\u0026#39;; +----------------------------------+--------+ | Variable_name | Value | +----------------------------------+--------+ | default_storage_engine | InnoDB | | default_tmp_storage_engine | InnoDB | | disabled_storage_engines | | | internal_tmp_disk_storage_engine | InnoDB | +----------------------------------+--------+ 4 rows in set (0.00 sec) 安装xtrabackup工具 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 yum install perl perl-devel libaio libaio-devel perl-Time-HiRes perl-DBD-MySQL -y # 下载软件且安装 wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.9/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.9-1.el7.x86_64.rpm yum localinstall percona-xtrabackup-24-2.4.9-1.el7.x86_64.rpm -y # 就是用它的命令而已 # 搜索查看安装的这个rpm包，默认生成了哪些文件 [root@tech-db-51 /opt]#rpm -ql percona-xtrabackup-24 /usr/bin/innobackupex /usr/bin/xbcloud /usr/bin/xbcloud_osenv /usr/bin/xbcrypt /usr/bin/xbstream /usr/bin/xtrabackup /usr/share/doc/percona-xtrabackup-24-2.4.9 /usr/share/doc/percona-xtrabackup-24-2.4.9/COPYING /usr/share/man/man1/innobackupex.1.gz /usr/share/man/man1/xbcrypt.1.gz /usr/share/man/man1/xbstream.1.gz /usr/share/man/man1/xtrabackup.1.gz 2.全量备份，恢复 1.明确，这个工具，其实就是再 备份mysql的数据文件而已\n1 2 3 4 5 6 7 8 0. 给你的机器，设置基于GTID的模式运行 1. 基于命令 ，全量备份命令 # 和mysqldump很像，链接实例，备份数据 # 创建备份目录 innobackupex --user=root --password=linux3306 -S /tmp/mysql.sock /xtrabackup_data/ 查看xtrabackup工具生成的日志文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 查看具体备份的数据信息，以及自己生成了哪些日志文件 xtrabackup_binlog_info 记录全量备份时，该实例最后的一个binlog 事务ID xtrabackup_logfile 是该工具本身的一个二进制日志文件 [root@tech-db-51 /xtrabackup_data/2022-08-10_15-29-12]#strings xtrabackup_logfile xtrabkup 220810 15:29:12 xtrabackup_info 当前3306全量备份的详细信息，xtraback备份当前实例数据，一个版本信息 [root@tech-db-51 /xtrabackup_data/2022-08-10_15-29-12]#cat xtrabackup_info uuid = 22363968-187e-11ed-8a4d-000c29463bc7 name = tool_name = innobackupex tool_command = --user=root --password=... -S /tmp/mysql.sock /xtrabackup_data/ tool_version = 2.4.9 ibbackup_version = 2.4.9 server_version = 5.7.28-log start_time = 2022-08-10 15:29:12 end_time = 2022-08-10 15:29:13 lock_time = 0 binlog_pos = filename \u0026#39;mysql-log-bin.000012\u0026#39;, position \u0026#39;194\u0026#39;, GTID of the last change \u0026#39;187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6\u0026#39; innodb_from_lsn = 0 innodb_to_lsn = 950998185 partial = N incremental = N format = file compact = N compressed = N encrypted = N # xtrabackup备份数据，也是有连续性记录， # xtrabackup通过lsn号，确认数据的起点，截止点 # xtrabackup备份数据，出现不一致的情况，会来查看该信息（DBA的活） [root@tech-db-51 /xtrabackup_data/2022-08-10_15-29-12]#cat xtrabackup_checkpoints backup_type = full-backuped from_lsn = 0 to_lsn = 950998185 last_lsn = 950998194 compact = 0 recover_binlog_info = 0 不要该工具自带的时间戳信息 1 2 3 4 --no-timestamp #自己指定备份的时间目录 innobackupex --no-timestamp --user=root --password=123456 -S /tmp/mysql.sock /xtrabackup_data_no_time/full_3306_db_$(date +%F)/ 恢复该全量备份的数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 1. 挪走自带的数据，用mv替代rm [root@tech-db-51 /linux0224/mysql_3306]#mv ./* /opt/3306_db_backup/ 2.尝试用xtrabackup命令恢复 恢复的思路其实，把备份的数据，原封不动，再放回mysql datadir下 3. 基于xtraback命令的参数，对默认所有的未提交事务，确保数据一致性 # 操作备份的数据即可 innobackupex --apply-log /xtrabackup_data_no_time/full_3306_db_2022-08-10/ 4. 此时就可以直接恢复数据了 # innobackupex \u0026gt; rsync 数据拷贝回去 innobackupex --defaults-file=/etc/my.cnf --copy-back --rsync /xtrabackup_data_no_time/full_3306_db_2022-08-10/ 4.1 重新授权给mysql [root@tech-db-51 /linux0224/mysql_3306]#chown -R mysql.mysql ./* 5.恢复数据之后，建议重启mysql，确保数据重新加载正常 6.修改配置文件，修改日志目录 [root@tech-db-51 /linux0224/mysql_3306]#mkdir -p /mysql_3306/logs/ [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]#chown -R mysql.mysql /mysql_3306/logs/ 7.重启 [root@tech-db-51 /linux0224/mysql_3306]#systemctl restart mysqld 8.新的日志目录 [root@tech-db-51 /linux0224/mysql_3306]#ls /mysql_3306/logs/ 3306-err.log 9.确保数据可以访问 mysql\u0026gt; select * from test_backup.test_table; +------+ | id | +------+ | 777 | | 888 | | 999 | +------+ 3 rows in set (0.01 sec) 3.增量备份 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 完成演练目标 周日full + 周一inc1 + 周二inc2 + 周三 inc3 注意命令细节即可，最后恢复时，需要先合并多个增量备份的日志，然后再统一恢复完整的数据。 # 1. 先模拟8-10 全量备份 innobackupex --no-timestamp --user=root --password=123456 -S /tmp/mysql.sock /xtrabackup_0224/full_3306_db_$(date +%F)/ # 2.检查全量数据 [root@tech-db-51 /xtrabackup_0224]#du -sh . 93M\t. [root@tech-db-51 /xtrabackup_0224]#ll total 4 drwxr-x--- 26 root root 4096 Aug 10 16:18 full_3306_db_2022-08-10 # 3.模拟次日的增量写入即可 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------+ | mysql-log-bin.000013 | 194 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6 | +----------------------+----------+--------------+------------------+------------------------------------------+ 1 row in set (0.00 sec) # 增量的数据写入 mysql\u0026gt; create database db_8_11; # 4. 进行次日的增量备份，生成增量数据目录 # --incremental-basedir 以哪个目录为基础数据目录，然后进行增量备份 # --incremental 增量备份的数据，放到哪 innobackupex --defaults-file=/etc/my.cnf --user=root --password=123456 --socket=/tmp/mysql.sock --no-timestamp --incremental-basedir=/xtrabackup_data/2025-03-22_18-04-19 --incremental /xtrabackup_0224/incr_1_2022-08-11 innobackupex --defaults-file=/etc/my.cnf --socket=/tmp/mysql.sock --no-timestamp --incremental-basedir=/xtrabackup_data/2025-03-22_18-04-19 --incremental /xtrabackup_data/incr_1_2025-03-22 # 5.进行 8-12的 增量备份，写入数据，模拟当天的数据增量 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+----------------------------------------------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+----------------------------------------------------------------------------------+ | mysql-log-bin.000013 | 362 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6, 9945ceea-1883-11ed-b2b4-000c29463bc7:1 | +----------------------+----------+--------------+------------------+----------------------------------------------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; create database db_8_12; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------+ | mysql-log-bin.000013 | 530 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6, 9945ceea-1883-11ed-b2b4-000c29463bc7:1-2 | +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) # 6.对 8-12的数据，进行增量备份 # --incremental-basedir=/xtrabackup_0224/incr_1_2022-08-11 以谁为相对进行增量 # --incremental=/xtrabackup_0224/incr_2_2022-08-12 本次增量数据写到哪 innobackupex --defaults-file=/etc/my.cnf --user=root --password=linux3306 --socket=/tmp/mysql.sock --no-timestamp --incremental-basedir=/xtrabackup_0224/incr_1_2022-08-11 --incremental /xtrabackup_0224/incr_2_2022-08-12 7.检查当前所有的备份环境 [root@tech-db-51 /xtrabackup_0224]#du -sh * 93M\tfull_3306_db_2022-08-10 3.6M\tincr_1_2022-08-11 3.6M\tincr_2_2022-08-12 [root@tech-db-51 /xtrabackup_0224]# [root@tech-db-51 /xtrabackup_0224]# [root@tech-db-51 /xtrabackup_0224]## 看懂22222 8.模拟8-13数据写入 恢复思路 先模拟删数据，全部删除，反正有全量备份\n1 2 3 mkdir -p /tmp/test_xtrabackup_db/ [root@tech-db-51 /xtrabackup_0224]#mv /linux0224/mysql_3306/* /tmp/test_xtrabackup_db/ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 # 1. 明确了，目前可以恢复 8-10 到 8-12的数据， # 2. 注意8-13的数据，再binlog里，找binlog在哪 [root@tech-db-51 /xtrabackup_0224]#ls /mysql_log/log_bin_3306/ all-06.txt mysql-log-bin.000001 mysql-log-bin.000003 mysql-log-bin.000005 mysql-log-bin.000007 mysql-log-bin.000009 mysql-log-bin.000011 mysql-log-bin.000013 mysqllogOK.sql table_delete.txt jpress.sql mysql-log-bin.000002 mysql-log-bin.000004 mysql-log-bin.000006 mysql-log-bin.000008 mysql-log-bin.000010 mysql-log-bin.000012 mysql-log-bin.index recovery.sql test4.txt [root@tech-db-51 /xtrabackup_0224]# # 3.开始合并增量日志 在使用 Percona XtraBackup 工具进行备份时，--apply-log 和--redo-only 参数用于处理备份的一致性和恢复。 --apply-log - 作用：将备份文件恢复到一致状态。 - 用途：在备份完成后，使用 `--apply-log` 可以应用 redo 日志，以确保数据文件的一致性。这一步通常在准备恢复之前执行，使得备份能够直接用于恢复。 --redo-only - 作用：应用 redo 日志但不清理 undo 日志。 - 用途：用于准备增量备份链。在应用增量备份时，先对基础备份使用 `--apply-log --redo-only`，然后逐个应用增量备份。最后，在应用完所有增量备份后，再次运行 `--apply-log`（不带 `--redo-only`）以完成恢复。 这两个步骤确保备份在恢复时是一致的，并且支持增量备份的应用。 - 先处理8-10全量数据 innobackupex --apply-log --redo-only /xtrabackup_0224/full_3306_db_2022-08-10 - 合并增量1，到全量数据 # --incremental-dir 填入增量的数据目录 写入 全量数据目录 innobackupex --apply-log --redo-only --incremental-dir=/xtrabackup_0224/incr_1_2022-08-11 /xtrabackup_0224/full_3306_db_2022-08-10 # 合并8-12的增量数据 innobackupex --apply-log --redo-only --incremental-dir=/xtrabackup_0224/incr_2_2022-08-12 /xtrabackup_0224/full_3306_db_2022-08-10 # 最后对full数据 一致性校验确认，提交事务 innobackupex --apply-log /xtrabackup_0224/full_3306_db_2022-08-10 # 基于最终的全量数据，恢复 # 预测结果，应该是有 db_8_11 db_8_12 innobackupex --copy-back /xtrabackup_0224/full_3306_db_2022-08-10 [root@tech-db-51 /linux0224/mysql_3306]#chown -R mysql.mysql ./* # 此时还差一个 8-13的增量写入， 目前是 8-10 8-11 8-12 数据全部恢复了 # 基于mysqlbinlog 基于GTID的号码，恢复数据 db_8-13 mysqlbinlog --skip-gtids --include-gtids=\u0026#39;9945ceea-1883-11ed-b2b4-000c29463bc7:3\u0026#39; /mysql_log/log_bin_3306/mysql-log-bin.000013 \u0026gt; /tmp/db_8_13.sql # 恢复该导出的SQL文件 mysql\u0026gt; set sql_log_bin=0; mysql\u0026gt; source /tmp/db_8_13.sql; mysql\u0026gt; set sql_log_bin=1; Query OK, 0 rows affected (0.00 sec) # 确认后续的日志，会继续记录 mysql\u0026gt; insert into db_8_13.table_13 values(6666); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------------------------------------------------+ | mysql-log-bin.000014 | 667 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6, 7929ae4c-188a-11ed-ba6b-000c29463bc7:1-2, 9945ceea-1883-11ed-b2b4-000c29463bc7:1-3 | +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 今日作业 1 2 3 4 5 6 7 1.整理mysql数据备份方案 全量+增量 2. xtrabackup工具，当你需要处理超过百GB级别的数据，才会用到这个。 但其实到这个时候，也就有DBA介入了。 3.预习mysql主从复制博客，做练习。 ","date":"2025-04-14T16:12:13+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/%E7%89%A9%E7%90%86%E5%A4%87%E4%BB%BD%E5%B7%A5%E5%85%B7xtrabackup/","title":"物理备份工具（xtrabackup）"},{"content":"1.复习 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 1. mysqldump实现逻辑备份 全量备份 备份某些库 备份某些库下的，某些表 以及只要数据，不要表结构 insert ，打开导出的sql文件看看，mysqldump导出的数据就是个普通文本 只要表结构，不要数据 2. binlog二进制日志 - binlog的作用,记录你修改类的操作，记录到日志中 除非你主动基于myqsldump数据备份,如果再还未备份之前 1. 建了一张表 2. 写入了些数据 3. 有人删表了 binlog的作用显而易见 - 再你未进行备份之前，你还没备份数据， - 如何配置打开binlog - 基于哪些SQL语句，可以查看binlog 的信息 注意： 1 2 3 4 5 https://dev.mysql.com/doc/refman/5.7/en/mysqlbinlog-row-events.html 在官网，查阅--base64-output=DECODE-ROWS 该参数的作用时，发现，官网明确说明了，这个参数，有更良好的阅读性 但是不应该用于数据恢复 再了解了binlog是用于记录数据变化的一个日志后，就得明白，这个日志是用于数据恢复的。\n1 2 数据写入，记录日志SQL 数据丢了？不用吗，日志SQL恢复即可。 1.前提要打开binlog功能 1 2 3 4 5 6 7 8 9 创建、导入数据库等操作，要提前就打开binlog，否则无法记录 mysql\u0026gt; show master status; （测试截止点 935） 查看当前正在用哪个binlog，以及数据截止点在哪 2. 查看某个binlog，每次事务的 pos值区间，以及对应的事件名（建库，写入数据，删除数据） mysql\u0026gt; mysql\u0026gt; show binlog events in \u0026#39;mysql-log-bin.000007\u0026#39;; 2.模拟误删库，恢复数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 模拟误删除库，恢复到删库之前 重新建数据 mysql\u0026gt; mysql\u0026gt; flush logs; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000008 | 154 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; mysql\u0026gt; create database lol01; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; mysql\u0026gt; use lol01; Database changed mysql\u0026gt; mysql\u0026gt; create table tanke(id int); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000008 | 483 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 查看发生了几次事务 show binlog events in \u0026#39;mysql-log-bin.000008\u0026#39;; # 本次事务区间 483-751 mysql\u0026gt; insert into tanke values(666),(777),(888); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 3.模拟数据误删除 4.恢复思路 基于binlog的日志事件查看，找到建库事件，删库事件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 1. 截取从建库到删库之间的所有的binlog 2.先看看当前的binlog mysql\u0026gt; show master status; 3.找到建库的事件pos值 4. 找到删库前的pos事件值 5.截取删库前的SQL恢复即可 从建表，到删数据前的 事务，进行恢复， 基于mysqlbinlog命令，截取 binlog日志，拿到这个区间的SQL mysql-log-bin.000008 # --start-position 从建表开始 316 # --stop-position 到删表之前结束 751 # 截取部分日志 mysqlbinlog --start-position=316 --stop-position=751 mysql-log-bin.000008 \u0026gt; /opt/不恢复直播吃电脑.txt # 预期结果是 ，查询tanke表，看到 666 777 888 # 要进入数据库，暂停事务的记录 mysql\u0026gt; set sql_log_bin=0; Query OK, 0 rows affected (0.00 sec) 导入数据 mysql\u0026gt; source /opt/不恢复直播吃电脑.txt 再次开启事务记录 mysql\u0026gt; select * from lol01.tanke; +------+ | id | +------+ | 666 | | 777 | | 888 | +------+ 3 rows in set (0.00 sec) # 再次开启事务记录 set sql_log_bin=1; 2.基于GTID的binlog应用 1 2 3 4 5 6 7 8 9 10 11 12 基于GTID，不再需要通过pos值去判定每一个事务操作的边界 create database --- pos值 范围 create table --- pos值 范围 insert into --- pos值 范围 mysql提供了更方便，更精确，更容易用于数据恢复的GTID模式 GTID (Global Transaction IDentifier) 是全局事务标识。它具有全局唯一性，一个事务对应一个GTID。 2.1 什么是GTID 从 MySQL 5.6.5 开始新增了一种基于 GTID 的复制方式。\n通过 GTID 保证了每个在主库上提交的事务在集群中有一个唯一的ID。\n这种方式强化了数据库的主备一致性，故障恢复以及容错能力。\n在原来基于二进制日志的复制中，从库需要告知主库要从哪个偏移量pos值进行增量同步，如果指定错误会造成数据的遗漏，从而造成数据的不一致。\n借助GTID，在发生主备切换的情况下，MySQL的其它从库可以自动在新主库上找到正确的复制位置，这大大简化了复杂复制拓扑下集群的维护，也减少了人为设置复制位置发生误操作的风险。\n另外，基于GTID的复制可以忽略已经执行过的事务，减少了数据发生不一致的风险。\n2.2 什么是事务 MySQL 的事务是一组可以一起执行的 SQL 操作，确保数据的一致性和完整性。事务的执行要么全部成功，要么全部失败。事务主要用于处理需要保证数据一致性的操作。\nACID 特性 事务具有以下四个重要的 ACID 特性：\n原子性（Atomicity）：\n事务中的所有操作要么全部完成，要么全部不执行。 如果事务中的某个操作失败，整个事务将回滚到初始状态。 一致性（Consistency）：\n事务开始前和结束后，数据库都必须处于一致的状态。 数据库的完整性约束不能被破坏。 隔离性（Isolation）：\n并发执行的事务相互之间不应影响。 每个事务在提交之前对其他事务不可见。 持久性（Durability）：\n一旦事务提交，其结果是永久性的，即使系统崩溃也不会丢失。 使用事务的基本语法 1 2 3 4 5 6 7 8 9 10 11 12 -- 开始事务 START TRANSACTION; -- 执行一系列操作 UPDATE accounts SET balance = balance - 100 WHERE account_id = 1; UPDATE accounts SET balance = balance + 100 WHERE account_id = 2; -- 提交事务 COMMIT; -- 或者回滚事务 ROLLBACK; START TRANSACTION 用于开始一个事务。 COMMIT 用于提交事务，将所有更改永久保存。 ROLLBACK 用于回滚事务，撤销所有未提交的更改。 通过事务和 ACID 特性，MySQL 可以确保数据的完整性和可靠性，特别是在多用户并发环境中。\nmysql默认的事务规则 在MySQL数据库中，事务默认是会自动提交的，也就是说，如果没有用 begin \u0026hellip; commit 来显式提交事务的话，MySQL 会认为每一条SQL语句都是一个事务，也就是每一条SQL语句都会自动提交。\n可以基于mysqlbinlog去分析日志，发现每一个语句都是事务操作。\n正确事务执行测试 确保，再事务之间的所有SQL，全部正确执行，以及永久生效，争取的事务执行过程。\nmysql默认的修改类的SQL，都是事务执行的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 create database linux0224; create table linux0224.bank( name varchar(20), money decimal(20, 2) )charset=utf8; #写入测试数据 use linux0224; insert into bank values(\u0026#34;小王\u0026#34;, 20000),(\u0026#34;表弟\u0026#34;, 6000); # 主动使用BEGIN ，commit语句区间，查看事务执行的过程，模拟修改数据，模拟转账 # 再事务中所有的SQL，要么都成功，要么都失败，事务的一致性 #数据修改完毕后，数据表，永久生效，写入磁盘。 # 如下2个SQL，分别是 ，给小王减去3000，给表弟加入3000，模拟转账 # 执行成功后，应该看到数据表的变化 # 这2个正确执行的事务，被binlog日志记录， 而刚才出错的，回滚了 begin; update bank set money=money-3000 where name=\u0026#34;小王\u0026#34;; update bank set money=money+3000 where name=\u0026#34;表弟\u0026#34;; commit; mysql\u0026gt; select * from bank; +--------+----------+ | name | money | +--------+----------+ | 小王 | 17000.00 | | 表弟 | 9000.00 | +--------+----------+ 2 rows in set (0.00 sec) 错误SQL事务执行，实现的恢复 mysql提供事务回滚，数据回滚\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 主动的事务 # 小王的SQL正确执行 # 第二条SQL输错 # rollback回滚操作， # 开发写代码，再程序中，进行异常逻辑判断 # 主动执行SQL，查看一个事务下的所有SQL，要么都成功，要么都失败 begin; update bank set money=money-3000 where name=\u0026#34;小王\u0026#34;; update bank ssssssssset money=money+3000 where name=\u0026#34;表弟\u0026#34;; rollback; 2.3 GTID长啥样 默认mysql没有开启gtid\n1 2 3 4 5 6 | mysql-log-bin.000014 | 1810 | Anonymous_Gtid | 100 | 1875 | SET @@SESSION.GTID_NEXT= \u0026#39;ANONYMOUS\u0026#39; | | mysql-log-bin.000014 | 1875 | Query | 100 | 1952 | BEGIN | | mysql-log-bin.000014 | 1952 | Table_map | 100 | 2009 | table_id: 144 (linux0224.bank) | | mysql-log-bin.000014 | 2009 | Write_rows | 100 | 2061 | table_id: 144 flags: STMT_END_F | | mysql-log-bin.000014 | 2061 | Xid | 100 | 2092 | COMMIT /* xid=1071 */ | +----------------------+------+----------------+-----------+-------------+--------------------------- GTID (Global Transaction ID) 是对于一个已提交事务的编号，并且是一个全局唯一的编号。\nGTID 实际上 是由 UUID+TID 组成的。\n其中 UUID 是一个 MySQL 实例的唯一标识。\nTID 代表了该实例上已经提交的事务数量，并且随着事务提交单调递增。\nGTID（全局事务标识符）的具体形式是：\n1 GTID = source_id:transaction_id 具体说明 source_id：通常是 server_uuid，用于唯一标识生成该事务的服务器。 transaction_id：是一个递增的整数，表示该服务器上事务的顺序。 server_uuid server_uuid 是一个全局唯一标识符（UUID），用于标识 MySQL 服务器实例。 这个 UUID 在 MySQL 数据目录下的 auto.cnf 文件中定义。 形式为一个标准的 UUID，例如：3E11FA47-71CA-11E1-9E33-C80AA9429562。 作用 唯一性：每个 MySQL 服务器都有一个唯一的 server_uuid，确保 GTID 的唯一性。 复制和恢复：在主从复制环境中，GTID 用于跟踪事务，从而简化故障转移和恢复操作。 通过 GTID 和 server_uuid，MySQL 可以更高效地进行复制和数据一致性管理。\n2.4 开启uuid 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 1. 修改配置文件，再my.cnf 加入server_id=50; 2. 具体配置如下 [mysqld] gtid-mode=ON enforce-gtid-consistency=true log-slave-updates=ON server_id=100 log_bin=/mysql_log/log_bin_3306/mysql-log-bin character_set_server=utf8mb4 log-error=/linux0224/mysql_3306/logs/3306-err.log port=3306 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3306/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock 重启mysql，配置生效，加载gtid功能 [root@tech-db-51 /mysql_log/log_bin_3306]#systemctl restart mysqld [root@tech-db-51 /mysql_log/log_bin_3306]# # 查看关于gtid的mysql内置变量 show variables like \u0026#39;%GTID%\u0026#39;; mysql\u0026gt; show variables like \u0026#39;%GTID%\u0026#39;; +----------------------------------+-----------+ | Variable_name | Value | +----------------------------------+-----------+ | binlog_gtid_simple_recovery | ON | | enforce_gtid_consistency | ON | | gtid_executed_compression_period | 1000 | | gtid_mode | ON | | gtid_next | AUTOMATIC | | gtid_owned | | | gtid_purged | | | session_track_gtids | OFF | +----------------------------------+-----------+ 8 rows in set (0.00 sec) mysql\u0026gt; # 表示以及开启GTID功能，你后续的事务操作，都会被记录 事务id [root@tech-db-51 /mysql_log/log_bin_3306]#mysql -uroot -plinux3306 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or /g. Your MySQL connection id is 2 Server version: 5.7.28-log MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;/h\u0026#39; for help. Type \u0026#39;/c\u0026#39; to clear the current input statement. mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000015 | 154 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; 建议 1 mysql5.7以后的版本，默认都开启GTID功能，用处很广。 2.5 GTID实践 第二次事务执行\n1 2 3 查看多次执行事务操作 ，生成的多个gtid记录 恢复数据表的玩法，练习，实现数据库的恢复 2.6 基于GTID截取日志 有了gtid之后，再也不用关心日志的开始pos，结束pos了，一个gtid记录，记录一个事务。\n还是基于binlog提取 你要的恢复数据得SQL，但是不用关心 \u0026ndash;start-pos \u0026ndash;stop -pos\n基于 \u0026ndash;include-gtids ，直接截取，你要的 事务id区间即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 --skip-gtids 如果我们是要恢复数据到源数据库或者和源数据库有相同 GTID 信息的实例，那么就要使用该参数。如果不带该参数的话，是无法恢复成功的。 因为包含的 GTID 已经在源数据库执行过了，根据 GTID 特性，一个 GTID 信息在一个数据库只能执行一次，所以不会恢复成功。 # 注意参数的添加，--skip-gtids ，不加mysql会进行gtid记录的幂等性检查，导入sql会报错 # 导出从建库，创建数据，的所有gtid记录，不需要记录pos了 # 基于解密参数，看看日志的可阅读性，在干啥 # 解析 binlog mysql-log-bin.000015 # 截取事务号 mysqlbinlog --skip-gtids --include-gtids=\u0026#39;187299d4-0e2b-11ed-8b0c-000c29463bc7:2-3\u0026#39; mysql-log-bin.000015 \u0026gt; /opt/huifu_xixi_table.txt # 关闭binlog记录 mysql\u0026gt; set sql_log_bin=0; #恢复 mysql\u0026gt; source /opt/huifu_xixi_table.txt #开启binlog记录 mysql\u0026gt; set sql_log_bin=1; Query OK, 0 rows affected (0.00 sec) # 其实区别就是 之前是基于 --start-pos 以及--stop-pos去决定，截取的日志区间，提取SQL 而现在直接基于GTID的号码，即可实现，截取数据区间。完成恢复，且更强大 3 最常见的数据库备份方式 中小型公司的常见备份玩法如下，不管是linux机器的数据备份\n还是备份阿里云的RDS云数据库，都是这个思路，。都可以基于mysqldump远程备份\nmysqldump -uroot -p -h -P ，适用于本地数据备份，也适用于远程备份阿里云的数据库。\nmysql -uroot -p -h -P\n1 2 3 4 5 6 7 8 9 10 1.核心思路，基于mysqldump备份时，加入-F参数，实现日志切割 每次一个binlog记录 2.crontab 每周一全量备份 3. 周一全量备份，以及日志中，获取数据截止点，也就是次日的开始。 4.截取binlog，次日数据是从，下一个GTID号码开始的。 5.找到删数据的GTID事务号，截取至前一个记录，即可截取数据恢复的区间。 全量备份 1 2 3 4 5 6 7 8 9 方案1：逻辑备份 基于mysqldump命令，使用-A参数，全部的库表备份 ,导出来的数据是一堆SQL语句，兼容性很强 --all-database 所有的库表 方案2，直接物理备份 [root@tech-db-51 ~]#ls /linux0224/mysql_3306/ cp tar rsync 全量备份的参数 不要携带GTID的数据导出\n1 2 3 4 5 6 7 --set-gtid-purged=OFF 1. 机器A mysqldump 导出数据，不用该参数，导出的SQL数据，携带当前机器A的 binlog历史记录 且机器B导入该SQL的话，也不会再新记录binlog 2. 机器A mysqldump导出数据携带该参数，导出的只有SQL数据，且不包含GTID信息 这样，新机器B导入该SQL数据，就会重新自己记录binlog 事务记录。 看看导出的SQL文件信息 另一个业务场景的基于GTID导出方式 1 2 [root@tech-db-51 ~]#mysqldump -uroot -p --set-gtid-purged=OFF -A -F \u0026gt; /tmp/no-gtid-all-db-flush-log.sql Enter password: 4. 两个备份，恢复场景 区分于，是否携带\nGTID的历史信息\n场景1：当前数据库的，备份，与恢复 老大给你一个RDS数据库\nip\nport\n让你去做好备份工作。\n全量备份 给数据库开启binlog功能 自主做更多的数据备份工作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 给当前数据库服务器，进行数据备份，数据增量写入恢复。 # 当前机器，当前实例，进行数据，备份+恢复 1. 模拟夜里定时任务执行，进行全量数据备份，刷新binlog，记录上一次事务的截止点（用于数据恢复，截取binlog日志） mysql\u0026gt; create table test_table(id int); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------+ | mysql-log-bin.000004 | 558 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-4 | +----------------------+----------+--------------+------------------+------------------------------------------+ 1 row in set (0.00 sec) # 当前3306数据库，04日志 1-4 的事务记录 # 创建一个目录，用于统一管理，mysql的备份数据 # 这个目录的数据，建议再用 rsync + inotify 试试同步到 备份服务器，最大化数据安全 # 备份 + 数据同步 # 且是携带着当前事务ID的历史记录的 # 以及全量备份了，历史的binlog，没用了，次日，刷新新的binlog，记录第二天的所有新的SQL操作 # 加上——F参数 # 备份之前的记录 | mysql-log-bin.000004 | 558 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-4 | # 备份后得记录 mkdir -p /mysql_3306_backup # -A 备份所有库表 # --single-transaction，给所有数据库加锁，防止数据写入，导致备份错误 # --master-data=2 将binlog的信息以注释形式备份 # -R 导出mysql自定义函数 # -E 导出events事件 # --max_allowed_packet 用于设置服务器或客户端允许处理的最大数据包大小。 mysqldump -uroot -plinux3306 -F -A --single-transaction --max_allowed_packet=64M -R -E \u0026gt; /mysql_3306_backup/full_db_$(date +%F).sql # 明确日志已经刷新了 # 看一看这个全量备份SQL 2. 模拟次日刷新后的日志，数据写入，以及删除数据的操作 mysql\u0026gt; insert into test_table values(777),(888),(999); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql\u0026gt; mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------+ | mysql-log-bin.000009 | 479 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-5 | +----------------------+----------+--------------+------------------+------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; drop database test_backup; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------+ | mysql-log-bin.000009 | 657 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6 | +----------------------+----------+--------------+------------------+------------------------------------------+ 1 row in set (0.00 sec) 3. 截取日志，进行数据恢复，实现全量数据的备份与恢复。 # 如何截取，要看你想恢复什么 # 思路 1. 解析二进制日志，看看都有0009日志 mysqlbinlog --base64-output=decode-rows -vv /mysql_log/log_bin_3306/mysql-log-bin.000009 \u0026gt; /tmp/09.log 2. 分析完毕 09 增量日之后，确认要 全量恢复库，增量恢复数据 3. 先导入全量数据 mysql\u0026gt; set sql_log_bin=0; mysql\u0026gt; source full_db_2022-08-10.sql; mysql\u0026gt; select * from test_table; Empty set (0.01 sec) 目前实现了基于全量备份的数据，找回了 库 test_backup; 4. 基于次日刷新的0009增量日志，恢复插入数据 基于mysqlbinlog 截取 00009日志，截取你要的事务区间 # --include-gtids 截取一个GTID事务区间 # 解密查看SQL #pos值区间 ，写入数据的 194-479 mysqlbinlog --base64-output=decode-rows -vv --skip-gtids --include-gtids=\u0026#39;187299d4-0e2b-11ed-8b0c-000c29463bc7:5\u0026#39; /mysql_log/log_bin_3306/mysql-log-bin.000009 \u0026gt; /tmp/decode_09.txt # 这是要用于恢复的SQL语句 mysqlbinlog --skip-gtids --include-gtids=\u0026#39;187299d4-0e2b-11ed-8b0c-000c29463bc7:5\u0026#39; /mysql_log/log_bin_3306/mysql-log-bin.000009 \u0026gt; /mysql_3306_backup/restore_test_backup_db.sql # 恢复数据的操作 mysql\u0026gt; set sql_log_bin=0; mysql\u0026gt; source /mysql_3306_backup/restore_test_backup_db.sql; mysql\u0026gt; select * from test_backup.test_table; +------+ | id | +------+ | 777 | | 888 | | 999 | +------+ 3 rows in set (0.00 sec) mysql\u0026gt; set sql_log_bin=1; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; # 总结 至此，完成 基于 1. 全量备份的 库、表的恢复 2. 次日刷新的binlog，截取事务区间，恢复的 表数据 场景2：远程数据库的复制，或者重新数据导入 数据库A导出的数据库，导入到 机器B\n3306实例的数据， 导入到新的 3307实例，让它继续开始binlog写入\n正确远程数据导入玩法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 -rw-r--r-- 1 root root 863K Aug 10 10:34 no-gtid-all-db-flush-log.sql 3307数据库，导入进入，看是否可以使用该数据，以及binlog重新记录 # 准备一个新的 初始化数据的 3307实例 # 打开GTID 以及binlog功能，重新记录 事务日志 mysql\u0026gt; source /tmp/no-gtid-all-db-flush-log.sql mysql\u0026gt; select * from kings.cike; +-----------+ | name | +-----------+ | 钟薛高 | | 兰陵王 | | 孙悟空 | +-----------+ 3 rows in set (0.00 sec) 错误的场景\n1 2 3 4 5 6 7 8 9 10 3306 导出的数据，携带了GTID历史记录 SET @@GLOBAL.GTID_PURGED=\u0026#39;187299d4-0e2b-11ed-8b0c-000c29463bc7:1-2\u0026#39;; 3307 实例的GTID 号码 mysqld --initialize-insecure --user=mysql --basedir=/opt/mysql --datadir=/linux0224/mysql_3307 | eba785df-16c3-11ed-9d4f-000c29463bc7:1-276 | 试试 导入3306的SLQ到 3307 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 1. 3307实例，重新初始化，基于GTID启动后，默认有自己的GTID信息 唯一事务ID标识的 mysql\u0026gt; create database 3307_db; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; show master status; +------------------+----------+--------------+------------------+----------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+----------------------------------------+ | mysql-bin.000001 | 322 | | | 68d3d065-185c-11ed-bcd5-000c29463bc7:1 | +------------------+----------+--------------+------------------+----------------------------------------+ 1 row in set (0.00 sec) [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock \u0026lt; /tmp/all-db-flush-log.sql ERROR 1840 (HY000) at line 24: @@GLOBAL.GTID_PURGED can only be set when @@GLOBAL.GTID_EXECUTED is empty. 2. 此时是无法导入3306携带GTID的SQL文件 3. 你可以重置3307的 binlog，重置它的GTID事务信息 reset master; 没有它自己的GTID历史记录了，清空3307自己的GTID事务记录 4. 你就可以正确导入 3306的数据了，且携带GTID的 [root@tech-db-51 /linux0224/mysql_3307]# [root@tech-db-51 /linux0224/mysql_3307]# [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock \u0026lt; /tmp/all-db-flush-log.sql [root@tech-db-51 /linux0224/mysql_3307]# 5. 此时的3307，就从3306的数据开始写入 ","date":"2025-04-14T16:10:17+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/%E5%A4%87%E4%BB%BD%E8%BF%9B%E9%98%B6gtid/","title":"备份进阶（GTID）"},{"content":"1.为什么要备份 运维是干什么的？\n保护服务器数据安全 维护公司运维资产7*24小时运转 企业真实案件：\nhttps://www.leiphone.com/category/sponsor/Isb7Smi17CHBTxVF.html\n企业丢了数据，就等于失去了商机、客户、产品、甚至倒闭。\n在各式各样的数据中，数据库的数据更是核心之核心，当然其他各式各样的如静态文件数据，也很重要，也会通过其他的备份方式来保证安全。\n2.备份恢复的职责 1 2 3 4 5 6 7 8 9 10 11 1. 备份、恢复的策略 备份周期、备份工具、备份方式、数据恢复方式 2.日常备份检查 日志、备份数据 3.定期恢复数据演练 4.数据故障时，利用现有的资源，快速恢复 5.数据迁移，数据库升级。 3.备份工具 物理备份: 直接备份数据库所对应的数据文件基至是整个磁盘。\n逻辑备份: 将数据从数据库中导出, 并将导出的数据进行存档备份。\n类别 物理备份 逻辑备份 备份对象 数据库的物理文件(如数据文件,控制文件,归档日志文件等) 数据库对象(如用户,表,存储过程等) 可移植性 较弱,甚至不可移植 数据库对象级备份,可移植性较强 占用空间 占用空间大 占用空间相对较小 恢复效率 效率高 效率较低 适用场景 大型业务系统或者整系统的容灾恢复、系统级全量备份 主备数据库间的增量数据备份、不同业务系统之间的数据同步、业务不中断升级过程中在线数据迁移 逻辑备份 把数据库、表，以SQL语句的形式，输出为文件的备份过程，这种方式称之为逻辑备份。\n但是这种方式效率并不高，以SQL导出，在海量数据下，例如几十G的场景，备份、恢复的时间都会过长。\n因此还会有其他备份方案。\n1 2 3 4 mysqldump mysqlbinlog mydumper binlog2sql 物理备份 1 2 3 1. 工具使用，https://www.percona.com/software/mysql-database/percona-xtrabackup 2.直接shell+crontab备份整个mysql数据目录 如何选 1 2 100G数据以内，逻辑备份没问题，服务器配置要跟上 100G 以上，建议物理备份 4.mysqldump备份 开始逻辑备份的学习\n只备份某些库 只备份某些表 以及只要表结构，不要表数据 结构，数据都要，全量备份等 1 2 3 4 5 6 7 8 9 10 11 12 mysqldump备份语法 Mysqldump -u用户名 -p密码 参数 数据库名 \u0026gt; 数据备份文件 mysql自带的备份工具，可以实现本地备份，远程备份 mysqldump命令备份过程，实际上是把数据库、表，以SQL语句的形式，输出为文件的备份过程，这种方式称之为逻辑备份。 但是这种方式效率并不高，以SQL导出，在海量数据下，例如几十G的场景，备份、恢复的时间都会过长。 因此还会有其他备份方案。 4.1 mysqldump连接参数 1 2 3 4 5 -u mysql用户名 -p mysql用户密码 -S mysql本地socket文件 -h 指定主机地址 -P 指定mysql端口 4.2 mysqldump备份参数 可以利用如下语句，实现数据库的数据、结构、很实用的技巧。\n全量备份 对当前数据库实例，导出，所有的库，表，以及数据，转储为SQL文件\n对这个文件进行导入执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 --all-databases，-A 转储所有数据库中的所有表。 mysqldump -uroot -plinux3306 --all-databases \u0026gt; /opt/all-3306.sql [root@tech-db-51 ~]#wc -l /opt/all-3306.sql 2030 /opt/all-3306.sql [root@tech-db-51 ~]# [root@tech-db-51 ~]#file /opt/all-3306.sql /opt/all-3306.sql: UTF-8 Unicode text, with very long lines [root@tech-db-51 ~]# # 这个备份的文件，具体步骤就是 # 有几张表示空表，没数据， lock, unlock之间是空的 1. 当前操作某个库， 先基于 if条件 判断，然后create 库 2. 删除库下的某个表，然后create 重建表结构 3. 先 lock 锁住表的数据写入，为了防止恢复出现问题； 恢复数据，insert 插入数据 unlock 解锁表，允许再次写入 mysqldump 逻辑备份，导出的SQL，解读 ，3个流程 1 每学一个备份的玩法，就进行数据导入，查看具体备份，恢复的情况。 准备一个新的数据库实例，模拟数据恢复，查看不同备份命令的数据恢复结果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 准备一个 3307 实例 1. 清空3307的数据 2. 重新初始化3307的数据 [root@tech-db-51 /linux0224/mysql_3307]#mysqld --initialize-insecure --user=mysql --basedir=/opt/mysql --datadir=/linux0224/mysql_3307/ 3.导入3306的数据即可覆盖 # 恢复数据的命令 [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock 3307 \u0026gt; 3306数据 （自建的库表，以及mysql默认得库表） mysql\u0026gt; source /opt/all-3306.sql 重启3307后，会读取所有3306 的数据了 [root@tech-db-51 /linux0224/mysql_3307]#bash /linux0224/3307.sh restart Restarting MySQL... Stoping MySQL... Starting MySQL... 此时3307的数据，完全以3306来了，用的3306的账密认证了。 [root@tech-db-51 /linux0224/mysql_3307]#mysql -uroot -plinux3306 -S /linux0224/mysql_3307/mysql.sock mysql: [Warning] Using a password on the command line interface can be insecure. 指定3306备份某个库下的某个表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 mysqldump -uroot -plinux3306 world city \u0026gt; /opt/world_city.sql 1. 删除city表 2. 创建city表结构 ，定义好字段 3. insert插入数据，city ，一条insert语句写入了所有数据 3307实例单独导入某个表数据 # 方式1，导入数据 mysql\u0026gt; create database test_world; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; use test_world; Database changed mysql\u0026gt; source /opt/world_city.sql # 方式2，命令行，指定库，导入 [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock test_world \u0026lt; /opt/world_city.sql mysql\u0026gt; select * from city where id \u0026lt;5; +----+----------------+-------------+----------+------------+ | ID | Name | CountryCode | District | Population | +----+----------------+-------------+----------+------------+ | 1 | Kabul | AFG | Kabol | 1780000 | | 2 | Qandahar | AFG | Qandahar | 237500 | | 3 | Herat | AFG | Herat | 186800 | | 4 | Mazar-e-Sharif | AFG | Balkh | 127800 | +----+----------------+-------------+----------+------------+ 4 rows in set (0.00 sec) 指定备份库下的多个表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #将3306 world库下的 country countrylanguage 导出为SQL，发给3307导入 [root@tech-db-51 ~]#mysqldump -uroot -plinux3306 world city country countrylanguage \u0026gt; /opt/world_all_tb.sql mysqldump: [Warning] Using a password on the command line interface can be insecure. [root@tech-db-51 ~]# [root@tech-db-51 ~]# [root@tech-db-51 ~]#vim /opt/world_all_tb.sql [root@tech-db-51 ~]# [root@tech-db-51 ~]## 该文件，就是对3张表的 结构，数据，导出 # 恢复数据，到3307实例 [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock test_world \u0026lt; /opt/world_all_tb.sql Database changed mysql\u0026gt; show tables; +----------------------+ | Tables_in_test_world | +----------------------+ | city | | country | | countrylanguage | +----------------------+ 3 rows in set (0.00 sec) # 小结 导出3306 world库下的多个表 恢复导入到了3307实例中 # 3307本身就有 city 表，数据会重复吗？ #不会，/opt/world_all_tb.sql ，先drop删表，create 建表，insert写入数据 指定你要哪些数据库，进行备份 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 --databases，-B 转储几个数据库。 通常情况，mysqldump将命令行中的第1个名字参量看作数据库名，后面的名看作表名。 使用该选项，它将所有名字参量看作数据库名。 -B可以跟上多个数据库名，同时备份多个库 尽量结合gzip命令压缩 # 导出3306的 dev01 库 school_db库 mysqldump -uroot -plinux3306 -B school_db dev01 \u0026gt; /opt/school_db-dev01.sql # 查看sql文件 # 导入到3307实例 mysql\u0026gt; ^DBye [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock \u0026lt; /opt/school_db-dev01.sql 只要表结构，不要数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 有一些服务器，你想拿到这些服务器上的数据库 ，表的结构，字段即可。 框架 拿到这些框架，导入测试服务器， --no-data参数 # 语法 mysqldump -uroot -p 库 该库下的表1 该库下的表2 --no-data # 导出生产服务器 3306实例的 员工库 下，职称表的结构 mysqldump -uroot -plinux3306 --no-data employees titles \u0026gt; /opt/emp_titles_no_data.sql # 看看 sql文件 少一个insert插入数据 # 备份的SQL文件，很简单 1. 删表 2. create 创建表结构 [root@tech-db-51 ~]#grep -Ev \u0026#39;#|\\*|--|^$\u0026#39; /opt/emp_titles_no_data.sql DROP TABLE IF EXISTS `titles`; CREATE TABLE `titles` ( `emp_no` int(11) NOT NULL, `title` varchar(50) NOT NULL, `from_date` date NOT NULL, `to_date` date DEFAULT NULL, PRIMARY KEY (`emp_no`,`title`,`from_date`), CONSTRAINT `titles_ibfk_1` FOREIGN KEY (`emp_no`) REFERENCES `employees` (`emp_no`) ON DELETE CASCADE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 只要表数据，不要结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 # 有一个现成的测试服务器，数据表都有了，但是就没数据 # 只要insert语句，不要 create table语句 --no-create-info，-t 还是遵循mysqldump的 默认语法 库 表1 表2 表3 数据导入，文件，可能比较大，建议压缩 # 导出3306 的 title表数据，以及 salaries mysqldump -uroot -plinux3306 --no-create-info employees titles salaries |gzip \u0026gt; /opt/data_employees_title_salaries.sql.gz # 恢复该数据，导入到 3307实例 # 创建表，导入sql文件 # 创建该2个对应的表结构即可 CREATE TABLE `titles` ( `emp_no` int(11) NOT NULL, `title` varchar(50) NOT NULL, `from_date` date NOT NULL, `to_date` date DEFAULT NULL, PRIMARY KEY (`emp_no`,`title`,`from_date`), CONSTRAINT `titles_ibfk_1` FOREIGN KEY (`emp_no`) REFERENCES `employees` (`emp_no`) ON DELETE CASCADE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 ; CREATE TABLE `salaries` ( `emp_no` int(11) NOT NULL, `salary` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`from_date`), CONSTRAINT `salaries_ibfk_1` FOREIGN KEY (`emp_no`) REFERENCES `employees` (`emp_no`) ON DELETE CASCADE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 导入sql数据 方式1 1. 先解压为普通的sql文件 2. 再学过命令导入 方法2 zcat data_employees_title_salaries.sql.gz | mysql -S /linux0224/mysql_3307/mysql.sock d1 # 验证数据的恢复titles mysql\u0026gt; select * from titles order by emp_no limit 0,5; +--------+-----------------+------------+------------+ | emp_no | title | from_date | to_date | +--------+-----------------+------------+------------+ | 10001 | Senior Engineer | 1986-06-26 | 9999-01-01 | | 10002 | Staff | 1996-08-03 | 9999-01-01 | | 10003 | Senior Engineer | 1995-12-03 | 9999-01-01 | | 10004 | Engineer | 1986-12-01 | 1995-12-01 | | 10004 | Senior Engineer | 1995-12-01 | 9999-01-01 | +--------+-----------------+------------+------------+ 5 rows in set (0.00 sec) # 工资表 mysql\u0026gt; select * from salaries order by emp_no limit 0,5; +--------+--------+------------+------------+ | emp_no | salary | from_date | to_date | +--------+--------+------------+------------+ | 10001 | 60117 | 1986-06-26 | 1987-06-26 | | 10001 | 62102 | 1987-06-26 | 1988-06-25 | | 10001 | 66074 | 1988-06-25 | 1989-06-25 | | 10001 | 66596 | 1989-06-25 | 1990-06-25 | | 10001 | 66961 | 1990-06-25 | 1991-06-25 | +--------+--------+------------+------------+ 5 rows in set (0.00 sec) 备份且压缩数据 对于数据库有大量数据表，以及信息，导出的备份文件，最好是压缩后的，节省磁盘。\n1 2 3 # 压缩数据备份， [root@tech-db-51 ~]#du -h /opt/data_employees_title_salaries.sql.gz 27M\t/opt/data_employees_title_salaries.sql.gz 什么是lock tables 禁止DML相关SQL执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 mysql提供的，基于会话的 锁表，防止他人冲突写入数据。 语法1，单独锁某个表 基于会话的，锁某个表 # 针对其他mysql链接会话的写入动作，锁住。 mysql\u0026gt; lock table world.city write; mysql\u0026gt; unlock tables; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from city order by id desc limit 0,5; +------+------+-------------+----------+------------+ | ID | Name | CountryCode | District | Population | +------+------+-------------+----------+------------+ | 4084 | | | | 0 | | 4083 | | | | 0 | | 4082 | | | | 0 | | 4081 | | | | 0 | | 4080 | | | | 0 | +------+------+-------------+----------+------------+ 5 rows in set (0.00 sec) 语法2，全局读锁，针对普通账号的写入权限。 set global read_only=1; set global read_only=0; 5.日志篇 日志的作用，不说大家应该都知道，可以收集、检测我们程序的健康状况\n默认这些日志，大部分是未开启的，运维小于可以通过命令、配置文件，开启这些日志，以及定义存储路径。\nmysql日志文件的作用：\n1、能记录物理数据页面的修改的信息；\n2、能将数据从逻辑上恢复至事务之前的状态；\n3、能以二进制文件的形式记录了数据库中的操作；\n4、能记录错误的相关信息；\n5、能从主服务器中二进制文件取的事件等等。\n普通日志 记录了服务器接收到的每一个查询或是命令，无论这些查询或是命令是否正确甚至是否包含语法错误，general log 都会将其记录下来 ，记录的格式为 {Time ，Id ，Command，Argument }。\n也正因为mysql服务器需要不断地记录日志，开启General log会产生不小的系统开销。 因此，Mysql默认是把General log关闭的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 产生大量的磁盘IO，导致数据库服务器的磁盘压力，CPU压力。 mysql数据库的特点是 底层的逻辑是 1.先写入数据到磁盘中 2. 记录本次写入动作，记录到日志中 增删改查语句，全部记录下来。 用在银行，证券等公司，需要对每一个SQL语句，做严格的记录，审核，后期的检查。恢复等。 采购高价的SSD超强的CPU，超大的存储磁盘。 二进制日志binlog 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 mysql将你执行的DML相关的SQL操作 insert 插入数据 create 建库，建表 默认会做的事 1. 实质性的创建库表数据，写入磁盘中。 做2件事，维护数据的安全 1. 定时备份 2. binlog二进制日志 将你每次的DML操作，额外开启一个binlog日志功能，记录本次修改数据的操作，写入到日志中 binlog是记录数据库被修改的SQL语句，对数据造成影响了。\n一般是DDL和DML语句，包含\ninsert update delete create drop alter 等关键字 作用 记录mysql数据的增量数据，且用来做增量数据恢复，前面老师已经完整的讲过、全量备份、增量备份的区别，如果不开启binlog，将无法恢复完整的数据。\n以及用在主从数据复制\n二进制binlog索引文件 该文件用于记录binlog的索引号\n1 2 [root@db-51 ~]#cat /linux0224/mysql_3306/logs/mysql-bin.index /linux0224/mysql_3306/logs/mysql-bin.000001 6.binlog日志（重点） binlog是mysql一大重点，Binlog是一个二进制格式的文件，用于记录用户对数据库更新的SQL语句信息\n例如更改数据库库表和更改表内容的SQL语句都会记录到binlog里，但是对库表等内容的查询则不会记录到日志中。\n1 2 3 4 记录 DML，insert update，delete DDL，create drop，alter，truncate DCL，grant revoke binlog的作用 当有数据写入到数据库时，还会同时把更新的SQL语句写入到对应的binlog文件里，这个文件就是上文所说的binlog文件。\n1 2 3 4 5 6 7 8 备注：mysql是先写日志，再写入数据的过程。 insert into city values(); 先后的mysql底层会 1. 先记录到binlog中，这个insert语句 2. 执行该语句，写入磁盘数据 配置log_bin 默认是没开启binlog功能的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 查看mysql关于log_bin的变量参数 查看log_bin的配置信息 mysql\u0026gt; show variables like \u0026#39;%log_bin%\u0026#39;; +---------------------------------+-------+ | Variable_name | Value | +---------------------------------+-------+ | log_bin | OFF | | log_bin_basename | | | log_bin_index | | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | ON | +---------------------------------+-------+ 6 rows in set (0.01 sec) 开启binlog 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 只需要修改配置文件，加入开启 log_bin的参数即可，就是永久生效的了 server_id=100 # 是指二进制日志，具体存储到哪，建议做法是，和mysql数据目录分开 mkdir -p /mysql_log/log_bin_3306/ log_bin=/mysql_log/log_bin_3306/mysql-log-bin # 最终配置 [root@tech-db-51 ~]#cat /etc/my.cnf [mysqld] server_id=100 log_bin=/mysql_log/log_bin_3306/mysql-log-bin character_set_server=utf8mb4 log-error=/linux0224/mysql_3306/logs/3306-err.log port=3306 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3306/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock [root@tech-db-51 ~]# # 重启mysqld mkdir -p /mysql_log/log_bin_3306/ chown -R mysql.mysql /mysql_log/ systemctl restart mysqld # 目前是没有二进制日志文件的，只有发生DML操作后，自动生成 [root@tech-db-51 ~]#cd /mysql_log/log_bin_3306/ [root@tech-db-51 /mysql_log/log_bin_3306]#ll total 0 # 检查mysql，二进制日志的变量配置信息 mysql\u0026gt; show variables like \u0026#39;%log_bin%\u0026#39;; +---------------------------------+---------------------------------------------+ | Variable_name | Value | +---------------------------------+---------------------------------------------+ | log_bin | ON | | log_bin_basename | /mysql_log/log_bin_3306/mysql-log-bin | | log_bin_index | /mysql_log/log_bin_3306/mysql-log-bin.index | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | ON | +---------------------------------+---------------------------------------------+ 6 rows in set (0.01 sec) mysql\u0026gt; 查看具体的日志信息\n1 2 3 4 5 [root@tech-db-51 /mysql_log/log_bin_3306]#ll total 8 -rw-r----- 1 mysql mysql 154 Aug 8 15:04 mysql-log-bin.000001 -rw-r----- 1 mysql mysql 45 Aug 8 15:04 mysql-log-bin.index [root@tech-db-51 /mysql_log/log_bin_3306]# binlog内容的格式 事件event记录方式 也就是binlog日志记录了如下内容，解密后可看。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 1. 事件描述 时间戳 server_id 加密方式 开始位置 start_pos 结束位置 end_pos mysql里面的数据操作，都是事务性，被mysql以 开始-结尾 做了一个记录 create database d1; 从开始 到结束，都被mysql 数字号，记录位置 2.事件内容 修改类的操作，SQL语句，数据行的变化 重点，使用binlog主要关注 start_pos end_pos 事件内容 二进制日志事件内容格式查看 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 查看binlog日志的详细信息 mysql\u0026gt; show variables like \u0026#39;%binlog%\u0026#39;; 这里看到| binlog_format 是ROW 对于DDL、DCL语句，直接将SQL本身记录到binlog中 对于DML : insert、update、delete 受到binlog_format参数控制。 SBR : Statement : 语句模式。之前版本，默认模式 RBR : ROW : 行记录模式。5.7以后，默认模式 MBR : mixed : 混合模式。 # 一句话，5.7版本中 binlog日志，基于行去记录 用户的DML操作 简单说就是，一个insert 语句，记录为一行日志，更新一个pos值 一个delete语句，也事一行日志，更新一个pos值 查看binlog日志文件情况 查看所有日志文件的信息，二进制日志\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [root@tech-db-51 /linux0224/mysql_3306]#ls /mysql_log/log_bin_3306/ mysql-log-bin.000001 mysql-log-bin.index # 查看当前数据库实例，用哪个日志文件记录 SQL中。 show binary logs; mysql\u0026gt; show binary logs; +----------------------+-----------+ | Log_name | File_size | +----------------------+-----------+ | mysql-log-bin.000001 | 154 | +----------------------+-----------+ 1 row in set (0.00 sec) 查看当前日志，记录的事件，最新截止点在哪 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000001 | 154 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) # 只要数据变化 刷新新日志文件 了解该命令即可，不能随便执行。。\n1 2 3 4 5 一般用于数据库恢复，数据库重置时，才会用到。 除非你已经做好了全量备份，次日新增数据时，重新记录新的binlog也行。 flush logs; 不能随便敲 查看当前mysql用哪个日志文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 查看当前mysql，正在用的哪个binlog日志文件 show master status; 显示mysql所有的binlog记录 你当前数据库实例，所有的数据变化，分散记录再了这些日志文件中 mysql\u0026gt; show binary logs; +----------------------+-----------+ | Log_name | File_size | +----------------------+-----------+ | mysql-log-bin.000001 | 557 | | mysql-log-bin.000002 | 328 | +----------------------+-----------+ 2 rows in set (0.00 sec) 模拟binlog记录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 1.写入数据，库，表 2.分别查看binlog记录pos值的变化，确认binlog会记录哪些SQL。 3.确认上述的所有数据创建操作，属于mysql的一个完整事务，到执行commit命令。 4. 当前用的数据库引擎，叫做innodb，默认就是DML操作都是事务性操作。 SQL执行完毕后，默认执行了一个commit提交指令。 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000002 | 508 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; mysql\u0026gt; insert into hei values(\u0026#34;11\u0026#34;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000002 | 783 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; 简单理解什么是mysql的事务 1 2 3 4 5 6 7 可以理解为 你去存钱 1.第一次存500，第二次存800，然后退出银行卡时，本次存钱的动作，永久写入数据库，你的余额永久变化了 2. 你去转账给好兄弟，第一次转了5块，第二次转了10块，这个过程都得你好兄弟的卡里，多了5块，10块，才是正确的，如果哪一方的账号出了问题，导致转账动作异常，数据库都能回退本次操作。 也就是，你不会少5块，对方也不会多5块，数据一致性完全正确。 这是mysql数据库提供的事务性特征。 查看日志事件 具体来看 二进制日志事件截图，看看，日志到底记录了个啥。\n1 2 3 1. binlog是二进制，人类看不懂的 2. 基于mysqlbinlog命令，解读为普通的SQL文件即可 体验binlog流程图解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 导出binlog [root@tech-db-51 /mysql_log/log_bin_3306]#mysqlbinlog mysql-log-bin.000003 \u0026gt; /tmp/mysql-log.txt 154\t建库 明文 325 建表 ,明文 501 插入表数据 at 768 从这开始 插入多条数据 1055 # 解密当前binlog，查看具体的SQL # 基于base64算法，按行解密binlog # -vv 显示日志的详细程度 [root@tech-db-51 /mysql_log/log_bin_3306]#mysqlbinlog --base64-output=decode-rows -vv mysql-log-bin.000003 \u0026gt; /tmp/decode-mysql-log.txt # 再次插入多条数据，pos值变化 mysql\u0026gt; insert into biekun77 values(2),(3),(4),(5),(6); Query OK, 5 rows affected (0.00 sec) Records: 5 Duplicates: 0 Warnings: 0 # 再次解密日志，查看 插入的数据 解密查看binlog日志 解密binlog，其实就是解密出具体的SQL语句，也就看到了具体的数值。\n1 2 3 4 [root@db-51 /mysql_backup]#mysqlbinlog /linux0224/mysql_3306/logs/mysql-bin.000003 [root@db-51 /mysql_backup]#mysqlbinlog --base64-output=decode-rows -vv /linux0224/mysql_3306/logs/mysql-bin.000003 7.binlog日志截取与恢复实践 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 1. 查看当前数据库，都用了哪些binlog mysql\u0026gt; show binary logs; +----------------------+-----------+ | Log_name | File_size | +----------------------+-----------+ | mysql-log-bin.000001 | 557 | | mysql-log-bin.000002 | 1109 | | mysql-log-bin.000003 | 1055 | +----------------------+-----------+ 3 rows in set (0.00 sec) 2. 当前正在用哪个binlog mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000003 | 1055 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 3. 查看binlog的玩法 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000003 | 1055 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 删除数据5 删除动作也是修改，也会提交事务，也会生成新的pos值 mysql\u0026gt; delete from biekun77 where id=5; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000003 | 1322 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) # 解密binlog日志 # 更精确的确认pos值的玩法 起点截止点 show binlog events in \u0026#39;mysql-log-bin.000003\u0026#39; # 恢复数据的命令 # --start-position 从哪个pos值开始 # --stop-positio 到哪个pos值结束 （delete语句之前截止） # 这个命令是，解密binlog，截取日志，只截取写入数据的 部分SQL，丢弃delete语句的部分 # delete删除数据 # 重新insert写入不就得了么 mysqlbinlog --start-position=381 --stop-position=752 mysql-log-bin.000004 \u0026gt; /tmp/restore-lol.sql 误删除数据的恢复思路 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 1. 使用mysql的GTID日志模式 用这个方式，就可以不用考虑POS值的选择麻烦了，目前生产玩法都是它，学习手工pos值的玩法，是为了更好理解GTID的优点。 2. 基于mysqlbinlog的日志提取 3.目前的思路是 - 如果是单行数据的delete 提取日志，解密SQL，然后手工insert插入数据即可 1. 当前的 日志状态 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000004 | 1793 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 2. 手工删除数据，基于日志恢复 # mysql\u0026gt; delete from tb1 where id =2; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000004 | 2049 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) # 当前状态 是 1793 2049截止，是数据删除 # 误删除了一个数据 # 删除的动作，被记录到了 binlog日志了 分析binlog日志，能知道你到底删除了什么 # delete也是被加密的数据 # 误误删除数据，你是不知道，到底删除了什么的 # 这个删除动作，由于开启binlog日志，所以delete动作也被记录下来AI # 提取binlog日志部分信息，解密出了，到底删了什么 mysqlbinlog --start-position=1793 --stop-position=2049 mysql-log-bin.000004 \u0026gt; /tmp/delete-test.sql # 单行恢复，删除了什么 # insert 写入 mysql\u0026gt; select * from data1.tb1; +------+ | id | +------+ | 1 | | 3 | | 4 | +------+ 3 rows in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; insert into data1.tb1 values(2); Query OK, 1 row affected (0.00 sec) - 如果是删库，删表级别的操作。 提取，从建库，到插入数据的部分 模拟练习 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 再来一次，建库，建表，删表，恢复数据 1.刷新日志，从头来 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000006 | 154 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; create database db06; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; use db06; Database changed mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000006 | 313 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; create table tb06(id int); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000006 | 477 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; insert into tb06 values(66),(77),(88); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000006 | 742 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) # 查看binlog的事件 1. 建库 154 \u0026gt; 313 2. 建表 313 \u0026gt; 477 3. 写入数据 477 \u0026gt; 742 4. 删库 742 \u0026gt; 899 4. 直接干掉这个库 ，db06 drop database db06; 查看 日志状态 show master status; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000006 | 899 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 日志事件 2. 恢复数据 你目前所有的操作，都被记录再了日志 mysql-log-bin.000006 - 先看啊看这个日志，完整的SQL记录 mysqlbinlog mysql-log-bin.000006 # 再次查看日志事件，截取，你要的 SQL范围 mysql\u0026gt; show binlog events in \u0026#39;mysql-log-bin.000006\u0026#39;; --start-position --stop-position mysqlbinlog --start-position=154 --stop-position=419 mysql-log-bin.000007 \u0026gt; /tmp/huifu-tb06.sql # 恢复操作 1. 先停止binlog的记录 mysql\u0026gt; set sql_log_bin=0; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show variables like \u0026#39;%log_bin%\u0026#39;; +---------------------------------+---------------------------------------------+ | Variable_name | Value | +---------------------------------+---------------------------------------------+ | log_bin | ON | | log_bin_basename | /mysql_log/log_bin_3306/mysql-log-bin | | log_bin_index | /mysql_log/log_bin_3306/mysql-log-bin.index | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | OFF | +---------------------------------+---------------------------------------------+ 6 rows in set (0.00 sec) 2数据导入 mysql\u0026gt; set sql_log_bin=0; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show variables like \u0026#39;%log_bin%\u0026#39;; +---------------------------------+---------------------------------------------+ | Variable_name | Value | +---------------------------------+---------------------------------------------+ | log_bin | ON | | log_bin_basename | /mysql_log/log_bin_3306/mysql-log-bin | | log_bin_index | /mysql_log/log_bin_3306/mysql-log-bin.index | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | OFF | +---------------------------------+---------------------------------------------+ 6 rows in set (0.00 sec) source /opt/huifu-tb06.sql 恢复binlog set sql_log_bin=1; 今日作业 1 2 3 4 5 6 1.完成mysqldump逻辑备份命令练习 2. 完成binlog日志作用整理，以及数据恢复实践 基于pos值的玩法，恢复数据通过了。 ","date":"2025-04-14T16:07:24+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%97%A5%E5%BF%97mysqldump/","title":"备份与日志（Mysqldump）"},{"content":"02-3-mysql运维核心基础 前置知识回顾\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 mysql多实例登录 mysql c/s模式 ，client server 两端 mysql客户端 机器本地的，/opt/mysql/bin/mysql 命令 windows机器上安装的一个 mysql命令 mysql服务端 10.0.0.51:3306 mysql -uroot -p密码 -h该账户允许登录的网段 -P实例端口 2种链接方式 入口一：基于ip：port的 网络链接形式，入口一 ，链接参数 ，-hlocahost -P3306 端口，窗口提供服务的入口 windows机器，去链接 mysql服务端 本质上是tcp的建立 netstat 查看网络链接情况 # 期望是你windows也装了个mysql，然后去登录 windows命令行： mysql -uroot -p密码 -hlocalhost # 远程链接 # 前提（默认mysql只提供了localhost登录，） # 授权操作，允许root@10.0.0.% 这个网段登录 windows命令行：发请求 10.0.0.1 这个windows的ip发出登录请求 ↓ mysql -uroot -plinux3306 -h10.0.0.51 -P3306 # 完整的登录命令 mysql -uroot -plinux3306 -hlocahost -P3306 入口二，只能在10.0.0.51这个机器上，机器本地，基于进程套接字文件的链接形式 不能用window去用这个方式 #这个命令只能是在10.0.0.51这个机器去执行 mysql -uroot -plinux3306 -S /linux3306/mysql_3306/mysql.sock 10.0.0.51:3307 10.0.0.51:3308 # 作为运维，如何给公司的其他人员配置mysql的权限，权限控制，限制 # 场景一：给开发装了一个linux的mysql服务端，开发只能再自己的机器上，去写代码，读数据库，增删改查测试 # 运维设置账号，先定权限，去远程链接，允许再什么样的网段中去链接，内网，允许再任意地址，只允许某一个ip去登录。 # 场景二：维护的阿里云，测试工程师需要测一份代码，需要有数据库的支撑 # 运维去创建一个测试库，测试账号，给这个测试工程师去用 # 例如ceshi01 ceshi666 123.206.16.61 23306端口 # mysql -uceshi01 -pceshi666 -h123.206.16.61 -P23306 # 把报错，截个图，李经理，帮忙看看吧，连不上了。 1.启动、关闭mysql原理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 systemctl start mysqld systemctl stop mysqld 如果这俩命令，报错了，如何排查 以及你得搞懂mysql启动的进程命令，背后的脚本加载逻辑，执行顺序 管理3306实例的脚本逻辑顺序 ①. 脚本放在了 /etc/init.d/mysqld ②. 可以用多种方式使用该脚本 1.给脚本添加执行权限 /etc/init.d/mysqld start 2. 该方式等于 service mysqld start 3.centos7上建议写法 systemctl start mysqld 4. service和systemctl命令都是去读取 /etc/init.d/目录下的脚本mysqld脚本文件 5.再centos7下的加载方式 /etc/init.d/mysqld ↓ systemctl 去调用 ↓ service 转化为systemctl mysqld_safe和mysqld区别 mysqld_safe作用\n1 2 3 4 5 6 7 先看看mysql的安装主程序目录 先用systemctl启动mysql试试，通过 ps命令 ，可以看到进程运行的完整命令和参数 [root@tech-db-51 ~]#yum install -y psmisc [root@tech-db-51 ~]#pstree -p 1 2 3 4 5 6 7 8 9 10 11 12 13 14 mysqld_safe作用 1. mysql官方启动脚本，是以执行mysqld_safe为入口，其实mysqld_safe也是个shell脚本，调用了myqsld命令启动服务 2.mysqld_safe脚本设置运行环境，如以守护进程运行 3.mysqld_safe检测mysqld运行状态 4.mysqld_safe检测mysqld进程运行信息，写入 mysql实例目录下的hostname.err文件 5.以及mysqld_safe会读取my.cnf配置文件的[mysqld],[mysqld_safe]等配置 mysqld作用 mysqld是mysql的核心程序，用于管理mysql的数据库文件，以及用户执行的SQL请求 mysqld读取my.cnf中 [mysqld]配置 启动命令区别 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 有3个实例 3306 复制mysql的官方脚本 入口 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; /etc/init.d/mysqld ↓ /opt/mysql/bin/mysqld_safe ↓ mysql主程序命令 /opt/mysql/bin/mysqld 3307 3308 [root@tech-db-51 ~]#bash /linux0224/3307.sh start Starting MySQL... [root@tech-db-51 ~]# [root@tech-db-51 ~]# [root@tech-db-51 ~]# [root@tech-db-51 ~]#bash /linux0224/3308.sh start Starting MySQL... [root@tech-db-51 ~]# # 查看3个mysql实例的进程命令 2.关闭mysql 脚本关闭 1 2 3 该实例，用什么脚本起的，就用什么脚本关 停止3307 命令关闭 1 2 3 4 5 6 7 8 更推荐用这个 # 先登录具体实例，然后再关闭 # 3308 mysql\u0026gt; shutdown; Query OK, 0 rows affected (0.00 sec) 特殊情况下，不建议用这个操作 1 2 3 4 5 6 7 8 9 直接用kill pkill killall kill pid # 除非进程卡死，无任何解决办法，再去 kill -9 pid 数据丢失，数据写入，事务提交，确认数据写入到磁盘，写入到日志 pkill 进程名 killall 进程名 直接杀死mysqld的玩法，可能导致下次mysql无法启动，日志会有报错信息 mysql丢失了服务端链接 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 mysql\u0026gt; shutdown; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; select user(); ERROR 2013 (HY000): Lost connection to MySQL server during query mysql\u0026gt; mysql\u0026gt; show databases(); ERROR 2006 (HY000): MySQL server has gone away No connection. Trying to reconnect... ERROR 2003 (HY000): Can\u0026#39;t connect to MySQL server on \u0026#39;127.0.0.1\u0026#39; (111) ERROR: Can\u0026#39;t connect to the server mysql\u0026gt; select user(); No connection. Trying to reconnect... ERROR 2003 (HY000): Can\u0026#39;t connect to MySQL server on \u0026#39;127.0.0.1\u0026#39; (111) ERROR: Can\u0026#39;t connect to the server 1 2 3 4 5 6 7 8 9 10 11 12 13 14 全部实例都挂了 [root@tech-db-51 ~]#systemctl stop mysqld [root@tech-db-51 ~]# [root@tech-db-51 ~]# [root@tech-db-51 ~]# [root@tech-db-51 ~]#!net netstat -tunlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1009/sshd tcp6 0 0 :::22 :::* LISTEN 1009/sshd [root@tech-db-51 ~]# [root@tech-db-51 ~]# 3.自定义mysqld服务管理脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 1.写mysql的运行脚本 1. 如 /linxu0224/3307.sh /linxu0224/3307.sh start /linxu0224/3307.sh stop /linxu0224/3307.sh restart 2. 写入 /etc/init.d/mysqld /etc/init.d/mysqld service systemctl 管理 3. centos7下，写服务管理脚本，参考 ，network脚本等写就行 找到centos7的 system服务脚本在哪，参考语法 #rpm -ql systemd|grep service [root@tech-db-51 ~]#systemctl status sshd ● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled) # 参考sshd脚本，写mysql管理脚本 [root@tech-db-51 ~]#cat /usr/lib/systemd/system/sshd.service [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.service Wants=sshd-keygen.service [Service] Type=notify EnvironmentFile=/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target 4. 参考写法，写一个systemctl 管理mysql的脚本 先关闭 /etc/init.d/mysqld脚本的功能 [root@tech-db-51 ~]#mv /etc/init.d/mysqld /linux0224/mysql_3306/ # 5.写入3306的服务管理脚本 cat \u0026gt; /etc/systemd/system/mysqld.service \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [Unit] Description=mysql server by www.lijinit.cn Documentation=man:mysqld(8) Documentation=https://dev.mysql.com/doc/refman/en/using-systemd.html After=network.target After=syslog.target [Install] WantedBy=multi-user.target [Service] User=mysql Group=mysql ExecStart=/opt/mysql/bin/mysqld --defaults-file=/etc/my.cnf LimitNOFILE=5000 EOF 6. 修改3306的配置文件，加入日志参数 [root@tech-db-51 ~]#mkdir -p /linux0224/mysql_3306/logs [root@tech-db-51 ~]# [root@tech-db-51 ~]#chown -R mysql.mysql /linux0224/ [root@tech-db-51 ~]#cat /etc/my.cnf [mysqld] log-error=/linux0224/mysql_3306/logs/3306-err.log port=3306 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3306/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock 7.启动3306，检测日志 # 重载systemctl 的脚本 systemctl daemon-reload systemctl restart mysqld systemctl stop mysqld # 管理mysql的脚本，方式，4种，具体再生产下遇见哪种，都会玩了 4.配置文件模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [root@db-51 ~]#cat /etc/my.cnf [mysqld] # 服务端标签 port=3306 # 端口 server_id # 主机编号，用于主从复制 user=mysql # 内置运行用户 basedir=/opt/mysql # 软件目录 datadir=/www.lijinit.cn/mysql_3306 # 数据目录 socket=/tmp/mysql.sock # 套接字文件路径 [mysql] socket=/tmp/mysql.sock # mysql客户端连接数据库，默认读取的socket文件路径 配置语法 [server] 服务端读取的配置 [mysqld] mysqld进程读取的配置 [mysqld_safe] mysqld_safe脚本会加载的配置 客户端配置参数 [mysql] 客户端命令读取的设置 [client] 所有本地客户端读取的设置 [mysqldump] 备份命令读取的设置 5.远程连接管理学习grant语句 本地连接 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 授权语句，创建一个用户，只允许本地连接 # 也能实现创建一个用户的作用 grant 权限 on 库.表 to 用户名@\u0026#39;允许登录的网段\u0026#39; identified by \u0026#39;远程登录的用户密码\u0026#39;; # 注意，写localhost 和127.0.0.1是不一样的 /linux0224/mysql_3306/mysql/该实例的用户数据都在这... /linux0224/mysql_3307/mysql/该实例的用户数据都在这... /linux0224/mysql_3308/mysql/该实例的用户数据都在这... # 创建wenjie用户，只允许再机器本地登录mysql 3307实例，给与最大权限，可以增删改查所有库表 # 先登录 [root@tech-db-51 ~]#mysql -uroot -plinux3307 -S /linux0224/mysql_3307/mysql.sock mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.28 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; mysql\u0026gt; grant all privileges on *.* to wenjie@\u0026#39;127.0.0.1\u0026#39; identified by \u0026#39;wenjie666\u0026#39;; 查看mysql的用户表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 查看3307实例 1. 登录 [root@tech-db-51 ~]# -uroot -plinux3307 -S /linux0224/mysql_3307/mysql.sock 2. 先进入mysql库，查看库下的所有表 mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) mysql\u0026gt; use mysql; # 查看当前再哪个库 mysql\u0026gt; select database(); +------------+ | database() | +------------+ | mysql | +------------+ 1 row in set (0.00 sec) # 查看当前库下有哪些表，2个语法 # 完整的 mysql\u0026gt; show tables from mysql; # 简写 mysql\u0026gt; show tables; # 进入mysql库，查看用户表，mysql本身存储的用户，账户密码表 # select 语句，查看表中的数据 大小写提示 数据库基础知识，不难，就是多，要细心做笔记，帮你大脑记忆\n1 2 # 目前数据库是不区分大小写的。。。。。。。。。。。。。。 # 内置的关键字建议大写，自定义的数据，建议小写 1 2 3 4 5 6 7 当前数据库有2个用户可以登录，只能本地登录 select user,host,authentication_string from mysql.user; root localhost wenjie 127.0.0.1 本地账号登录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 文杰 [root@tech-db-51 ~]#mysql -uwenjie -pwenjie666 -h127.0.0.1 -P3307 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 4 Server version: 5.7.28 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) mysql\u0026gt; # wenjie账户有最大的权限 使用mysql套接字登录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 再加一个用户记录，注意用root添加 grant all privileges on *.* to wenjie@\u0026#39;localhost\u0026#39; identified by \u0026#39;wenjie666\u0026#39;; [root@tech-db-51 ~]#mysql -uwenjie -pwenjie666 -S /linux0224/mysql_3307/mysql.sock mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 8 Server version: 5.7.28 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; # 基于自建的账号，走socket文件登录数据库，本地登录 mysql\u0026gt; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;远程连接\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 关于登录的方式选择 1 2 1. 本地登录，建议用socket去链接，或者ip:port也行 2. 远程登录，只能走IP:port了 授权，允许访问的网段 其他机器，登录10.0.0.51的3307的数据库实例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 只允许wenjie用户在 10.0.0.0~255 网段登录，有最大的权限 # 授权语句只能用root去操作 # % 百分号表示一个任意匹配的意思 grant all privileges on *.* to wenjie@\u0026#39;10.0.0.%\u0026#39; identified by \u0026#39;wenjie666\u0026#39;; #查询mysql的用户表的信息，当前mysql实例，有哪些用户信息 select * from mysql.user; # 默认查询所有的字段 select user,host from mysql.user; # 再创建一个用户 songlin01 只允许再内网172网段登录mysql grant all privileges on *.* to songlin01@\u0026#39;172.16.1.%\u0026#39; identified by \u0026#39;songlin666\u0026#39;; mysql\u0026gt; mysql\u0026gt; select user,host from mysql.user; +---------------+------------+ | user | host | +---------------+------------+ | wenjie | 10.0.0.% | | wenjie | 127.0.0.1 | | songlin01 | 172.16.1.% | | mysql.session | localhost | | mysql.sys | localhost | | root | localhost | | wenjie | localhost | +---------------+------------+ 7 rows in set (0.00 sec) mysql\u0026gt; #grant创建， select 查看 试试远程去登录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # wenjie用户，再10网段的机器登录 # 10.0.0.xxx的机器，能和这个 10.0.0.51:3307确保通信就行 # 留作用windows去登录，查看 -------------------------------------------------- # songlin01用户，只允许再172的内网环境登录 #172.16.1.xx 的机器，和 172.16.1.51:3307 # 找一个装有mysql的机器，作为客户端测试即可 ---------------------------------------------------------------------- # 查看mysql 3307 服务端绑定的ip：port [root@tech-db-51 ~]#netstat -tunlp|grep 3307 tcp6 0 0 :::3307 :::* LISTEN 4312/mysqld # 如果你限制mysql只能在内网访问 navicat图形化访问 1 2 3 4 5 6 7 8 玩mysql 2方式 1. mysql -uroot -p登录，纯命令行操作，所有的增删改查，都要输入SQL语句。 2. 所有的操作，全是图形化点点点。navicat工具， wenjie用户，允许再10.0.0.xx网段登录 1 2 3 4 5 至此完成了 1。 再内网环境下的 从 71 \u0026gt; 51 使用songlin01用户 2. 再模拟外网的环境 从windows \u0026gt; 51 ，用的是 wenjie用户 查看mysql的tcp链接 6.mysql用户管理 6.1 用户说明 1 2 3 4 5 6 7 8 9 linux 用户 - 登录系统 - 管理文件 mysql用户 - 登录mysql - 管理mysql的库、表，能管理哪些库，表，以及能做什么梦事 都看grant语句，给的权限了 6.2 远程登录白名单语法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 mysql 用户授权语法 远程登录，不在服务端的机器上去登 服务端 10.0.0.51:3307 10.0.0.7机器，去登 51 用户名@\u0026#39;网段白名单\u0026#39; 语法 lijin@\u0026#39;localhost\u0026#39; lijin可以在本地登录（ip:3306），以及socket lijin@\u0026#39;10.0.0.10\u0026#39; lijin只能在10.0.0.10这个客户端登录 lijin@\u0026#39;10.0.0.%\u0026#39; lijin只能在10.0.0.xx/24网段登录 lijin@\u0026#39;10.0.0.5%\u0026#39; lijin只能在10.0.0.50~59 登录 lijin@\u0026#39;%\u0026#39; lijin可以在任意地址登录该mysql服务端 lijin@\u0026#39;db-51\u0026#39; 基于主机名的登录限制 6.3 用户管理 查看mysql用户列表 1 2 3 4 5 6 7 # 查看mysql库下的user表的数据 # user 用户名 # host 允许登录的网段白名单 # authentication_string 验证字符串，密码的意思（加密显示的） select user,host,authentication_string from mysql.user; # 查询 创建用户 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 创建用户切设置密码 create user lijin02@\u0026#39;localhost\u0026#39; identified by \u0026#39;123\u0026#39;; # 明确区分，关键字和用户数据 CREATE USER xinlin01@\u0026#39;10.0.0.71\u0026#39; IDENTIFIED BY \u0026#39;xinlin666\u0026#39;; Last login: Fri Jul 29 22:15:15 2022 from 10.0.0.1 [root@zabbix-server-71 ~]#mysql -uxinlin01 -pxinlin666 -h10.0.0.51 -P3307 .Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MySQL connection id is 22 Server version: 5.7.28 MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. MySQL [(none)]\u0026gt; MySQL [(none)]\u0026gt; MySQL [(none)]\u0026gt; select user(); +--------------------+ | user() | +--------------------+ | xinlin01@10.0.0.71 | +--------------------+ 1 row in set (0.00 sec) MySQL [(none)]\u0026gt; MySQL [(none)]\u0026gt; 修改用户密码，root去修改 1 2 3 4 5 6 7 8 9 10 # root权限最大的，修改表数据了，修改语法是基于 # 区分关键字用大写给大家表示 # 修改用户xinlin01的密码 为 ，juanwang666 select user,host,authentication_string from mysql.user; ALTER USER xinlin01@\u0026#39;10.0.0.71\u0026#39; IDENTIFIED BY \u0026#39;juanwang666\u0026#39;; 普通用户改自己密码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 注意修改自己的密码，要进行加密处理 # 需求，让wenjie修改自己的密码为 laoliu666 set password=password(\u0026#39;lijin666\u0026#39;); 等于 # 先看这个写法 SET PASSWORD=PASSWORD(\u0026#39;新的密码\u0026#39;) select password(\u0026#39;laoliu666\u0026#39;); # wenjie修改自己的密码 SET PASSWORD=PASSWORD(\u0026#39;laoliu666\u0026#39;) 删除用户 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 用root用户去删除普通用户 # 运维一般创建普通账户，不可能给最大权限 mysql\u0026gt; DROP USER xinlin01@\u0026#39;10.0.0.71\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; select user,host,authentication_string from mysql.user; +---------------+-----------+-------------------------------------------+ | user | host | authentication_string | +---------------+-----------+-------------------------------------------+ | root | localhost | *19A77E0F06928E313B68F2AAB7756D508846258B | | mysql.session | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | | mysql.sys | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | +---------------+-----------+-------------------------------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; # root，清空了所有的无用账号 配置root远程链接 1 2 3 4 5 6 7 8 9 10 11 12 13 mysql\u0026gt; select user,host,authentication_string from mysql.user; +---------------+-----------+-------------------------------------------+ | user | host | authentication_string | +---------------+-----------+-------------------------------------------+ | root | localhost | *19A77E0F06928E313B68F2AAB7756D508846258B | | mysql.session | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | | mysql.sys | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | | root | % | *83F7A15725AF362EF5EAFC16E1F3F97FDAB9B411 | +---------------+-----------+-------------------------------------------+ 4 rows in set (0.00 sec) mysql\u0026gt; #本地链接root密码是 linux3307 远程链接是lijin666 mysql\u0026gt; 7.grant授权管理 权限的作用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 限制mysql的用户，可以执行哪些SQL语句。 使用grant语句可以创建用户且进行权限控制 限制用户，可以用如下哪些语句 show privileges # 查看权限规则语法 create user create database drop 删除语句 alter user 更新数据 [root@tech-db-51 ~]# [root@tech-db-51 ~]#mysql -uroot -plijin666 -h10.0.0.51 -P3307 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 35 Server version: 5.7.28 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; mysql\u0026gt; show privileges # 用于 grant 给与的权限1,权限2,权限3 on 库.表 to 用户名@允许登录的网段规则 indentified by \u0026#39;密码\u0026#39;； 查看授权规则语法 1 2 3 4 5 6 7 grant不会用怎么办？ help grant; 语法如下 grant 给与的权限1,权限2,权限3 on 库.表 to 用户名@允许登录的网段规则 indentified by \u0026#39;密码\u0026#39;； grant授权命令 1 2 查看所有文档 mysql\u0026gt; help grant; 授权实践 root默认不允许远程登录，给与权限，允许远程登录\n1 GRANT ALL PRIVILEGES on *.* to root@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;lijin666\u0026#39;; 给一个普通开发者jiaqiang01的账户权限，只能增删改查基本操作，且限定某个数据库，且只允许在内网环境连接。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 select,update,delete,insert dev01 库 172.16.1.% # 创建数据库 # 运维，使用最大的权限账户， # root@\u0026#39;localhost\u0026#39; # 查看如下权限表的，是最高权限的root用户 mysql\u0026gt; show grants; +---------------------------------------------------------------------+ | Grants for root@localhost | +---------------------------------------------------------------------+ | GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | | GRANT PROXY ON \u0026#39;\u0026#39;@\u0026#39;\u0026#39; TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | +---------------------------------------------------------------------+ 2 rows in set (0.00 sec) CREATE DATABASE dev01; # 创建了jiaqiang01用户，以及授权 # GRANT SELECT,UPDATE,DELETE,INSERT ON dev01.* TO jiaqiang01@\u0026#39;172.16.1.%\u0026#39; IDENTIFIED BY \u0026#39;jiaqiang666\u0026#39;; mysql\u0026gt; select user,host from mysql.user; +---------------+------------+ | user | host | +---------------+------------+ | root | % | | jiaqiang01 | 172.16.1.% | | mysql.session | localhost | | mysql.sys | localhost | | root | localhost | +---------------+------------+ 5 rows in set (0.00 sec) 查看具体用户的权限 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 show grants # 查看当前用户的权限信息 mysql\u0026gt; show grants; +---------------------------------------------------------------------+ | Grants for root@localhost | +---------------------------------------------------------------------+ | GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | | GRANT PROXY ON \u0026#39;\u0026#39;@\u0026#39;\u0026#39; TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | +---------------------------------------------------------------------+ 2 rows in set (0.00 sec) select user,host from mysql.user; show grants for 用户@\u0026#39;网段\u0026#39;; 查询具体用户的权限 # 如何查看jiaqiang01的权限 show grants for jiaqiang01@\u0026#39;172.16.1.%\u0026#39;; mysql\u0026gt; show grants for jiaqiang01@\u0026#39;172.16.1.%\u0026#39;; +--------------------------------------------------------------------------------+ | Grants for jiaqiang01@172.16.1.% | +--------------------------------------------------------------------------------+ | GRANT USAGE ON *.* TO \u0026#39;jiaqiang01\u0026#39;@\u0026#39;172.16.1.%\u0026#39; | | GRANT SELECT, INSERT, UPDATE, DELETE ON `dev01`.* TO \u0026#39;jiaqiang01\u0026#39;@\u0026#39;172.16.1.%\u0026#39; | +--------------------------------------------------------------------------------+ 2 rows in set (0.00 sec) 回收权限 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # grant授权的语句 # 移除jiaqiang01 对dev01库下的所有表的 delete 权限 # 大写语法 REVOKE DELETE ON dev01.* from jiaqiang01@\u0026#39;172.16.1.%\u0026#39; ; # 移除所有权限，针对dev01这个库 REVOKE ALL ON dev01.* from jiaqiang01@\u0026#39;172.16.1.%\u0026#39; ; show grants for jiaqiang01@\u0026#39;172.16.1.%\u0026#39;; # 此时jiaqiang01用户只剩下登录权限了 mysql\u0026gt; mysql\u0026gt; show grants for jiaqiang01@\u0026#39;172.16.1.%\u0026#39;; +-------------------------------------------------+ | Grants for jiaqiang01@172.16.1.% | +-------------------------------------------------+ | GRANT USAGE ON *.* TO \u0026#39;jiaqiang01\u0026#39;@\u0026#39;172.16.1.%\u0026#39; | +-------------------------------------------------+ 1 row in set (0.00 sec) # 使用jiaqiang01用户登录 [root@tech-db-51 ~]#mysql -ujiaqiang01 -pjiaqiang666 -h172.16.1.51 -P3307 只有账户、无任意权限 该账户只能登录\n1 2 3 4 5 6 7 mysql\u0026gt; show grants for jiaqiang01@\u0026#39;172.16.1.%\u0026#39;; +-------------------------------------------------+ | Grants for jiaqiang01@172.16.1.% | +-------------------------------------------------+ | GRANT USAGE ON *.* TO \u0026#39;jiaqiang01\u0026#39;@\u0026#39;172.16.1.%\u0026#39; | +-------------------------------------------------+ 1 row in set (0.00 sec) 作业练习 mysql知识量大，需要记忆的多\n做好笔记，思维脑图\n就能学好了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 1.完成mysql远程连接的命令整理，grant语句整理 2. 实际案例练习 3306实例 创建三个普通账号，授权练习 1. 运维账号给与最大权限，允许远程连接 2.开发账号，只能对开发库有增删改查权限，只允许在10，172两个网段连接 3.测试账号，只能对测试库增，改，查的权限，且只允许在172内网连接。 3307实例，安装jpress博客，且可以navicat远程访问 在阿里云部署mysql5.7.28 ，修改默认端口为23306，防止数据库被恶意扫描，确保可以navicat，和cmd远程访问 ","date":"2025-04-14T16:04:59+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/mysql%E6%9D%83%E9%99%90%E7%AF%87/","title":"MySQL权限篇"},{"content":"03-MySQL基础 一、入门 Navicat图形化\n① 安装：略。\n② 连接MySQL服务器\n二、MySQL命令 SQL命令 概念：MySQL客户端远程操作和管理MySQL服务器里面的数据一种指令（代码）。\n语法规则：\n① 必须以分号结尾，MySQL服务器以分号判定SQL是否结束了。\n② 关键词大小写一样，不敏感。例如：select 和SELECT​，但是数据\u0026rsquo;abc\u0026rsquo; \u0026lsquo;ABC\u0026rsquo;;\n③ 注释使用 \u0026ndash;表示。\n1 -- 说明文字,不算代码，mysql不执行，给程序员给人看的。 数据库管理 (1) 查看当前数据库版本信息\n1 2 select version(); SELECT version(); (2) 查看当前mysql服务器连接的客户端信息\n1 show processlist; 结果说明 MySQL核心概念 例如：学校管理学生信息\n目的：提高数据管理和检索效率。\n1 2 3 4 5 1. 学生信息：鹿晗博 2. 班级：66班 3. 年级：3年级 4. 专业：计算机专业 5. 学校：清华大学 数据库数据管理：row行数据​、table表​、database库​。\n关键词 概念 说明 row​ 行 一条数据。 table​ 表 一个表和包含多row行数据，一个表存数据都是业务含义相似的数据，例如：学生表存学生，老师表存老师，商品表，存商品。 database​ 库 管理table表，一个database管理多个table。一个软件系统的多张表管理在一个database。 primary key​ 主键 唯一标识一条数据，例如：身份证号、卡号、学生号、工号、游戏ID、递增不重复的数字。\ncolumn​ 列 列不属于数据，明确table当前列的数据含义、数据类型。 database管理命令 (1) 创建database\n语法\ncreate database db名字;​\n代码\n1 2 3 4 -- 创建一个 edu的database create database edu; -- 创建一个shop的database create database shop; (2) 查看系统所有database\n语法\nshow databases;​\n(3) 切换database\n语法\nuse db名字;​\n(4) 删除database\n语法\ndrop database db名字;​\n三、 table管理命令 1. 表结构 表名\n列信息：① 列名 ② 数据类型 ③ 约束\n​\n1 2 3 4 5 6 7 1. 表名： 例如：t_product、t_emp、t_user、t_category 命名规范：t_名字 2. 列信息 列名：表名列的含义 命名规范：username、password、product_name、shangping_mingzi 数据类型：该列的所有的值类型是什么：数字、文本、日期。 2.数据类型 总类 类型 说明 整数 int 整数：范围 -2147483648~2147483647 bigint​ 大整数 小数 double(m,n)​ 小数。m表示数字的最大长度，n表示最多小数位。\n例如：double(5,2)，123.45 √ 12.345 x ​ 文本/字符串 char(n) 定长文字类型，n表示最大的字符个数，如果实际给的字符个数少于n，MySQL自动补白。补够n的个数。\n例如：char(1) 最多只能存1个字符，char(11) 最多存11个字符\n注意：char(11),如果只存了10个字符，剩余字符空间自动补白。\n场景：性别、状态、手机号\n优点：查找效率比较高。 varchar(n)​ 可变长文字类型，n表示最大字符个数，如果实际给的个数少于n。\n例如：用户名、商品名、简介、地址。\n优点：节省空间 text``longtext 65,535字符 ≈ 64KB长度字符串\nlongtext 最大 4GB字符\n日期 date 日期，包含信息\n日期date：年月日\n时间time：时分秒\n3. 表管理命令 (1) 建表\n语法\n1 2 3 4 5 create table 表名( 列名1 类型, 列名2 类型, 列名3 类型 ); 案例\n创建一个员工表,包含：工号、姓名、生日、性别(1男 0女 2其他)、手机号、工资、地址\n1 2 3 4 5 6 7 8 9 create table t_emp( emp_id bigint, emp_name varchar(20), sex char(1), birth date, mobile char(11), salary double(10,2), address varchar(100) ); (2) 查看表信息\n查看表结构信息\n语法：\ndesc 表名;​\n(3) 删除表\n语法\ndrop table 表名;​\n(4) 约束\n概念\n建表针对列添加除了类型以外额外数据限制要求,常见：主键、非空、唯一、自增。\n常见约束\n约束 说明 例子 primary key​ 主键：唯一+非空 身份证、工号、学号、游戏ID not null​ 非空，要求该列的值必须给 用户名、手机号、密码\u0026hellip; unique​ 唯一，要求该列的值不能重复 手机号、用户名 auto_increment​ 自增列，该列的值自动有MySQL分配，主键递增。 ID分配 语法\n1 2 3 4 5 create table 表名( 列名1 类型 约束 约束, 列名2 类型 约束, 列名3 类型 约束 ); 案例\n创建一个员工表,包含：工号、姓名、生日、性别(1男 0女 2其他)、手机号、工资、地址\n1 2 3 4 5 6 7 8 9 create table t_emp_check( emp_id bigint primary key auto_increment, emp_name varchar(20) not null unique, sex char(1), birth date, mobile char(11) unique, salary double(10,2) not null, address varchar(100) ); 任务：\n1 2 3 4 5 6 7 8 9 10 11 创建一个学生表： 学号 姓名 班级号 专业名称 性别 出生日期 籍贯 手机号 政治面貌 高考成绩 4. 数据管理 准备一个table表\n1 2 3 4 5 6 7 8 9 10 11 12 -- 创建一个database：baizhi create database baizhi; use baizhi; -- 用户表 create table t_user( id bigint primary key auto_increment, username varchar(20), password varchar(20), age int, birth date, mobile varchar(11) ); 添加数据 场景\n向t_user表添加一条数据：luhanbo、123123、20、1999-9-9、 15533367988\n语法\n1 2 3 4 5 6 分析： ① 表 ② 列... ③ 数据值... 语法： insert into 表名(列名1,列名2,列名3...) values(值1,值2,值3...); 注意：表名后面的列顺序，和values后面值的顺序保持一致。\nSQL\n1 2 insert into t_user(username,password,age,birth,mobile) values(\u0026#39;luhanbo\u0026#39;,\u0026#39;123123\u0026#39;,20,\u0026#39;1999-9-9\u0026#39;,\u0026#39;15533367777\u0026#39;); 批量插入\n1 2 3 4 5 insert into 表名(列名1,列名2,列名3...) values(值1,值2,值3...), (值1,值2,值3...), (值1,值2,值3...), (值1,值2,值3...); 查询数据 场景\n从t_user表查询全部数据\n语法\nselect * from 表名;​\n1 2 select: 指定数据提取那些列 from: 指定数据来源哪张表 SQL\n1 2 3 4 5 -- 查询部分列 select 列1,列1,列1,列1 from 表名; --查询所有列 select * from t_user; 修改数据 场景：\n修改t_user表中悟空，age=800，密码=111111?\n语法\n1 2 3 4 5 6 分析： ① 指定表 ② 指定那条数据 ③ 那些列，新值 update 表名 set 列名=新值,列名=新值 where id = ? SQL\n1 2 3 4 5 update t_user set age=800, password=111111 where id = 2; 删除数据 场景\n删除数据库的luhanbo这条数据？\n语法\n1 2 3 4 5 6 分析： ① 表 ② 那条数据？ 语法： delete from 表 where id=?; SQL\n1 delete from t_user where id = 1; 清空表truncate 将表中全部数据截断（将表数据部分占用空间直接回收），保留表结构。\n方法1：delete删除\ndelete from 表;​ 问题：逐行删除，效率低，数据量越大删除越慢。 方法2：truncate 截断\ntruncate table 表;​ truncate特点\nTRUNCATE不支持WHERE条件 自增长列，TRUNCATE后归1，delete删除的数据占用递增之，不会释放的。 效率高于DELETE 复制表 将表复制一份新的，场景：调试、测试场景。\n仅复制表结构\n针对原表的完整表结构进行复制，包含 所有列、类型、约束。\n语法： 1 CREATE TABLE 待创建的表名 LIKE 已有表名 示例： 1 2 mysql\u0026gt; create table departments like nsd2021.departments; Query OK, 0 rows affected (0.01 sec) 复制表结构及数据\n针对查询语句结果，创建一个表，可以制定要选择的那些数据那些列。作为新表。\n语法： 1 2 CREATE TABLE 待创建的表名 SELECT 字段, ... FROM 已有表名 示例： 1 2 3 4 mysql\u0026gt; create table departments2 -\u0026gt; select * from nsd2021.departments; Query OK, 13 rows affected (0.01 sec) Records: 13 Duplicates: 0 Warnings: 0 四、查询 1、数据准备 (1) 步骤\n① 创建database，名字：edu\ncreate database edu;\n② 进入baizhi\nuse edu;​\n③ 复制课堂案例数据edu员工.sql中所有代码，粘贴到mysql的客户端sql命令中。执行。\n(2) 简介\nt_employees：员工表\n员工ID 名字 姓 邮箱 手机号 入职时间 职位ID 月薪 佣金比例 直属领导ID 部门ID EMPLOYEE_ID FIRST_NAME LAST_NAME EMAIL PHONE_NUMBER HIRE_DATE JOB_ID SALARY COMMISSION_PCT MANAGER_ID DEPARTMENT_ID t_jobs：职位表\nt_departments：部门表\nt_countries：国家信息\nt_locations：分公司事业部所在地址\n2、SQL语句总结(最后) 关键词作用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 1. select 选择提取列 2. from 指定数据来源哪个表 3. where 指定过滤数据的条件 ① and or 连接多个条件 ② between 区间查询：数字 日期 ③ is null | is not null ④ in 枚举选项，满足任何一个即可 ⑤ like模糊查询 4. order by 排序 5. limit 满足查询结果的数据进行截取 6. group by 分组 SQL书写语法\n1 2 3 4 5 6 7 8 9 10 1. 版本1 select 列名1,列名2,列名3 from 表名; 2. 版本2 select 列名1,列名2,列名3 from 表名 where 条件; 3. 版本3 select ... from ... where 条件 order by 排序列 limit start,num; 4. 版本4 SQL的执行顺序\n执行顺序 关键字 作用 1 from​ 明确数据源 2 where​ 过滤表中数据 3 group by​ 对满足where条件的数据进行分组group having​ 对分组后的数据进行过滤。 6 select​ 选择指定的列 7 order by​ 排序 8 limit​ 截取查询结果 3、简单查询 (1) 查询部分列\n场景\n查询t_emp中所有员工的id工号、名字、月薪？\n关键\n1 2 1. select：选择要查看的列。 2. from: 确定数据来源的表 语法\n1 select 列名1,列名2,列名3 from 表名; 案例\n1 2 select employee_id,first_name,salary from t_emp; (2) 查询全部列\n场景\n查询t_emp表所有员工的全部信息：id、名字、月薪、姓、职位、部门id、佣金？\n语法\n1 2 select * from t_employees; (3) 列数学运算\n场景\n查看所有员工的id、名字、月薪、年薪（salary*12）？\n语法\n1 2 3 4 select 列+n,列-n,列*n,列/n from 表名; 注意：列的数据类型必须是数字类型：int 、bigint、double。 案例\n1 2 select employee_id,first_name,salary from t_employees; (4) 列起别名\n场景\n查看所有员工的id、名字、月薪(mon_salary)、年薪(year_salary)？\n说明\nselect查询结果列名，并不一定是表中的列名，由select语句后面的单词决定。\n语法\n1 2 3 4 5 select 列1 as 别名 ,列2 as 别名,列3 as \u0026#34;别名\u0026#34; ... from 表名; 注意： 如果别名中有特殊字符，关键词，空格，需要使用引号，建议使用双引号定义别名。 案例\n1 2 select employee_id,first_name,salary as \u0026#34;mon_salary\u0026#34;,salary*12 as \u0026#34;year_salary\u0026#34; from t_employees; (5) 去重\n场景：\n查询员工t_emp表所有的领导的id编号？\n关键词\ndistinct​\n作用：针对查询结果中重复的数据，进行去重。(只有一行数据中所有列的值都一样，才算做重复数据。distinct作用于后面所有列)\n重复数据定义：看一整行row，一行数据所有的值，都重复。\n语法：\n1 2 select distinct 列名1,列名2,列名3 from 表名; (6) case-when(**)\n场景\n查询所有员工的id、名字、工资、工资等级(10000+:A,8000~10000:B, 6000 ~8000:C, 6000-：D)\n语法\ncase-when是用来生成查询结果的列，书写位置在select后面和其他列同级别。\n1 2 3 4 5 6 7 8 9 10 case when 条件1 then 值1 when 条件2 then 值2 when 条件3 then 值3 else 值4 end 说明： 1. 按照case条件从上开始判断，满足某个条件，则选择then后面的值作为当前列的值，如果不满足，则继续向下判断。 如果都不成立，最后值选择else的值。 代码\n1 2 3 4 5 6 7 8 select employee_id,first_name,salary, case when salary \u0026gt; 10000 then \u0026#39;A\u0026#39; when salary \u0026gt; 8000 then \u0026#39;B\u0026#39; when salary \u0026gt; 6000 then \u0026#39;C\u0026#39; else \u0026#39;D\u0026#39; end from t_employees; 4、where条件查询 场景： 用户选择数据过滤的条件，然后出发查询操作，获得满足过滤条件的数据。\n​\n关键词\nwhere​\n作用：对查询表中的数据进行条件帅选，只有满足where条件的数据才会被客户端查询得到。\n运行机制\n① from表中所有数据，逐条进行where条件判断。\n② 只有满足where条件，才会被保留在查询结果中。\n语法\n1 select 列名1,列名2,列名3 from 表名 where 过滤条件; (1) 单条件\n场景：\n查询工资大于等于10000员工信息：id、名字、工资。\n代码\n1 2 3 select employee_id,first_name,salary from t_employees where salary \u0026gt;= 10000; (2) 多条件\n场景\n查询部门编号90，且工资大于10000的员工信息id、名字、工资？\n分析\n1 2 3 where条件： ① 条件1：department_id = 90 ② 条件2：salary \u0026gt;= 10000 语法\n1 2 3 4 5 6 7 select 列名1,列名2,列名3 from 表名 where 条件1 and|or 条件2 说明： and：且：只有and两边条件都满足，才会作为查询结果。 or：或：数据条件只要满足1个即可作为查询结果。 代码\n1 2 3 4 5 -- 1. 查询部门编号90，且工资大于10000的员工信息id、名字、工资？ select employee_id,first_name,salary,department_id from t_employees where department_id = 90 and salary\u0026gt;= 10000; \u0026ndash; 2. 查询部门编号90，或者 工资大于10000的员工信息id、名字、工资？ select employee_id,first_name,salary,department_id from t_employees where department_id = 90 or salary\u0026gt;= 10000;\n\u0026ndash; 3. 查询工资 8000~10000之间员工信息：id，名字，工资。 select employee_id,first_name,salary from t_employees where salary \u0026gt;= 8000 and salary \u0026lt;=10000;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 (3) 区间 * 场景 查询工资 8000~10000之间员工信息：id，名字，工资。 * 关键 ​`where 列名 between min and max`​ 含义：过滤数据条件在min和max之间的数据。(结果中包含min和max的情况) * 语法 ```sql select 列名1,列名2,列名3 from 表名 where 列名 between 最小值 and 最大值; 代码\n1 2 3 select employee_id,first_name,salary from t_employees where salary between 8000 and 10000; (4) in枚举\n场景\n查询部门编号60 70 80 部门的员工信息：id、名字、工资、部门id？\n关键\nwhere 列 in (值1,值2,值3,值4)​\n含义： 判断列的值否满足in后面括号中任意一个值，如果满足任意一个，即可作为查询结果。\n语法\n1 2 3 select 列名1,列名2,列名3 from 表名 where 列 in (值1,值2,值3,值4) 代码\n1 2 3 select employee_id,first_name,salary,department_id from t_employees where department_id in (60,70,80,90); (5) 空值\n场景\n查询员工信息，没有佣金的员工信息？\n关键词\nwhere 列 is ​​null​​\n含义：判断指定列的值是否是null，如果是null，则作为查询结果。\nwhere 列 is ​​not null​​\n含义：判断指定的值是否是非null(是否有值)。\n代码\n1 2 3 4 -- 查询员工信息，没有佣金的员工信息？ select * from t_employees where comission_pct is null; (6) 模糊查询\n场景：\n查询员工职位名称 以\u0026quot;IT\u0026quot;开头的员工信息？\n语法\nwhere 列名 like '关键词和通配符'​\nSQL通配符：\n序号 符号 含义 1 %​ 任意字符，个数0~n个 2 _​ 任意字符，表示1个 代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- 查询员工职位名称 以\u0026#34;IT\u0026#34;开头的员工信息？ select * from t_employees where job_id like \u0026#39;IT%\u0026#39;; -- 查询名字中以A开头的员工信息？ select * from t_employees where first_name like \u0026#39;A%\u0026#39;; -- 查询员工的名字4个字母的员工信息？ select * from t_employees where first_name like \u0026#39;____\u0026#39;; 5、order排序 场景：为了方便用户查看信息，数据展示往往会提供可以排序的功能。\n​\n关键词\norder by 列名 asc | desc​\norder by可以支持整数、小数、日期类型排序。(可以对字符串排序)\n语法\n1 select ... from ... where ... order by 排序列1 asc|desc,排序列2 asc|desc 说明： order by：基于指定列进行排序,可以指定多个列，且当第一个列的值相同，按照第二列的排序方式进行排序。 asc：升序 默认 desc：降序\n1 2 3 4 5 6 7 8 9 10 11 12 * 代码 ```sql -- 查询员工信息，按照薪资降序排序？ select * from t_employees order by salary desc; -- 查询员工信息，按照信息升序，如果薪资相同按照部门id降序排序？ select * from t_employees order by salary asc,department_id desc; 6、limit截取 场景：往往每次查询返回给用户的数据并不是全部数据，而是进行截取分批查询，分页展示​。\n​\n分析优化：\n1 2 3 1. 实际开发中，数据不会全部查询发送给客户端，用户多了以后不需要的数据也会大量占用MySQL服务器网络带宽，降低查询效率。 结论：不必要查询的数据，就不返回给用户。 2. select后面的列，不需要的数据，就不要给客户端传输。不要使用select *. 语法\nlimit start,count​\n1 2 3 4 limit start,count start: 截取数据，从第几条开始，从 0 开始计数。 count:本次查询，查询多少条。 代码\n1 2 3 4 -- 查询员工的信息，每页显示10条，查询第一页（0,10） select * from t_employees limit 0,10; 五、函数 概念：\nMySQL内置了一些SQL 特定数据处理功能的工具，叫做函数。\n语法\n函数名()​\n函数名(参数)​\n1. 单行函数 概念：\n被单行函数处理的数据，输入n条，输出n个结果。逐条数据进行处理。 总结：单行函数处理的目标数据一行一行，一行数据产生一条结果。\n​\n常见：\n1 2 3 4 5 6 7 8 9 10 11 12 13 1. 获得当前系统时间：(MySQL-Server服务器所在电脑) sysdate() 2. 获得字符串长度： length(列名) 3. 字符串拼接： concat(列,列,列,\u0026#39;abc\u0026#39;) 4. 将字符串格式 \u0026#39;1999年9月9日\u0026#39; 转变成date类型。 str_to_date(参数..) 5. 提取日期中部分数据(日期：年月日 时分秒) date_format(参数..) 6. 其他... 相同单行函数。 (1) sysdate 获得日期\n场景：\n1 2 -- 查看当前系统时间 select 语法：\n1 select sysdate(); (2) length 获得字符串长度\n语法\n1 length(列名) 场景\n1 2 3 4 5 6 7 8 -- 1. 查看所有员工的id，名字，工资，及其名字的长度？ select employee_id,first_name,salary,length(first_name) from t_employees; -- 2. 查看员工的名字长度是5位员工信息？ select * from t_employees where length(first_name) = 5; (3) concat 字符串拼接\n语法\n1 2 3 concat(列名1,列名2) concat(列名1,列名2,列名3...) concat(列名1,\u0026#39;固定字符\u0026#39;) 场景\n1 2 3 4 5 6 -- 查看员工姓名和工资？ select concat(first_name,last_name),salary from t_employees; select concat(first_name,\u0026#39;·\u0026#39;,last_name) as \u0026#34;name\u0026#34;,salary from t_employees; (4) str_to_date 字符串转为date\n语法\n1 str_to_date(\u0026#39;1999年9月9日\u0026#39;,\u0026#39;日期提取格式\u0026#39;) 日期通配符\n格式标识符 含义 **%Y**​ 年（4位） **%m**​ 月，格式为（01~12) **%d**​ 天，格式为（00~31） **%H**​ 小时，格式为（00~23） **%i**​ 分钟，格式为（00~59） **%s**​ 秒，格式为（00~59） 场景\n1 2 3 4 5 -- 将 \u0026#39;1999年9月9日\u0026#39; 转化为日期类型 select str_to_date(\u0026#39;1999年9月9日\u0026#39;,\u0026#39;%Y年%m月%d日\u0026#39;); -- 向t_user表的name和birth添加一条数据\u0026#39;麦克阿瑟\u0026#39; \u0026#39;1999年9月9日\u0026#39; insert into t_user(name,birth) values(\u0026#39;美国五星上将马克阿瑟\u0026#39;,str_to_date(\u0026#39;1999年9月9日\u0026#39;,\u0026#39;%Y年%m月%d日\u0026#39;)); (5) date_format 日期格式化\n作用：提取日期的部分(年 月 日 时 分 秒)信息。\n语法：\n1 2 date_format(date类型列名,\u0026#39;日期格式\u0026#39;) -- 结果是一个字符串类型的结果。 date_format(date类型列名,\u0026#39;%Y-%m\u0026#39;) -- 场景\n1 2 3 4 5 6 7 8 9 -- 1. 查看所有员工的入职日期，精确到年月(1999-9)？ select first_name,date_format(hire_date,\u0026#39;%Y-%m\u0026#39;) from t_employees; -- 2. 查看一下本月生日的员工信息？（假设hire_date就是生日） -- 翻译：hire_date 的月份 = 当前系统时间的月份 select * from t_employees where date_format(hire_date,\u0026#39;%m\u0026#39;) = date_format(sysdate(),\u0026#39;%m\u0026#39;); 2. 组函数 概念：\n对组数据进行处理的，输入n组数据，产生n条结果。\n常见组函数\n1 2 3 4 5 6 1 统计一组的总个数： count(列) 2 统计总和： sum(列) 3. 最大值、最小值、平均值 max(列)\tmin(列) avg(列) 案例\n当sql中没有分组group by 操作，组函数会将原表where过滤之后的数据当成一组来看。\n1 2 3 4 5 6 7 前提：如果针对一张表的数据，统计(没有分组)，一张表直接看做1组。 -- 1. 统计所有员工人数？ select count(employee_id) from t_employees; -- 2. 统计员工的平均工资？ -- 3. 插卡员工最大工资和最小工资？ -- 4. 统计员工月人力成本？ select avg(salary),max(salary),min(salary),sum(salary),fist_name from t_employees; 六、分组 1. 分组group 对from表满足where条件之后的数据进行分组。\n场景\n1 2 3 1. 统计每个部门的平均工资？ 2. 统计每个班级的班级人数？ 3. 统计每种类别的商品平均价格？ 思路\n① 第一步：按照某个列，将数据分成多组。\n② 第二步：对每组数据，进行组函数统计。\n关键词\ngroup by 分组依据列名​\n语法\n1 2 3 4 select ... from ... where ... group by 依据列 代码\n1 2 3 4 -- 1. 统计每个部门的平均工资？(平均工资 部门id) select department_id,avg(salary),max(salary),min(salary) from t_employees group by department_id; 注意：\n表数据一旦经过分组group by后， select后只能出现group by的字段。 select后还能出现组函数处理字段。 2. 分组过滤having 场景：\n查看平均工资高于8000的，部门id，平均工资，人数？\n思路：\n分析(x)\n1 2 3 4 select dept_id,avg(salary),count(emp_id) from t_emp where 部门平均工资\u0026gt;8000 group by 部门id 自以为是的SQL\n1 2 3 4 select department_id,avg(salary),count(employee_id) from t_employees where avg(salary) \u0026gt; 8000 group by department_id; 错误原因：\n① where关键词执行顺序在group分组之前。\n② where语句执行，数据未分组，不能使用组函数。\n关键词\nhaving​\n作用：对分组后的数据进行过滤，可以having中使用组函数处理结果(组函数、分组依据列)\n语法\n1 2 3 4 5 select ... from ... where 分组前的过滤条件 group by 分组依据列 having 分组后过滤条件 代码改写\n1 2 3 4 5 -- 查看平均工资高于8000的，部门id，平均工资，人数？ select department_id,avg(salary),count(employee_id) from t_employees group by department_id having avg(salary) \u0026gt;= 8000; 3. 对比where和having 场景\n统计统计60,80,90部门的平均工资(department_id,平均工资)？\n代码\n1 2 3 4 5 6 7 8 9 10 11 1. 方式1 select department_id,avg(salary) from t_employees group by department_id having department_id in (60,80,90); 2. 方式2 select department_id,avg(salary) from t_employees where department_id in (60,80,90) group by department_id; 总结\n① where是在分组之前过滤。\n② having是在分组之后过滤。\n③ where过滤早于having，但凡可以，优先使用where过滤掉不需要的数据。以免无意义的数据进入后续处理流程，浪费MySQL操作性能。\n七、SQL总结 1. 编写顺序 语法\nselect ... from ... where ... group by ... having ... order by .... limit ...;​\n详细\n1 2 3 4 5 6 7 select 列,列... from 表 where 分组前过滤条件 group by 分组依据列 having 分组后的过滤条件 order by 列 desc|asc,列 desc|asc limit start,total; SQL编写思路\n① 先分析需求，用自己的思路，需要如何操作，1,2,3,4 ？\n② 确定所需的关键词，注意关键词执行顺序。\n③ 补充完每个关键字依据。\n2. 执行顺序 SQL关键词执行顺序\n八、子查询 select查询的from的表，是另一个sql的查询结果，嵌套查询。\n1. 单列单行 总结\n子查询结果单行单列的一个值，通常用在单值条件判断。\n场景\n查询工资大于Nancy工资的员工信息? 查询与Nancy同一部门（department_id）的员工信息 1 2 -- 1. 查询工资大于Nancy工资的员工信息 -- 2. 查询与Nancy同一部门（department_id）的员工信息? 分析1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1. 查询工资大于xSalary的员工信息？ select * from t_employees where salary \u0026gt; xSalary; 2. 查询Nancy的工资xSalary？ select salary from t_employees where first_name = \u0026#39;Nancy\u0026#39;; 3. 组合 将Nancy工资SQL作为子查询，替换xSalary。 select * from t_employees where salary \u0026gt; (select salary from t_employees where first_name = \u0026#39;Nancy\u0026#39;); 分析1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- 查询与Nancy同一部门（department_id）的员工信息 1. 查询员工信息，where department_id = ? select * from t_employees where department_id = XDeptId; 2. 查询Nancy所在部门是？ select deparment_id from t_employees where first_name = \u0026#39;Nancy\u0026#39;;--XDeptId 3. 组合 select * from t_employees where department_id = (select deparment_id from t_employees where first_name = \u0026#39;Nancy\u0026#39;); 2. 单列多行 总结\n查询结果是单列多行的多个值，通常用在in条件语法中。\n场景\n1 -- 查询与名字叫john(多个人同名)同一部门的员工信息？ 分析\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1. 查询员工的信息？where department_id in (x,y,z...) 假设 deptids select * from t_employees where department_id in (deptids) 2. 查询john(重名)所在部门id。-- deptids select department_id from t_employees where first_name = \u0026#39;John\u0026#39;; 3. 组装 select * from t_employees where department_id in (select department_id from t_employees where first_name = \u0026#39;John\u0026#39;); 3. 多列多行 场景\n1 -- 计算工资最高的前5名员工的薪资总和 分析\n1 2 3 4 5 6 7 8 9 10 11 顺序： ① order by排序：order by salary desc分组： ② limit：limit 0,5 ③ 分组函数：sum(salary) 自以为是的SQL： select sum(salary) from t_employees order by salary desc limit 0,5; 思路\n注意：from后面是一个sql子查询的话，需要起别名，然后使用子查询别名表的列：别名.列名​.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1. 先排序+limit select salary,first_name from t_employees order by salary desc limit 0,5; -- t_temp 2. 对上SQL结果，统计sum select sum(salary) from t_temp; 3. 组装 select sum(tb.salary) from (select salary,first_name from t_employees order by salary desc limit 0,5) as tb; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## 六、表连接 \u0026gt; 当查询数据需要的列，来源于多张表的时候，需要将多表合并成1个表，作为from查询。 ### (1) 左外连 * 概念： 在sql的连接操作中，左表为主，右表为辅，连接结果**保留全部左表**数据。 * 场景： 查询员工的信息：工号id、名字、工资、部门名称？ * 语法 ```sql 表1 别名1 left join 表2 别名2 on 别名1.字段 = 别名2.字段 -- 将场景表连接 t_employees as t_emp left join t_departments as t_dept on t_emp.department_id = t_dept.department_id 说明：将2个表合并成一张表。 思路\n代码\n1 2 select e.employee_id,e.first_name,e.salary,d.department_name from t_employees as e left join t_departments as d on e.department_id = d.department_id; 代码2\n1 2 3 4 5 6 7 8 -- 查询员工的信息：工号id、名字、工资、部门名称，职位名字title，职位最大工资，职位最小工资？ 1. 数据来源的表：员工表、部门表、职位表？ select e.EMPLOYEE_ID,e.FIRST_NAME,e.SALARY,d.DEPARTMENT_NAME,j.JOB_TITLE,j.MAX_SALARY,j.MIN_SALARY from t_employees e left join t_departments d on e.department_id = d.department_id left join t_jobs j on e.job_id = j.job_id; (2) 右外连 概念\n以右表为主，左表为辅，保留全部右表数据，左表中只有满足on条件的数据才会保留。\n语法\n表1 right join 表2 on 连接条件;​\n(3) 内连接 概念\n没有主次之分，只保留满足on连接条件的数据。\n语法\n表1 inner join 表2 on 连接条件;​\n(4) 自连接 需要通过表连接，将2个条数据连接成一条数据。借助左外连实现数据连接。如果join2个表都是同一个表的。自连接。\n场景\n查看员工的id、名字、工资、及其上级领导的id、名字、工资?\n代码\n1 2 3 4 5 6 7 1. 2个员工表自连接成1张表 t_employees e1 left join t_employees e2 on e1.manager_id = e2.employee_id 2. SQL select e1.EMPLOYEE_ID,e1.FIRST_NAME,e1.SALARY,e2.EMPLOYEE_ID,e2.FIRST_NAME,e2.SALARY from t_employees e1 left join t_employees e2 on e1.manager_id = e2.employee_id; ","date":"2025-04-14T15:49:32+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/mysql%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","title":"MySQL基础语法"},{"content":"02-2-mysql基础实践 为什么mysql用的这么多 性能强悍，服务稳定，很少因为MySQL自身宕机\n开放源代码，社区很活跃，出了问题可以很快得到解决方案\nMySQL软件体积优化了N次后，安装包也很小，部署简单，配置易懂，文档也多\n历史悠久，MySQL得到了全世界的公司验证，选它没问题\nLAMP,LNMP、都是和MySQL架构\nMySQL便于编程语言，基于API直接获取数据，如java、python、golang等\n版本选择 企业版 MySQL企业版由MySQLAB公司内部专门的人员负责开发及维护,但同时也会吸纳社区人员编写的优秀代码及算法,并且由他们严格按照软件测试流程对这些采纳的代码进行测试,确定没有问题之后才会进行发布。简单地说,MySQL企业版是由MySQL公司内部发布的,它参考了社区版的先进代码功能和算法,是MySQL公司的赢利产品,需要付费才能使用及提供服务支持,稳定性和可靠性无疑都是最好的,当然了,企业腰包得够鼓才能买得起。某知名分类门户网站2008年就购买过MySQL企业版,价格不比那些闭源的商业数据库便宜,也是大几十万。\n社区版 MySQL社区版则是由分散在世界各地的MySQL开发者、爱好者以及用户参与开发与测试的，包括软件代码的管理、测试工作，也是他们在负责。社区也会设立BUG汇报机制，收集用户在使用过程中遇到的BUG情况，相比于企业版，社区版的开发及测试环境没有那么严格。\n选哪个 mysql是成熟产品，企业版和社区版在性能方面区别不大，对于我们学习而言，社区版即可。它们的区别可以如下了解\n企业版对代码的管理、测试更严格、稳定性更好 企业版不遵循GPL开源协议，而社区版遵循，可以免费用 企业版可以购买额外的收费服务，如7*24的技术支持，有钱任性。 社区版的安全性，稳定性，无法像企业版有及时的维护、技术支持。 MySQL特点 支持多种操作系统,Windows、MacOS、Linux等支持多种语言API,如C、C++、Python、PHP、Java等\n支持多线程、充分利用硬件资源支持多种存储引掌\nmysq就是一个基于socket编写的C/S架构的软件\n客户端软件：mysq自带:如mysql命令,mysqldump命令等;python模块:如pymysql\nMySQL服务端-客户端 先看下什么是B/S和C/S架构。\nB/S是Browser/Server指浏览器和服务器端,在客户机不需要装软件,只需要装一个浏览器。\nC/S是Client/Server指客户端和服务器,在客户机端必须装客户端软件及相应环境后,才能访问服务器\nMySQL是基于客户端-服务端的运行模式数据库,服务满负责数据处理,运行在数据库服务器上。\n用户通过发送增删改查等请求,发送给 客户端软件,然后通过网络提交请求给 服务端,服务端接收到请求,再进行处理,然后返回。\n服务端、客户端可以在不同的机器上,也可以在一台机器上。\n这种服务端,客户端,就在生活里很常见,如打游戏时的登录,QQ、微信的登录,MySQL也是一个登录的过程。\nmysql下载选择 了解数据库后，我们可以下载mysql软件了\nhttp://mirrors.sohu.com/mysql/\nmysql安装启动 准备3个新机器，\ndb-51\ndb-52\ndb-53\n我们会用到\n或者自己快照管理\n1.安装全流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 yum 源码编译 rpm包 装和卸载 如何处理依赖关系 都是要掌握的技能 我这里是省事，二进制解压即用 # 确认时间正确 [root@tech-db-51 /opt]#crontab -l * * * * * ntpdate -u ntp.aliyun.com 1 .准备好包 [root@tech-db-51 /opt]#ll total 707688 -rw-r--r-- 1 root root 724672294 Jul 28 19:56 mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz [root@tech-db-51 /opt]# [root@tech-db-51 /opt]# [root@tech-db-51 /opt]#du -h 692M\t. 2. 解压缩 [root@tech-db-51 /opt]## 常见做法，做软连接，便于二进制包的升级，后续的使用路径，用的都是软连接 [root@tech-db-51 /opt]# [root@tech-db-51 /opt]# [root@tech-db-51 /opt]#ln -s /opt/mysql-5.7.38-linux-glibc2.12-x86_64 /opt/mysql [root@tech-db-51 /opt]# [root@tech-db-51 /opt]# [root@tech-db-51 /opt]# [root@tech-db-51 /opt]#ls /opt/ -l total 707688 lrwxrwxrwx 1 root root 40 Jul 28 19:58 mysql -\u0026gt; /opt/mysql-5.7.38-linux-glibc2.12-x86_64 drwxr-xr-x 9 root root 129 Jul 28 19:57 mysql-5.7.38-linux-glibc2.12-x86_64 -rw-r--r-- 1 root root 724672294 Jul 28 19:56 mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz [root@tech-db-51 /opt]# # 3. 配置PATH echo \u0026#39;export PATH=$PATH:/opt/mysql/bin\u0026#39; \u0026gt;\u0026gt; /etc/profile source /etc/profile # 4. 验证mysql版本 [root@tech-db-51 /opt]#mysql -V mysql Ver 14.14 Distrib 5.7.38, for linux-glibc2.12 (x86_64) using EditLine wrapper [root@tech-db-51 /opt]# # 5.删除mariadb的依赖，删除默认的配置文件 yum remove mariadb-libs.x86_64 -y rm -f /etc/my.cnf # 6.装mysql5.7特有的依赖包 yum install libaio-devel -y #7. 创建数据目录， # 准备mysql的数据目录，授权用户 useradd -s /sbin/nologin -M mysql mkdir -p /linux0224/ mkdir -p /linux0224/mysql_3306/ # 授权 chown -R mysql.mysql /linux0224/ chown -R mysql.mysql /linux0224/mysql_3306/ chown -R mysql.mysql /opt/mysql* #检查 ls -ld /linux0224 /linux0224/mysql_3306/ /opt/mysql* [root@tech-db-51 /opt]#ls -ld /linux0224 /linux0224/mysql_3306/ /opt/mysql* # 8.此时自建的mysql目录，没有输数据，mysql 无法使用，初始化生成mysql默认库的数据源 ，用户等信息，即可启动 # mysqld 服务端命令，启动，初始化，都用的这个 # --basedir mysql二进制命令装再哪了，主程序目录 # --datadir 数据目录初始到哪 mysqld --initialize-insecure --user=mysql --basedir=/opt/mysql --datadir=/linux0224/mysql_3306/ 2.配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 初始化完毕后，有配置文件即可正确启动，告诉 my.cnf mysqld的数据源目录在哪，日志写入到哪等 # /etc/my.cnf 默认mysql会去读这个，不指定，也读这个 # [mysqld] 服务端会读取的配置 # [mysql] 再机器本地，执行mysql命令，客户端读取的配置 # socket 本地进程套接字文件，用于mysql客户端再本地区链接 cat \u0026gt;/etc/my.cnf \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [mysqld] port=3306 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3306/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock EOF 3.启动脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 复制自带脚本即可 [root@tech-db-51 /linux0224/mysql_3306]#cp /opt/mysql/support-files/mysql.server /etc/init.d/mysqld [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]#systemctl daemon-reload [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]#systemctl status mysqld ● mysqld.service - LSB: start and stop MySQL Loaded: loaded (/etc/rc.d/init.d/mysqld; bad; vendor preset: disabled) Active: inactive (dead) Docs: man:systemd-sysv-generator(8) 4.登录mysql 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 启动即可 [root@tech-db-51 /linux0224/mysql_3306]#systemctl start mysqld [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]#mysql Welcome to the MySQL monitor. Commands end with ; or /g. Your MySQL connection id is 2 Server version: 5.7.38 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;/h\u0026#39; for help. Type \u0026#39;/c\u0026#39; to clear the current input statement. mysql\u0026gt; mysql多实例管理 前面已经针对MySQL数据库进行了介绍,并说明了为什么选择MySQL数据库,以及MySQL数据库在Linux系统下的多种安装方式,同时以单实例讲解了如何以编译方式安装MySQL和基础安全优化等内容,本章将为大家讲解更为实用的MySQL多实例安装\n百度、淘宝、阿里、新浪等大公司无一例外地都会使用多实例的方式 部署数据库,那么是什么原因促使他们选择多实例数据库的部署方式呢?\n单实例,也就是老师前面是带着大家,在一台Linux上,某个目录下,安装了一个mysql,且启动了这个mysql,这就表示,这个机器上,有单独的一个mysql个体,一个实例。\n什么是多实例 多实例,就是一台Linux上,同时运行多个mysql,当然是区别了不同的端口,例如3306、3307、3308。运行三个mysql数据库\n这三个mysql,就相当于三个独立的卧室,互相没关系,在Linux上的呈现区别就是\n不同的端口 不同的数据目录,不同的配置文件 不同的mysql进程,不同的pid 多实例的好处 可有效利用服务器资源。当单个服务器资源有剩余时,可以充分利用剩余的资源提供更多的服务,且可以实现资源的逻辑隔离。\n节约服务器资源。若公司资金紧张,但是数据库又需要各自尽量独立地提供服务,而且还需要用到主从复制等技术,那么选择多实例就再好不过了。\n例如公司有多个业务,需要用到好几套mysq数据库,都得单独的部著,数据区分开\n多实例的弊端 MySQL多实例有它的好处,也有其弊端,比如,会存在资源互相抢占的问题。当某个数据库实例并发很高或者有SQL慢查询时,整个实例会消耗大量的系统CPU、磁盘1/O等资源,导致服务器上的其他数据库实例提供服务的质量一起下降。\n这就相当于大家住在一个房子的不同卧室中,早展起来上班,都要刷牙、洗脸等,这样卫生间就会长期处于占用状态,其他人则必须要等待。\n不同实例获取的资源是相对独立的,无法像虚拟化一样完全隔离。(毕竞大家都是在同一个文件系统下)\n以后老师教大家学习虚拟化后,就可以实现完全隔离。\n学MySQL多实例用在哪些场景 资金紧张的公司 若公司资金紧张,公司业务访问量不太大,但又希望不同业务的数据库服务各自能够尽量独立地提供服务而互相不受影响,或者,还有需要主从复制等技术提供备份或读写分离服务的需求,那么,多实例就再好不过了\n比如:可以通过3台服务器部署9~15个实例,交叉做主从复制、数据备份及读写分离\n这样就可以等同于9~15台服务器每个只装一个数据库才有的效果。(很省钱了)\n这里需要强调的是,所谓的尽量独立是相对的。\n用户并发访问量不大的业务 当公司业务访问量不太大的时候,服务器的资源基本上都是浪费的,这时就很适合多实例的应用,如果对SQL语句的优化做得比较好,MySQL多实例会是一个很值得使用的技术,即使并发很大,合理分配好系统资源以及搭配好服务,也不会有太大的问题。\n例如某古董、古玩展示的网站,比起电商网站,并发量会小一些,更多追求稳定,而不是高性能、高并发。 大型网站也有用多实例\n大型网站也有用多实例 门户网站通常都会使用多实例,因为配置硬件好的服务器,可以节省IDC机柜空间,同时,运行多实例也会减少硬件资源占用率不满的浪费。\nMySQL多实例部署 图解 创建数据目录 1 2 3 4 5 mkdir -p /linux0224/mysql_3307 mkdir -p /linux0224/mysql_3308 chown -R mysql.mysql /linux0224 初始化2个实例的数据 1 2 3 4 5 6 7 8 9 mysqld --initialize-insecure --user=mysql --basedir=/opt/mysql --datadir=/linux0224/mysql_3307 mysqld --initialize-insecure --user=mysql --basedir=/opt/mysql --datadir=/linux0224/mysql_3308 # 都会默认创建一个账户，链接权限 root 空密码 只允许再localhost登录 至此有3个实例了 1 2 3 4 5 6 7 8 9 10 [root@tech-db-51 /linux0224]#ll total 4 drwxr-xr-x 6 mysql mysql 4096 Jul 28 14:00 mysql_3306 drwxr-xr-x 5 mysql mysql 314 Jul 28 14:37 mysql_3307 drwxr-xr-x 5 mysql mysql 314 Jul 28 14:38 mysql_3308 [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#du -sh * 134M\tmysql_3306 122M\tmysql_3307 122M\tmysql_3308 额外创建俩实例的配置文件 3306 1 2 3 4 5 6 7 8 9 10 11 [root@tech-db-51 /linux0224]#cat /etc/my.cnf [mysqld] port=3306 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3306/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock 3307 区别在参数\n1 2 3 4 5 6 7 8 9 10 11 cat /etc/my.cnf [mysqld] port=3307 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3307/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock port\ndatadir\nsocket 进程套接字文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 链接mysql的俩方式，找到它 进程 pid 能链接程序的俩方式 1. 通过远程网络的链接形式，效率很低，网络波动， ip:port 10.0.0.51:3306 mysql -uroot -p -h10.0.0.51 -P3306 -------------------------------- -------------------------------- -------------------------------- 2. 通过再机器本地，进程套接字文件去链接，直接是基于内存的链接 程序和程序之间，直接走内存数据，效率极高，遇见一些软件的部署，走socket链接 如nginx的反向代理配置 proxy_pass ip:port; proxy_pass unxi:socket; /linux0224/mysql_3307/mysql.sock # -S 等于 -h -P # 链接3307的进程 mysql -uroot -p密码 -S /linux0224/mysql_3307/mysql.sock mysql -uroot -p密码 -S /linux0224/mysql_3306/mysql.sock mysql -uroot -p密码 -S /linux0224/mysql_3308/mysql.sock log目录\n1 2 3 4 5 6 7 8 9 cat \u0026gt;/etc/mysql_3307.cnf \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [mysqld] port=3307 user=mysql basedir=/opt/mysql/ datadir=/linux0224/mysql_3307/ socket=/linux0224/mysql_3307/mysql.sock log_error=/linux0224/mysql_3307/mysql.log EOF 3308 1 2 3 4 5 6 7 8 9 10 cat \u0026gt;/etc/mysql_3308.cnf \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [mysqld] port=3308 user=mysql basedir=/opt/mysql/ datadir=/linux0224/mysql_3308/ socket=/linux0224/mysql_3308/mysql.sock log_error=/linux0224/mysql_3308/mysql.log EOF 检查配置文件 1 2 3 [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#ls /etc/my* /etc/my.cnf /etc/mysql_3307.cnf /etc/mysql_3308.cnf 多实例脚本 有3个数据目录+ 3个独立的配置文件+ shell脚本 -=====3个运行程序\n提供一个脚本模板，自己区分3个实例的端口，数据目录即可\n生成 3307 和3308即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 cat \u0026gt; /linux0224/3307.sh \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; port=\u0026#34;3307\u0026#34; mysql_user=\u0026#34;mysql\u0026#34; Cmdpath=\u0026#34;/opt/mysql/bin/\u0026#34; # socket用于判断程序是否运行 # 程序运行中，该socket文件存在 # 进程挂了，socket文件自动消失 mysql_sock=\u0026#34;/linux0224/mysql_${port}/mysql.sock\u0026#34; # 定义路径，mysql进程启动后，一个存储该进程pid号码的文件在哪 mysqld_pid_file_path=/linux0224/mysql_${port}/mysqld_${port}.pid # 启动mysqld服务端的入口命令 start(){ if [ ! -e \u0026#34;$mysql_sock\u0026#34; ];then printf \u0026#34;Starting MySQL.../n\u0026#34; # mysql的启动逻辑 # mysqld_safe 脚本 \u0026gt; mysqld 脚本 \u0026gt; 运行mysql进程 /bin/sh ${Cmdpath}/mysqld_safe --defaults-file=/etc/mysql_${port}.cnf --pid-file=$mysqld_pid_file_path 2\u0026gt;\u0026amp;1 \u0026gt; /dev/null \u0026amp; sleep 3 else printf \u0026#34;MySQL is running.../n\u0026#34; exit 1 fi } stop(){ if [ ! -e \u0026#34;$mysql_sock\u0026#34; ];then printf \u0026#34;MySQL is stopped.../n\u0026#34; exit 1 else printf \u0026#34;Stoping MySQL.../n\u0026#34; mysqld_pid=`cat \u0026#34;$mysqld_pid_file_path\u0026#34;` if (kill -0 $mysqld_pid 2\u0026gt;/dev/null) then kill $mysqld_pid sleep 2 fi fi } restart(){ printf \u0026#34;Restarting MySQL.../n\u0026#34; stop sleep 2 start } case \u0026#34;$1\u0026#34; in start) start ;; stop) stop ;; restart) restart ;; *) printf \u0026#34;Usage: /data/${port}/mysql{start|stop|restart}/n\u0026#34; esac EOF 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 cat \u0026gt; /linux0224/3308.sh \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; port=\u0026#34;3308\u0026#34; mysql_user=\u0026#34;mysql\u0026#34; Cmdpath=\u0026#34;/opt/mysql/bin/\u0026#34; # socket用于判断程序是否运行 # 程序运行中，该socket文件存在 # 进程挂了，socket文件自动消失 mysql_sock=\u0026#34;/linux0224/mysql_${port}/mysql.sock\u0026#34; # 定义路径，mysql进程启动后，一个存储该进程pid号码的文件在哪 mysqld_pid_file_path=/linux0224/mysql_${port}/mysqld_${port}.pid # 启动mysqld服务端的入口命令 start(){ if [ ! -e \u0026#34;$mysql_sock\u0026#34; ];then printf \u0026#34;Starting MySQL.../n\u0026#34; # mysql的启动逻辑 # mysqld_safe 脚本 \u0026gt; mysqld 脚本 \u0026gt; 运行mysql进程 /bin/sh ${Cmdpath}/mysqld_safe --defaults-file=/etc/mysql_${port}.cnf --pid-file=$mysqld_pid_file_path 2\u0026gt;\u0026amp;1 \u0026gt; /dev/null \u0026amp; sleep 3 else printf \u0026#34;MySQL is running.../n\u0026#34; exit 1 fi } stop(){ if [ ! -e \u0026#34;$mysql_sock\u0026#34; ];then printf \u0026#34;MySQL is stopped.../n\u0026#34; exit 1 else printf \u0026#34;Stoping MySQL.../n\u0026#34; mysqld_pid=`cat \u0026#34;$mysqld_pid_file_path\u0026#34;` if (kill -0 $mysqld_pid 2\u0026gt;/dev/null) then kill $mysqld_pid sleep 2 fi fi } restart(){ printf \u0026#34;Restarting MySQL.../n\u0026#34; stop sleep 2 start } case \u0026#34;$1\u0026#34; in start) start ;; stop) stop ;; restart) restart ;; *) printf \u0026#34;Usage: /data/${port}/mysql{start|stop|restart}/n\u0026#34; esac EOF 启动多实例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 查看已有的3306实例 [root@tech-db-51 /linux0224]#netstat -tunlp|grep 3306 tcp6 0 0 :::3306 :::* LISTEN 2018/mysqld # 启动3307 [root@tech-db-51 /linux0224]#bash 3307.sh start Starting MySQL... Logging to \u0026#39;/linux0224/mysql_3307/mysql.log\u0026#39;. [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#netstat -tunlp|grep mysql tcp6 0 0 :::3306 :::* LISTEN 2018/mysqld tcp6 0 0 :::3307 :::* LISTEN 12514/mysqld # 启动3308 [root@tech-db-51 /linux0224]#bash 3308.sh start Starting MySQL... Logging to \u0026#39;/linux0224/mysql_3308/mysql.log\u0026#39;. [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#netstat -tunlp|grep mysql tcp6 0 0 :::3306 :::* LISTEN 2018/mysqld tcp6 0 0 :::3307 :::* LISTEN 12514/mysqld tcp6 0 0 :::3308 :::* LISTEN 12700/mysqld 检查3个实例的pid文件，socket文件 1 2 3 4 5 6 7 8 # pid文件 ，3个实例的 [root@tech-db-51 /linux0224]#find . -name \u0026#39;*.pid\u0026#39; ./mysql_3306/tech-db-51.pid ./mysql_3307/mysqld_3307.pid ./mysql_3308/mysqld_3308.pid #socket文件 生产下的暗坑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [root@tech-db-51 /linux0224]#systemctl start mysqld [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#bash /linux0224/3307.sh start Starting MySQL... [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#find / -name \u0026#39;*.sock\u0026#39; |xargs -i ls -l {} srwxrwxrwx 1 mysql mysql 0 Jul 28 15:00 /tmp/mysql.sock srwxrwxrwx 1 mysql mysql 0 Jul 28 15:00 /linux0224/mysql_3307/mysql.sock srwxrwxrwx 1 mysql mysql 0 Jul 28 14:55 /linux0224/mysql_3308/mysql.sock [root@tech-db-51 /linux0224]# 有些程序，不专业的程序员，会清空/tmp下的数据 # mysql的链接有的链接方式是走 sock文件的，因此sock文件不得删除，导致无法链接 # 建议，sock文件，别放入/tmp目录 设置多实例的密码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 3实例， # mysqladmin和mysql一样，也是客户端链接命令 # 精确定位 每一个实例 # ip:port # socket mysqladmin -uroot -p password 新的密码 # ==================3306========= # socket修改 # -u账户 # -p密码 ，啥也没写，会交互式提示让你输入 mysqladmin -uroot -p -S /tmp/mysql.sock password linux0224 # 还要再改3306的密码 # -p后面建议别跟上密码，因为history能看到密码记录 # mysql也给你提示不安全 # mysqladmin -uroot -plinux0224 -S /tmp/mysql.sock password linux3306 mysql -uroot -p mysql\u0026gt; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;123456\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; FLUSH PRIVILEGES; Query OK, 0 rows affected (0.00 sec) # ==================3307========= mysqladmin -uroot -p -S /linux0224/mysql_3307/mysql.sock password linux3307 # ==================3308========= mysqladmin -uroot -p -S /linux0224/mysql_3308/mysql.sock password linux3308 登录多实例 ip:port方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 [root@tech-db-51 /linux0224]#mysql -hlocalhost -P3306 -uroot -plinux3306 -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; mysql: [Warning] Using a password on the command line interface can be insecure. +---------------+-------+ | Variable_name | Value | +---------------+-------+ | port | 3306 | +---------------+-------+ # 3307 ，mysql的用户远程链接，权限问题 [root@tech-db-51 /linux0224]#mysql -uroot -plinux3307 -h127.0.0.1 -P3307 -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; mysql: [Warning] Using a password on the command line interface can be insecure. +---------------+-------+ | Variable_name | Value | +---------------+-------+ | port | 3307 | +---------------+-------+ [root@tech-db-51 /linux0224]#mysql -uroot -plinux3308 -h127.0.0.1 -P3308 -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; mysql: [Warning] Using a password on the command line interface can be insecure. +---------------+-------+ | Variable_name | Value | +---------------+-------+ | port | 3308 | +---------------+-------+ # ip:port有很多种规则 # 授权语法 # locahost, 127.0.0.1 10.0.0.10 sock文件方式 1 2 3 4 5 6 7 8 mysql -uroot -plinux3308 -S /linux0224/mysql_3308/mysql.sock -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; mysql -uroot -plinux3307 -S /linux0224/mysql_3307/mysql.sock -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; mysql -uroot -plinux3306 -S /tmp/mysql.sock -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; 查看mysql的仨实例进程信息 ","date":"2025-04-14T15:44:19+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/mysql%E5%9F%BA%E7%A1%80%E5%AE%9E%E8%B7%B5/","title":"MySQL基础实践"},{"content":"02-1-数据库基础知识 1 2 今天主要快速入门，学习数据库的核心理论，运维和数据库的关系等 以及安装部署 数据库开篇架构 什么是数据? 1 2 3 数据就是数值,也就是我们通过观察、实验或计算得出的结果。 数据有很多种,最简单的就是数字。 数据也可以是文字、图像、声音等。 1 2 3 4 qq 就是mysql 我们打游戏最怕什么?最怕被盗号,怕自己的账号,密码丢失。 打游戏时候,腾讯为了保护大家的账号安全,提供了密码服务xl 数据存储 很早很早以前，古人是这么存数据的\n结绳、契刻、结珠、石头替代法等等,如今纸张是人们广泛使用的信息载体。但是书籍不便于 询、共享、储藏等缺点。\n计算机去存储，管理数据\n随着计算机的发展,人们将信息转化为二进制数字,存储在磁性存储介质中,也就是磁盘进行 据记录。数据通过文件系统管理,以文件形式显示出来。 但是大量的文件数据,查询内容,还是很不方便。 在这个背景下,一个专门用于数据管理的工具诞生了,它能让我们更简单的管理数据。\n什么是数据库 顾名思义，数据库(DB，database)按照数据结构来组织、存储和管理数据的“仓库”，是一个文件或者一组文件。\n表是数据库中存储数据的基本单位，数据按照分类存储在不同的表中，便于查询。\n数据库可以通过统一的一些指令对数据进行增、删、改、查(Create,Retrive,Updata,Delete)等操作。\n例如财务人员使用Excel统计公司资产信息，进行管理，计算账户\nDBMS Database Management System，数据库管理系统\n数据库管理系统这一软件用于创建和操作数据库。\n主流数据库软件,如Mysql(免费),Oracle(收费,甲骨文公司),MicrosoftSQLServer、SQLite(轻型)等。\nmysq主要用于大型门户,例如搜狗、新浪等,它主要的优势就是开放源代码,因为开放源代码这个数据库是免费的,他现在是甲骨文公司的产品。\noracle主要用于银行、铁路、飞机场等。该数据库功能强大,软件费用高。也是甲骨文公司的产品\nsqlserver是微软公司的产品,主要应用于大中型企业,如联想、方正等。\n数据库基础知识 首先mysql前面超哥已经多少带着大家接触过，安装过、使用过，大家心中有一个基础的认识。\n运维和数据库 说白了，数据库就是存数据的，是一款软件，用专门的数据库语言，增删改查数据。\n数据库的形式\n自己再inux上,直接安装,例如上图,数据都在inux机器磁盘上,运维自己管理 云服务器RDS产品(数据库安装在阿里巴巴的服务器上,我们通过账号密码,远程使用) 数据库类别 目前主流数据库软件，分为两种\n关系型数据库 非关系型数据库 关系型数据库 关系型数据库模型可将复杂的数据结构归结为简单的二元关系（即二维表格形式）\n数据库的操作建立在一个、或者多个关系表格上,通过对这些表格进行分类、合并、连接等查询方式,来找 到我们想要的数据。\n最常见的数据库里是MySQL和Oracle,\n图解数据库概念 数据库\u0026ndash;文件夹…文件夹名字(luffy_dev) 数据库里的数据表\u0026ndash;文件夹里的table数据表\u0026ndash;数据表的名字 数据表里的数据…-文件中的数据\u0026ndash;例如一个excel里的数据 什么是表 在 MySQL 中，表是数据库中的基本存储结构，用于组织和存储数据。表由行和列组成，每个表都有一个名称，用于标识和访问。\n什么是列 列是表中的一个垂直部分，代表数据的一个属性或字段。每列都有一个名称和数据类型，用于定义该列可以存储的数据类型（如整数、字符串等）。\n什么是行 行是表中的一个水平部分，代表一条完整的数据记录。每行包含多个列的值，每个值对应于表中定义的一个列。\n什么是主键 主键是表中一列或多列的组合，其值唯一标识表中的每一行。主键约束确保没有两行具有相同的主键值，通常用于快速检索数据和建立表之间的关系。\n什么是外键 外键是数据库表中的一个约束，用于建立和维护两个表之间的数据关联。它是一个或多个列，其值引用另一表的主键。外键约束确保数据的一致性和完整性，防止无效数据插入。通过外键，可以在不同表之间建立关系，实现数据的关联性和完整性。\n运维要学的：什么是SQL SQL是结构化查询语言的缩写,读作S-Q-L或者sequel,全称是(Structured QueryLanguage),是一种专用来与数据库交流的语言。\nSQL语法主要是\n查询语言:select 操作语言:insert、update、delete 事务处理:begintransaction、commit、rolback 权限控制:grant、revoke 数据库管理:create、drop 以上语法不区分大小写\n什么是mariadb、mysql MySQL是一个开源的中小型关系型数据库管理系统,被应用于大、中、小型网站。由于其具有体积小、速度快、总体拥有成本低,且开放源码等特点,因此许多大中小型网站选择它作为网站数据库,从而降低网站总体拥有成本,甚至国内知名的淘宝网也选择弃用Oracle而更换成更为开放的MySQL。\nMySQL数据库的应用范围主要包括互联网领域、大中小型网站、游戏公司、电商平台等,因用户广泛,其产生了很多高并发的成熟解决方案,因此传统企业的用户也在逐渐增多。\nMariaDB mariadb是mysq数据库的一个分支,主要由开源社区维护,采用GPL授权许可。 开发这个MariaDB数据库分支的可能原因之一是:Oracle公司收购了MySQL之后,有将MySQL闭源的潜在风险,因此MySQL开源社区采用分支的方式来避开这个风险。开发MariaDB数据库的目的是完全兼容MySQL数据库,包括APl和命令行,使之能够轻松地成为MySQL的替 代品。在存储引擎方面,它使用XtraDB来代替MySQL的InnoDB。MariaDB由MySQL的创始人Michael Widenius主导开发,他早前普以10亿美元的价格,将自己创建的公司MySQLAB卖给Sun,此后,随着Sun被甲骨文收购,MySQL的所有权也落入Oracle的手中。MariaDB数据库的名称来自MySQL的创始人Michael Widenius的女儿Maria的名字 MariaDB基于事务的Maria存储引擎,替换了MySQL的MyiSAM存储引擎,使用Percona的XtraDB替换了MySQL的innoDB存储引攀。\nMariaDB数据库的早期版本,均依照MySQL的版本发行。因此,使用MariaDB的人都会从MySQL中了解到MariaDB的相关功能,学习MySQL数据库的人,也可以轻松上手掌握MariaDB数据库。\n1 2 3 4 5 6 7 8 9 目前市面上用的最多的，是mysql 5.7系列 一些最新的公司，用的是mysql8.0 传统行业，mysql更低的版本 或者其他数据库软件如 oracle，sql server等 本次学习mysql 5.7系列 其他关系型数据库 这里大家只需要了解有该数据库即可\nMicrosoft SQL Server Microsoft Access PostgreSQL DB2 Sysbase Informix 数据库具体应用场景 相亲网 譬如网站的注册登录功能，正确流程是，注册成功-\u0026gt;可以登录。\n工程师就要检测在注册成功后，检查数据库是否正确保留了信息。\n游戏数据库 如下是英雄联盟所有的英雄数据库，列出了所有英雄数据\n总结 数据库方面知识，主要以运维、开发分为两个方向，不同的方向所重点学习的内容不一样\n运维人员，主要是对数据库架构、设计、维护 单实例、多实例 SQL语句基础CURD学习、权限管理 字符集、数据库引擎 备份方案 复制方案 高可用方案 开发人员，主要是对数据进行设计、开发 针对业务进行数据库设计、表结构设计 高性能索引 视图 存储过程 函数 ","date":"2025-04-14T15:41:38+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/mysql%E6%A0%B8%E5%BF%83%E5%85%A5%E9%97%A8/","title":"MySQL核心入门"},{"content":"开篇前言 第二阶段：综合架构篇 学习前言 第一阶段总结 1 2 3 4 5 6 7 8 9 10 第一阶段 1.死记硬背 2.多敲命令，多做练习题 3.学的东西的确特别多，但是工作里日常用的其实反复就那几个，参数也就那几个 关于学习方法的理解 1.在不知道网站是如何搭建的时候（没做过这件事，会很难，LNMP LAMP，wordpress，discuz）刚开始，没有思路是最难的 2.在尝试实践过后，有了思路过后，后面的工作就是反复的重复，成为熟练工了 3.为什么新人是万事开头难 4.你会发现领导都是不干活，都是写写文案，出方案，写写PPT，年入50万（人家曾经也辛苦过10年时间） 第二阶段开始，学习思路的转变 更多的是架构的理解，而不是太多的操作\n1 2 3 4 5 6 7 大家都一样装软件，nginx 修改配置 修改端口的参数 修改网站html根目录的参数 启动 启动玩了之后有日志 你得去看日志，看大量的屏幕的英文输出，是正确启动，还是错误？ 主动的思考\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 第二阶段 1.和第一阶段完全不一样，更多的是理解 （你千万不能死记硬背操作，否则换一个场景，你又不知道自己在干什么） - 主动的通过自己的思考，想出每一题的解决方案，转化为你所理解的正则符号- 自己主动再去找更多的练习，不会的和老师交流 2.第二阶段会频繁的使用第一阶段的命令 3.第二阶段大多数是使用软件(ftp,ssh,rsync,nginx)，修改配置文件，那配置文件，好几百、几千行，你根本无法背诵 背死在固定的某一行，某些参数 - 理解你要做什么，去修改什么软件的配置文件，修改的参数是什么意思 4.做好笔记（帮你理解如何修改配置，如何使用软件，的流程） 盖房子一样，流程性很重，以及盖房子之间，cad图纸得画好 （架构图要画好，从前端，到后端，到数据库，之间所有涉及服务，如何去理解，他们之间如何相互调用，通信） 比如同样的安装nginx高可用，集群\n1 2 3 4 5 6 7 8 9 10 11 第一、你先理解原理，心中有了架构思维，这是最重要的 第二、具体nginx集群的安装部署，这其实就很简单了，你笔记做好，以后用到，拿出来复制粘贴即可。 第三、这也是为什么，你会发现，越牛逼的大佬，具体干的活越少，而是写方案，出架构图，因为这是一个有含金量的东西， 当然，人家架构师也是从普通运维，一步步锻炼，反复安装部署软件几千次，敲打几万次命令， 心中早已有无数方案，踩过无数的坑，因此才能独当一面，见招拆招。 500台机器，维护几万的日活 维护了5万台机器，维护过几十亿的日活 小白成长记 也是你未来很长一段时间要走的路线..\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 小白（2月24进班级之前，连电脑都不太会玩） \u0026gt; 初级运维（很多的命令，服务搭建，配置，权限，等等等。。。。） \u0026gt; 运维熟练工 （通过不断的学习各种软件，反复的安装yum，编译，修改配置，刚开始是vim手动去修改，sed修改配置文件,启动systemctl，自己写启动脚本，得看进程，看端口，不断的去练习 ps ，netstat，ss，lsof） 学了2月过去， 网站集群，数据库，shell编程，监控 \u0026gt; 高级运维开发 linux+python \u0026gt; 架构师 linux+python+安全+全栈==架构师 你在教室，每一天的学习强度，上班之后，一下子降低70% 每天的学习，输入大量的知识，自己看看书， 你现在的学习环境，类似于公司的测试环境，机器配置都是最低的，服务安装也是单机的配置也不复杂 小白 \u0026gt; 新人 linux命令会用了 \u0026gt; 初级运维 各种运维工具熟练安装、配置、搭建 \u0026gt; 中高级运维 运维+编程，完成高级运维自动化开发工作 \u0026gt; 高级运维、运维开发 最后、架构师 -实实在在维护过五年以上的linux服务器，从小公司，中型公司，大公司 -解决过太多问题，写过太多笔记、运维博客（博客园等，找运维大佬，写了有10年以上，linux命令基础，到服务部署，到xxx 所有运维都是围绕着k8s去转） -扛得住大公司的大并发架构，复杂运维架构，在阿里，卷累了，不想卷了 -也能在小公司独当一面，一个人就能扛起公司所有的运维工作 -解决方案架构师（架构在心中，出几个PPT，月入几万，全球技术峰会，全球devops技术大佬会，公司也会有技术分享会，运维，给开发同事分享k8s的技术，linux基础都不会，docker，k8s,jenkins，领导是给钱，打绩效的， 500/课，2000/课) -高级运维工程师（熟练操作sed、awk、grep、linux、nginx、mysql、jenkins、redis、kafka、zookeeper、hadoop、oracle、docker、kubernetes、prometheus，等一堆工具，维护过千台服务器，维护过日活一亿的网站，起步50k+） 小白 \u0026gt; 工地新人 \u0026gt; 熟练小推车、铁锹 、和水泥 \u0026gt; 学会了工地图纸设计、造价方案 \u0026gt; 学会了和领导喝酒 \u0026gt; 自己成为了当初最讨厌的那个人（老板，月入百万） 如何学好第二阶段 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1.画图、架构图（一图胜千言、无图言*） 画图工具 https://www.processon.com/ https://excalidraw.com/ 2.理解流程、架构先后关系，如软件安装的先后关系，服务启动的先后关系 3. nginx mysql 运行了 程序一定会有日志输出，开发，运维，都通过这个日志，去掌握程序运行的状态 因此你后面的学习，工作生涯，会和大量的英文接触 所以，请你从此安装机器，再也别用中文了 程序崩溃，无法运行，这个信息，毫无意义，你得通过程序反馈的英文报错，日志，去搜索，去理解它的含义 学会看日志 学会看日志 学会看日志， 无论新人，还是20年架构师，干活都是在看日志 （程序运行了，正常，还是故障，只能去看运行日志！） 提问的艺术 错误的提问 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 傻蛋的提问 - 在吗? 我在 - 有人知道nginx吗？ 大量的死群，qq群，微信群，学习交流群 我知道，nginx是一个服务器 - 我遇到问题了 - 服务起不来了 - 什么问题？ - nginx报错了？ - 什么报错？ - 怎么看？ 。。。我tm想给你一锤子 ============================================================================================ 如果有同学加过各种学习群，你就会见到各种这样的提问 有人知道centos吗？ nginx报错了怎么看？ 然后群里永远是死群，无人回答，你让人家怎么回。。 正确的提问 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 正确的提问艺术 架构搭建中，没人能简单服务为什么没启动、请求为什么没转发成功，自己要捋顺流程，再告诉别人大概你做了什么事 lnmp的部署 linux 最小化安装，系统的基础依赖会有区别 nginx安装 装在了哪里 mysql php,python 如 各位大佬们打扰了，我部署LNMP时出错了，我做了如下的操作 1.怎么装的nginx 2.配置文件在哪，日志目录在哪 3.我改了什么操作，才导致报错的 nginx启动不了，看nginx的日志 4.如果你这些流程自己很清晰，其实你几乎已经快找到问题所在了，只不过经验欠缺，可能还无法解决问题 我已经尝试了这些解决方案，但是还是不行（这样大佬知道你做了什么事，是不是方案错了） 1. 2. 3. 以下是nginx的日志报错，有大佬懂的话可以指点以下，感谢 图1 图2 这样的提问，试问，如果是你，你愿不愿意回答一下？是不是好多了？ 笔记的重要性 1 2 3 4 部署搭建过程，务必记录好步骤，你如果部署出错了，记录下出错的日志,也给记下来 这样你有问题喊老师、同学来看看，大家才知道你做了什么，哪出错了 否则，神仙也不知道你做了什么事，你的问题也无法得到解决，耽误你我时间。 搜索工具的重要性 1 2 你能遇见的绝大多数错误，搜索引擎上，都会有人曾经搜索过，查询过 也有人发布过类似问题的解决方案，合理利用它，能解决你大部分问题。 学点英语 1 2 3 4 5 6 做IT避免不了和英语打交道 运维部署，会反复和大量的英文日志打交道，看日志、看日志、要学会怎么看、提取重点部分信息 无论是去翻译，还是去搜索 都要反复积累英文单词的理解、否则一直看不懂日志，那肯定做不好 AI工具 1 GPT、天工大模型、KIM I等 分享两本书 淘宝的十年\n大型网站架构\n大型网站架构特点(淘宝网) 和传统企业应用系统相比，大型网站系统具备如下特点： ·高并发，大流量：需要扛得住高并发，大流量的用户访问。Google日均PV数35亿，日均IP访问数3亿；腾讯QQ同时在线用户数过亿；淘宝双11当天活动交易额过百亿，活动开始的第一分钟独立访问用户数 达千万 ·高可用：网站系统需要7*24小时不间断提供服务，大型网站的宕机事件通常都会成为新闻焦点，例如百度域名曾被黑客劫持无法访问。 ·海量数据，高可用数据库：需要存储，管理海量数据，使用大量的服务器 ·世界各地用户分布广泛，网络环境复杂：大型网站都是为全球用户提供服务，全球各地网络环境千差万 别，即使国内也有多个运营商网络互通难的问题，面对海外用户还得假设海外数据中心。 ·服务器安全问题：互联网的开放性，很容易受到黑客攻击，需要保护服务器安全，保证数据安全。 ·需求快速变更，发布频繁：和传统应用比较不同，互联网产品为了快速满足市场需求，产品发布率很 高，一天内网站发布几十次已是正常。 ·渐进式发展：即使是世界级大型网站，也都是由小型架构慢慢演变而来，如阿里巴巴本是在马云家中客厅诞生。\n基本架构名词 在介绍架构演进之前，你需要先有一些基本的名词理解\n单体应用架构 单机就是所有的业务全部写在一个项目中，部署服务到一台服务器上，所有的请求业务都由这台服务器处 理，无论是开发代码、还是运维部署、都比较简单粗暴，重启搞定一切。 显然，当业务增长到一定程度的时候，服务器的硬件会无法满足业务需求。自然而然地想到一个程序不行就 部署多个喽，就是集群。\n集群架构 单机处理到达瓶颈的时候，你就把单机复制几份，这样就构成了一个“集群”。 集群中每台服务器就叫做这个集群的一个“节点”,所有节点构成了一个集群。 每个节点都提供相同的服务，那么这样系统的处理能力就相当于提升了好几倍(有几个节点就相当于提升了 几倍)。 集群中的一个节点掉线时，也不会影响到整体的集群业务。\n负载均衡 但问题是用户的请求究竟由哪个节点来处理呢?最好能够让此时此刻负载较小的节点来处理，这样使得每个 节点的压力都比较平均。 要实现这个功能，就需要在所有节点之前增加一个“调度者”的角色，用户的所有请求都先交给它，然后它根 据当前所有节点的负载情况，决定将这个请求交给哪个节点处理。 这个“调度者”有个牛逼了名字——负载均衡服务器。 负载均衡：协调集群里的每个节点均衡地接受业务请求。 通俗的讲就是服务A和服务B相同时间段内处理的同类业务请求数量是相似的。\n高可用 集群系统中部分节点失效时，其他节点能够接替它继续提供服务，则可认为系统具有高可用性。\n淘宝网的十年架构演进 大型网站都是由小型网站发展而来，网站架构也是一样，从小网站逐步演化，最开始小网站访问人数很少，一台服务器即可完成工作。\n此时应用程序，数据库，文件等所有资源都在一台服务器，也就是我们常见的LAMP、LNMP单机，使用各种开源软件和一台普通的服务器即可运行网站。\n单机架构 以淘宝作为例子。在网站最初时，应用数量与用户数都较少，可以把Tomcat(后端)和数据库部署在同一台服务器上。\n浏览器往www.taobao.com发起请求时，首先经过DNS服务器（域名系统）把域名转换为实际IP地址10.102.4.1，浏览器转而访问该IP对应的Tomcat。\n随着用户数的增长，Tomcat和数据库之间竞争资源，单机性能不足以支撑业务\n第一次升级、tomcat和数据库分开了 因为tomcat是java写的，非常占内存资源，总是和数据库抢占磁盘资源、内存资源，导致服务器压力过大，网站解析、处理整体能力都很差。\n因此让tomcat和数据库分开两台机器，显著提升各自的运行性能。\n应用服务和数据库分离 随着网站业务的发展，用户量增多，一台服务器逐渐支撑不住，越来越多的用户访问导致网站响应速度变慢，越来越多的数据，导致存储空间不足。这时候应该把应用和数据分离，使用三台服务器的架构，分别运行应用服务器、文件服务器、数据库服务器。\n这三台机器对硬件资源要求各不同，\n应用服务器需要处理大量的业务逻辑，需要更强大，更快的CPU处理器 数据库服务器需要更快速的读写数据，因此需要更强大的磁盘和大内存 文件服务器要存储大量用户上传的文件，因此需要更大容量的硬盘。 应用和数据分离后，不同作用的服务器承担不同的服务角色，各司其职，网站的并发处理能力和存储空间都得到了很大的改善，进一步支持网站业务。\n但是随着公司发展，用户持续增长，网站此时架构又一次面临挑战，数据库压力太大，导致用户访问延迟，用户体验变差，老板又要拍板骂人了，需要对网站架构进一步优化。\n1 2 3 4 5 6 7 8 9 10 mysql是磁盘性数据库，和机械硬盘，固态硬盘的读写速度挂钩 如果硬盘太差，速度速度从物理上就慢 其他的软件技术都是白扯 数据库，读写速度很快？ 内存读写速度，比磁盘块的多的多 市面上主流的磁盘数据库，mysql 内存性数据，redis，直接数据写入到内存中 第二次升级、引入本地缓存、分布式缓存 1 数据放在内存中，这就叫做缓存（数据写入到内存中，读写都是和内存交互） 网站访问特点也逃不掉现实世界的二八定律：80%的业务访问集中在20%的商品数据上。\n例如淘宝的用户最关注的都是成交量多，评价较好的商品；\n很明显，对于网站的数据，就有热数据，冷数据之分，大部分的业务集中在一小部分数据上，那么如果把热门的数据缓存再内存中，是不是可以减轻数据库的访问压力，提高网站的整体访问效果呢，当然是可以。\nPS：内存的I/O速度是远超于磁盘的\n网站的缓存主要分两种：\n缓存再应用服务器上的本地缓存（内存） 缓存放在专门的分布式缓存服务器上（单独的一台大内存服务器） 本地缓存的弊端 1 2 3 4 5 6 7 第一种缓存，利用程序本身提供的缓存功能（还未引入第二种内存数据库，） php java python 本身这个程序，可以将部分数据，直接写入到内存里，读取时候，也去读取内存的数据 这个叫做程序的本身缓存，本地缓存 比如修改tomcat的参数、添加JVM缓存参数、或者在应用服务器部署memcached缓存数据库，也都可以。\n本地缓存的访问更快，没有网络延时，但是应用服务器的内存有限，缓存的数据量有限制，而且会有缓存和应用程序争夺内存的情况。\n分布式缓存的优点 远程分布式缓存可以采用集群的方案，部署较大内存的服务器作为专门的缓存服务器，可以在理论上实现内存不受限的扩容服务。当然这需要有成本代价。\n新的问题又来了\n使用缓存后，数据库的访问压力得到有效的缓解，但是应用服务器在后续也有了瓶颈；\n缓存抗住了绝大多数的访问请求，但是随着淘宝网的崛起，用户越来越多，并发压力更大了，网站的压力就集中在了tomcat这样的应用服务器上；\n后端服务器解析速度越来越慢；\n主要使用负载均衡集群方式改善。\n1 2 第二种缓存，需要引入独立的产品，独立的软件 引入一个新的数据库，叫做redis数据库 第三次升级、引入反向代理、负载均衡 关于反向代理的概念\n反向代理，以房东 \u0026gt; 中介 \u0026gt; 租客 正向代理， 用户浏览器 \u0026gt; vpn \u0026gt; facebook 使用集群是网站解决高并发，海量请求的常见手段，俗话说三个臭皮匠，胜过诸葛亮。\n一台服务器的处理能力，存储空间都会有瓶颈，此时压根不要企图再去换一个更强大的服务器，对于大型网站而言，无论多么强大的服务器，都满足不了业务增长的需求，此时你的做法应该是再增加一个臭皮匠，也就是增加一台服务器，去分担原有服务器的压力。\n对于网站架构而言，通过增加机器的形式改善负载压力，就可以持续不断的改善系统性能，实现系统的可伸缩性。\n在很多台机器上，都部署tomcat、使用反向代理软件nginx，把请求均匀的分发给每一个tomcat。\n假设tomcat本身最多支持1000个并发（1000个用户同时在线）；\nNginx最多支持50000个并发（支持5万个用户同时连接）；\n那么nginx只要把5万个并发请求，转发给50个tomcat服务器就能扛得住这个流量；\n通过负载均衡调度服务器，将用户的请求分发到应用服务器集群中的任何一台机器上，根据用户访问量，来决定增/删集群中的服务器，以此来解决应用服务器的压力。\n涉及技术、nginx、haproxy、lvs等\n问题又来了\n既然理论上，只要不断增加负载均衡的节点，应用服务器的数量，后端就必然能扛得住更多的用户流量；\n此时的压力就落到了谁身上？\n数据库，此时数据库mysql、依然是单机，读写性能达到瓶颈。\n第四次升级、数据库读写分离 数据库优化技术，读写分离\n网站在使用缓存后，使得大部分数据的读取操作，不通过数据库就可以访问完成，但是也会有一部分的读取操作（例如缓存未命中，缓存过期）和全部的写入操作需要访问数据库，在网站达到一定规模之后，数据库因为负载压力过高而成为网站瓶颈。\n主从复制 目前主流的数据库软件都提供了主从热备功能 ，配置两台数据库的主从关系，可以将一台数据库的数据，同步更新到另一台机器上。\n网站利用该功能，可以实现数据读写分离，减轻数据库负载压力。\n读写分离 数据库规划为读库（从库）；写库（主库）；\n应用服务器进行写入操作的时候，访问主数据库，主数据库通过主从复制机制将数据更新同步到从数据库，这样当\n应用服务器读取数据的时候，可以通过从库获取数据，以此实现数据读写分离；\n针对不同的网站业务，读，写的操作比率，也是不一样的。\n如电商类站点，用户浏览商品居多，读取居多；\n博客类站点，用户写入数据居多，需要依次进行不同的优化调整。\n读库可以有多个，通过主从同步技术把写库的数据，同步到所有的读库；\n对于需要读取最新数据的场景，可以再从写库，同步到缓存中，确保可以通过缓存也能拿到最新数据；\n这里的数据库拆分、主要是DBA的专业数据库运维工作内容，以及开发工程师要根据业务的拆分涉及，系统运维主要以配置数据库复制为主。\n问题又来了 依然是随着淘宝网的发展，不仅是用户量、并发量更大了、业务复杂性也更高了\n业务越来越多、不同业务之间的访问量、访问频率相差也太大，甚至有业务会对数据库竞争，相互影响性能，因此数据库瓶颈依然是个问题。\n后续就是DBA级别的数据库优化架构了，主要是\n数据库按业务分为多个数据库 数据表拆分 这就不在网站架构的讨论范畴了，因此不做讲解了\n第五次升级、负载均衡升级 假设nginx能够支撑5万的用户并发，但是此时的淘宝网已经有50万的用户了，也就是入口的nginx也扛不住这个请求压力了，瓶颈此时出现在了nginx。\n因此依然是采用负载均衡的理念，运行多个nginx来分摊这个集中式的请求压力；\n入口此时发现被修改为了叫做LVS、或是F5这样的软件，它俩也是提供负载均衡能力的软件，但是性能上比nginx更强悍，支持更高的并发，单机的F5就能扛得住支持几十万的用户请求，但是价格昂贵，是一台硬件负载均衡设备，需要企业估值成本；\n成本不允许，则可以使用开源技术，LVS替代F5、性能也足够强悍，也是提供负载均衡的能力。\n但是LVS是软件负载均衡，也就是linux上运行的一个程序而已，如果lvs服务器宕机了，会导致网站入口直接就挂了，因此需要实现高可用，常见的方案就是keepalived；\n第六次升级、DNS负载均衡 1 2 3 4 5 6 7 提示，服务器理论上，最大并发数是 \u0026gt;\u0026gt;\u0026gt; 2**48 281474976710656 每一条连接都是要消耗系统资源的，所以实际中可能会设置最大并发数来保证服务器的安全和稳定，所以这个理论最大并发数是不可能达到的。 实际中并发数和业务是直接相关的，服务器支持几十万连接是没问题的 由于LVS这套软件负载均衡技术，虽说并发数能达到几十万，但是淘宝实在是太挣钱了，老百姓花钱的能力太强了，淘宝网的用户已经达到千万、上亿级别了。\n并且此时的服务器架构，已经是在全国不同的地区，有很多的机房了，并且用户也是分散在全国不同的地区，和服务器的距离各不相同；\n新疆的用户访问淘宝网，请求如果是发给了杭州的淘宝服务器，那这个过程显然是太慢太慢了。。\n你得让新疆的用户，访问淘宝网，这个请求发给了新疆周边的淘宝服务器、或者说找到一个离新疆最近的淘宝服务器（前提是，淘宝在新疆地区周边部署了机房），要不只能通过网络去找其他地区的服务器了。\n以阿里云官网提供的资料来看，如果是新疆的用户，离得最近的就是呼和浩特这个机房。\nDNS负载均衡 在DNS服务器中可以配置一个域名、解析到多个IP地址，每个IP地址对应不同地区的机房服务器IP。\n用户在不同的地区访问www.taobao.com时，DNS服务器会自动判断该用户所在地区，然后选择离他最近的淘宝服务器，返回其IP地址提供访问。\n因此实现了DNS负载均衡，让用户可以访问离自己最近的淘宝网服务器，这样的话，只要增加机房，扩大服务器规模，无论你是千万、千亿级别的并发量，都可以负载均衡、分发给在全国各地的机房了，因此网站入口的并发再也不是问题。\n问题又来了 此时流量入口，不是什么大问题了，难题依然是在业务的复杂度上、业务发展、数据越来越恐怖，后续的优化、又是在数据库角度了\n第N次升级 引入NoSQL数据库，redis 引入搜索引擎技术，ElasticSearch 代码架构升级、大功能拆为小功能，如淘宝网首页，业务拆分为 淘宝网代码 天猫超市代码 聚划算代码 \u0026hellip; 复杂的功能抽象成微服务、置于淘宝网首页的诸多功能 淘宝网代码 天猫超市代码 聚划算代码 这些等等子系统都有一些共同的功能，如 用户数据管理系统 订单管理系统 支付系统 物流系统 \u0026hellip; 这些系统在多个应用中都存在，代码没必要重复的运行、重复的单独写、维护，因此可以抽象为一个公共的服务来关系，这就是微服务的概念，此时多个应用，都可以统一使用这些公共的微服务。 这些微服务系统，都交给专门的团队去维护即可，目前市面上的微服务以阿里的Dubbo、SpringCLoud框架为主流。 当业务以微服务模式运行后、不仅开发工作更细化了、运维部署也更加频繁，且细化了 容器时代 目前市面上最主流的就是通过docker容器技术管理微服务应用，每一个微服务也就是一个个应用程序，全部运行在docker容器里，当容器数量过多后，你必须进行容器编排管理。\n目前最主流的docker管理平台肯定是Kubernetes了。\n以云平台承载系统 到这里，就不是关乎于网站架构的性能问题了，而是成本问题，机器的运行、管理成本，服务器很贵的，部门每个月都有支出预算，这个月服务器费用是50万，如何降低个10万？是不是需要合理的去规划机器的硬件配置，以及不用的机器，是否要回收，关机？\n机房的电费也是很贵的。。\n问题它又来了 使用容器化技术后服务动态扩缩容问题得以解决，但是物理机器还是需要公司自身来管理\n在非大促的时候，还是需要闲置着大量的机器资源来应对大促，机器自身成本和运维成本都极高，资源利用率低\n现在的企业，要么是用公有云（阿里、腾讯、华为云等），部署运行自己的应用；\n要么就是自己有机房、搭建私有云平台，管理虚拟机。\n核心都是在与系统部署在云平台上，利用云平台的海量机器资源，以及可以动态伸缩机器资源，可以在如大促的时候申请更多的机器硬件，结合docker、k8s快速部署业务；\n在大促结束之后，在降低、释放资源，真正做到按需付费，资源利用率提高了，也很大的降低了运营成本。\n云平台是什么 所谓的云平台，就是把海量机器资源，通过统一的资源管理，抽象为一个资源整体，在之上可按需动态申请硬件资源（如CPU、内存、网络等），并且之上提供通用的操作系统，提供常用的技术组件（如Hadoop技术栈，MPP数据库等）供用户使用，甚至提供开发好的应用，用户不需要关系应用内部使用了什么技术，就能够解决需求（如音视频转码服务、邮件服务、个人博客等）。\n在云平台中会涉及如下几个概念：\n**IaaS：**基础设施即服务。对应于上面所说的机器资源统一为资源整体，可动态申请硬件资源的层面； **PaaS：**平台即服务。对应于上面所说的提供常用的技术组件方便系统的开发和维护； **SaaS：**软件即服务。对应于上面所说的提供开发好的应用或服务，按功能或性能要求付费。 架构师原则 N+1设计。系统中的每个组件都应做到没有单点故障；\n回滚设计。确保系统可以向前兼容，在系统升级时应能有办法回滚版本；\n禁用设计。应该提供控制具体功能是否可用的配置，在系统出现故障时能够快速下线功能；\n监控设计。在设计阶段就要考虑监控的手段；\n多活数据中心设计。若系统需要极高的高可用，应考虑在多地实施数据中心进行多活，至少在一个机房断电的情况下系统依然可用；\n采用成熟的技术。刚开发的或开源的技术往往存在很多隐藏的bug，出了问题没有商业支持可能会是一个灾难；\n资源隔离设计。应避免单一业务占用全部资源；\n架构应能水平扩展。系统只有做到能水平扩展，才能有效避免瓶颈问题；\n非核心则购买。非核心功能若需要占用大量的研发资源才能解决，则考虑购买成熟的产品；\n使用商用硬件。商用硬件能有效降低硬件故障的机率；\n快速迭代。系统应该快速开发小功能模块，尽快上线进行验证，早日发现问题大大降低系统交付的风险；\n无状态设计。服务接口应该做成无状态的，当前接口的访问不依赖于接口上次访问的状态。\n今日任务 创建虚拟机，为实验环境做准备\n1 2 3 4 5 6 7 1.今天学习的知识就是理解架构图，理解网站架构演进，升级的历程， 绘制同样的图，去理解架构 2.创建虚拟机，为了我们的运维架构部署做准备 -创建模板机，设置双网卡，主机名，静态ip地址 - 克隆该机器，克隆9台，且 根据文档，设置好主机名，ip地址 架构图中的服务组件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 1.用户、顾客（浏览器） 访问网站的用户请求 2.防火墙、保安（iptables） 设定防火墙策略、防火墙规则，请求的进入、响应的出口，针对ip、port的流量控制 3.负载均衡服务器、迎宾服务员（nginx） 对用户的请求进行调度、纷发 4.web服务器，点餐前台服务员（nginx） 接收用户请求、处理、响应用户请求，返回服务器资料 5.数据库服务器、厨房后厨仓库（mysql） 存储网站的动态数据、提供读写数据功能 6.存储服务器、粮仓仓库（nfs） 存储图片、音频、视频、各种附件等容量较大的静态资源 7.备份服务器、粮仓仓库二号（rsync+crond定时备份、rsync+inotify实时备份） 二次备份所有数据，存储图片、音频、视频、各种附件等容量较大的静态资源 8.缓存服务器、自助取餐（redis） 数据存储在内存里，提供内存的高速数据读写 以及减轻mysql服务器的读写压力 9.ansible服务器、调度总台（ansible） 批量化管理所有的服务器 服务器环境规划 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 服务器作用 主机名 外网地址 内网地址 运行软件 管理机 master-61 10.0.0.61 172.16.1.61 Ansible/zabbix/jumpserver/openvpn 负载均衡服务器 slb-5 10.0.0.5 172.16.1.5 nginx/keepalived 负载均衡服务器 slb-6 10.0.0.6 172.16.1.6 nginx/keepalived web服务器 web-7 10.0.0.7 172.16.1.7 nginx/php web服务器 web-8 10.0.0.8 172.16.1.8 nginx/tomcat web服务器 web-9 10.0.0.9 172.16.1.9 nginx/php 存储服务器 nfs-31 10.0.0.31 172.16.1.31 nfs/rsyncd/lsyncd 备份服务器 rsync-41 10.0.0.41 172.16.1.41 nfs/rsyncd/lsyncd 数据库服务器 db-51 10.0.0.51 172.16.1.51 mysql/redis 注意去理解架构图，生产环境下、只有最外层的负载均衡设备，才能对接到公网流量，因此需要配置公网ip地址； 其他功能的服务器，只需要单网卡，内网IP即可； 外网地址 - 模拟互联网的公网ip - 你可以直接使用windows，ping通该地址，（xshell）ssh连接该地址（服务器） 内网地址 - 模拟服务器的内网，局域网环境 - 无法直接通过xshell连接该服务器 综合架构实践 1.关闭你之前旧的所有虚拟机，甚至删除也行，别开机，因为你之前修改过网络设置\n2.你这里要修改新的网络设置，需要修改vmware的虚拟网络编辑器（实测要关闭dhcp功能，反正我们都是用静态ip）\n1.创建新虚拟机（模板机） 1 2 3 4 5 6 系统 centos7 内存 至少2G/1c（特殊情况，给1c/1g也够了） 网卡 eth0，使用NAT、模拟外网环境 ，网段是10.0.0.xx eth1，使用LAN区段，模拟内网环境，网段是172.16.1.xx 硬盘容量，40G 再添加另一块网卡（充当内网环境的网卡）\n1 2 3 4 提示，常见的LAN和WAN是什么？ WAN接口，也就是广域网（WAN，Wide Area Network）的缩写，也称之为远程网（long haul network ）。 而LAN接口，也就是局域网（Local Area Network，LAN）的缩写，它是指在某一区域内由多台计算机互联成的计算机组。 图解双网卡的配置\n2.安装centos7 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 1.进入内核选择界面时，按上下方向键，取消自动选择 2.输入tab键，复制粘贴进去如下代码，以下代码的作用是禁用基于硬件设备的命名风格，使网卡的命名风格回退到eth0、eth1的形式： net.ifnames=0 biosdevname=0 3.输入回车，启动 4.请注意，必须是英文，以后再也别用中文了，因为你要看日志 5.只需要修改亚洲上海时区,其他全部默认 6.网络设置、修改静态ip地址、设置主机名 模板机，主机名 lj-template-100 ip，10.0.0.100 网关，10.0.0.254 网络配置\n3.登录该机器\n1 ssh root@10.0.0.100 3.简化网卡配置文件 友情提醒，sed是一个双刃剑\n用好了、高效修改配置文件\n用坏了，可能不小心会清空你的配置文件\n所以自己看着来，细心是第一位，做好备份是第一位\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 1.删除网卡配置文件中关于ipv4、ipv6的行 [root@lj-template-100 ~]# sed -i \u0026#39;/ipv[46]/Id\u0026#39; /etc/sysconfig/network-scripts/ifcfg-eth0 2.再删除如下四行 proxy_method browser_only defroute uuid sed -r -i \u0026#39;/(proxy_method|browser_only|uuid|defroute)/Id\u0026#39; /etc/sysconfig/network-scripts/ifcfg-eth0 3.上述俩语句，你也可以一行搞定 确保最终的配置如下，和我一样即可 [root@lj-template-100 network-scripts]# sed -ri \u0026#39;/(proxy_method|browser_only|uuid|defroute)/Id\u0026#39; /etc/sysconfig/network-scripts/ifcfg-eth0 [root@lj-template-100 network-scripts]# [root@lj-template-100 network-scripts]# cat ifcfg-eth0 TYPE=Ethernet BOOTPROTO=none NAME=eth0 DEVICE=eth0 ONBOOT=yes IPADDR=10.0.0.100 PREFIX=24 GATEWAY=10.0.0.254 DNS1=223.5.5.5 4.如果你不这么做，你后续克隆虚拟机，会导致无法上网，必须要删除网卡配置文件的uuid 还得编辑eth1内网网卡配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 [root@lj-template-100 network-scripts]# sed -r -e \u0026#39;s#eth0#eth1#g\u0026#39; -e \u0026#39;s#10.0.0.100#172.16.1.100#g\u0026#39; -e \u0026#39;s#10.0.0.254#172.16.1.254#g\u0026#39; ifcfg-eth0 \u0026gt;ifcfg-eth1 [root@lj-template-100 network-scripts]# cat ifcfg-eth1 TYPE=Ethernet BOOTPROTO=none NAME=eth1 DEVICE=eth1 ONBOOT=yes IPADDR=172.16.1.100 PREFIX=24 GATEWAY=172.16.1.254 DNS1=223.5.5.5 如果sed用的不熟，实在不行，vim去手动改也一样 最后重启网络服务，确保ip正常\n1 2 3 4 5 6 7 [root@lj-template-100 network-scripts]# systemctl restart network [root@lj-template-100 network-scripts]# ip addr show |grep -E \u0026#39;eth0|eth1\u0026#39; 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 inet 10.0.0.100/24 brd 10.0.0.255 scope global noprefixroute eth0 3: eth1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 inet 172.16.1.100/24 brd 172.16.1.255 scope global noprefixroute eth1 最后用你的windows、验证这两块网卡\n5.系统初始化优化 关闭NetworkManager【注意！】 NetworkManager 服务是一个用于管理和配置网络连接的后台守护进程。它的主要目的是简化网络配置，特别是在动态环境中（如笔记本电脑或移动设备），所以如果你的网络环境是WIFI，请不要关闭该服务\n1 2 [root@lj-template-100 ~]# systemctl stop NetworkManager [root@lj-template-100 ~]# systemctl disable NetworkManager 关闭防火墙、selinux 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [root@lj-template-100 ~]# systemctl stop firewalld [root@lj-template-100 ~]# systemctl disable firewalld [root@lj-template-100 ~]# sed -i \u0026#39;/^SELINUX=/c SELINUX=disabled\u0026#39; /etc/selinux/config [root@lj-template-100 ~]# grep -i \u0026#39;selinux=\u0026#39; /etc/selinux/config # SELINUX= can take one of these three values: SELINUX=disabled [root@lj-template-100 ~]# setenforce 0 [root@lj-template-100 ~]# getenforce Permissive [root@lj-template-100 ~]# iptables -F [root@lj-template-100 ~]# iptables -X [root@lj-template-100 ~]# iptables -Z 最后检查 [root@lj-template-100 ~]# iptables -L [root@lj-template-100 ~]# systemctl is-enabled firewalld NetworkManager disabled disabled 加速ssh连接 修改如下2个参数\n1 2 3 4 5 [root@lj-template-100 yum.repos.d]# grep -Ei \u0026#39;^(usedns|gssapiauth)\u0026#39; /etc/ssh/sshd_config GSSAPIAuthentication no UseDNS no [root@lj-template-100 yum.repos.d]# systemctl restart sshd.service 优化PS1变量 1 echo \u0026#39;export PS1=\u0026#34;[\\[\\e[34;1m\\]\\u@\\[\\e[0m\\]\\[\\e[32;1m\\]\\H\\[\\e[0m\\] \\[\\e[31;1m\\]\\w\\[\\e[0m\\]]\\\\$\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/profile yum源优化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 1.备份旧的默认repo [root@lj-template-100 ~]# cd /etc/yum.repos.d/ [root@lj-template-100 yum.repos.d]# mkdir bakrepo [root@lj-template-100 yum.repos.d]# mv *.repo bakrepo/ 2.下载新的repo curl https://mirrors.aliyun.com/repo/Centos-7.repo \u0026gt; /etc/yum.repos.d/centos-base.repo curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 或 wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 3.清楚旧的yum缓存 生成新的缓存 yum clean all \u0026amp;\u0026amp; yum makecache 安装基础软件 1 yum install -y tree wget bash-completion bash-completion-extras lrzsz net-tools sysstat iotop iftop htop unzip telnet ntpdate lsof vim 关闭邮件告警 1 2 3 你所有的操作，都会被linux内置的邮件服务器记录，不断的写入 /var/log下的日志文件，可能会占用多余的磁盘 [root@lj-template-100 ~]# echo \u0026#39;unset mailcheck\u0026#39; \u0026gt;\u0026gt; /etc/profile [root@lj-template-100 ~]# source /etc/profile 配置hosts解析 1 2 3 4 5 6 7 8 9 10 11 12 cat \u0026gt; /etc/hosts \u0026lt;\u0026lt;EOF # 外网地址 内网地址 主机名 10.0.0.61 172.16.1.61 master-61 10.0.0.5 172.16.1.5 slb-5 10.0.0.6 172.16.1.6 slb-6 10.0.0.7 172.16.1.7 web-7 10.0.0.8 172.16.1.8 web-8 10.0.0.9 172.16.1.9 web-9 10.0.0.31 172.16.1.31 nfs-31 10.0.0.41 172.16.1.41 rsync-41 10.0.0.51 172.16.1.51 db-51 EOF 时间同步 1 2 3 4 5 6 7 8 systemctl status crond crontab -e * * * * * /usr/sbin/ntpdate time1.aliyun.com \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 #检查 [root@template-linux01 ~]#crontab -l 关闭swap 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 取消swap的功能，不适用这个从磁盘获取而来的部分内存容量，因为效率太差，企业里的服务器内存都巨大 [root@lj-template-100 ~]# swapoff -a [root@lj-template-100 ~]# free -m total used free shared buff/cache available Mem: 1982 97 1409 9 475 1699 Swap: 0 0 0 [root@lj-template-100 ~]# vim /etc/fstab [root@lj-template-100 ~]# cat /etc/fstab # # /etc/fstab # Created by anaconda on Mon Apr 18 01:03:08 2022 # # Accessible filesystems, by reference, are maintained under \u0026#39;/dev/disk\u0026#39; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=16dbd4b1-60b3-4770-b20a-4d0b59b39e4a /boot xfs defaults 0 0 6.修改ip的脚本 至此，上述所有的初始化操作，已经针对模板机修改好了，然后克隆该机器，也自动有了所有的配置\n未读需要修改的就是ip地址、主机名，每一个机器都不一样，因此你可设置一个简单脚本。\nnetwork_init.sh\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/bin/bash read -p \u0026#34;请输入IP主机位：\u0026#34; my_ip read -p \u0026#34;请输入主机名：\u0026#34; host_name echo \u0026#39;正在修改网卡配置文件eth0\u0026#39; sed -i \u0026#34;/IPADDR/s#100#${my_ip}#g\u0026#34; /etc/sysconfig/network-scripts/ifcfg-eth0 echo \u0026#39;正在修改网卡配置文件eth1\u0026#39; sed -i \u0026#34;/IPADDR/s#100#${my_ip}#g\u0026#34; /etc/sysconfig/network-scripts/ifcfg-eth1 echo \u0026#39;网卡配置文件修改完毕\u0026#39; echo \u0026#39;正在修改主机名\u0026#39; hostnamectl set-hostname ${host_name} echo \u0026#34;==========================\u0026#34; echo \u0026#34;此时的eth0配置是：\u0026#34; `cat /etc/sysconfig/network-scripts/ifcfg-eth0` echo \u0026#34;==========================\u0026#34; echo \u0026#34;此时的eth1配置是：\u0026#34; `cat /etc/sysconfig/network-scripts/ifcfg-eth1` echo \u0026#34;当前的主机名是：\u0026#34; `hostname` echo \u0026#39;重启network服务中\u0026#39; systemctl restart network 7.拍摄快照 8.克隆新的虚拟机 新虚拟机，克隆完毕后\n检查一下初始化的配置是否正确 ip、主机名是否正确，按照规划的来 是否可以ssh 是否可以上网 全部做好首次的快照 循环操作，完成9台机器的创建\n","date":"2025-04-14T15:40:04+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux%E7%BB%BC%E5%90%88%E6%9E%B6%E6%9E%84/","title":"Linux综合架构"},{"content":"数据备份的重要性 数据备份方案 企业网站和应用都得有完全的数据备份方案确保数据不丢失，通常企业有如下的数据备份方案\n定时任务定期备份 需要周期性备份的数据可以分两类：\n后台程序代码、运维配置文件修改，一般会定时任务执行脚本进行文件备份，然后配置Rsync工具推送到远程服条器备份 对于数据库文件用定时任务脚本配合数据库提供的备份工具，定时生成备份文件，配合Rsync备份到远端 为什么要用实时同步服务 因为定时任务有缺陷，一分钟以内的数据无法进行同步，容易造成数据丢失\n实时复制方案 实施复制是最适合企业备份重要数据的方式，用于用户提交的数据备份，对于用户提交的普通文件(jpg、 tar、zip、MP4、txt,html)等待，都可以用Inofity+Rsync实时备份方案。 对于数据文件，还有更复杂的分布式存储方案，把数据同时备份成多份，如FastDFS、GlusterFS等 对于提交到数据库中的数据，还可以用数据库的主从复制(如MySQL),这是软件自带的实时备份。 图解备份方式 实时同步结合NFS 实时同步的难点 1.什么条件下开始同步 2.同步哪些文件夹 3.多长时间同一次? 4.用什么工具同步?\ninotify隆重出场 Inotify是一个强大的，细粒度的，异步的文件系统事件监控机制。 事件是指如文件的增删改查都是事件。\nLinux2.6.13开始就引入了inotify这个功能，用于监控文件系统的增删改查等事件。\n1 2 3 4 查看内核 uname -a 升级系统(包括内核) yum upgrade 第三方软件能实现监控文件内容变化，其实是因为linux提供了这个inotify机制功能。\nInofity-tools+Rsync实施复制实战 先准备rsyncd服务环境 部署拓扑图 Backup服务器（rsync服务端） 1 2 3 4 5 6 7 1.恢复了快照，重新安装rsync服务端 2.快速的部署rsyncd服务端 [root@rsync-41 ~]#vim instal_rsync.sh 3.执行脚本部署服务端的rsync [root@rsync-41 ~]#bash instal_rsync.sh dev服务器部署（rsync客户端） 1 [root@nfs-31 ~]#yum install rsync -y 准备部署inotify-tools软件（nfs-31机器） 内核检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 [root@nfs-31 ~]#uname -r 3.10.0-862.el7.x86_64 还有内核参数检查， 本质上是linux支持inotify机制 在性能还可以优化，支持更高的文件并发数 检测多少个文件 ，文件内容大量的发生变化，inotify机制能同时检测多少文件 这个参数的优化，就是调整linux的几个文件 [root@nfs-31 ~]#ls -l /proc/sys/fs/inotify/ total 0 -rw-r--r-- 1 root root 0 Apr 20 20:08 max_queued_events -rw-r--r-- 1 root root 0 Apr 20 20:08 max_user_instances -rw-r--r-- 1 root root 0 Apr 20 20:08 max_user_watches 系统文件解释 max_user_watches: 设置inotifywait或inotifywatch命令可以监视的文件数量（单进程） 默认只能监控8192个文件 max_user_instances: 设置每个用户可以运行的inotifywait或inotifywatch命令的进程数 默认每个用户可以开启inotify服务128个进程 max_queued_events: 设置inotify实例事件（event）队列可容纳的事件数量 默认监控事件队列长度为16384 inotify-tools 系统自带的比较low的工具 sersync 金山云的运维通过c++开发的工具 lsyncd三个工具 最新的，目前有人在用，适用于大规模服务器环境的工具 这些工具就3件事 1.优化，调整了这3文件的参数 2.检测某个目录 3.触发rsync命令 安装inotifty-tools工具 1 2 3 4 5 6 7 需要配置好epel源，才可以安装 [root@nfs-31 ~]# yum install inotify-tools -y 检查生成的软件命令 [root@nfs-31 ~]# rpm -ql inotify-tools |head -2 /usr/bin/inotifywait /usr/bin/inotifywatch 1 2 3 4 上述操作我们安装好了Inotify-tools软件，生成2个重要的命令 inotifywait：在被监控的目录等待特定文件系统事件（open、close、delete等事件），执行后处于阻塞状态，适合在Shell脚本中使用，是实现监控的关键 Inotifywatch：收集被监控的文件系统使用的统计数据（文件系统事件发生的次数统计） inotifywait实践 所有事件，任意的linux命令，只要对该目录的数据 对文件发生了修改动作，都会被检测到\n1 2 3 4 5 6 7 8 9 10 11 12 [root@nfs-31 ~]#mkdir /nfs-data [root@nfs-31 ~]#inotifywait -mrq --timefmt \u0026#39;%T\u0026#39; --format \u0026#34;%T----%w------%f 捕获到的事件是：%e\u0026#34; /nfs-data 12:27:56----/nfs-data/------ 捕获到的事件是：CLOSE_NOWRITE,CLOSE,ISDIR 12:27:56----/nfs-data/------ 捕获到的事件是：OPEN,ISDIR 12:27:56----/nfs-data/------ 捕获到的事件是：CLOSE_NOWRITE,CLOSE,ISDIR 参数解释： -m:即“-monitor”表示始终保持事件监听状态。 -r:即“-recursive”表示递归查询目录 -q:即“-quiet”表示打印出监控事件 -e:即“-event”,通过此参数可以指定要监控的 需要指定检测事件的名字 1 2 3 4 5 6 7 8 9 10 11 Events 含义 access 文件或目录被读取 modify 文件或目录内容被修改 attrib 文件或目录属性被改变 close 文件或目录封闭，无论读/写模式 open 文件或目录被打开 moved_to 文件或目录被移动至另外一个目录 move 文件或目录被移动到另一个目录或从另一个目录移动至当前目录 create 文件或目录被创建在当前目录 delete 文件或目录被删除 umount 文件系统被卸载 Create、delete 检测，创建，删除两个时间，只有你执行了对应的linux命令，才会生成日志\n1 2 3 4 5 6 7 8 -e events 事件名 [root@nfs-31 ~]#inotifywait -mrq --timefmt \u0026#39;%T\u0026#39; --format \u0026#34;%T----%w------%f 捕获到的事件是：%e\u0026#34; -e delete,create /nfs-data 12:29:46----/nfs-data/------hehe.log 捕获到的事件是：CREATE 12:30:24----/nfs-data/------aoligei.log 捕获到的事件是：CREATE 12:31:03----/nfs-data/------hehe.log 捕获到的事件是：DELETE move事件 1 2 3 4 5 6 7 8 9 10 11 [root@nfs-31 ~]# [root@nfs-31 ~]#inotifywait -mrq --timefmt \u0026#39;%T\u0026#39; --format \u0026#34;%T----%w------%f 捕获到的事件是：%e\u0026#34; -e move /nfs-data 12:31:48----/nfs-data/------xixi.log 捕获到的事件是：MOVED_FROM 12:31:48----/nfs-data/------xixi.png 捕获到的事件是：MOVED_TO 12:32:17----/nfs-data/------xixi.png 捕获到的事件是：MOVED_FROM 12:32:54----/nfs-data/------xixi.png 捕获到的事件是：MOVED_TO close_write事件 1 [root@nfs-31 ~]#inotifywait -mrq --timefmt \u0026#39;%T\u0026#39; --format \u0026#34;%T----%w------%f 捕获到的事件是：%e\u0026#34; -e close_write /nfs-data 总结inotify-wait命令 1 2 3 1.该命令，在大量文件生成的时候，需要检测，性能会骤然下降，以及会丢失数据，有部分的文件，会无法被检测到，也就是无法被后续的动作抓取到 适用于数据量不大的情况下，你用也没问题 基于sersync工具同步（了解） 检测文件事件的工具，条件\n某些文件不检测 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 1.下载安装 https://code.google.com/archive/p/sersync/ cd /opt \u0026amp;\u0026amp; wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz [root@nfs-31 /opt]#tar -zxvf sersync2.5.4_64bit_binary_stable_final.tar.gz 修改名字 [root@nfs-31 /opt]#mv GNU-Linux-x86/ sersync254 2.修改配置文件 找到需要检测的目录配置段，修改为你的机器环境即可 检测nfs-31 /nfs-data目录 修改如下部分配置 23 \u0026lt;sersync\u0026gt; 24 \u0026lt;localpath watch=\u0026#34;/nfs-data\u0026#34;\u0026gt; 25 \u0026lt;remote ip=\u0026#34;172.16.1.41\u0026#34; name=\u0026#34;backup\u0026#34;/\u0026gt; 26 \u0026lt;/localpath\u0026gt; 27 \u0026lt;rsync\u0026gt; 28 \u0026lt;commonParams params=\u0026#34;-az\u0026#34;/\u0026gt; 29 \u0026lt;auth start=\u0026#34;true\u0026#34; users=\u0026#34;rsync_backup\u0026#34; passwordfile=\u0026#34;/etc/rsync.pwd\u0026#34;/\u0026gt; 3.启动服务 [root@nfs-31 /nfs-data]#/opt/sersync254/sersync2 -r -d -o /opt/sersync254/confxml.xml 3.1 发现报错了，如何看日志，解决问题，咱们当前得问题是 1.没有密码文件 2.密码文件权限不对 [root@nfs-31 /nfs-data]#echo \u0026#34;bz666\u0026#34; \u0026gt; /etc/rsync.pwd [root@nfs-31 /nfs-data]#chmod 600 /etc/rsync.pwd 4.使用工具 必须先确认sersync帮你生成的rsync命令，能正确的执行 5.查看sersync是否帮你做了同步 你必须确保，rsync可以手动，sersync才能帮你同步！！！ 排查错误的经验所在 lsyncd工具（推荐使用） 注意，当你做了很多的实验，机器上，可能会同时运行很多个rsync数据同步程序，为了保证工具的准确性，注意只保留一个即可\n1 2 3 4 5 6 7 8 https://github.com/lsyncd/lsyncd Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。 我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。 另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。 lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。 实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 0.干掉sersync工具 1.下载安装 [root@nfs-31 /nfs-data]#yum install lsyncd -y 2.修改配置文件,（只检测一个目录） [root@nfs-31 /data]#cat /etc/lsyncd.conf settings { logfile =\u0026#34;/var/log/lsyncd/lsyncd.log\u0026#34;, statusFile =\u0026#34;/var/log/lsyncd/lsyncd.status\u0026#34;, inotifyMode = \u0026#34;CloseWrite\u0026#34;, maxProcesses = 8, } sync { default.rsync, source = \u0026#34;/nfs-data\u0026#34;, target = \u0026#34;rsync_backup@172.16.1.41::backup\u0026#34;, delete= true, exclude = {\u0026#34;.*\u0026#34;}, delay=1, rsync = { binary = \u0026#34;/usr/bin/rsync\u0026#34;, archive = true, compress = true, verbose = true, password_file=\u0026#34;/etc/rsync.pas\u0026#34;, _extra={\u0026#34;--bwlimit=200\u0026#34;} } } 3.启动服务 [root@nfs-31 /nfs-data]#systemctl start lsryncd [root@nfs-31 /nfs-data]# [root@nfs-31 /nfs-data]#systemctl start lsyncd [root@nfs-31 /nfs-data]# [root@nfs-31 /nfs-data]#systemctl status lsyncd 4.使用工具 [root@nfs-31 /nfs-data]#for i in {1..100};do echo ${i} \u0026gt; ${i}.log;sleep 0.1;done 实战小项目 三台机器（回快照）\nweb-7 （1.web-7的网页根目录数据来自于nfs共享目录/nfs-nginx-data/ ，要求该目录下的所有用户映射为www（uid=11111），允许读写） （整理为脚本）\n1 2 3 4 5 6 7 1.安装软件 yum install -y nginx yum install -y rsync yum install nfs-utils rpcbind -y 2.创建挂载点 mkdir -p /test-nfs [root@nfs-31 ~]#mount -t nfs 172.16.1.31:/nfs-nginx-data /test-nfs nfs-31 （2.在web-7的nginx网站根目录下创建首页文件后，触发实时同步，备份到rsync-41机器上） （整理为脚本）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 1.因为我现在啥软件也没有，所以现在先安装软件 [root@nfs-31 ~]#yum install -y nginx [root@nfs-31 ~]#yum install -y rsync [root@nfs-31 ~]yum install nfs-utils rpcbind -y 2.接下来要把nfs-31上的数据共享到web-7目录下 先创建共享目录 [root@nfs-31 ~]#mkdir /nfs-nginx-data 修改配置文件 cat \u0026gt; /etc/rsyncd.conf \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; uid = www gid = www port = 873 fake super = yes use chroot = no max connections = 200 timeout = 600 ignore errors read only = false list = false auth users = rsync_backup secrets file = /etc/rsync.passwd log file = /var/log/rsyncd.log ##################################### [backup] comment = this is first backup dir path = /backup [data] comment = this is second backup dir,to website data.. path = /data EOF 再创建用户 useradd -u 11111 -M -s /sbin/nologin www 修改权限 [root@nfs-31 ~]#chown -R www:www /data/ [root@nfs-31 ~]#chown -R www:www /backup/ [root@nfs-31 ~]#ll -d /data /backup/ drwxr-xr-x 2 www www 6 3月 11 22:39 /backup/ drwxr-xr-x 2 www www 6 3月 11 22:39 /data .创建密码文件，写入账户和密码，用于和客户端连接时候的认证 [root@nfs-31 ~]#vim /etc/rsync.passwd 2.写入账户密码 [root@nfs-31 ~]#cat /etc/rsync.passwd rsync_backup:szm666 3.这一步，非常重要，rsync要求降低密码文件的权限，且必须是600 [root@nfs-31 ~]#chmod 600 /etc/rsync.passwd [root@nfs-31 ~]#ll /etc/rsync.passwd -rw------- 1 root root 23 Apr 20 11:36 /etc/rsync.passwd [root@nfs-31 ~]#systemctl start rpcbind.service [root@nfs-31 ~]#systemctl start rpcbind.socket [root@nfs-31 ~]#systemctl start nfs nfs配置文件修改或，无需重启，使用重新加载，方式NFS端口号再次变化[root@nfs-31 ~]#systemctl reload nfs rsync-41 （3.数据备份服务器） （整理为脚本）\n1 [root@rsync-41 ~]#yum install rsync ","date":"2025-04-14T15:38:22+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/","title":"实时同步"},{"content":"nfs前言 用于Linux之间进行文件共享则是用NFS服务(Network FileSystem) 目的在于让不同的机器，不同的操作系统可以彼此分享各自的文件数据 NFS服务可以将远程Linux系统上的文件共享资源挂载到本地机器的目录上 NFS很像Windows系统的网络共享、安全功能、网络驱动器映射 一般情况下，中小型网站集群架构后端通常用 NFS数据共享，如果大型网络集群，还会用更复杂的文件系统，如GlusterFS、FastDFS等。 NFS系统已有30年发展历史，代表了一个稳定的网络文件系统，具备可扩展，高性能等特点。 由于网络速度的加快和延迟的减少，NFS系统一直是通过网络提供文件系统的不错的选择，特别是在中小型互联网企业用的广泛。 NFS在企业的应用架构 在企业集群架构的工作场景中，NFS网络文件系统一般被用来存储共享视频、图片、静态文件，通常网站用 户上传的文件也都会放在NFS共享里，例如BBS产品(论坛)产生的图片、附件、头像等，然后前端所有的节 点访问静态资源时都会读取NFS存储上的资源。 阿里云等公有云平台的NAS就是云版的NFS服务应用。 这个奔驰官网，需要展示大量的图片，动态图，html网页文件，这些都是存储在服务器上的。 企业生产集群为什么需要共享存储 先看一下如果没有共享存储的问题\nA用户上传图片到web01服务器，然后用户B访该图片，结果B的请求被负载均衡分发到了Web02,但是由于 没有配置共享存储，web02没有该图片，导致用户B看不到该资源，用户心理很不爽呀。\n那么如果配置了共享存储，无论A用户上传的图片是发给了web01还是其他，最终都会存储到共享存储上， 用户B再访问该图片的时候，无论请求被负载均衡发给了web01,web02、web03最终都会去共享存储上寻 找资源，这样也就能够访问到资源了。\n这个共享存储对于中小企业，也就是使用服务器配置NFS网络文件共享系统实现。\n任务：用NFS完成网站共享存储 什么是NFS共享存储 1 2 3 4 5 6 7 8 9 10 11 network file system 网络文件系统 NFS主要使用在局域网下，让不同的主机之间可以共享文件、或者目录数据 主要用于linux系统上实现文件共享的一种协议，其客户端主要是Linux 没有用户认证机制，且数据在网络上传送的时候是明文传送，一般只能在局域网中使用 不需要输入账号密码，在配置文件中，定义好可访问该NFS的机器，ip地址即可，如果需要进行安全认证， 还得借助其他用户认证的插件，结合NFS，提高安全性 支持多节点同时挂载及并发写入 NFS服务架构(NFS原理) NFS程序运行后，产生如下组件 RPC(Remote Procedure Call Protocol):远程过程调用协议，它是一种通过网络从远程计算机程序 上请求服务，不需要了解底层网络技术的协议。 rpcbind//负责NFS的数据传输，远程过程调用tcpludp协议端口11 nfs-utils //控制共享哪些文件，权限管理 什么是RPC RPC(Remote Procedure Call)远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需 要了解底层网络技术的协议。 下类个简单的例子来理解RPC： 1 2 3 4 5 6 7 远程过程调用，相对应的就是，本地过程调用。 rpc一般是开发中的网络编程知识 1.本地写好了一个代码文件，如hello-world.py ，本地运行该程序，这就是本地过程调用（执行程序，拿到结果） 2.远程过程调用 将代码文件放在远程服务器上，在自己笔记本上，远程调用、执行该代码文件，执行结果会通过网络把数据发回来，这就是远程过程调用 NFS和RPC关系 我们已知NFS是通过网络来进行数据传输(网络文件系统),因此NFS会使用 一些port来传输数据。 关键点： 但是NFS在传输数据的时，使用的端口是随机选择(可以重启NFS服务查看 端口)。 既然NFS是随机端口选择(好比银行的取钱窗口总发生变化，你知道几号窗口 是取钱业务吗?) 那么NFS在传输数据的时候，怎么知道NFS服务器使用的端口是哪个呢? 答案就是NFS使用的RPC(Remote Procedure Call,就是远程过程调用) 协议来实现的。 NFS结合rpcbind通信原理 1 2 3 4 5 6 7 8 1.NFS服务端启动后、将自己的端口信息，注册到rpcbind服务中 2.NFS客户端通过TCP/IP的方式，连接到NFS服务端提供的rpcbind服务，并且从该服务中获取具体的端口信息 3.NFS客户端拿到具体端口信息后，将自己需要执行的函数，通过网络发给NFS服务端对应的端口 4.NFS服务端接收到请求后，通过rpc.nfsd进程判断该客户端是否有权限连接 5.NFS服务端的rpc.mount进程判断客户端是否有对应的操作权限 6.最终NFS服务端会将客户端请求的函数，识别为本地可以执行的命令，传递给内核、最终内核驱动硬件 结论:nfs的客户端、服务端之间的通信基于rpc协议，且必须运行rpcbind服务 rpcbind服务 该服务是用于，nfs启动后，将端口号，注册到这个rpcbind服务中\n图解NFS工作原理 nfs工作流程图原理 NFS服务端部署 机器准备\n1 2 3 4 5 6 nfs服务端 nfs-31 多个nfs客户端 web-7 最终完成效果: 让web-7 可以读写 nfs共享的静态文件数据 安装nfs服务，需要安装如下软件包: ·nfs-utils:NFS服务的主程序，包括了rpc.nfsd、rpc.mountd这两个守护进 程以及相关文档，命令 ·rpcbind:是centos7/6环境下的RPC程序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 1.准备好nfs服务端机器 2.安装nfs工具包 [root@nfs-31 ~]#yum install nfs-utils rpcbind -y 3.修改配置文件，填写为你需要的共享参数即可 先学学该软件的配置文件语法，每一个软件的配置文件语法，可能都不相同 [root@nfs-31 ~]#cat /etc/exports 需要你填入如下配置，定义共享文件，以及限定访问的ip主机，以及共享的参数，权限设置 4. 设置一个共享 /nfs-data文件夹，运行172.16.1.0局域网内的用户可以访问，权限是只读 [root@nfs-31 ~]#mkdir /nfs-data [root@nfs-31 ~]#vim /etc/exports /nfs-data 172.16.1.0/24(ro) 5.注意要先启动rpcbind服务 确保如下2个进程都运行，rpc服务才正常，如果想停止rpc服务，也是关闭这俩进程 rpcbind.service rpcbind.socket [root@nfs-31 ~]#systemctl start rpcbind.service 一定要先启动rpc服务 [root@nfs-31 ~]#systemctl start rpcbind.socket [root@nfs-31 ~]#netstat -tunlp 6.运行nfs服务 ，每次重启nfs，nfs端口号，不断变化中 [root@nfs-31 ~]#systemctl start nfs 7.检查nfs共享的情况 [root@nfs-31 ~]#showmount -e 172.16.1.31 Export list for 172.16.1.31: /nfs-data 172.16.1.0/24 创建测试数据 [root@nfs-31 ~]#touch /nfs-data/123.txt 8.客户端可以去挂载使用了 9.修改服务端的nfs配置文件，允许读写操作 这里需要添加参数，让挂载后的客户端，身份改为匿名用户，降低权限，以及设置对应的读写权限 root_squash 这个参数，就是将客户端机器在nfs中创建的数据，用于改为nfsnobody [root@nfs-31 ~]#cat /etc/exports /nfs-data 172.16.1.0/24(rw,root_squash) 还需要修改该共享文件夹的权限 [root@nfs-31 ~]#chown -R nfsnobody:nfsnobody /nfs-data 10.nfs配置文件修改或，无需重启，使用重新加载，方式NFS端口号再次变化 方法1 [root@nfs-31 ~]#systemctl reload nfs 方法2，更新nfs的配置文件设置 [root@nfs-31 ~]#exportfs -r 配置文件默认语法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 默认配置文件路径是/etc/exports exports配置文件语法 NFS共享目录 NFS客户端地址(参数1、参数2...) 客户点地址2（参数1、参数2...） 例如 / hostname1(rw) hostname2(rw,no_root_squash) /pub *(rw) /home/chao 123.206.16.61(ro) 参数解释 1.NFS共享目录：为NFS服务器要共享的实际目录，必须绝对路径，注意目录的本地权限，如果要读写共享，要让本地目录可以被NFS客户端的(nfsnobody)读写 2.NFS客户端地址，也就是NFS服务器端授权可以访问共享目录的客户端地址，详见下表 3.权限参数，对授权的NFS客户端访问权限设置，见下表 nfs客户端地址说明 客户端地址 具体地址 说明 单一客户端 192.168.178.142 用的少 整个网段 192.168.178.0/24 24表示子网掩码255.255.255.0，指定网段，用的较多192.168.178.1~ 192.168.178.254 授权域名客户端 nfs.cn 弃用 授权整个域名客户端 *.cn 弃用 关于nfs挂载参数所有解释 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 ro 只读 rw 读写 root_squash 当nfs客户端以root访问时，它的权限映射为NFS服务端的匿名用户，它的用户ID/GID会变成nfsnobody no_root_squash 同上，但映射客户端的root为服务器的root，不安全，避免使用 all_squash 所有nfs客户端用户映射为匿名用户，生产常用参数，降低用户权限，增大安全性。 sync 数据同步写入到内存与硬盘，优点数据安全，缺点性能较差 async 数据写入到内存，再写入硬盘，效率高，但可能内存数据会丢 /etc/exports man 5 exports 共享目录 共享选项 /nfs/share *(ro,sync) 共享主机： * ：代表所有主机 192.168.0.0/24：代表共享给某个网段 192.168.0.0/24(rw) 192.168.1.0/24(ro) :代表共享给不同网段 192.168.0.254：共享给某个IP *.yuchaoit.cn:代表共享给某个域下的所有主机 共享选项： ro：只读，不常用 rw：读写 sync：实时同步，直接写入磁盘 async：异步，先缓存在内存再同步磁盘 anonuid：设置访问nfs服务的用户的uid，uid需要在/etc/passwd中存在 anongid：设置访问nfs服务的用户的gid root_squash ：默认选项 root用户创建的文件的属主和属组都变成nfsnobody,其他人nfs-server端是它自己，client端是nobody。 no_root_squash：root用户创建的文件属主和属组还是root，其他人server端是它自己uid，client端是nobody。 all_squash： 不管是root还是其他普通用户创建的文件的属主和属组都是nfsnobody 说明： 请用如下的参数，即可，生产环境用这个 anonuid和anongid参数和all_squash一起使用。 all_squash表示不管是root还是其他普通用户从客户端所创建的文件在服务器端的拥有者和所属组都是nfsnobody；服务端为了对文件做相应管理，可以设置anonuid和anongid进而指定文件的拥有者和所属组 NFS客户端部署 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 1.查看机器的挂载情况 mount -l 2. 查看磁盘分区挂载情况 df -h 3.挂载nfs，查看nfs [root@web-7 ~]#yum install nfs-utils -y [root@web-7 ~]#mount -t nfs 172.16.1.31:/nfs-data /test-nfs [root@web-7 ~]#df -h 4.尝试读写数据 [root@web-7 ~]#ls /test-nfs touch /test-nfs/hello.log # 发现没有权限 5.更新nfs服务端的读写权限后，再次测试数据操作 [root@web-7 ~]# [root@web-7 ~]#touch /test-nfs/456.txt [root@web-7 ~]# [root@web-7 ~]#ll /test-nfs/ total 0 -rw-r--r-- 1 nfsnobody nfsnobody 0 Apr 22 10:58 123.txt -rw-r--r-- 1 nfsnobody nfsnobody 0 Apr 22 11:12 456.txt [root@web-7 ~]#echo \u0026#34;今天又是氪金的一天\u0026#34; \u0026gt;\u0026gt; /test-nfs/123.txt [root@web-7 ~]#cat /test-nfs/123.txt 今天又是氪金的一天 [root@web-7 ~]#cat /test-nfs/123.txt 今天又是氪金的一天 冲他个十万吧 勇士 NFS结合nginx实现共享存储 安装部署nfs服务端\n生产环境下的参数rw,sync,all_squash,anonuid,anongid\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 rw,sync, all_squash ,将web-7的任意用户root,bob01,，在该共享目录下的操作，全部改为nfsnobody以实现权限控制 web-7 /test-nfs 172.16.1.31:/nfs-data 无论是root去读写 、/test-nfs 还是bob01读写 /test-nfs 创建的数据，都会被改为user，group都是 默认的nfsnobody anonuid=id号 anongid= 集合这俩参数，就可以限制在 该nfs共享目录下的所有用户操作，统一被限制为了某个指定的用户 需求说明 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 任务需求 1.nginx的启动用户必须是www，uid是 1500，不允许登录 [root@web-7 ~]#useradd www -u 1500 -M -s /sbin/nologin 1.0 安装nginx [root@web-7 ~]#yum install nginx -y 1.1 修改nginx配置文件，指定是www用户运行 [root@web-7 ~]#vim /etc/nginx/nginx.conf 修改如下 user www; 1.2 启动nginx [root@web-7 ~]#systemctl start nginx 1.3 检查nginx进程 [root@web-7 ~]#ps -ef|grep nginx root 5038 1 0 12:07 ? 00:00:00 nginx: master process /usr/sbin/nginx www 5040 5038 0 12:07 ? 00:00:00 nginx: worker process 2.nfs共享存储用户也是www，uid是 1500，不允许登录，允许读写 修改nfs配置文件如下，限定客户端在该目录中的操作，权限都被转化为www用户 限制nginx机器才能访问 [root@nfs-31 ~]#mkdir /nfs-nginx [root@nfs-31 ~]#useradd www -u 1500 -M -s /sbin/nologin 修改配置文件 [root@nfs-31 ~]#cat /etc/exports /nfs-data *(rw,all_squash) /nfs-nginx 172.16.1.7(rw,sync,all_squash,anonuid=1500,anongid=1500) 3.重新加载nfs（reload是针对已经有进程在运行了，重新读取配置文件） 你是新安装的机器nfs，还能reload吗？ [root@nfs-31 ~]#systemctl reload nfs 4.修改共享目录的属主、属组为www [root@nfs-31 /nfs-nginx]#chown -R www.www /nfs-nginx/ [root@nfs-31 /nfs-nginx]#ll -d /nfs-nginx/ drwxr-xr-x 2 www www 6 Apr 22 12:09 /nfs-nginx/ 3.nginx网站可以正常读写共享存储资料 先挂载nfs mount -t nfs 172.16.1.31:/nfs-nginx /usr/share/nginx/html/ [root@web-7 ~]#df -h |grep nginx 172.16.1.31:/nfs-nginx 17G 1.6G 16G 10% /usr/share/nginx/html 客户端生成网页，和图片等静态资源，查看是否写入到NFS服务端 [root@web-7 ~]#vim /usr/share/nginx/html/index.html 模拟用普通用户，到该nginx目录下，生成一个数据图片 [client01@web-7 /usr/share/nginx/html]$wget -O /usr/share/nginx/html/liyunlong.jpg https://inews.gtimg.com/newsapp_bt/0/8823765779/1000 4.修改nginx网页，加载该用户自己创建的图片信息吗 [client01@web-7 /usr/share/nginx/html]$cat index.html \u0026lt;meta charset=utf-8\u0026gt; 把我李云龙的意大利炮拿来 \u0026lt;img src=\u0026#39;./liyunlong.jpg\u0026#39;\u0026gt; 5.模拟用户访问该nginx网站 http://10.0.0.7/ NFS故障案例 1.客户端未挂载NFS\n1 2 3 4 5 6 7 [root@web-7 ~]# [root@web-7 ~]#umount /usr/share/nginx/html [root@web-7 ~]# 重新挂载 mount -t nfs 172.16.1.31:/nfs-nginx /usr/share/nginx/html/ 2.服务端出问题，。nfs挂了\n导致nginx页面卡死，nginx网页目录操作也都卡死\n此时明确了共享存储出问题了\n去共享存储NFS服务器上找原因\n1 2 发现nfs挂了，重启即可 systemctl restart nfs 3.nfs修复后，客户端的挂载可以恢复\n4.如果真的nfs死机了，且暂时无法恢复，你还得快速恢复网站的业务，可以强制取消挂载\n1 2 3 4 5 6 7 8 使用强制卸载参数 ，先看看挂载了什么 mount -l |grep nfs umount -fl 挂载点 # 取消挂载即可 然后最终还是要以恢复NFS为主 ","date":"2025-04-14T15:36:22+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/nfs%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"NFS学习笔记"},{"content":"第1章 Rsync介绍 备份是太常见、且太重要的一个日常工作了。\n备份源码、文档、数据库、等等。\n类似cp命令拷贝，但是支持服务器之间的网络拷贝，且保证安全性。\nRsync是一款开源的、快速的、多功能的、可实现全量及增量的本地或远程数据同步备份的优秀工具。并且 可以不进行改变原有数据的属性信息，实现数据的备份迁移特性。\nRsync软件适用于unix/linux/windows等多种操作系统平台。\nRsync是一个快速和非常通用的文件复制工具。它能本地复制，远程复制，或者远程守护进程方式复制。\n它提供了大量的参数来控制其行为的各个方面，并且允许非常灵活的方式来实现文件的传输复制。它以其 delta-transfer算法闻名。减少通过网络数据发送数量，利用只发送源文件和目标文件之间的差异信息，从而 实现数据的增量同步复制。\nRsync被广泛用于数据备份和镜像，并且作为一种改进后的复制命令用于日常运维。\nRsync具备使本地和远程两台主机之间的数据快速复制，远程备份的功能，Rsync命令本身即可实现异地主机 复制数据，功能类似scp又优于scp,scp每次都是全量备份，rsync可以实现增量拷贝(和scp一样都是基于 ssh服务传输),Rsync软件还支持配置守护进程，实现异机数据复制。\n增量复制是Rsync—特点，优于scp,cp命令。\nRsync实现如下功能\n本地数据同步复制，效果如cp 远程数据同步复制，如scp 本地数据删除，如rm 远程数据查看，如ls 1.rsync三种工作模式 本地模式，类似cp 远程模式，常用，类似scp,不同的机器之间，通过网络拷贝数据 后台服务模式，常用，用于实时数据同步，安全性更高 2.rsync的备份方式 全量备份\n就是完全备份，所有指定的客户端的数据，全部被备份到server01机器上(效率太低，重复性备份文件)\n增量备份\nrsync自动检测，只会将新增加的文件，备份到server01下，而不会重复备份已存在的数据，备份效率高\n3.rsync的备份架构 第2章 Rsync本地模式和远程模式 1.命令说明 单纯通过rsync的命令，来实现数据目录A 拷贝到数据目录B\n也就是模拟cp的用法 很简单\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 rsync [选项] 源数据 目的数据 1.安装 [root@rsync-41 ~]#yum install rsync -y 2.命令语法，分几个模式 - 本地模式 rsync 参数 源路径 目标路径 rsync -xxxxx /var/log /tmp - 远程模式，推送方式，把自己的数据推送到另一台机器上（上传） 语法1 ，rsync默认走ssh协议 rsync 参数 源路径 user@ip:目标路径 [root@rsync-41 ~]#rsync -avzP /var/log/ root@10.0.0.31:/tmp/ 语法2 rsync 参数 源路径 user@ip::目标路径 - 远程模式，拉取方式，拉取别人机器的数据到自己的机器上（下载） rsync 参数 user@ip:源路径 目标路径 rsync 参数 user@ip::源路径目标路径 [root@rsync-41 ~]#rsync -avzP root@10.0.0.31:/var/log/ /tmp/ 参数解释 -v 详细模式输出 -a 归档模式，递归的方式传输文件，并保持文件的属性，等同于 -rlptgoD -r 递归拷贝目录 -l 保留软链接 -p 保留原有权限 -t 保留原有时间（修改） -g 保留属组权限 -o 保留属主权限 -D 等于--devices --specials 表示支持b,c,s,p类型的文件 -R 保留相对路径 -H 保留硬链接 -A 保留ACL策略 -e 指定要执行的远程shell命令 -E 保留可执行权限 -X 保留扩展属性信息 a属性 比较常用的组合参数 rsync -avzP -a 保持文件原有属性 -v 显示传输细节情况 -z 对传输数据压缩传输 -P 显示文件传输的进度信息 2.本地模式 linux机器本身，数据来回发送\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 对文件同步 把本地的的/var/log/messages 文件 拷贝到/opt下 拷贝单个文件 [root@rsync-41 ~]#rsync -avzP /var/log/messages /opt sending incremental file list messages 985,500 100% 56.79MB/s 0:00:00 (xfr#1, to-chk=0/1) sent 123,300 bytes received 35 bytes 246,670.00 bytes/sec total size is 985,500 speedup is 7.99 拷贝单个大文件，拷贝大文件时，要注意限速，否则占用磁盘IO太多，以及如果是网络传输的话，占用网络带宽，会导致其他程序受影响所以rsync这样的备份服务，都是在夜里，凌晨操作，尽量不影响其他程序 先生成一个5G文件 [root@rsync-41 ~]#dd bs=100M count=50 if=/dev/zero of=/var/log/my_self.log [root@rsync-41 ~]#rsync -avzP /var/log/my_self.log /opt 查看磁盘的读写IO情况 [root@rsync-41 ~]#iotop `借助--bwlimit=xx（单位MB）限制单个大文件的传输，速度只给他20M每秒` [root@rsync-41 ~]#rsync -avzP --bwlimit=20 /var/log/my_self.log /opt sending incremental file list my_self.log 393,117,696 7% 20.14MB/s 0:03:55 扩展\ndd: 是一个用于复制和转换文件命令\nif=/dev/zero: 指定输入文件（input file）为 /dev/zero。/dev/zero 是一个特殊的设备文件，它只生成空字符（null bytes，即值为 0 的字节）。 of=ceshi.txt: 指定输出文件（output file）为 ceshi.txt。这意味着 dd 命令将把从 /dev/zero 读取的数据写入到 ceshi.txt 文件中 count=1: 表示只复制 1 个块（block）的数据。 bs=10M: 设置块大小（block size）为 10 兆字节（Megabytes） 这种操作通常用于快速生成一个指定大小的文件，尤其是当你需要一个大文件来进行某种测试或填充磁盘空间时。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 对目录同步（注意语法的区别） 拷贝后的数据，会携带该目录本身 [root@rsync-41 ~]#rsync -avzP /var/log /opt 不拷贝该目录本身，仅拷贝目录下的数据 [root@rsync-41 ~]#rsync -avzP /var/log/ /opt 测试文件夹的增量拷贝 [root@rsync-41 ~]#rsync -avzP /test1/ /test2 sending incremental file list sent 118 bytes received 12 bytes 260.00 bytes/sec total size is 0 speedup is 0.00 [root@rsync-41 ~]#echo \u0026#34;123\u0026#34; \u0026gt;/test1/1.png [root@rsync-41 ~]#rsync -avzP /test1/ /test2 sending incremental file list 1.png 4 100% 0.00kB/s 0:00:00 (xfr#1, to-chk=4/6) sent 175 bytes received 35 bytes 420.00 bytes/sec total size is 4 speedup is 0.02 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 无差异化拷贝 使用--delete参数 将目标目录的数据清空，保证完全和源目录的数据一致 [root@rsync-41 /test2]#rsync -azvP --delete /test1/ /test2/ sending incremental file list deleting 行者孙.png ./ 白龙马.png 0 100% 0.00kB/s 0:00:00 (xfr#1, to-chk=0/12) sent 269 bytes received 55 bytes 648.00 bytes/sec total size is 4 speedup is 0.01 [root@rsync-41 /test2]#ls /test1/ 1.png 2.png 3.png 4.png 5.png 孙悟空1 孙悟空2 孙悟空3 孙悟空4 孙悟空5 白龙马.png [root@rsync-41 /test2]#ls /test2 1.png 2.png 3.png 4.png 5.png 孙悟空1 孙悟空2 孙悟空3 孙悟空4 孙悟空5 白龙马.png 3.远程模式 1 2 把rsync-41 /root下的数据 拷贝到 nfs-31 /tmp下 1 2 3 4 5 6 7 8 9 PUSH 推送模式，上传模式 把rsync-41 /root下的数据，拷贝到 nfs-31 /tmp下 登录rsync41 用ip形式、再用主机名形式 添加无差异化参数，该参数，慎用！搞清楚了你在做什么！ [root@rsync-41 ~]#rsync -avzP --delete /root/ root@172.16.1.31:/tmp/ 1 2 3 4 5 6 PULL 拉取模式（你要琢磨，数据最终放在了哪） 把rsync-41 /root下的数据，拷贝到 nfs-31 /tmp下 [root@nfs-31 ~]#rsync -avzP root@172.16.1.41:/root/ /tmp/ 拉取rsync41的/etc/passwd文件到 nfs-31的/opt下，使用主机名通信 [root@nfs-31 ~]#rsync -avzP root@rsync-41:/etc/passwd /opt/ 1 2 3 4 5 传输整个目录,包含目录本身 [root@nfs-31 ~]#rsync -avzP root@172.16.1.41:/root /tmp/ 只传输目录下的文件,不包含目录本身 [root@nfs-31 ~]#rsync -avzP root@172.16.1.41:/root/ /tmp/ 1 2 3 4 不同主机之间同步数据 --delete [root@nfs-31 ~]#rsync -avzP --delete root@172.16.1.41:/root /tmp/ 注意:如果/和一个空目录进行完全同步,那么效果和删根目录一样 1 2 3 4 5 6 7 注意:传输过程不限速导致带宽被占满 ,--bwlimit=50 远程传输 nfs-31下的 /tmp/2G.log 备份到 rsync-41的/opt下 [root@nfs-31 ~]#dd bs=100M count=20 if=/dev/zero of=/tmp/2G.log [root@nfs-31 ~]#rsync -avzP /tmp/2G.log root@172.16.1.41:/opt 1 2 远程备份文件，且改名 [root@nfs-31 /tmp]#rsync -avzP /tmp/2G.log root@172.16.1.41:/opt/2G.logggggggggggggggggggggg 1 2 3 4 远程传输 nfs-31下的 /tmp/2G.log 备份到 rsync-41的/opt下，且是无差异化备份 等于清空原有/opt下的数据 [root@nfs-31 ~]#rsync -avzP --delete /tmp/2G.log root@172.16.1.41:/opt/2G.log 第3章 Rsync服务模式-服务端配置 0.为什么需要服务模式 ​\tRsync 借助 SSH 协议同步数据存在的缺陷: ​\t1.使用系统用户（不安全） /etc/passwd ​\t2.使用普通用户（会导致权限不足情况） ​\t3.守护进程传输方式: rsync 自身非常重要的功能(不使用系统用户，更加安全)\n1.安装rsync 1 [root@rsync-41 ~]#yum install rsync -y 2.修改配置文件 复制粘贴如下代码即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [root@rsync-41 ~]#cat \u0026gt; /etc/rsyncd.conf \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; uid = www gid = www port = 873 fake super = yes use chroot = no max connections = 200 timeout = 600 ignore errors read only = false list = false auth users = rsync_backup secrets file = /etc/rsync.passwd log file = /var/log/rsyncd.log ##################################### [backup] comment = this is first backup dir path = /backup [data] comment = this is second backup dir,to website data.. path = /data EOF 配置信息说明：\n3.创建用户以及数据目录 1 2 3 4 5 6 7 8 9 10 11 12 13 根据你的配置文件中定义的信息，创建对应的用户，备份的目录 该无法登录的用户，只是用于运行进程的账户 [root@rsync-41 ~]#useradd -u 1000 -M -s /sbin/nologin www 创建配置文件中定义的2个备份目录 [root@rsync-41 ~]#mkdir -p /data/ /backup/ 修改备份目录的权限 [root@rsync-41 ~]#chown -R www:www /data/ [root@rsync-41 ~]#chown -R www:www /backup/ [root@rsync-41 ~]#ll -d /data /backup/ drwxr-xr-x 2 www www 6 Apr 20 11:34 /backup/ drwxr-xr-x 2 www www 6 Apr 20 11:34 /data 4.创建rsync专用的账户密码（这一步很重要，有错基本也是来这排查） 1 2 3 4 5 6 7 8 9 10 11 1.创建密码文件，写入账户和密码，用于和客户端连接时候的认证 [root@rsync-41 ~]#vim /etc/rsync.passwd 2.写入账户密码 [root@rsync-41 ~]#cat /etc/rsync.passwd rsync_backup:lj666 3.这一步，非常重要，rsync要求降低密码文件的权限，且必须是600 [root@rsync-41 ~]#chmod 600 /etc/rsync.passwd [root@rsync-41 ~]#ll /etc/rsync.passwd -rw------- 1 root root 23 Apr 20 11:36 /etc/rsync.passwd 5.加入开机自启动 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 设置rsyncd服务，运行，且开机自启 [root@rsync-41 ~]#systemctl start rsyncd 检查rsyncd服务是否运行，以及该服务的运行日志 [root@rsync-41 ~]#systemctl status rsyncd ● rsyncd.service - fast remote file copy program daemon Loaded: loaded (/usr/lib/systemd/system/rsyncd.service; disabled; vendor preset: disabled) Active: active (running) since Wed 2022-04-20 11:46:57 CST; 4s ago Main PID: 6078 (rsync) CGroup: /system.slice/rsyncd.service └─6078 /usr/bin/rsync --daemon --no-detach Apr 20 11:46:57 rsync-41 systemd[1]: Started fast remote file copy program daemon. Apr 20 11:46:57 rsync-41 systemd[1]: Starting fast remote file copy program daemon... Apr 20 11:46:57 rsync-41 rsyncd[6078]: params.c:Parameter() - Ignoring badly formed line in config file: ignore errors Apr 20 11:46:57 rsync-41 rsyncd[6078]: rsyncd version 3.1.2 starting, listening on port 873 6.检查服务是否运行 1 2 3 4 5 6 7 8 9 10 11 12 [root@rsync-41 ~]#systemctl status rsyncd # 无论是学习期间还是上班了，都养成好习惯 # 给别人启动了某程序后，给自己启动某程序 务必去检查，验证是否正确 [root@rsync-41 ~]#ps -ef|grep \u0026#39;rsync\u0026#39; | grep -v \u0026#39;grep\u0026#39; root 6078 1 0 11:46 ? 00:00:00 /usr/bin/rsync --daemon --no-detach [root@rsync-41 ~]#netstat -tunlp|grep rsync tcp 0 0 0.0.0.0:873 0.0.0.0:* LISTEN 6078/rsync tcp6 0 0 :::873 :::* LISTEN 6078/rsync 第4章 Rsync服务模式-客户端配置 安装rsync\n1 [root@nfs-31 ~]#yum install rsync -y 第5章 操作服务端rsync-41的数据 推送，备份，发送nfs-31的数据发给rsync-41 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 把客户端的数据，发送给服务端的backup备份模块下 把客户端的 /tmp/200M.log 备份，发送到rsync-41机器上的 backup模块下 rsync -avzP /tmp/200M.log 账户@主机名::模块名 默认无密码变量，也无密码文件，需要你自己输入该rsync_backup虚拟用户的密码 需要交互式的输入密码，无法再脚本中使用rsync同步命令 rsync基本都是和脚本结合使用 [root@nfs-31 ~]#rsync -avzP /tmp/200M.log rsync_backup@rsync-41::backup 非交互式密码的操作，如下2个方法 1. 生成密码文件，每次连接都指定这个密码文件（在客户端生成） [root@nfs-31 ~]#echo \u0026#39;lj666\u0026#39; \u0026gt; /etc/my_rsync.pwd 还必须降低密码文件的权限才行，必须是600 [root@nfs-31 ~]#chmod 600 /etc/my_rsync.pwd 此时可以传输数据了，往data模块下传输 [root@nfs-31 ~]#rsync -avzP --password-file=/etc/my_rsync.pwd /tmp/200M.log rsync_backup@rsync-41::data 如果是脚本中的话，去掉vP显示过程的参数去掉 [root@nfs-31 ~]#rsync -az --password-file=/etc/my_rsync.pwd /tmp/200M.log rsync_backup@rsync-41::data 2. 生成密码变量，让当前系统中存在叫做 RSYNC_PASSWORD 这个变量，以及变量的值，是配置文件中的密码即可 [root@nfs-31 ~]#export RSYNC_PASSWORD=\u0026#39;lj666\u0026#39; [root@nfs-31 ~]#rsync -avzP /tmp/200M.log rsync_backup@rsync-41::backup 上传过程中文件改名 [root@nfs-31 ~]#rsync -avzP /tmp/200M.log rsync_backup@rsync-41::backup/11111.log 下载备份服务器的数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 rsync -avzP 账户@主机名::模块名 下载的目标路径 如果需要输入密码，则可以撤销这个密码变量 [root@nfs-31 ~]#unset RSYNC_PASSWORD 或者重新登录，只要密码变量失效，就必须得输入密码了，或者使用密码文件 [root@nfs-31 ~]#rsync -avzP rsync_backup@rsync-41::backup /tmp/ 非交互式的密码认证方式 1，使用密码变量 [root@nfs-31 ~]#export RSYNC_PASSWORD=\u0026#39;lj666\u0026#39; 2.指定密码文件 [root@nfs-31 ~]#rsync -avzP --password-file=/etc/my_rsync.pwd rsync_backup@rsync-41::backup /tmp/ 下载过程中文件改名 [root@nfs-31 ~]#rsync -avzP --password-file=/etc/my_rsync.pwd rsync_backup@rsync-41::backup/222222222.log /tmp/ 第6章 关于rsync的常见错误 rsync由于配置步骤比较细节，比较坑比较多，你可能会遇见各种错误\nRsync服务端排错思路 1.检查rsync服务端的配置文件路径是否正确：/etc/rsyncd.conf 2.查看配置文件的host allow ,host deny允许的ip网段是否允许客户端访问 3.查看配置文件中的path参数路径是否存在，权限是否正确(和配置文件的UUID参数对应) 4.查看rsync服务是否启动，端口、进程是否存活 5.查看iptables防火墙、selinux是否允许rsync服务通过，或是关闭 6.查看服务端rsync配置文件的密码文件，权限是否600,格式，语法是否正确，且和配置文件的secrect files参数对应 7.如果是推送数据，要查看配置rsyncd.conf中的用户对该rsync模块下的文件是否可以读取\nRsync客户端排错 1.查看rsync客户端配置的密码文件权限是否600,密码文件格式是否正确，是否和服务端的密码一致 2.尝试telnet连接rsync服务端的873端口，检测服务是否可以连接 3.客户端执行命令语法要检查，细心\n","date":"2025-04-14T15:26:03+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/rsync%E6%9C%8D%E5%8A%A1/","title":"Rsync服务"},{"content":"文件共享服务 文件共享服务方案有很多，了解即可\nftp（简单文件传输服务）\n提供用户认证机制 可以输入账号密码 python -m SimpleHTTPServer\n1 2 平时，简易的快速进行文件下载，下载服务器上的资料 python -m SimpleHTTPServer nginx也提供了文件下载的功能\n提供用户认证机制 反向代理，负载均衡 web服务器，静态文件服务器的作用 如ftp服务器的作用 samba(linux和windows之间共享数据)\n提供用户认证机制 nfs（实际工作中主要用这个）\n搭建ftp服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 1.需要安装vsftpd服务 yum install vsftpd -y 2.修改ftp配置文件，设置账号密码，登录ftp服务器，可以查看某文件夹下的数据资料（共享文件夹） 3.创建一个linux的用户（ftp使用linux的用户信息，不靠谱） useradd ops01 设置该用户密码 [root@nfs-31 ~]#echo \u0026#39;123456\u0026#39; | passwd --stdin ops01 Changing password for user ops01. passwd: all authentication tokens updated successfully. 4.修改ftp配置文件，设置用于共享的目录 [root@nfs-31 ~]#rpm -ql vsftpd |grep \u0026#39;.conf$\u0026#39; /etc/vsftpd/vsftpd.conf 4.1 关闭所有的匿名用户功能，不安全 找出和匿名用户相关的配置参数 [root@nfs-31 ~]#grep \u0026#39;^anonymous\u0026#39; /etc/vsftpd/vsftpd.conf anonymous_enable=NO 4.2添加自定义的共享文件夹配置参数，笔记的解释，别写入linux中，写笔记上，否则可能会导致编码不识别，程序出错 直接在文件最低下，添加如下配置 # 配置解释 # local_root=/data/kefu 指定本地用户的默认数据根目录 # chroot_local_user=YES 禁锢本地用户的默认数据目录（禁止用户切换到其他目录） # allow_writeable_chroot=YES 允许ftp用户登录后，可以创建数据 你只需要修改如下三个参数即可 # ftp用户，ops01登录ftp之后，只能看到/test_0224这个文件夹下的数据 ## by myself local_root=/test_0224/ chroot_local_user=YES allow_writeable_chroot=YES 5.创建用于共享的文件夹 mkdir /test_0224/ touch /test_0224/wenjie.png 别忘记修改文件夹的权限，否则无法读取了，修改为刚才自定义的用户 chown -R ops01:ops01 /test_0224/ [root@nfs-31 ~]#ll -d /test_0224/ drwxr-xr-x 2 ops01 ops01 24 Apr 19 14:53 /test_0224/ 6.此时可以重启vsftpd服务 [root@nfs-31 ~]#systemctl restart vsftpd [root@nfs-31 ~]#ps -ef|grep vsftpd root 2221 1 0 15:01 ? 00:00:00 /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf root 2226 1168 0 15:02 pts/0 00:00:00 grep --color=auto vsftpd 使用客户端，验证ftp的登录，数据查看 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 你可以用另一台机器，安装ftp程序，登录vsftpd服务端 yum install ftp -y 登录ftp设备的命令 ftp 机器的ip地址 如 ftp 172.16.1.31 输入账号密码 ops01 123456 进入之后，输入? 查看ftp提供的命令帮助 ftp\u0026gt; pwd 查看当前的ftp目录位置 257 \u0026#34;/\u0026#34; ftp提供的上传下载 下载功能 ftp\u0026gt; get (remote-file) 文杰.png (local-file) 文杰1.png local: 文杰1.png remote: 文杰.png 227 Entering Passive Mode (10,0,0,31,149,223). 150 Opening BINARY mode data connection for 文杰.png (0 bytes). 226 Transfer complete. ftp\u0026gt; 上传功能 ftp\u0026gt; ftp\u0026gt; put (local-file) /opt/4111111.jpg (remote-file) 4444444.jpg local: /opt/4111111.jpg remote: 4444444.jpg 227 Entering Passive Mode (10,0,0,31,185,67). 150 Ok to send data. 226 Transfer complete. windows的ftp客户端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 windows访问ftp 命令行操作 C:\\Users\\lj\u0026gt;ftp ftp\u0026gt; bye C:\\Users\\lj\u0026gt;ftp 10.0.0.31 连接到 10.0.0.31。 220 (vsFTPd 3.0.2) 200 Always in UTF8 mode. 用户(10.0.0.31:(none)): ops01 331 Please specify the password. 密码: 230 Login successful. ftp\u0026gt; ls 200 PORT command successful. Consider using PASV. 150 Here comes the directory listing. 41.png 4444444.jpg 佳强.png 文杰.png 226 Directory send OK. ftp: 收到 48 字节，用时 0.00秒 48000.00千字节/秒。 ftp\u0026gt; 图形化连接ftp设备: 指定协议语法 ftp://10.0.0.31/ ","date":"2025-04-14T15:25:11+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/ftp%E6%9C%8D%E5%8A%A1/","title":"FTP服务"},{"content":"Linux-磁盘管理 1. 磁盘管理工具 (1)硬盘概念结构 机械硬盘：依赖于磁盘上的磁性材料记录数据，内部构造包括磁盘盘片、磁头和主轴电机等。在读写数据时，磁头通过高速旋转的盘片记录或读取磁性信息。由于机械部件的存在，HDD在工作时会产生噪音‌。\n固态硬盘：基于闪存技术（通常是NAND闪存）存储数据，没有任何机械结构。数据通过电子传输直接读写，因此读取速度比HDD快得多，且更为安静‌。\n​\n💡硬盘接口类型：IDE、SATA、SCSI、FC\n磁盘接口类型 说明 IDE（Integrated Device Electronics:电子集成驱动器） 最初硬盘的通用标准，任何电子集成驱动器都属于IDE，甚至包括SCSI； SATA（Serial-ATA：串行ATA） SATA的出现将ATA和IDE区分开来，而IDE则属于Parallel-ATA(并行ATA)。所以，一般来说，IDE称为并口，SATA称为串口。 SCSI（Small Computer System Interface：小型计算机系统专用接口） SCSI硬盘就是采用这种接口的硬盘。SAS(Serial Attached SCSI)就是串口的SCSI接口。一般服务器硬盘采用这两类接口，其性能比上述两种硬盘要高，稳定性更强，支持热插拔，但是价格高，容量小，噪音大。 FC（FibreChannel） 使光纤通道能够直接作为硬盘连接接口，为高吞度吐量性能密集型系统的设计者开辟了一条提高I/O性能水平的途径。 (2)使用 fdisk 分区工具 查看分区表\n1 fdisk -l /dev/sda 硬盘分区\n主分区：也称为主磁盘分区，主分区中不能再划分其他类型的分区，因此每个主分区都相当于一个逻辑磁盘。\n逻辑分区：扩展分区与逻辑分区是为了突破分区表中只能保存4个分区的限制而出现的，扩展分区不能直接使用，需要在扩展分区内划分一个或多个逻辑分区后才能使用。\n扩展分区：在扩展分区上面，可以创建多个逻辑分区，硬逻辑分区是盘上一块连续的区域，它是扩展分区的组成部分。 1 2 3 4 # 通常所说的“硬盘分区”就是指修改磁盘分区表，注意以下情况： 1 考虑到磁盘的连续性，一般建议将扩展分区放在最后面的柱面内。 2 一个硬盘只有一个扩展分区，除去主分区，其它空间都分配给扩展分区。 3 硬盘容量=主分区+扩展分区；扩展分区容量=各个逻辑分区容量之和 修改硬盘的分区表\n1 2 3 4 5 6 7 8 9 10 11 [root@localhost ~]# fdisk /dev/sdb n 创建新的分区-----\u0026gt;分区类型 回车-----\u0026gt;分区编号 回车----\u0026gt;起始扇区 回车-----\u0026gt;在last结束时 +2G p 查看分区表 n 创建新的分区-----\u0026gt;分区类型 回车-----\u0026gt;分区编号 回车----\u0026gt;起始扇区 回车-----\u0026gt;在last结束时 +1G w 保存并退出 [root@localhost ~]# lsblk [root@localhost ~]# ls /dev/sdb[1-2] 常用交互指令：\nm 列出指令帮助\np 查看现有的分区表\nn 新建分区\nd 删除分区\nq 放弃更改并退出\nw 保存更改并退出\n(3)格式化分区 常用的格式化工具 mkfs 工具集\nmkfs.ext3 分区设备路径\nmkfs. ext4 分区设备路径\nmkfs.xfs 分区设备路径\nmkfs.vfat 分区设备路径\n格式化：赋予空间文件系统类型过程\n文件系统：空间存储数据的规则\nWindows常见文件系统：NTFS、FAT、FAT32\nLinux常见文件系统: ext4(RHEL6)、XFS(RHEL7)\n1 2 3 4 5 [root@localhost ~]# mkfs.ext4 /dev/sdb1 [root@localhost ~]# blkid /dev/sdb1 #查看文件系统类型 [root@localhost ~]# mkfs.xfs /dev/sdb2 [root@localhost ~]# blkid /dev/sdb2 #查看文件系统类型 挂载使用 1 2 3 4 5 6 7 [root@localhost ~]# mkdir /mypart1 [root@localhost ~]# mount /dev/sdb1 /mypart1 [root@localhost ~]# df -h #查看当前系统正在挂载设备 [root@localhost ~]# mkdir /mypart2 [root@localhost ~]# mount /dev/sdb2 /mypart2 [root@localhost ~]# df -h #查看当前系统正在挂载设备 开机自动挂载 /etc/fstab 格式：设备路径 挂载点 类型 参数 备份标记 检测顺序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@localhost ~]# blkid /dev/sdb1 #查看文件系统类型 [root@localhost ~]# blkid /dev/sdb2 #查看文件系统类型 [root@localhost ~]# vim /etc/fstab /dev/sdb1 /mypart1 ext4 defaults 0 0 /dev/sdb2 /mypart2 xfs defaults 0 0 [root@localhost ~]# umount /mypart1 [root@localhost ~]# umount /mypart2 [root@localhost ~]# df -h | grep sdb [root@localhost ~]# mount -a 检测/etc/fstab开机自动挂载配置文件,格式是否正确 检测/etc/fstab中,书写完成,但当前没有挂载的设备,进行挂载 [root@localhost ~]# df -h | grep sdb /etc/fstab书写错误：\n输入root的密码（输入的内容不显示）\n继续编辑/etc/fstab内容进行修复 vim /etc/fstab\n(4)综合分区 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@localhost ~]# fdisk /dev/sdb p 查看分区表 n 创建主分区-----\u0026gt;回车-----\u0026gt;回车----\u0026gt;回车-----\u0026gt;在last结束时 +2G p 查看分区表 n 创建扩展分区 -----\u0026gt;回车----\u0026gt;起始回车-----\u0026gt;结束回车 将所有空间给扩展分区 p 查看分区表 n 创建逻辑分区-----\u0026gt;起始回车------\u0026gt;结束+2G n 创建逻辑分区-----\u0026gt;起始回车------\u0026gt;结束+2G n 创建逻辑分区-----\u0026gt;起始回车------\u0026gt;结束+2G p 查看分区表 w 保存并退出 [root@localhost ~]# partprobe #刷新分区表 Warning: 无法以读写方式打开 /dev/sr0 (只读文件系统)。/dev/sr0 已按照只读方式打开。 [root@localhost ~]# lsblk 总结：\n1.识别硬盘 lsblk\n2.分区规划 fdisk 分区模式MBR\n3.刷新分区表 partprobe\n4.格式化 mkfs.ext4 mkfs.xfs blkid\n5.挂载使用 mount /etc/fstab mount -a df -h\n(5) GPT分区模式 添加全新的硬盘，为GPT分区模式准备 关闭虚拟机\n1 [root@localhost ~]# poweroff 添加一块5硬盘\n查看系统识别的硬盘\n1 [root@localhost ~]# lsblk GPT分区模式，分区进阶 全局唯一标识分区表\n突破固定大小64字节的分区表限制\n最多可支持128个主分区，最大支持18EB容量\n1 EB = 1024 PB = 1024 x 1024 TB\nparted常用分区指令（专门划分GPT分区模式）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 [root@localhost ~]# parted /dev/sdc (parted) mktable gpt #指定分区模式为GPT (parted) mkpart #划分新的分区 分区名称？ []? Haha #分区的名字，随意起名 文件系统类型？ [ext2]? ext4 #文件系统类型，随意写 起始点？ 0 #起始点 结束点？ 4G #结束点 忽略/Ignore/放弃/Cancel? Ignore #忽略分区表占用的空间 (parted) print (parted) unit GB #采用GB作为单位 (parted) print (parted) mkpart 分区名称？ []? haha 文件系统类型？ [ext2]? ext4 起始点？ 4G 结束点？ 100% #全部空间 (parted) print (parted) quit 2. 交换空间（虚拟内存） 利用硬盘的空间，充当真正内存\n作用：当物理内存不够时候，暂时将物理内存中的数据，放到交换空间中，缓解真实物理内存的不足\nCPU\u0026mdash;\u0026ndash;\u0026gt;内存\u0026mdash;\u0026mdash;\u0026gt;硬盘\n(1）方式一 利用未使用的分区空间制作交换空间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ]# ls /dev/sdc1 ]# mkswap /dev/sdc1 #格式化交换文件系统 ]# blkid /dev/sdc1 #查看文件系统 ]# swapon /dev/sdc1 #启用交换分区 ]# swapon #查看组成交换空间的成员信息 ]# free -m #查看交换空间总共的大小 ]# swapoff /dev/sdc1 #停用交换分区 ]# swapon #查看组成交换空间的成员信息 ]# free -m #查看交换空间总共的大小 ]# vim /etc/fstab #开机自动启用交换分区 /dev/sdc1 swap swap defaults 0 0 ]# swapon ]# swapon -a #专门用于检测交换分区 ]# swapon (2）方式二 利用一个文件，进行制作交换空间 生成一个2G的文件\ndd if=源设备 of=目标设备 bs=块大小 count=次数\n1 2 3 ]# ls /dev/zero #永远产生数据 ]# dd if=/dev/zero of=/opt/swap.txt bs=1M count=2048 ]# du -sh /opt/swap.txt #查看占用磁盘空间大小 利用文件占用空间，充当交换空间\n1 2 3 4 ]# mkswap /opt/swap.txt #格式化交换文件系统 ]# swapon /opt/swap.txt #启用交换文件 swapon: /opt/swap.txt：不安全的权限 0644，建议使用 0600。 ]# swapon #查看交接空间组成的成员信息 3. 逻辑卷管理 (1）什么是 LVM？ 💡逻辑卷管理（Logical Volume Management, LVM）是一种灵活的磁盘管理机制，允许动态调整磁盘空间。\n优点:\n动态调整分区大小。 支持在线扩展和缩减。 支持快照功能，便于备份和恢复。 (2）LVM 核心概念 物理卷 (Physical Volume, PV): 物理硬盘或分区。 卷组 (Volume Group, VG): 由一个或多个物理卷组成的存储池。 逻辑卷 (Logical Volume, LV): 从卷组中划分出的虚拟分区，可格式化和挂载使用。 ​\n（3）主要命令语法 1 2 3 4 5 6 # 语法格式 pvcreate 设备名1 [设备名2 … …] #创建物理卷 vgcreate 卷组名 物理卷名1 物理卷名2 #创建卷组 lvcreate -L 容量大小 -n 逻辑卷名 卷组名 #创建逻辑卷 lvextend -L +大小 /dev/卷组名/逻辑卷名 #扩展逻辑卷 lvreduce -L -大小 /dev/卷组名/逻辑卷名 #缩减逻辑卷 （4）配置案例 创建和管理物理卷 1 2 3 4 5 6 [root@centos ~]#fdisk /dev/sdb 进行分区 注意：分区类型一定要改成8e（lvm类型） [root@centos ~]#pvcreate /dev/sdb1 /dev/sdb2 把1和2创建成物理卷 [root@centos ~]#pvscan 扫描物理卷 [root@centos ~]#pvdisplay 显示物理卷（查看物理卷） [root@centos ~]# pvremove /dev/sdb2 删除物理卷 创建和管理卷组 1 2 3 4 5 6 [root@centos ~]# vgscan ---扫描卷组 [root@centos ~]# vgcreate hb2022 /dev/sdb1 /dev/sdb2 /dev/sdc1 ----创建卷组名称为hb2022 把物理卷sdb1、sdb2、sdc1加入到组内 [root@centos ~]# vgdisplay hb2022 ---查看卷组名字为hb2022的卷组的详细信息 [root@centos ~]# vgextend hb2022 /dev/sdc2 ---扩展卷组大小，把物理卷sdc2加入到卷组 [root@centos ~]# vgreduce hb2022 /dev/sdc2 ----缩小卷组大小，把物理卷sdc2减掉 [root@centos ~]# vgremove hb2022 ----移除卷组 创建和管理逻辑卷 1 2 3 4 5 6 [root@centos ~]# lvscan ----扫描逻辑卷 [root@centos ~]# lvcreate -L 20G -n benet hb2022 ---创建逻辑卷空间为20G，名称为benet，所占用的卷组为hb2022 [root@centos ~]# lvdisplay hb2022—查看逻辑卷详细信息 [root@centos ~]# lvextend -L +9G /dev/hb2022/benet ---扩展逻辑卷的大小，增加9G [root@centos ~]# lvreduce -L -9G /dev/hb2022/benet ---扩展逻辑卷的大小，减少9G（需要y的确认） [root@centos ~]# lvremove /dev/hb2022/benet ------删除逻辑卷 逻辑卷格式化 1 [root@centos ~]# mkfs -t xfs /dev/hb2022/benet ---把逻辑卷benet格式为xfs 挂载逻辑卷 1 2 3 [root@centos ~]# mkdir benet ---在宿主目录创建一个benet目录（作为挂载点） [root@centos ~]# mount /dev/hb2022/benet /root/benet ----挂载benet逻辑卷到宿主目录下benet目录（挂载点） [root@centos ~]# df -Th ---查看挂载情况 永久挂载逻辑卷 1 2 3 4 [root@centos ~]# vi /etc/fstab ---修改永久挂载 /dev/hb2022/benet /root/benet xfs defaults 0 0 或者 /dev/mapper/hb2022-benet /root/benet xfs defaults 0 0 ‍\n","date":"2025-04-14T15:03:08+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux-%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/","title":"Linux 磁盘管理"},{"content":"Linux-网络配置与防火墙 一、Linux网络配置 （1）配置永久主机名 1 2 3 4 5 6 7 8 9 10 11 [root@localhost ~]# echo svr7.tedu.cn \u0026gt; /etc/hostname [root@localhost ~]# cat /etc/hostname svr7.tedu.cn [root@localhost ~]# hostname svr7.tedu.cn #修改当前 [root@localhost ~]# hostname svr7.tedu.cn 开启一个新的终端查看提示符的变化\n（2）查看网络接口信息 1 [root@centos ~]# ifconfig ​\n（3）配置网卡IP地址、子网掩码、网关地址 设置网卡相关参数\n1 2 3 4 5 6 7 8 9 10 11 ]# vi /etc/sysconfig/network-scripts/ifcfg-ens33 #不同版本操作系统网卡命名规则不同，可到/etc/sysconfig/network-scripts/目录下查看网卡具体名称 TYPE=Ethernet ----设置网卡类型，Ethernet表示以太网。 BOOTPROTO=static ----网络接口配置方式。Static为静态，dhcp为动态获取。 DEVICE=ens33 ----设置网络接口名称 ONBOOT=yes ----系统启动时是否激活 IPADDR=192.168.4.11 ----ip地址 NETMASK=255.255.255.0 ----子网掩码 GATEWAY=192.168.4.1 ----网关 DNS1=8.8.8.8 ----NDS地址 DNS2=114.114.114.114 ----NDS地址 重启网络服务，令配置命令生效 1 2 [root@svr7 ~]# systemctgl restart network [root@svr7 ~]# ipconfig #查看结果 （4）配置DNS服务器地址 DNS服务器：负责域名解析的机器，将域名解析为IP地址\n1 2 3 4 5 [root@svr7 ~]# echo nameserver 8.8.8.8 \u0026gt; /etc/resolv.conf [root@svr7 ~]# cat /etc/resolv.conf nameserver 8.8.8.8 （5）设置路由route 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #添加到指定网段的路由记录 语法：route add -net 网段地址 gw IP地址 例子：[root@centos ~]# route add -net 192.168.10.0/24 gw 192.168.4.1 #删除到指定网段的路由记录 语法：route del -net 网段地址 例子：[root@centos ~]# route del -net 192.168.10.0/24 #删除路由表中的默认网关记录 语法：route del default gw IP地址 例子：[root@centos ~]# route del default gw 192.168.137.2 #向路由表中添加默认网关记录 语法：route add default gw IP地址 例子：[root@centos ~]# route add default gw 192.168.137.2 （6）常用网络测试工具 测试网络连接 ping\n1 2 3 4 ping命令 测试网络连通性 [root@centos ~]# ping www.baidu.com 按Ctrl+C中止测试 跟踪数据包 traceroute\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 测试从当前主机到目的主机之间经过的网络节点 traceroute 目标主机地址 无法响应的主机会显示* [root@centos ~]# traceroute www.baidu.com 通过最多 30 个跃点跟踪 到 www.baidu.com [110.242.68.3] 的路由: 1 23 ms 27 ms 19 ms bogon [192.168.20.1] 2 12 ms 7 ms 10 ms dns1.online.tj.cn [111.162.92.1] 3 * * * 请求超时。 4 * * * 请求超时。 5 * * * 请求超时。 6 * 15 ms * 110.242.66.178 7 34 ms 32 ms 22 ms 221.194.45.134 8 * * * 请求超时。 9 * * * 请求超时。 10 * * * 请求超时。 11 18 ms 189 ms 297 ms 110.242.68.3 跟踪完成。 域名解析 nslookup\n1 2 3 测试DNS域名解析 nslookup 目标主机地址 [DNS服务器地址] [root@centos ~]# nslookup www.baidu.com 二、物理机与虚拟机的通信 （1）VMware网络连接常用的三种方式 桥接模式：将虚拟机直接连接到物理网络，虚拟机会获得与主机相同的网络中的独立 IP 地址，就像一台独立的物理设备。 1 2 3 4 5 6 7 8 #特点 * 虚拟机与主机处于同一局域网。 * 虚拟机可以访问外部网络（如互联网），也可以被同一局域网中的其他设备访问。 * 虚拟机的 IP 地址由局域网中的 DHCP 服务器分配，或手动配置。 #使用场景 * 需要虚拟机作为独立设备运行，并与局域网中的其他设备通信。 * 需要虚拟机对外提供服务（如 Web 服务器、数据库服务器）。 NAT模式：通过主机的网络连接共享外部网络访问权限。虚拟机通过主机的 IP 地址与外部网络通信。 1 2 3 4 5 6 7 8 #特点 * 虚拟机可以访问外部网络（如互联网），但外部网络无法直接访问虚拟机。 * 虚拟机的 IP 地址由 VMware 虚拟网络中的 DHCP 服务器分配。 * 主机充当虚拟机的网关。 #使用场景 * 需要虚拟机访问外部网络，但不希望虚拟机暴露在局域网中。 * 适合个人开发、测试环境。 仅主机模式：将虚拟机与主机连接到一个私有网络中，虚拟机只能与主机通信，无法访问外部网络。 1 2 3 4 5 6 7 8 #特点 * 虚拟机与主机之间可以互相通信。 * 虚拟机无法访问外部网络（如互联网）。 * 虚拟机的 IP 地址由 VMware 虚拟网络中的 DHCP 服务器分配。 #使用场景 * 需要虚拟机与主机之间进行隔离通信。 * 适合测试和开发环境，尤其是需要隔离外部网络的场景。 特性 桥接模式 NAT 模式 仅主机模式 网络访问 可以访问外部网络 可以访问外部网络 无法访问外部网络 外部访问虚拟机 可以 不可以 不可以 IP 地址来源 局域网 DHCP 或手动配置 VMware 虚拟网络 DHCP VMware 虚拟网络 DHCP 虚拟机与主机通信 可以 可以 可以 适用场景 虚拟机作为独立设备运行 虚拟机访问外部网络 虚拟机与主机隔离通信 （2）查看物理机虚拟网卡 💡物理机网络连接中可以看到用于与虚拟机连接的虚拟网卡，其中vmnet1虚拟网卡用于仅主机模式，vmnet8用于NAT模式，vmnet0没有显示出来，用于桥接模式的连接。\n​\n1 2 3 虚拟机需要与外网通信，可以使用桥接模式，NAT模式这两种网络连接方式 桥接模式需要设置局域网同段地址，会引起地址冲突问题，设置IP地址前需要通过ping命令测试改地址是否有人使用 为避免冲突，建议使用NAT模式设置网络连接（创建虚拟机网卡时选择该模式或在虚拟机设置——网络适配器中选择该模式） （3）查看VMnet8的网络信息 NAT模式网段信息\n1 ‍VMware虚拟机依次点击菜单栏编辑——虚拟网络编辑器——VMnet8，可以看到当前默认的网段信息，如需更改网段，在下方子网IP处进行修改。 NAT模式网关的查看\n1 2 点击NAT设置按钮，可以看到该网段默认的网关地址 注意：查看到网段及网关信息，在虚拟机网卡设置中未使用DHCP自动获取方式，通过手工静态方式设置，那么就要使用该网段及网关进行设置 ​\n（4）测试通信 ping命令测试网络联通性\n1 2 ping -c 3 192.168.91.2 #测试与网关之间的联通 ping -c 3 www.baidu.com #测试与外网之间的联通，前提需要配置好DNS地址 （5）课堂练习 1 2 3 1、创建一台CentOS主机，要求能够访问外网，可以分别尝试桥接、NAT这两种不同的模式来实现 2、创建两台CentOS主机，不仅要求能够访问外网，彼此之间要求能够相互访问 三、远程管理(Linux与Linux) 软件包的安装\n1 2 3 4 5 6 7 [root@svr7 /]# rpm -qa | grep openssh openssh-7.4p1-16.el7.x86_64 openssh-server-7.4p1-16.el7.x86_64 openssh-clients-7.4p1-16.el7.x86_64 远程登录工具 ssh\n虚拟机A：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [root@svr7 /]# \u0026gt; /etc/resolv.conf [root@svr7 /]# ssh root@192.168.4.207 ………necting (yes/no)? yes root@192.168.4.207\u0026#39;s password: #输入密码 [root@pc207 ~]# touch /root/hahaxixi.txt [root@pc207 ~]# exit 登出 Connection to 192.168.4.207 closed. [root@svr7 /]# cat /root/.ssh/known_hosts #记录曾经远程管理的机器 实现ssh远程管理无密码验证\n虚拟机A：\n1.生成公钥(锁)与私钥(钥匙)进行验证\n1 2 3 4 5 6 7 8 9 10 11 [root@svr7 ~]# ssh-keygen #一路回车 …….save the key (/root/.ssh/id_rsa): #保存位置 ……..assphrase): #设置密码为空 …….. again: #设置密码为空 [root@svr7 ~]# ls /root/.ssh/ id_rsa(私钥) id_rsa.pub(公钥) known_hosts 2.将公钥(锁)传递给虚拟机B\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [root@svr7 ~]# ssh-copy-id root@192.168.4.207 [root@svr7 ~]# ssh root@192.168.4.207 #测试无密码 [root@pc207 ~]# exit 登出 Connection to 192.168.4.207 closed. [root@svr7 ~]# 虚拟机B [root@pc207 ~]# ls /root/.ssh/ authorized_keys(别的机器传递过来的公钥) known_hosts [root@pc207 ~]# 安全复制工具 scp=ssh+cp\n– scp [-r] 用户名@服务器:路径 本地路径\n– scp [-r] 本地路径 用户名@服务器:路径\n虚拟机A：\n1 2 3 4 5 ]# scp /etc/passwd root@192.168.4.207:/root ]# scp -r /home root@192.168.4.207:/root/ ]# scp root@192.168.4.207:/etc/passwd /mnt/ 虚拟机B：\n1 ]# ls /root 四、Linux防火墙 （1）防火墙 作用：隔离，严格过滤入站，放行出站\n硬件防火墙：保护一个网络中所有机器\n软件防火墙：保护本机\n1 2 3 4 5 6 7 8 9 10 11 • 管理工具：firewall-cmd(命令)、firewall-config(图形工具) • 根据所在的网络场所区分，预设保护规则集 • public：仅允许访问本机的ssh、dhcp、ping服务 • trusted：允许任何访问 • block：拒绝任何来访请求，有明确的回应 • drop：丢弃任何来访的数据包，没有明确的回应 （2） 防火墙判定的规则： 1.查看请求中源IP地址，查看自己所有区域，哪个区域有该源IP地址规则，则进入哪个区域 2.进入默认区域（默认情况下为public） （3）修改默认区域 虚拟机A：\n1 2 3 [root@svr7 ~]# rpm -q firewalld #防火墙软件 firewalld-0.4.4.4-14.el7.noarch 虚拟机A：\n1 ]# firewall-cmd --get-default-zone #查看默认区域 虚拟机B\n1 2 3 [root@pc207 /]# ping -c 2 192.168.4.7 #成功 [root@pc207 /]# curl http://192.168.4.7 #失败 虚拟机A：\n1 ]# firewall-cmd --set-default-zone=trusted #修改默认区域 虚拟机B\n1 2 3 [root@pc207 /]# ping -c 2 192.168.4.7 #成功 [root@pc207 /]# curl http://192.168.4.7 #成功 （4）区域中添加允许的协议 虚拟机A：\n1 2 3 4 5 6 7 8 9 ]# firewall-cmd --set-default-zone=public #修改默认区域 ]# firewall-cmd --get-default-zone #查看默认区域 ]# firewall-cmd --zone=public --list-all #查看区域规则 ]# firewall-cmd --zone=public --add-service=http #添加协议 ]# firewall-cmd --zone=public --list-all #查看区域规则 虚拟机B\n1 2 3 4 5 [root@pc207 /]# curl http://192.168.4.7 #访问成功 hahaxixihehelele哈哈嘻嘻 [root@pc207 /]# （5）永久规则 永久（\u0026ndash;permanent）\n默认区域的修改，默认就是永久的\n1 2 3 4 5 6 7 8 9 10 11 12 13 ]# firewall-cmd --reload #重新加载防火墙永久的配置 ]# firewall-cmd --zone=public --list-all #查看区域规则 ]# firewall-cmd --permanent --zone=public --add-service=http #永久规则 ]# firewall-cmd --zone=public --list-all #查看区域规则 ]# firewall-cmd --reload #重新加载防火墙永久的配置 ]# firewall-cmd --zone=public --list-all #查看区域规则 （6）单独拒绝192.168.4.207所有访问，允许其他机器 防火墙判定的规则: 1.查看请求中源IP地址，查看自己所有区域，哪个区域有该源IP地址规则，则进入哪个区域\n2.进入默认区域（默认情况下为public）\n虚拟机A\n.添加源IP地址规则\n1 2 3 4 5 ]# firewall-cmd --zone=block --add-source=192.168.4.207 ]# firewall-cmd --get-default-zone #查看默认区域 public 虚拟机B\n1 ]# curl http://192.168.4.7 #访问失败 ‍\n","date":"2025-04-14T14:32:32+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E4%B8%8E%E9%98%B2%E7%81%AB%E5%A2%99/","title":"Linux 网络配置与防火墙"},{"content":"Linux-文件系统与权限管理 一、文件系统 1、文件系统概述 💡文件系统是操作系统用于明确存储设备或分区上的文件的方法和数据结构；即在存储设备上组织文件的方法。操作系统中负责管理和存储文件信息的软件机构称为文件管理系统，简称文件系统。\n2、文件系统类型及使用场景 常见文件类型 使用场景 FAT windows9X系统使用的文件系统，包括FAT16，FAT32 NTFS NTFS文件系统是一个基于安全性的文件系统，是Windows NT所采用的独特的文件系统结构，Win 2000采用了更新版本的NTFS文件系统NTFS 5.0 NFS 网络文件系统，用于在UNIX系统间通过网络进行文件共享 RAW RAW文件系统是一种磁盘未经处理或者未经格式化产生的文件系统 Ext GNU/Linux系统中标准的文件系统，其特点为存取文件的性能极好，对于中小型的文件更显示出优势，包括Ext2，Ext3，Ext4 XFS 一种高性能的日志文件系统，最早于1993年，由Silicon Graphics为他们的IRIX操作系统而开发，之后被移植到Linux内核上，特别擅长处理大文件，同时提供平滑的数据传输。 ISO 9600 该文件系统中光盘所使用的标准文件系统，Linux对该文件系统也有很好的支持，不仅能读取光盘和光盘ISO映像文件，而且还支持在Linux环境中刻录光 3、系统交换分区 💡Linux系统交换空间（swap）就是磁盘上的一块区域，可以是一个分区，也可以是一个文件，简单的说就是当物理内存资源紧张时，将内存中不常访问的资源保存到预先设定的硬盘上的交换空间，来释放该资源占用的内存，这样系统就有更多的物理内存为各个进程服务，而当系统需要访问swap上存储的内容时，再将swap上的数据加载到内存中。\nRAM大小 推荐的交换空间 ≤ 2GB 2X RAM 2GB – 8GB = RAM \u0026gt;8GB 8GB 二、权限管理 基本权限 – 读取：允许查看内容-read 利用r表示\n– 写入：允许修改内容-write 利用w表示\n– 可执行：允许运行和切换-excute 利用x表示\n对于文本文件 读取权限(r)：cat、head、tail、less、grep\n写入权限(w)：vi（保存退出）、\u0026gt;、\u0026gt;\u0026gt;\n可执行权限(x)：Shell脚本、Python脚本\n归属关系 – 所有者：拥有此文件/目录的用户-user 利用u表示\n– 所属组：拥有此文件/目录的组-group 利用g表示\n– 其他用户：除所有者、所属组以外的用户-other 利用o表示\n执行 ls -l或ls -ld命令查看文件/目录权限 以-开头：表示文本文件\n以d开头：表示目录\n以l开头:快捷方式或者链接文件\n1 2 3 4 5 6 [root@A ~]# ls -l /etc/shadow [root@A ~]# ls -l /etc/passwd [root@A ~]# ls -ld /etc/ [root@A ~]# ls -ld /root [root@A ~]# ls -ld /home/zhangsan [root@A ~]# ls -ld /tmp #默认具备附加权限的目录 修改权限 chmod命令 – 格式：chmod [ugoa] [+-=] [rwx] 文件\u0026hellip;\n常用命令选项 – -R：递归修改权限\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 [root@A /]# mkdir /nsd01 [root@A /]# ls -ld /nsd01 [root@A /]# chmod u-w /nsd01 #修改所有者权限 [root@A /]# ls -ld /nsd01 [root@A /]# chmod u+w /nsd01 #修改所有者权限 [root@A /]# ls -ld /nsd01 [root@A /]# chmod g=rwx /nsd01 #修改所属组权限 [root@A /]# ls -ld /nsd01 [root@A /]# chmod u=rwx,g=rx,o=--- /nsd01 [root@A /]# ls -ld /nsd01 [root@A /]# chmod a=rwx /nsd01 #赋予所有人rwx权限 [root@A /]# ls -ld /nsd01 [root@A /]# mkdir -p /opt/aaa/bbb/ccc [root@A /]# ls -R /opt/aaa [root@A /]# chmod -R o=--- /opt/aaa #递归设置权限 [root@A /]# ls -ld /opt/aaa [root@A /]# ls -ld /opt/aaa/bbb/ [root@A /]# ls -ld /opt/aaa/bbb/ccc/ Linux 判断用户具备的权限 1.首先判断，用户对于该数据，处于的身份(角色)\n2.查看数据，相应身份的权限位置，权限内容\n• 用户对于目录具备权限\n读取权限(r)：可以查看目录内容\n写入权限(w)：可以新建、删除、改名,目录的内容，对目录本身没有修改权限\n可执行权限(x)：可以进入切换到该目录下(一位用户能否切换到一个目录只和x执行权限有关)\n案例1：设置基本权限 1）以root身份新建/nsddir1/目录，在此目录下新建readme.txt文件 1 2 3 4 5 [root@localhost ~]# mkdir /nsddir1 [root@localhost ~]# echo 123456 \u0026gt; /nsddir1/readme.txt [root@localhost ~]# cat /nsddir1/readme.txt 2）使用户zhangsan能够修改readme.txt文件内容 1 [root@localhost ~]# chmod o+w /nsddir1/readme.txt 3）使用户zhangsan不可以修改readme.txt文件内容 1 [root@localhost ~]# chmod o-w /nsddir1/readme.txt 4）使用户zhangsan能够在此目录下创建/删除子目录 1 2 3 [root@localhost ~]# chmod o+w /nsddir1/ [root@localhost ~]# ls -ld /nsddir1/ 5）调整此目录的权限，使任何用户都不能进入，然后测试用户zhangsan是否还能修改readme.txt（测试结果不能，对父目录没有权限） 1 [root@localhost ~]# chmod a-x /nsddir1/ 6）为此目录及其下所有文档设置权限 rwxr-x\u0026mdash; 1 [root@localhost ~]# chmod -R u=rwx,g=rx,o=--- /nsddir1/ 权限位的8进制数表示 r、w、x分别对应4、2、1，后3组分别求和\n分组 User权限 Group权限 Other权限 字符 r w x r - x r - x 数字 4 2 1 4 0 1 4 0 1 求和 7 5 5 1 2 3 4 5 6 7 8 9 10 [root@A /]# mkdir /nsd03 [root@A /]# ls -ld /nsd03 [root@A /]# chmod 700 /nsd03 [root@A /]# ls -ld /nsd03 [root@A /]# chmod 007 /nsd03 [root@A /]# ls -ld /nsd03 [root@A /]# chmod 750 /nsd03 [root@A /]# ls -ld /nsd03 新建文件/目录的默认权限 – 一般文件默认均不给 x 执行权限\n– 其他取决于 ​umask​​ 设置\n– 目录默认的权限为755，文件的默认权限为644\n1 2 3 4 5 6 7 8 9 [root@A /]# umask 0022 [root@A /]# umask 077 #修改umask值 [root@A /]# umask 0077 [root@A /]# mkdir /nsd05 [root@A /]# ls -ld /nsd05 drwx------. 2 root root 6 9月 8 14:17 /nsd05 [root@A /]# umask 022 修改归属关系 chown命令 – chown 属主 文件\u0026hellip;\n– chown 属主:属组 文件\u0026hellip;\n– chown :属组 文件\u0026hellip;\n常用命令选项 – -R：递归修改归属关系\n1 2 3 4 5 6 7 8 9 10 11 [root@A /]# mkdir /nsd07 [root@A /]# ls -ld /nsd07 [root@A /]# groupadd tmooc #创建tmooc组 [root@A /]# chown zhangsan:tmooc /nsd07 [root@A /]# ls -ld /nsd07 [root@A /]# chown lisi /nsd07 #单独修改所有者 [root@A /]# ls -ld /nsd07 [root@A /]# chown :root /nsd07 #单独修改所属组 [root@A /]# ls -ld /nsd07 Linux 判断用户具备的权限 匹配即停止原则 1.用户对于该数据处于的身份(角色) 所有者 \u0026gt; 所属组 \u0026gt;其他人\n2.查看数据，相应身份的权限位置，权限内容\n案例2：归属关系练习 1）利用root的身份新建/tarena目录，并进一步完成下列操作 1 [root@localhost ~]# mkdir /tarena 2）将/tarena属主设为gelin01，属组设为tmooc组 1 2 3 4 5 [root@localhost ~]# useradd gelin01 [root@localhost ~]# groupadd tmooc [root@localhost ~]# chown gelin01:tmooc /tarena 3）使用户gelin01对此目录具有rwx权限，除去所有者与所属组之外的用户对此目录无任何权限 1 [root@localhost ~]# chmod o=--- /tarena 4）使用户gelin02能进入、查看此目录 1 2 3 [root@localhost ~]# useradd gelin02 [root@localhost ~]# gpasswd -a gelin02 tmooc 5）将gelin01加入tmooc组，将tarena目录的权限设为450，测试gelin01用户能否进入此目录 1 2 3 [root@localhost ~]# gpasswd -a gelin01 tmooc [root@localhost ~]# chmod 450 /tarena 案例3： 实现lisi用户可以读取/etc/shadow文件内容，您有几种办法？ 利用其他人 1 [root@A /]# chmod o+r /etc/shadow 利用所属组 1 2 3 [root@A /]# chown :lisi /etc/shadow [root@A /]# chmod g+r /etc/shadow 利用所有者 1 2 3 [root@A /]# chown lisi /etc/shadow [root@A /]# chmod u+r /etc/shadow 利用ACL策略 1 [root@A /]# setfacl -m u:lisi:r /etc/shadow 附加权限（特殊权限） 粘滞位，Sticky Bit 权限 – 占用其他人（Other）的 x 位\n– 显示为 t 或 T，取决于其他人是否有 x 权限\n– 适用于目录，用来限制用户滥用写入权\n– 在设置了粘滞位的文件夹下，即使用户有写入权限，也不能删除或改名其他用户文档\n1 2 3 4 5 6 [root@A /]# mkdir /home/public [root@A /]# chmod 777 /home/public [root@A /]# ls -ld /home/public [root@A /]# chmod o+t /home/public [root@A /]# ls -ld /home/public SGID 权限 – 占用属组（Group）的 x 位\n– 显示为 s 或 S，取决于属组是否有 x 权限\n– 对目录有效\n– 在一个具有SGID权限的目录下，新建 的文档会自动继承此目录的属组身份\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@A /]# mkdir /nsd10 [root@A /]# ls -ld /nsd10 [root@A /]# chown :tmooc /nsd10 [root@A /]# ls -ld /nsd10 [root@A /]# mkdir /nsd10/abc01 [root@A /]# ls -ld /nsd10/abc01 [root@A /]# chmod g+s /nsd10 #赋予SetGID权限 [root@A /]# ls -ld /nsd10 [root@A /]# mkdir /nsd10/abc02 [root@A /]# ls -ld /nsd10/abc02 [root@A /]# touch /nsd10/1.txt [root@A /]# ls -l /nsd10/1.txt ACL策略管理（ACL权限） acl 访问策略 – \u0026lt;u\u0026gt;​能够对个别用户、个别组设置独立的权限**​ \u0026lt;/u\u0026gt;\n– 大多数挂载的EXT3/4、XFS文件系统默认已支持\n• setfacl命令\n– 格式：setfacl [选项] u:用户名:权限 文件\u0026hellip;\nsetfacl [选项] g:组名:权限 文件\u0026hellip;\n• 常用命令选项\n– -m：定义一条ACL策略\n– -x：清除指定的ACL策略\n– -b：清除所有已设置的ACL策略\n– -R：递归设置ACL策略\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@A /]# mkdir /nsd11 [root@A /]# chmod 770 /nsd11 [root@A /]# ls -ld /nsd11 [root@A /]# su - lisi [lisi@A ~]$ cd /nsd11 -bash: cd: /nsd11: 权限不够 [lisi@A ~]$ exit [root@A /]# setfacl -m u:lisi:rx /nsd11 #设置ACL策略 [root@A /]# getfacl /nsd11 #查看ACL策略 [root@A /]# su - lisi [lisi@A ~]$ cd /nsd11 [lisi@A nsd11]$ pwd [lisi@A nsd11]$ exit [root@A /]# 将某个用户拉黑（制作黑名单） 1 2 3 [root@A /]# ls -ld /home/public/ drwxrwxrwt. 2 root root 41 9月 8 15:53 /home/public/ [root@A /]# setfacl -m u:lisi:--- /home/public setfacl 命令练习 1 2 3 4 5 6 7 8 9 10 11 [root@A /]# mkdir /nsd12 [root@A /]# setfacl -m u:dc:rwx /nsd12 [root@A /]# setfacl -m u:zhangsan:rx /nsd12 [root@A /]# setfacl -m u:lisi:rwx /nsd12 [root@A /]# setfacl -m u:tom:rwx /nsd12 [root@A /]# getfacl /nsd12 #查看ACL策略 [root@A /]# setfacl -x u:zhangsan /nsd12 #删除指定ACL [root@A /]# getfacl /nsd12 [root@A /]# setfacl -b /nsd12 #清除所有ACL策略 [root@A /]# getfacl /nsd12 -R : 递归设置 ACL 策略 1 2 3 4 5 6 7 8 9 10 [root@A /]# ls -R /opt/aaa /opt/aaa: bbb /opt/aaa/bbb: ccc /opt/aaa/bbb/ccc: [root@A /]# setfacl -Rm u:lisi:rx /opt/aaa [root@A /]# getfacl /opt/aaa [root@A /]# getfacl /opt/aaa/bbb [root@A /]# getfacl /opt/aaa/bbb/ccc 课后习题 案例1：chmod权限设置 1）以root用户新建/nsddir/目录，在该目录下新建文件readme.txt\n1 2 [root@Localhost ~]# mkdir /nsddir/ [root@Localhost ~]# touch /nsddir/readme.txt 2）使用户zhangsan能够在/nsddir/目录下创建/删除子目录\n1 2 3 4 5 6 [root@Localhost ~]# useradd zhangsan [root@Localhost ~]# chmod o+w /nsddir/ [root@localhost ~]# su -zhangsan [zhangsan@localhost ~]$ mkdir /nsddir/zhangsan [zhangsan@localhost ~]$ ls /nsddir [zhangsan@localhost ~]$ exit 3）使用户zhangsan能够修改/nsddir/readme.txt文件的容\n1 2 3 4 [root@Localhost ~]# chmod o+w /nsddir/readme.txt [zhangsan@localhost ~]$ echo xixi \u0026gt;\u0026gt; /nsddir/readme.txt [zhangsan@localhost ~]$ cat /nsddir/readme.txt [zhangsan@localhost ~]$ exit 案例2：chown归属设置 1）新建/tarena1目录\na）将属主设为gelin01，属组设为tarena组 1 2 3 4 [root@Localhost ~]# mkdir /tarena1 [root@Localhost ~]# useradd gelin01 [root@Localhost ~]# groupadd tarena [root@Localhost ~]# chown gelin01:tarena /tarena1 b）使用户gelin01对此目录具有rwx权限，其他人对此目录无任何权限 1 2 3 [root@Localhost ~]# ls -ld /tarena1 [root@Localhost ~]# chmod o=--- /tarena1 [root@Localhost ~]# ls -ld /tarena1 2）使用户gelin02能进入、查看/tarena1文件夹（提示：将gelin02加入所属组）\n1 2 3 4 5 6 7 [root@Localhost ~]# useradd gelin02 [root@Localhost ~]# gpasswd -a gelin02 tarena [root@Localhost ~]# id gelin02 [root@Localhost ~]# su-gelin02 [gelin02@Localhost ~]# cd /tarena1 [gelin02@Localhost ~]# ls [gelin02@Localhost ~]# exit 3）新建/tarena2目录\na）将属组设为tarena 1 2 [root@Localhost ~]# mkdir /tarena2 [root@Localhost ~]# chown :tarena /tarena2 b）使tarena组的任何用户都能在此目录下创建、删除文件 1 2 3 4 5 6 7 8 [root@Localhost ~]# chmod g+w /tarena2 [root@Localhost ~]# useradd ceshi [root@Localhost ~]# gpasswd -a ceshi tarena [root@Localhost ~]# id ceshi [root@Localhost ~]# su -ceshi [ceshi@Localhost ~]# mkdir /tarena2/ceshi [ceshi@Localhost ~]# ls /tarena2 [ceshi@Localhost ~]# exit 4）新建/tarena/public目录\na）使任何用户对此目录都有rwx权限 1 2 [root@Localhost ~]# mkdir -p /tarena/public [root@Localhost ~]# chmod 777 /tarena/public b）拒绝zhangsan进入此目录，对此目录无任何权限（提示ACL黑名单） 1 2 3 4 5 6 7 [root@Localhost ~]# ls -ld /tarena/public [root@Localhost ~]# setfacl -m u:zhangsan:--- /tarena/public [root@Localhost ~]# useradd zhangsan [root@Localhost ~]# su -zhangsan [zhangsan@Localhost ~]# ls /tarena/public [zhangsan@Localhost ~]# cd /tarena/public [zhangsan@Localhost ~]# exit 案例3:权限设置 1、创建文件夹/data/test,设置目录的访问权限，使所有者和所属组具备读写执行的权限；其他人无任何权限。\n1 2 3 [root@Localhost ~]# mkdir -p /data/test [root@Localhost ~]# chmod u=rwx,g=rwx,o=--- /data/test 或者 chmod 770 /data/test [root@Localhost ~]# ls -ld /data/test 2、递归修改文件夹/data/test的归属使所有者为zhangsan，所属组为tarena。\n1 2 [root@Localhost ~]# chown -R zhangsan:tarena /data/test [root@Localhost ~]# ls -ld /data/test 3、请实现在test目录下，新建的所有子文件或目录的所属组都会是tarena。\n1 2 3 [root@Localhost ~]# chmod g+s /data/test [root@Localhost ~]# mkdir /data/test/abc [root@Localhost ~]# ls -ld /data/test/abc 4、为lisi创建ACL访问权限，使得lisi可以查看/etc/shadow文件\n1 2 3 4 5 [root@Localhost ~]# useradd lisi [root@Localhost ~]# setfacl -m u:liai:r /etc/shadow [root@Localhost ~]# getfacl /etc/shadow [root@Localhost ~]# su-lisi [lisi@Localhost ~]# cat /etc 案例4:虚拟机 上操作 将文件 /etc/fstab 拷贝为 /var/tmp/fstab，并调整文件 /var/tmp/fstab权限\n满足以下要求：\n– 此文件的拥有者是 root\n– 此文件对任何人都不可执行\n– 用户 natasha 能够对此文件执行读和写操作\n– 用户 harry 对此文件既不能读，也不能写\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@Localhost ~]# mkdir -p /var/tmp/fstab [root@Localhost ~]# cp /etc/fstab /var/tmp/fstab [root@Localhost ~]# ls -l /var/tmp/fstab [root@Localhost ~]# chmod a-x /var/tmp/fstab [root@Localhost ~]# setfacl -m u:natasha:rw /var/tmp/fstab [root@Localhost ~]# getfacl /var/tmp/fstab [root@Localhost ~]# su -natasha [natasha@Localhost ~]# cat /var/tmp/fstab [natasha@Localhost ~]# echo ceshi \u0026gt;\u0026gt; /var/tmp/fstab [natasha@Localhost ~]# cat /var/tmp/fstab [natasha@Localhost ~]# exit [root@Localhost ~]# setfacl -m u:harry:--- /var/tmp/fstab [root@Localhost ~]# getfacl /var/tmp/fstab [root@Localhost ~]# su-harry [harry@Localhost ~]# cat /var/tmp/fstab [harry@Localhost ~]# echo ceshi \u0026gt;\u0026gt; /var/tmp/fstab [harry@Localhost ~]# exit 案例5:虚拟机上操作 创建一个共用目录 /home/admins，要求如下：\n– 此目录的所属组是 adminuser – adminuser 组的成员对此目录有读写和执行的权限，并且其他用户没有任何权限 – 在此目录中创建的文件，其所属组会自动设置为 属于 adminuser 组 1 2 3 4 5 6 7 8 9 10 [root@Localhost ~]# mkdir /home/admins [root@Localhost ~]# groupadd adminuser [root@Localhost ~]# chown :adminuser /home/admins [root@Localhost ~]# ls -ld /home/admins [root@Localhost ~]# chmod g:rwx,o:--- /home/admins [root@Localhost ~]# chown g+s /home/admins [root@Localhost ~]# ls -ld /home/admins [root@Localhost ~]# mkdir /home/admins/ceshi [root@Localhost ~]# ls -ld/home/admins/ceshi ‍\n","date":"2025-04-14T14:27:42+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/","title":"Linux 文件系统与权限管理"},{"content":"Linux-进程管理与服务管理 一、Linux进程管理 进程\n💡处于运行状态的任务(程序)，叫做计算机的一个进程。\n常见进程\nSSHD进程：远程连接程序 chronyd进程: 负责管理系统日期时间 network: 管理操作系统网络ip地址，网卡，网关，网络连接状态。 firewalld:防火墙，定制有选择性拦截非法的网络连接。(默认 22端口 放开)，其他所有端口都是不被本机以外计算机访问。 其他程序：MySQL、Tomcat、Nginx、自开发程序。 查看进程\n1 2 3 4 5 6 7 # 命令 ps [-参数] # 参数 -a：显示 当前窗口 下的进程 -u：显示 当前用户 下的进程 -x：显示 当前主机 下的所有进程 命令结果含义 1 2 3 PID(进程号) TTY TIME CMD(该程序进程对应那个命令) 2405 pts/0 00:00:00 bash 2427 pts/0 00:00:00 ps 关闭进程\n1 2 3 4 5 6 7 8 9 # 命令 kill [-参数] 进程id 说明：默认情况kill，只能关闭闲置的进程，没有人正在使用。 # 参数 -9 ：强制退出（小心使用：强制杀死程序，不管有没有人正在使用。） -18 ：继续 -19 ：暂停 程序：静态没有运行的代码 占用硬盘空间\n进程：正在运行的代码 占用CPU与内存的资源\n进程唯一标识 : PID\n父进程与子进程 树型结构\nsystemd：所有进程的父进程 上帝进程\n查看进程 pstree — Processes Tree\n格式：pstree [选项] [PID或用户名]\n• 常用命令选项\n-a：显示完整的命令行\n-p：列出对应PID编号\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@localhost ~]# pstree #查看正在运行的进程信息 [root@localhost ~]# useradd lisi [root@localhost ~]# pstree lisi 未发现进程。 [root@localhost ~]# pstree lisi #登录lisi用户，查看进程 bash───vim [root@localhost ~]# pstree -p lisi #显示进程的PID bash(6838)───vim(6874) [root@localhost ~]# pstree -a lisi #显示完成的命令 bash └─vim a.txt 查看进程\nps aux 操作（显示的信息非常详细）\n列出正在运行的所有进程\n用户 进程ID %CPU %内存 虚拟内存 固定内存 终端 状态 起始时间 CPU时间 程序指令\n1 2 3 4 5 6 7 8 9 10 11 [root@localhost ~]# wc -l /etc/passwd 43 /etc/passwd [root@localhost ~]# ps aux | wc -l [root@localhost ~]# ps -elf | wc -l [root@localhost ~]# find /etc -name \u0026#34;*.conf\u0026#34; [root@localhost ~]# find /etc -name \u0026#34;*.conf\u0026#34; | wc -l ps -elf 操作（可以显示进程的父进程PID）\n进程动态排名top 交互式工具\n格式：top [-d 刷新秒数] [-U 用户名]\n1 2 3 4 5 6 7 [root@localhost ~]# top 输入P(大写)，按照CPU进行排序 输入M(大写)，按照内存进行排序 输入q退出 检索进程pgrep — Process Grep\n用途：pgrep [选项]\u0026hellip; 查询条件\n常用命令选项\n-l：输出进程名，而不仅仅是 PID\n-U：检索指定用户的进程\n-x：精确匹配完整的进程名\n1 2 3 [root@localhost ~]# pgrep -l a [root@localhost ~]# pgrep -l c 进程的前后台调度\n• Ctrl + z 组合键\n挂起当前进程（暂停当前的进程并转入后台）\n• jobs 命令\n查看后台任务列表\n• fg 命令\n将后台任务恢复到前台运行\n• bg 命令\n激活后台被挂起的任务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@localhost /]# sleep 3600 \u0026amp; #进程正在运行的状态放入后台 [root@localhost /]# firefox \u0026amp; [root@localhost ~]# sleep 3600 ^Z #按ctrl +z 暂停放入后台 [1]+ 已停止 sleep 3600 [root@localhost ~]# jobs #查看后台进程的信息 [1]+ 已停止 sleep 3600 [root@localhost ~]# bg 1 #将后台编号为1 的进程恢复运行 [1]+ sleep 3600 \u0026amp; [root@localhost ~]# jobs [1]+ 运行中 sleep 3600 \u0026amp; [root@localhost ~]# fg 1 #将后台编号为1的进程恢复到前台\nsleep 3600\n^C #按ctrl +c 结束进程\n[root@localhost ~]#\n杀死进程\n干掉进程的不同方法\nCtrl+c 组合键，中断当前命令程序\nkill [-9] PID\u0026hellip; 、kill [-9] %后台任务编号\nkillall [-9] 进程名\u0026hellip;\npkill [-9] 查找条件，包含就可以\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@localhost ~]# sleep 3600 \u0026amp; [root@localhost ~]# sleep 3600 \u0026amp; [root@localhost ~]# sleep 3600 \u0026amp; [root@localhost ~]# jobs -l #显示后台进程信息，显示PID [1] 8618 运行中 sleep 3600 \u0026amp; [2]- 8625 运行中 sleep 3600 \u0026amp; [3]+ 8632 运行中 sleep 3600 \u0026amp; [root@localhost ~]# kill 8618 #按照PID杀死 [1] 已终止 sleep 3600 [root@localhost ~]# jobs -l [root@localhost ~]# killall sleep 3600 #杀死所有sleep 3600进程 杀死一个用户开启的所有进程（强制踢出一个用户）\n1 [root@localhost ~]# killall -9 -u lisi 二、Linux服务管理 💡服务可以理解成软件程序​，特点是运行和系统可以绑定​。\n1 2 3 4 5 6 # 常见服务 sshd 远程连接 NetworkManager 网络管理器 chronyd 时钟 firewalld 防火墙 mysqld 数据库 1 2 3 4 5 1. 查看服务状态 systemctl status 服务名 说明： inactive 不可用 active 正在运行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 2. 启动服务 systemctl start 服务名 3. 重启服务 systemctl restart 服务名 4. 关闭服务 systemctl stop 服务名 例子： 关闭防火墙 systemctl stop firewalld 5. 设置开启自启动 systemctl enable 服务名 例子： 关闭防火墙 6. 关闭开机自启动 systemctl disabled 服务名 ‍\n","date":"2025-04-14T14:20:58+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E4%B8%8E%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/","title":"Linux 进程管理与服务管理"},{"content":" Linux-基础命令与操作 一、 Linux系统 1. Linux系统 💡开源的，免费的类Unix企业服务常用的操作系统，支持多用户，多任务，多处理器。\n1 2 3 Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统 ​Linux也继承了Unix的文件设计思想，一切皆文件(文件夹也是文件)​ Linux之父是“托瓦斯林纳斯” 开源 免费​\n开源：开放Linux操作系统源代码，任何人可以免费使用，且对Linux代码定制升级。\n最安全\n最稳定\n性能效率对比较高\n2.版本说明 💡Linux由于是开源的，所以有很多公司在Linux内核程序基础上开发了自己的有特别功能的程序(工具)，然后，再命令为一个新的版本，因此Linux有众多的版本型号。\n1 总结：严格来讲，Linux操作系统指的是“linux内核+各种软件”. 商业公司维护的发型版本 社区组织维护的发行版本 3.虚拟机的安装 💡通过软件技术，虚拟出一套计算机硬件设备：CPU、内存、硬盘、网卡、显示器。\n版本\nVMware​ 收费 virtrubox​ 免费 Oracle公司 企业虚拟机​ 云服务器​ （1）VMware的安装 VMware17安装包\n1 VMware17激活码:JU090-6039P-08409-8J0QH-2YR7F （2）虚拟创建一个计算机设备​ （3）安装CentOS操作系统 系统盘\n保存了操作系统文件的光盘\n虚拟镜像光盘：CentOS-7-x86_64-DVD-1804.iso​\n安装过程\n2. 安装CentOS7.zip\n（4）命令行界面 CentoS安装好以后，命令行界面，没有图形化操作界面。\n① 原因节省服务器CPU和内存资源。\n② 命令行操作效率，速度，远超过图形化界面。\n（5）vmware使用 开关机 虚拟机路径 快照 克隆 二 、Linux基础命令与操作 1. Linux远程连接 （1）linux工作环境 实际工作中，不会直接触碰服务器，会通过Linux远程连接工具服务器。\n（2）SSH工具 ① 查看Linux的ip地址\nip addr​\n② SecureCRT连接linux\n1 2 3 4 5 6 1. linux的ip 192.168.199.131 2. 用户名 root 3. 密码 admins （3）Windows的ssh（了解）\n1 2 3 1. 打开windows的cmd命令行 2. 输入命令 ssh root@linux的ip地址 ​\n2. 命令行介绍 （1）Linux终端 终端terminal​（命令行客户端） 1 2 3 4 5 6 7 1. 概念：用来连接和操作linux系统的接口，存在于用户和计算机之间沟通的桥梁。 2. 终端快捷键 ① tab ：命令自动补全。 例如： da+tab ② ctrl+c： 强行中断 停止退出当前程序命令。 ③ ↑ ↓ ：直接找到回显之前执行过历史命令。 Linux命令 1 2 3 4 5 1. 命令是一种操作Linux系统的一种指令。 2. linux命令区分大小写。 3. linux命令结构 linux命令 参数 其中多个参数可以组合使用。 （2）命令行提示符 1 2 3 4 5 6 7 [root@baizhi-centos ~]# root ：当前登录系统的用户 @：无意义，仅分隔符 baizhi-centos：计算机名字 ~ ： 当前命令所在的 目录路径 ，home #或者$: 表示当前用户超级管理员，$表示普通用户。 （3）基本命令 查看ip 1 2 3 4 5 1. 完整命令 ip address 2. 简化命令 ip addr 网络ping 1 2 3 4 5 6 7 8 9 10 11 # 命令 ping ip地址 # 参数 -c 次数：设置ping发送数据包次数。 # 案例 本机内部网络是否联通。 ping 127.0.0.1 ping localhost # 案例 ping -c 5 192.168.199.131 清屏 1 clear 关机 序号 命令 备注 1 init 0​ 立刻关机，只有管理员可以使用 2 poweroff​ 立刻关机 3 shutdown​ 立刻或定时关机 重启 序号 命令 备注 1 reboot​ 立即重启 操作系统信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 场景： 同时拿到10个服务器，判断10个服务器操作系统版本环境是否一致。 # 命令 uname # 参数 -s 输出 内核名称 (默认) -n 输出网络节点上的主机名 -r 输出内核版本 -v 输出内核的构建容器和版本信息 -m 输出主机的硬件架构名称 -p 输出处理器类型或\u0026#34;unknown\u0026#34; -i 输出硬件平台或\u0026#34;unknown\u0026#34; -o 输出操作系统名称 -a 以如下次序输出所有信息。其中若-p和-i的结果不可知则省略 也可以 --all # 注意 多个参数可以合并使用 例如： uname -svr 磁盘信息 1 2 3 1. 查看物理磁盘空间 df是一个用于显示文件系统磁盘空间使用情况的命令行工具，它可以帮助用户查看磁盘分区的总空间、已用空间、可用空间以及挂载点等信息。 df -h 磁盘使用空间 1 2 3 4 5 6 7 8 9 10 11 1. 查看文件或目录的大小 du #语法 du [-ahs] [文件名|目录] #参数 -a 显示子文件的大小 -h 以易读的方式显示 KB,MB,GB等 -s summarize 统计总占有量 说明： -s和-a不能同时使用 例如： du -h 配置硬件信息 1 2 3 4 5 1. 查看CPU信息 lscpu 2. 查看内存 free -h 系统程序的资源占用情况 1 2 3 4 5 6 7 8 9 10 11 12 13 1. 实时查看 #命令： top #快捷键： ↑ ： 上翻 ↓ ：下翻 q ：退出 2. 场景 ① 服务器卡顿 DDOS攻击 中毒 查看原因：top 主机名 1 2 3 4 5 1. 查看主机名 hostname 2. 修改主机名 hostnamectl set-hostname 新主机名 ​\n系统时间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # 命令 date \u0026#39;+参数\u0026#39; 说明： 一个日期包含信息：年 月 日 星期 时 分秒 毫秒 纳秒 时区 # 参数 1. 日期格式 %c : 直接显示日期与时间 (2023年10月08日 星期日 15时57分35秒) %x : 直接显示日期 (YYYY-mm-dd) %D : 直接显示日期 (mm/dd/yy) %X : 相当于 %H:%M:%S %T : 直接显示时间 (24 小时制) %r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M) 2. 提取详细日期属性 %Y : 完整年份 (0000..9999) %y : 年份的最后两位数字 (00.99) %m : 月份 (01..12) %d : 日 (01..31) %H : 小时(00..23) %M : 分钟(00..59) %S : 秒 %n : 下一行 %t : 跳格 tab %p : 显示本地 AM 或 PM 3. 其他日期属性（了解） %Z : 显示时区 %w : 一周中的第几天 (0..6)。说明每星期第0天是周日。 %a : 星期几 (Sun..Sat) %A : 星期几 (Sunday..Saturday) %b : 月份 (Jan..Dec) %B : 月份 (January..December) %s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数 计算机对于日期信息统计方式：时钟从1970年开始计算过去了多少秒，内部底层存储日期(数字秒) %n : 下一行 %t : 跳格 tab 1 2 # 案例: 获取日期格式显示：xxxx-xx-xx xx:xx:xx date \u0026#39;+%Y-%m-%d %H:%M:%S\u0026#39; 3. 文件管理 （1）Linux文件系统(了解) ① Linux文件系统没有C​ D​ E​ 盘，顶级目录是/​ ② Linux文件类型：目录、文件、符号链接文件​ （2）Inode元数据 1 2 3 4 5 6 7 8 9 1. Linux文件管理 数据 空间： 存放 数据 本身，100MB 10GB 文件本身所在位置。 元空间： 文件 描述信息(元数据) (文件名 大小 日期 用户 类型 文件所在地址)---Inode。 2.场景： Linux文件查找 ① 先在元空间中，找到文件描述信息。速度快。（元空间小），得到文件地址。 ② 如果需要得到文件内容，通过地址直接定位到对应位置即可。--- 寻道过程。 元数据 ​Inode​​ 数据 ​data​​ 概念 文件的描述信息(文件名 大小 类型 权限 日期等等) 文件内真正存储的数据内容 容量 非常小，且不同大小的文件的元数据信息大小相同 256B字节 大小不等：KB MB GB TB等 位置 元空间**（内存+硬盘）​** 数据空间**（硬盘）​** 类比 公安局档案信息、学生档案信息、生死簿 人、学生、鬼 （3）路径命令 命令 作用 常用选项 用法 示例 pwd​ 查看当前命令所在目录 — cd​ 切换目录 — cd [目录]​ cd /home​ ls​ 查看目录中的文件和目录 -a 显示所有文件含隐藏\n-l 显示文件完整描述元数据\n-R 显示指定目录分支内各子目录中的文件清单\nls [选项] [目录]​ `ls -al /root ls -alR /root ls -al \u0026gt; a.txt` 1 2 3 4 5 6 7 8 9 10 11 # 路径特殊字符 1 / : 顶级目录 2 . : 当前路径位置 通常使用相对路径使用 例如：切换到当前目录下的class目录 cd ./class 3 .. : 上一级路径 常用在相对路径。 4 ~ :当前用户所在的home目录， 例如baizhi用户的目录对应 /home/baizhi 例如root用户所在目录，特殊 /root 1 2 3 4 5 6 7 8 9 10 11 # 绝对路径和相对路径 1 绝对路径：是从根目录（/）开始的完整路径，用于定位文件系统中的任何文件或目录。 例如： /home/user/documents/file.txt就是一个绝对路径，它直接指向根目录下的home目录中的user目录下的documents目录中的file.txt文件。 2 相对路径：是相对于当前工作目录的路径。 例如： 如果你在/home/user目录中，要访问documents目录中的file.txt文件，你可以使用相对路径documents/file.txt。 相对路径让你不需要知道文件的完整路径，只需要知道它与当前工作目录的位置关系。 # 理解和正确使用这两种路径类型对于在Linux系统中高效地导航和操作文件至关重要。 ls文件元数据详解1 1 2 3 # 文件类型 d： 目录 -：普通文件 （4）文件操作命令 命令 作用 常用选项 用法 示例 ​touch​​ 创建一个空文件 — touch [文件名.后缀名]​ touch a.txt​ ​mkdir​​ 创建目录 -p 如果父目录不存在则创建 mkdir [选项] [目录名]​ `mkdir test mkdir -p test/user` ​rm​​ 删除文件或目录 -f 删除文件，不需要确认。\n-r 删除目录\n-fr 强制删除目录，不需要确认 rm ``[选项]`` [目录]​ cd /home​ ​cp​​ 复制文件或目录 -r 复制目录（含文件） cp [选项] [源文件] [拷贝后文件]​ `cp a/abc.txt b/bcd.txt cp a/abc.text b cp -r a b cp -r a/* b` ​mv​​ 移动文件 — mv [源文件] [目标目录]​ 参考cp ​find​​ 查找某个文件所在位置 -name 指定搜索的关键词\n说明：关键词可以使用*进行通配符匹配 find [搜索范围目录] [选项] [关键字]​ `find . find / -name \u0026ldquo;a\u0026rdquo; find / -name \u0026ldquo;a.txt\u0026rdquo; find /root -name \u0026ldquo;a.txt\u0026rdquo; find /root -name \u0026quot; *.txt\u0026quot;` 1 2 3 4 1. 课堂案例命令 2. 作业题目 3. 整理笔记（面试题+命令） 4(尝试). 没讲过的命令 试试。 （5）文件读取命令 命令 作用 常用选项 用法 示例 ​cat​​ 一次性读取整个文件，适合查看小文件 — cat [文件路径]​ cat a.txt​ ​less​​ 文件阅读器，可控制翻页，适合查看大文件 — less [文件路径]​\n↑ ：上翻1行\n↓：下翻1行\n空格 ：向下翻页，\nb：向上翻页\nq退出 less a.txt​ ​head​​ 查看文件前几行 -n 行数 head [文件路径] [选项] 行数​ head a.txt -n 2​ ​tail​​ 查看文件后几行，实时跟踪查看\n常用在服务日志文件 -n 行数\n-f 不断刷新实时更新 tail [文件路径] [选项] 行数​ tail -f a.txt -n 5​ ​grep​​ 在文件中搜索关键字，结果获得关键词所在一行文本提取。 -n 显示行号 grep [选项] 关键字 文件路径​ grep -n local a.txt​ ​echo​​ 用于展示一行/打印一行文字到控制台 — echo 字符串|环境变量名​ echo you are best ​ （6）压缩解压 💡将多个文件打包成一个文件。\n作用：\n① 方便管理和移动。把一些备份数据压缩。\n② 将文件空间占用变小，节约磁盘空间。\n③ 将大量小文件，合并成单个压缩文件，将文件在磁盘存放由随机存放转为顺序存放，访问（移动还是拷贝）文件对文件读取由随机读取变成顺序读取。效率快。\nlinux系统下常用的压缩文件格式有 tar.gz​\n1 2 3 4 5 windows系统：rar，zip。 linux压缩格式： 1. tar 2. tar.gz 压缩/解压tar.gz文件\n1 2 3 4 5 6 7 8 9 10 11 1. 压缩文件操作命令： # 命令 tar -cf 压缩文件名 被压缩文件或者目录路径 # 参数 -c 创建压缩文件 -x 解压压缩文件 -f 执行压缩文件名 -v 显示压缩过程的信息。 -z 主要针对tar.gz压缩格式操作需要 # 第二参数 -C 指定文件解压后所在目录。 案例 压缩 tar -zcvf 压缩后文件名.tar.gz 被压缩文件路径 解压缩 默认解压到当前目录下 tar -zxvf 被解压文件名.tar.gz tar -zxvf 被解压文件名.tar.gz -C 解压后文件存放位置路径 （7）帮助指令 💡man指令：查看指定命令的帮助文档。\n1 2 3 4 5 6 7 语法： man 指令 例子: man ls man pwd man cd 💡\u0026ndash;help参数：大部分Linux命令都支持\u0026ndash;help参数，用于显示该命令的简要帮助信息。\n1 2 3 语法： 指令 --help cd --help 4. vi编辑器 💡编辑文本文件的软件程序，例如：txt文件、xx.ini、xxx.py、xxx.xml、xxx.conf。\n所有的类Unix系统中都会内置vi文本编辑器\n启动命令：vi 文件名​\nvi命令的工作模式：\n1 2 3 1. 命令模式（Command mode）：启动vi编辑器时进入的模式，该模式下可以进行复制、粘贴、删除等操作。 2. 输入模式（Insert mode）：在命令模式下按\u0026#34;i\u0026#34;键进入输入模式，该模式下可以修改文本内容。 3. 底线模式（Last line mode）：在命令模式下按下“:”键进入底线命令模式，该模式下可以对文件内容进行替换、保存、或退出编辑。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 三种模式的切换 ![](https://p.sda1.dev/23/310b9c21fbb6dfdc9b00019294b41c7b/image_ZTx1Aay6G2-20240424161452-kttqch7.png) * 各模式下的操作： | 模式名称 | 快捷键/命令 | 支持的操作 | | ------------ | ----------- | ------------------------------------------- | | **命令模式** | `i`​ | 进入输入模式，在光标前插入insert | | | | | | | `o`​ | 进入输入模式，在光标位置下新建一行输入 | | | `: `​ | 进入底线模式 | | | gg | 定位到第一行 | | | G | 定位到最后一行 | | | nyy | n为整数，`复制`​n行，从光标位置向下复制n行。 | | | p | 粘贴到光标的下一行。 | | | ndd | n为整数，删除n行，从光标向下数n行。 | | **底线模式** | set nu | 显示行号 | | | set nonu | 取消行号 | | | `q`​ | 退出不保存 | | | `q!`​ | 强制退出不保存 | | | `w`​ | 保存内容 | | | `wq`​ | 保存退出 | | | `wq!`​ | 强制保存退出 | 注意事项： 1. vi编辑模式，最好不要编写中文。 2. 如果可以，大量内容编写，可以使用外部文本编辑器 mobaxterm外部工具。 ### 5. Linux软件安装 #### （1）RPM软件 \u0026gt; 💡linux中软件包的一种格式，类似windows(exe msi)。 1. 作用：用于在Linux系统中管理（`安装`​、`卸载`​、`查看`​）.rpm程序包。 2. 常用命令参数： * 命令的格式 ```bash rpm [-参数] rpm软件的文件名。 命令参数 作用 pql​ 显示rpm软件包内部文件 i [软件全名]​ 安装应用程序 e [软件名]​ 卸载应用程序 v​ 显示安装过程信息 h ​ 线程进度条 qa 显示所有已安装的程序包 案例：安装tree命令\n1 2 3 4 5 # 安装 rpm -ivh tree文件名.rpm # 卸载 rpm -evh tree关键名 （2）Yum软件包管理器 Yum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE、CentOS中的Shell前端软件包管理器。\n基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，\n无须繁琐地一次次下载、安装。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## 列出所有可以安装的软件包 yum list ## 安装软件 yum install -y 软件名 # 安装tree yum install -y tree yum install -y vim ## 卸载软件 yum remove 软件名 ## 更新软件(了解) yum update 软件名 ## 查找软件包 yum search all 软件名 # 例如安装vim [root@one ~]# yum install -y vim 常用的工具 1 2 3 4 5 6 7 8 9 10 11 12 # VIM 编辑器 功能类似vi，比vi增加了关键词高亮效果，便于阅读和编写。 安装：yum install -y vim # wget 下载器 安装： yum install -y wget 命令： wget url地址 [参数] 参数： -P 下载文件的保存路径：指定下载文件所存放的路径。 6.管道命令 概念：\n1 管道 就是可以将两个或者多个命令（程序或者进程）连接到一起，把一个命令的输出作为下一个命令的输入，以这种方式连接的两个或者多个命令就形成了管道（pipe） 管道符：|\n语法\n1 command1 | command2 .... ① 连接多个命令 ② 执行顺序，从左至右，会将前一个命令得输出结果，作为后一个命令输入内容。 例：\n1 2 3 4 5 6 # 查询名字包含ssh的进程 ps -aux | grep ssh # 获取ls -al 输出的前5行 ls -al | head -n 5 # 获取ls -al 输出的前5行，查找是否含有关键字a ls -al | head -n 5 | grep a 7.用户与用户组 （1）用户配置文件 /etc/passwd​：存储用户信息。\n格式：用户名:密码占位符:UID:GID:描述信息:家目录:默认Shell​\n示例：\n1 root:x:0:0:root:/root:/bin/bash /etc/shadow​：存储用户密码信息（加密）。\n格式：用户名:加密密码:最后修改时间:最小间隔:最大间隔:警告时间:失效时间:保留字段​\n示例：\n1 root:$6$randomsalt$encryptedpassword:19180:0:99999:7::: （2）用户管理命令 useradd​：创建用户。\n示例：\n1 useradd -m -s /bin/bash username 常用选项：\n-m​：创建家目录。 -s​：指定默认 Shell。 -u​：指定 UID。 -g​：指定主用户组。 -G​：指定附加用户组。 usermod​：修改用户信息。\n示例：\n1 usermod -aG groupname username 常用选项：\n-aG​：将用户添加到附加用户组。 -s​：修改默认 Shell。 -L​：锁定用户。 -U​：解锁用户。 userdel​：删除用户。\n示例：\n1 userdel -r username 常用选项：\n-r​：删除用户及其家目录。 passwd​：修改用户密码。\n示例：\n1 passwd username （3）查看用户信息 id​：查看用户 UID、GID 和所属组。\n示例：\n1 id username whoami​：查看当前登录用户。\nw​：查看当前登录用户及其活动。\n（4）用户组配置文件 /etc/group​：存储用户组信息。\n格式：组名:组密码占位符:GID:组成员​\n示例：\n1 developers:x:1001:user1,user2 （5）用户组管理命令 groupadd​：创建用户组。\n示例：\n1 groupadd groupname groupmod​：修改用户组信息。\n示例：\n1 groupmod -n newgroupname oldgroupname groupdel​：删除用户组。\n示例：\n1 groupdel groupname （6）查看用户组信息 groups​：查看当前用户所属组。\n示例：\n1 groups username （7）其他相关命令 su​：切换用户。\n示例：\n1 su - username sudo​：以超级用户权限执行命令。\n示例：\n1 sudo command visudo​：编辑 /etc/sudoers​ 文件，配置用户权限。\n（8）常用操作示例 创建用户并添加到组 1 2 useradd -m -s /bin/bash user1 usermod -aG developers user1 查看用户所属组 1 groups user1 修改文件权限 1 2 chmod 755 script.sh chown user1:developers script.sh 切换用户 1 su - user1 ","date":"2025-04-12T22:28:22+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E4%B8%8E%E6%93%8D%E4%BD%9C/","title":"Linux相关基础与操作"}]