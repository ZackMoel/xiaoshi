[{"content":"1.为什么要学物理备份？ 一个合格的运维工程师或者dba工程师,如果有从事数据库方面的话,首先需要做的就是备份,如果没有备份,出现问题的话,你的业务就会出问题,你的工作甚至会丢掉\n所以备份是重要的,但光有备份还不行,备份后如果出现问题,你还得使用备份数据来恢复,但恢复数据的时间一般都是很长的,不符合业务需求,所以回复效率较高的物理备份也会被使用。\n就像前文给大家看的微盟数据库被删。,最后是腾讯云的工程师协助进行数据恢复\n但是单纯的物理备份会有以下问题：\n存储引擎依赖：\n物理备份通常与特定的存储引擎实现密切相关。不同版本的 MySQL 可能会对存储引擎的内部数据结构（如 InnoDB 的 redo 和 undo 日志）进行更改，从而导致兼容性问题。 版本变化：\nMySQL 的不同版本之间，数据文件格式可能会发生变化。物理备份直接复制数据文件，这些变化可能导致备份在不同版本之间不兼容。 平台依赖：\n物理备份可能依赖于特定的操作系统和文件系统特性。例如，文件锁定和文件系统快照在不同操作系统上可能表现不同。 事务日志：\nredo 和 undo 日志用于恢复和回滚事务。它们的格式和管理方式在不同版本中可能会有所变化，影响备份的可移植性。 为了解决以上问题，所以一个快速备份与恢复的软件就很有必要。\nxtrabackup工具 Percona-xtrabackup是Percona公司开发的一个用于MySQL数据库物理热备的备份工具,支持MySQL、Percona server和MariaDB,开源免费,是目前较为受欢迎的主流备份工具\nxtrabackup只能备份innoDB和xtraDB两种数据引擎的表,而不能备份MyiSAM数据表。\n特点\n物理备份工具,拷贝数据文件 备份和恢复数据的速度非常快,安全可靠 在备份期间执行的事务不会间断,备份innodb数据不影响业务 备份期间不增加太多数据库的性能压力 支持对备份的数据自动校验 运行全量,增量,压缩备份及流备份 支持在线迁移表以及快速创建新的从库 运行几乎所有版本的mysql和maridb 什么是物理备份 查看如下物理备份方式\n1 2 3 4 5 6 7 8 9 10 11 12 1. 基于逻辑备份的全量备份，导入执行，前提是数据库能正常启动 2. 直接恢复物理文件数据 - tar对mysql数据打包压缩，做了个备份 - 删数据 - 解压恢复数据 - 数据库重启还是可以继续用 但是这种方式太粗暴，有更专门的工具，通过这种直接操作数据文件的，备份，恢复方案，且对数据库做很多的校验工作。 一些主流的物理备份工具，例如xtrabackup工具 数据文件扩张名 文件类型 作用 .idb文件 以独立表空间存储的InnoDB引擎类型的数据文件扩展名 .ibdata文件 以共享表空间存储的InnoDB引擎类型的数据文件扩展名 .frm文件 存放于表相关的元数据(meta)信息及表结构的定义信息 .MYD文件 存放MyISAM引擎表的数据文件扩展名 .MYI文件 存放MyISAM引擎表的索引信息文件扩展名 看看mysql的数据是什么 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [root@tech-db-51 /linux0224/mysql_3306/test_backup]#ll total 112 -rw-r----- 1 mysql mysql 67 Aug 10 12:15 db.opt -rw-r----- 1 mysql mysql 8556 Aug 10 12:15 test_table.frm -rw-r----- 1 mysql mysql 98304 Aug 10 12:32 test_table.ibd 所以数据库引擎，就是帮你 1. 分析SQL语法 2. 执行SQL 3. 修改库，表数据 4. 提供了如事务的特性，能回滚，等，。 mysql\u0026gt; show engines; 查看当前机器是什么引擎 mysql\u0026gt; show variables like \u0026#39;%storage%\u0026#39;; +----------------------------------+--------+ | Variable_name | Value | +----------------------------------+--------+ | default_storage_engine | InnoDB | | default_tmp_storage_engine | InnoDB | | disabled_storage_engines | | | internal_tmp_disk_storage_engine | InnoDB | +----------------------------------+--------+ 4 rows in set (0.00 sec) 安装xtrabackup工具 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 yum install perl perl-devel libaio libaio-devel perl-Time-HiRes perl-DBD-MySQL -y # 下载软件且安装 wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.9/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.9-1.el7.x86_64.rpm yum localinstall percona-xtrabackup-24-2.4.9-1.el7.x86_64.rpm -y # 就是用它的命令而已 # 搜索查看安装的这个rpm包，默认生成了哪些文件 [root@tech-db-51 /opt]#rpm -ql percona-xtrabackup-24 /usr/bin/innobackupex /usr/bin/xbcloud /usr/bin/xbcloud_osenv /usr/bin/xbcrypt /usr/bin/xbstream /usr/bin/xtrabackup /usr/share/doc/percona-xtrabackup-24-2.4.9 /usr/share/doc/percona-xtrabackup-24-2.4.9/COPYING /usr/share/man/man1/innobackupex.1.gz /usr/share/man/man1/xbcrypt.1.gz /usr/share/man/man1/xbstream.1.gz /usr/share/man/man1/xtrabackup.1.gz 2.全量备份，恢复 1.明确，这个工具，其实就是再 备份mysql的数据文件而已\n1 2 3 4 5 6 7 8 0. 给你的机器，设置基于GTID的模式运行 1. 基于命令 ，全量备份命令 # 和mysqldump很像，链接实例，备份数据 # 创建备份目录 innobackupex --user=root --password=linux3306 -S /tmp/mysql.sock /xtrabackup_data/ 查看xtrabackup工具生成的日志文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 查看具体备份的数据信息，以及自己生成了哪些日志文件 xtrabackup_binlog_info 记录全量备份时，该实例最后的一个binlog 事务ID xtrabackup_logfile 是该工具本身的一个二进制日志文件 [root@tech-db-51 /xtrabackup_data/2022-08-10_15-29-12]#strings xtrabackup_logfile xtrabkup 220810 15:29:12 xtrabackup_info 当前3306全量备份的详细信息，xtraback备份当前实例数据，一个版本信息 [root@tech-db-51 /xtrabackup_data/2022-08-10_15-29-12]#cat xtrabackup_info uuid = 22363968-187e-11ed-8a4d-000c29463bc7 name = tool_name = innobackupex tool_command = --user=root --password=... -S /tmp/mysql.sock /xtrabackup_data/ tool_version = 2.4.9 ibbackup_version = 2.4.9 server_version = 5.7.28-log start_time = 2022-08-10 15:29:12 end_time = 2022-08-10 15:29:13 lock_time = 0 binlog_pos = filename \u0026#39;mysql-log-bin.000012\u0026#39;, position \u0026#39;194\u0026#39;, GTID of the last change \u0026#39;187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6\u0026#39; innodb_from_lsn = 0 innodb_to_lsn = 950998185 partial = N incremental = N format = file compact = N compressed = N encrypted = N # xtrabackup备份数据，也是有连续性记录， # xtrabackup通过lsn号，确认数据的起点，截止点 # xtrabackup备份数据，出现不一致的情况，会来查看该信息（DBA的活） [root@tech-db-51 /xtrabackup_data/2022-08-10_15-29-12]#cat xtrabackup_checkpoints backup_type = full-backuped from_lsn = 0 to_lsn = 950998185 last_lsn = 950998194 compact = 0 recover_binlog_info = 0 不要该工具自带的时间戳信息 1 2 3 4 --no-timestamp #自己指定备份的时间目录 innobackupex --no-timestamp --user=root --password=123456 -S /tmp/mysql.sock /xtrabackup_data_no_time/full_3306_db_$(date +%F)/ 恢复该全量备份的数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 1. 挪走自带的数据，用mv替代rm [root@tech-db-51 /linux0224/mysql_3306]#mv ./* /opt/3306_db_backup/ 2.尝试用xtrabackup命令恢复 恢复的思路其实，把备份的数据，原封不动，再放回mysql datadir下 3. 基于xtraback命令的参数，对默认所有的未提交事务，确保数据一致性 # 操作备份的数据即可 innobackupex --apply-log /xtrabackup_data_no_time/full_3306_db_2022-08-10/ 4. 此时就可以直接恢复数据了 # innobackupex \u0026gt; rsync 数据拷贝回去 innobackupex --defaults-file=/etc/my.cnf --copy-back --rsync /xtrabackup_data_no_time/full_3306_db_2022-08-10/ 4.1 重新授权给mysql [root@tech-db-51 /linux0224/mysql_3306]#chown -R mysql.mysql ./* 5.恢复数据之后，建议重启mysql，确保数据重新加载正常 6.修改配置文件，修改日志目录 [root@tech-db-51 /linux0224/mysql_3306]#mkdir -p /mysql_3306/logs/ [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]#chown -R mysql.mysql /mysql_3306/logs/ 7.重启 [root@tech-db-51 /linux0224/mysql_3306]#systemctl restart mysqld 8.新的日志目录 [root@tech-db-51 /linux0224/mysql_3306]#ls /mysql_3306/logs/ 3306-err.log 9.确保数据可以访问 mysql\u0026gt; select * from test_backup.test_table; +------+ | id | +------+ | 777 | | 888 | | 999 | +------+ 3 rows in set (0.01 sec) 3.增量备份 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 完成演练目标 周日full + 周一inc1 + 周二inc2 + 周三 inc3 注意命令细节即可，最后恢复时，需要先合并多个增量备份的日志，然后再统一恢复完整的数据。 # 1. 先模拟8-10 全量备份 innobackupex --no-timestamp --user=root --password=123456 -S /tmp/mysql.sock /xtrabackup_0224/full_3306_db_$(date +%F)/ # 2.检查全量数据 [root@tech-db-51 /xtrabackup_0224]#du -sh . 93M\t. [root@tech-db-51 /xtrabackup_0224]#ll total 4 drwxr-x--- 26 root root 4096 Aug 10 16:18 full_3306_db_2022-08-10 # 3.模拟次日的增量写入即可 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------+ | mysql-log-bin.000013 | 194 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6 | +----------------------+----------+--------------+------------------+------------------------------------------+ 1 row in set (0.00 sec) # 增量的数据写入 mysql\u0026gt; create database db_8_11; # 4. 进行次日的增量备份，生成增量数据目录 # --incremental-basedir 以哪个目录为基础数据目录，然后进行增量备份 # --incremental 增量备份的数据，放到哪 innobackupex --defaults-file=/etc/my.cnf --user=root --password=123456 --socket=/tmp/mysql.sock --no-timestamp --incremental-basedir=/xtrabackup_data/2025-03-22_18-04-19 --incremental /xtrabackup_0224/incr_1_2022-08-11 innobackupex --defaults-file=/etc/my.cnf --socket=/tmp/mysql.sock --no-timestamp --incremental-basedir=/xtrabackup_data/2025-03-22_18-04-19 --incremental /xtrabackup_data/incr_1_2025-03-22 # 5.进行 8-12的 增量备份，写入数据，模拟当天的数据增量 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+----------------------------------------------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+----------------------------------------------------------------------------------+ | mysql-log-bin.000013 | 362 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6, 9945ceea-1883-11ed-b2b4-000c29463bc7:1 | +----------------------+----------+--------------+------------------+----------------------------------------------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; create database db_8_12; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------+ | mysql-log-bin.000013 | 530 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6, 9945ceea-1883-11ed-b2b4-000c29463bc7:1-2 | +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) # 6.对 8-12的数据，进行增量备份 # --incremental-basedir=/xtrabackup_0224/incr_1_2022-08-11 以谁为相对进行增量 # --incremental=/xtrabackup_0224/incr_2_2022-08-12 本次增量数据写到哪 innobackupex --defaults-file=/etc/my.cnf --user=root --password=linux3306 --socket=/tmp/mysql.sock --no-timestamp --incremental-basedir=/xtrabackup_0224/incr_1_2022-08-11 --incremental /xtrabackup_0224/incr_2_2022-08-12 7.检查当前所有的备份环境 [root@tech-db-51 /xtrabackup_0224]#du -sh * 93M\tfull_3306_db_2022-08-10 3.6M\tincr_1_2022-08-11 3.6M\tincr_2_2022-08-12 [root@tech-db-51 /xtrabackup_0224]# [root@tech-db-51 /xtrabackup_0224]# [root@tech-db-51 /xtrabackup_0224]## 看懂22222 8.模拟8-13数据写入 恢复思路 先模拟删数据，全部删除，反正有全量备份\n1 2 3 mkdir -p /tmp/test_xtrabackup_db/ [root@tech-db-51 /xtrabackup_0224]#mv /linux0224/mysql_3306/* /tmp/test_xtrabackup_db/ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 # 1. 明确了，目前可以恢复 8-10 到 8-12的数据， # 2. 注意8-13的数据，再binlog里，找binlog在哪 [root@tech-db-51 /xtrabackup_0224]#ls /mysql_log/log_bin_3306/ all-06.txt mysql-log-bin.000001 mysql-log-bin.000003 mysql-log-bin.000005 mysql-log-bin.000007 mysql-log-bin.000009 mysql-log-bin.000011 mysql-log-bin.000013 mysqllogOK.sql table_delete.txt jpress.sql mysql-log-bin.000002 mysql-log-bin.000004 mysql-log-bin.000006 mysql-log-bin.000008 mysql-log-bin.000010 mysql-log-bin.000012 mysql-log-bin.index recovery.sql test4.txt [root@tech-db-51 /xtrabackup_0224]# # 3.开始合并增量日志 在使用 Percona XtraBackup 工具进行备份时，--apply-log 和--redo-only 参数用于处理备份的一致性和恢复。 --apply-log - 作用：将备份文件恢复到一致状态。 - 用途：在备份完成后，使用 `--apply-log` 可以应用 redo 日志，以确保数据文件的一致性。这一步通常在准备恢复之前执行，使得备份能够直接用于恢复。 --redo-only - 作用：应用 redo 日志但不清理 undo 日志。 - 用途：用于准备增量备份链。在应用增量备份时，先对基础备份使用 `--apply-log --redo-only`，然后逐个应用增量备份。最后，在应用完所有增量备份后，再次运行 `--apply-log`（不带 `--redo-only`）以完成恢复。 这两个步骤确保备份在恢复时是一致的，并且支持增量备份的应用。 - 先处理8-10全量数据 innobackupex --apply-log --redo-only /xtrabackup_0224/full_3306_db_2022-08-10 - 合并增量1，到全量数据 # --incremental-dir 填入增量的数据目录 写入 全量数据目录 innobackupex --apply-log --redo-only --incremental-dir=/xtrabackup_0224/incr_1_2022-08-11 /xtrabackup_0224/full_3306_db_2022-08-10 # 合并8-12的增量数据 innobackupex --apply-log --redo-only --incremental-dir=/xtrabackup_0224/incr_2_2022-08-12 /xtrabackup_0224/full_3306_db_2022-08-10 # 最后对full数据 一致性校验确认，提交事务 innobackupex --apply-log /xtrabackup_0224/full_3306_db_2022-08-10 # 基于最终的全量数据，恢复 # 预测结果，应该是有 db_8_11 db_8_12 innobackupex --copy-back /xtrabackup_0224/full_3306_db_2022-08-10 [root@tech-db-51 /linux0224/mysql_3306]#chown -R mysql.mysql ./* # 此时还差一个 8-13的增量写入， 目前是 8-10 8-11 8-12 数据全部恢复了 # 基于mysqlbinlog 基于GTID的号码，恢复数据 db_8-13 mysqlbinlog --skip-gtids --include-gtids=\u0026#39;9945ceea-1883-11ed-b2b4-000c29463bc7:3\u0026#39; /mysql_log/log_bin_3306/mysql-log-bin.000013 \u0026gt; /tmp/db_8_13.sql # 恢复该导出的SQL文件 mysql\u0026gt; set sql_log_bin=0; mysql\u0026gt; source /tmp/db_8_13.sql; mysql\u0026gt; set sql_log_bin=1; Query OK, 0 rows affected (0.00 sec) # 确认后续的日志，会继续记录 mysql\u0026gt; insert into db_8_13.table_13 values(6666); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------------------------------------------------+ | mysql-log-bin.000014 | 667 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6, 7929ae4c-188a-11ed-ba6b-000c29463bc7:1-2, 9945ceea-1883-11ed-b2b4-000c29463bc7:1-3 | +----------------------+----------+--------------+------------------+------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 今日作业 1 2 3 4 5 6 7 1.整理mysql数据备份方案 全量+增量 2. xtrabackup工具，当你需要处理超过百GB级别的数据，才会用到这个。 但其实到这个时候，也就有DBA介入了。 3.预习mysql主从复制博客，做练习。 ","date":"2025-04-14T16:12:13+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/%E7%89%A9%E7%90%86%E5%A4%87%E4%BB%BD%E5%B7%A5%E5%85%B7xtrabackup/","title":"物理备份工具（xtrabackup）"},{"content":"1.复习 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 1. mysqldump实现逻辑备份 全量备份 备份某些库 备份某些库下的，某些表 以及只要数据，不要表结构 insert ，打开导出的sql文件看看，mysqldump导出的数据就是个普通文本 只要表结构，不要数据 2. binlog二进制日志 - binlog的作用,记录你修改类的操作，记录到日志中 除非你主动基于myqsldump数据备份,如果再还未备份之前 1. 建了一张表 2. 写入了些数据 3. 有人删表了 binlog的作用显而易见 - 再你未进行备份之前，你还没备份数据， - 如何配置打开binlog - 基于哪些SQL语句，可以查看binlog 的信息 注意： 1 2 3 4 5 https://dev.mysql.com/doc/refman/5.7/en/mysqlbinlog-row-events.html 在官网，查阅--base64-output=DECODE-ROWS 该参数的作用时，发现，官网明确说明了，这个参数，有更良好的阅读性 但是不应该用于数据恢复 再了解了binlog是用于记录数据变化的一个日志后，就得明白，这个日志是用于数据恢复的。\n1 2 数据写入，记录日志SQL 数据丢了？不用吗，日志SQL恢复即可。 1.前提要打开binlog功能 1 2 3 4 5 6 7 8 9 创建、导入数据库等操作，要提前就打开binlog，否则无法记录 mysql\u0026gt; show master status; （测试截止点 935） 查看当前正在用哪个binlog，以及数据截止点在哪 2. 查看某个binlog，每次事务的 pos值区间，以及对应的事件名（建库，写入数据，删除数据） mysql\u0026gt; mysql\u0026gt; show binlog events in \u0026#39;mysql-log-bin.000007\u0026#39;; 2.模拟误删库，恢复数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 模拟误删除库，恢复到删库之前 重新建数据 mysql\u0026gt; mysql\u0026gt; flush logs; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000008 | 154 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; mysql\u0026gt; create database lol01; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; mysql\u0026gt; use lol01; Database changed mysql\u0026gt; mysql\u0026gt; create table tanke(id int); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000008 | 483 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 查看发生了几次事务 show binlog events in \u0026#39;mysql-log-bin.000008\u0026#39;; # 本次事务区间 483-751 mysql\u0026gt; insert into tanke values(666),(777),(888); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 3.模拟数据误删除 4.恢复思路 基于binlog的日志事件查看，找到建库事件，删库事件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 1. 截取从建库到删库之间的所有的binlog 2.先看看当前的binlog mysql\u0026gt; show master status; 3.找到建库的事件pos值 4. 找到删库前的pos事件值 5.截取删库前的SQL恢复即可 从建表，到删数据前的 事务，进行恢复， 基于mysqlbinlog命令，截取 binlog日志，拿到这个区间的SQL mysql-log-bin.000008 # --start-position 从建表开始 316 # --stop-position 到删表之前结束 751 # 截取部分日志 mysqlbinlog --start-position=316 --stop-position=751 mysql-log-bin.000008 \u0026gt; /opt/不恢复直播吃电脑.txt # 预期结果是 ，查询tanke表，看到 666 777 888 # 要进入数据库，暂停事务的记录 mysql\u0026gt; set sql_log_bin=0; Query OK, 0 rows affected (0.00 sec) 导入数据 mysql\u0026gt; source /opt/不恢复直播吃电脑.txt 再次开启事务记录 mysql\u0026gt; select * from lol01.tanke; +------+ | id | +------+ | 666 | | 777 | | 888 | +------+ 3 rows in set (0.00 sec) # 再次开启事务记录 set sql_log_bin=1; 2.基于GTID的binlog应用 1 2 3 4 5 6 7 8 9 10 11 12 基于GTID，不再需要通过pos值去判定每一个事务操作的边界 create database --- pos值 范围 create table --- pos值 范围 insert into --- pos值 范围 mysql提供了更方便，更精确，更容易用于数据恢复的GTID模式 GTID (Global Transaction IDentifier) 是全局事务标识。它具有全局唯一性，一个事务对应一个GTID。 2.1 什么是GTID 从 MySQL 5.6.5 开始新增了一种基于 GTID 的复制方式。\n通过 GTID 保证了每个在主库上提交的事务在集群中有一个唯一的ID。\n这种方式强化了数据库的主备一致性，故障恢复以及容错能力。\n在原来基于二进制日志的复制中，从库需要告知主库要从哪个偏移量pos值进行增量同步，如果指定错误会造成数据的遗漏，从而造成数据的不一致。\n借助GTID，在发生主备切换的情况下，MySQL的其它从库可以自动在新主库上找到正确的复制位置，这大大简化了复杂复制拓扑下集群的维护，也减少了人为设置复制位置发生误操作的风险。\n另外，基于GTID的复制可以忽略已经执行过的事务，减少了数据发生不一致的风险。\n2.2 什么是事务 MySQL 的事务是一组可以一起执行的 SQL 操作，确保数据的一致性和完整性。事务的执行要么全部成功，要么全部失败。事务主要用于处理需要保证数据一致性的操作。\nACID 特性 事务具有以下四个重要的 ACID 特性：\n原子性（Atomicity）：\n事务中的所有操作要么全部完成，要么全部不执行。 如果事务中的某个操作失败，整个事务将回滚到初始状态。 一致性（Consistency）：\n事务开始前和结束后，数据库都必须处于一致的状态。 数据库的完整性约束不能被破坏。 隔离性（Isolation）：\n并发执行的事务相互之间不应影响。 每个事务在提交之前对其他事务不可见。 持久性（Durability）：\n一旦事务提交，其结果是永久性的，即使系统崩溃也不会丢失。 使用事务的基本语法 1 2 3 4 5 6 7 8 9 10 11 12 -- 开始事务 START TRANSACTION; -- 执行一系列操作 UPDATE accounts SET balance = balance - 100 WHERE account_id = 1; UPDATE accounts SET balance = balance + 100 WHERE account_id = 2; -- 提交事务 COMMIT; -- 或者回滚事务 ROLLBACK; START TRANSACTION 用于开始一个事务。 COMMIT 用于提交事务，将所有更改永久保存。 ROLLBACK 用于回滚事务，撤销所有未提交的更改。 通过事务和 ACID 特性，MySQL 可以确保数据的完整性和可靠性，特别是在多用户并发环境中。\nmysql默认的事务规则 在MySQL数据库中，事务默认是会自动提交的，也就是说，如果没有用 begin \u0026hellip; commit 来显式提交事务的话，MySQL 会认为每一条SQL语句都是一个事务，也就是每一条SQL语句都会自动提交。\n可以基于mysqlbinlog去分析日志，发现每一个语句都是事务操作。\n正确事务执行测试 确保，再事务之间的所有SQL，全部正确执行，以及永久生效，争取的事务执行过程。\nmysql默认的修改类的SQL，都是事务执行的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 create database linux0224; create table linux0224.bank( name varchar(20), money decimal(20, 2) )charset=utf8; #写入测试数据 use linux0224; insert into bank values(\u0026#34;小王\u0026#34;, 20000),(\u0026#34;表弟\u0026#34;, 6000); # 主动使用BEGIN ，commit语句区间，查看事务执行的过程，模拟修改数据，模拟转账 # 再事务中所有的SQL，要么都成功，要么都失败，事务的一致性 #数据修改完毕后，数据表，永久生效，写入磁盘。 # 如下2个SQL，分别是 ，给小王减去3000，给表弟加入3000，模拟转账 # 执行成功后，应该看到数据表的变化 # 这2个正确执行的事务，被binlog日志记录， 而刚才出错的，回滚了 begin; update bank set money=money-3000 where name=\u0026#34;小王\u0026#34;; update bank set money=money+3000 where name=\u0026#34;表弟\u0026#34;; commit; mysql\u0026gt; select * from bank; +--------+----------+ | name | money | +--------+----------+ | 小王 | 17000.00 | | 表弟 | 9000.00 | +--------+----------+ 2 rows in set (0.00 sec) 错误SQL事务执行，实现的恢复 mysql提供事务回滚，数据回滚\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 主动的事务 # 小王的SQL正确执行 # 第二条SQL输错 # rollback回滚操作， # 开发写代码，再程序中，进行异常逻辑判断 # 主动执行SQL，查看一个事务下的所有SQL，要么都成功，要么都失败 begin; update bank set money=money-3000 where name=\u0026#34;小王\u0026#34;; update bank ssssssssset money=money+3000 where name=\u0026#34;表弟\u0026#34;; rollback; 2.3 GTID长啥样 默认mysql没有开启gtid\n1 2 3 4 5 6 | mysql-log-bin.000014 | 1810 | Anonymous_Gtid | 100 | 1875 | SET @@SESSION.GTID_NEXT= \u0026#39;ANONYMOUS\u0026#39; | | mysql-log-bin.000014 | 1875 | Query | 100 | 1952 | BEGIN | | mysql-log-bin.000014 | 1952 | Table_map | 100 | 2009 | table_id: 144 (linux0224.bank) | | mysql-log-bin.000014 | 2009 | Write_rows | 100 | 2061 | table_id: 144 flags: STMT_END_F | | mysql-log-bin.000014 | 2061 | Xid | 100 | 2092 | COMMIT /* xid=1071 */ | +----------------------+------+----------------+-----------+-------------+--------------------------- GTID (Global Transaction ID) 是对于一个已提交事务的编号，并且是一个全局唯一的编号。\nGTID 实际上 是由 UUID+TID 组成的。\n其中 UUID 是一个 MySQL 实例的唯一标识。\nTID 代表了该实例上已经提交的事务数量，并且随着事务提交单调递增。\nGTID（全局事务标识符）的具体形式是：\n1 GTID = source_id:transaction_id 具体说明 source_id：通常是 server_uuid，用于唯一标识生成该事务的服务器。 transaction_id：是一个递增的整数，表示该服务器上事务的顺序。 server_uuid server_uuid 是一个全局唯一标识符（UUID），用于标识 MySQL 服务器实例。 这个 UUID 在 MySQL 数据目录下的 auto.cnf 文件中定义。 形式为一个标准的 UUID，例如：3E11FA47-71CA-11E1-9E33-C80AA9429562。 作用 唯一性：每个 MySQL 服务器都有一个唯一的 server_uuid，确保 GTID 的唯一性。 复制和恢复：在主从复制环境中，GTID 用于跟踪事务，从而简化故障转移和恢复操作。 通过 GTID 和 server_uuid，MySQL 可以更高效地进行复制和数据一致性管理。\n2.4 开启uuid 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 1. 修改配置文件，再my.cnf 加入server_id=50; 2. 具体配置如下 [mysqld] gtid-mode=ON enforce-gtid-consistency=true log-slave-updates=ON server_id=100 log_bin=/mysql_log/log_bin_3306/mysql-log-bin character_set_server=utf8mb4 log-error=/linux0224/mysql_3306/logs/3306-err.log port=3306 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3306/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock 重启mysql，配置生效，加载gtid功能 [root@tech-db-51 /mysql_log/log_bin_3306]#systemctl restart mysqld [root@tech-db-51 /mysql_log/log_bin_3306]# # 查看关于gtid的mysql内置变量 show variables like \u0026#39;%GTID%\u0026#39;; mysql\u0026gt; show variables like \u0026#39;%GTID%\u0026#39;; +----------------------------------+-----------+ | Variable_name | Value | +----------------------------------+-----------+ | binlog_gtid_simple_recovery | ON | | enforce_gtid_consistency | ON | | gtid_executed_compression_period | 1000 | | gtid_mode | ON | | gtid_next | AUTOMATIC | | gtid_owned | | | gtid_purged | | | session_track_gtids | OFF | +----------------------------------+-----------+ 8 rows in set (0.00 sec) mysql\u0026gt; # 表示以及开启GTID功能，你后续的事务操作，都会被记录 事务id [root@tech-db-51 /mysql_log/log_bin_3306]#mysql -uroot -plinux3306 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or /g. Your MySQL connection id is 2 Server version: 5.7.28-log MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;/h\u0026#39; for help. Type \u0026#39;/c\u0026#39; to clear the current input statement. mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000015 | 154 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; 建议 1 mysql5.7以后的版本，默认都开启GTID功能，用处很广。 2.5 GTID实践 第二次事务执行\n1 2 3 查看多次执行事务操作 ，生成的多个gtid记录 恢复数据表的玩法，练习，实现数据库的恢复 2.6 基于GTID截取日志 有了gtid之后，再也不用关心日志的开始pos，结束pos了，一个gtid记录，记录一个事务。\n还是基于binlog提取 你要的恢复数据得SQL，但是不用关心 \u0026ndash;start-pos \u0026ndash;stop -pos\n基于 \u0026ndash;include-gtids ，直接截取，你要的 事务id区间即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 --skip-gtids 如果我们是要恢复数据到源数据库或者和源数据库有相同 GTID 信息的实例，那么就要使用该参数。如果不带该参数的话，是无法恢复成功的。 因为包含的 GTID 已经在源数据库执行过了，根据 GTID 特性，一个 GTID 信息在一个数据库只能执行一次，所以不会恢复成功。 # 注意参数的添加，--skip-gtids ，不加mysql会进行gtid记录的幂等性检查，导入sql会报错 # 导出从建库，创建数据，的所有gtid记录，不需要记录pos了 # 基于解密参数，看看日志的可阅读性，在干啥 # 解析 binlog mysql-log-bin.000015 # 截取事务号 mysqlbinlog --skip-gtids --include-gtids=\u0026#39;187299d4-0e2b-11ed-8b0c-000c29463bc7:2-3\u0026#39; mysql-log-bin.000015 \u0026gt; /opt/huifu_xixi_table.txt # 关闭binlog记录 mysql\u0026gt; set sql_log_bin=0; #恢复 mysql\u0026gt; source /opt/huifu_xixi_table.txt #开启binlog记录 mysql\u0026gt; set sql_log_bin=1; Query OK, 0 rows affected (0.00 sec) # 其实区别就是 之前是基于 --start-pos 以及--stop-pos去决定，截取的日志区间，提取SQL 而现在直接基于GTID的号码，即可实现，截取数据区间。完成恢复，且更强大 3 最常见的数据库备份方式 中小型公司的常见备份玩法如下，不管是linux机器的数据备份\n还是备份阿里云的RDS云数据库，都是这个思路，。都可以基于mysqldump远程备份\nmysqldump -uroot -p -h -P ，适用于本地数据备份，也适用于远程备份阿里云的数据库。\nmysql -uroot -p -h -P\n1 2 3 4 5 6 7 8 9 10 1.核心思路，基于mysqldump备份时，加入-F参数，实现日志切割 每次一个binlog记录 2.crontab 每周一全量备份 3. 周一全量备份，以及日志中，获取数据截止点，也就是次日的开始。 4.截取binlog，次日数据是从，下一个GTID号码开始的。 5.找到删数据的GTID事务号，截取至前一个记录，即可截取数据恢复的区间。 全量备份 1 2 3 4 5 6 7 8 9 方案1：逻辑备份 基于mysqldump命令，使用-A参数，全部的库表备份 ,导出来的数据是一堆SQL语句，兼容性很强 --all-database 所有的库表 方案2，直接物理备份 [root@tech-db-51 ~]#ls /linux0224/mysql_3306/ cp tar rsync 全量备份的参数 不要携带GTID的数据导出\n1 2 3 4 5 6 7 --set-gtid-purged=OFF 1. 机器A mysqldump 导出数据，不用该参数，导出的SQL数据，携带当前机器A的 binlog历史记录 且机器B导入该SQL的话，也不会再新记录binlog 2. 机器A mysqldump导出数据携带该参数，导出的只有SQL数据，且不包含GTID信息 这样，新机器B导入该SQL数据，就会重新自己记录binlog 事务记录。 看看导出的SQL文件信息 另一个业务场景的基于GTID导出方式 1 2 [root@tech-db-51 ~]#mysqldump -uroot -p --set-gtid-purged=OFF -A -F \u0026gt; /tmp/no-gtid-all-db-flush-log.sql Enter password: 4. 两个备份，恢复场景 区分于，是否携带\nGTID的历史信息\n场景1：当前数据库的，备份，与恢复 老大给你一个RDS数据库\nip\nport\n让你去做好备份工作。\n全量备份 给数据库开启binlog功能 自主做更多的数据备份工作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 给当前数据库服务器，进行数据备份，数据增量写入恢复。 # 当前机器，当前实例，进行数据，备份+恢复 1. 模拟夜里定时任务执行，进行全量数据备份，刷新binlog，记录上一次事务的截止点（用于数据恢复，截取binlog日志） mysql\u0026gt; create table test_table(id int); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------+ | mysql-log-bin.000004 | 558 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-4 | +----------------------+----------+--------------+------------------+------------------------------------------+ 1 row in set (0.00 sec) # 当前3306数据库，04日志 1-4 的事务记录 # 创建一个目录，用于统一管理，mysql的备份数据 # 这个目录的数据，建议再用 rsync + inotify 试试同步到 备份服务器，最大化数据安全 # 备份 + 数据同步 # 且是携带着当前事务ID的历史记录的 # 以及全量备份了，历史的binlog，没用了，次日，刷新新的binlog，记录第二天的所有新的SQL操作 # 加上——F参数 # 备份之前的记录 | mysql-log-bin.000004 | 558 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-4 | # 备份后得记录 mkdir -p /mysql_3306_backup # -A 备份所有库表 # --single-transaction，给所有数据库加锁，防止数据写入，导致备份错误 # --master-data=2 将binlog的信息以注释形式备份 # -R 导出mysql自定义函数 # -E 导出events事件 # --max_allowed_packet 用于设置服务器或客户端允许处理的最大数据包大小。 mysqldump -uroot -plinux3306 -F -A --single-transaction --max_allowed_packet=64M -R -E \u0026gt; /mysql_3306_backup/full_db_$(date +%F).sql # 明确日志已经刷新了 # 看一看这个全量备份SQL 2. 模拟次日刷新后的日志，数据写入，以及删除数据的操作 mysql\u0026gt; insert into test_table values(777),(888),(999); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql\u0026gt; mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------+ | mysql-log-bin.000009 | 479 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-5 | +----------------------+----------+--------------+------------------+------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; drop database test_backup; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+------------------------------------------+ | mysql-log-bin.000009 | 657 | | | 187299d4-0e2b-11ed-8b0c-000c29463bc7:1-6 | +----------------------+----------+--------------+------------------+------------------------------------------+ 1 row in set (0.00 sec) 3. 截取日志，进行数据恢复，实现全量数据的备份与恢复。 # 如何截取，要看你想恢复什么 # 思路 1. 解析二进制日志，看看都有0009日志 mysqlbinlog --base64-output=decode-rows -vv /mysql_log/log_bin_3306/mysql-log-bin.000009 \u0026gt; /tmp/09.log 2. 分析完毕 09 增量日之后，确认要 全量恢复库，增量恢复数据 3. 先导入全量数据 mysql\u0026gt; set sql_log_bin=0; mysql\u0026gt; source full_db_2022-08-10.sql; mysql\u0026gt; select * from test_table; Empty set (0.01 sec) 目前实现了基于全量备份的数据，找回了 库 test_backup; 4. 基于次日刷新的0009增量日志，恢复插入数据 基于mysqlbinlog 截取 00009日志，截取你要的事务区间 # --include-gtids 截取一个GTID事务区间 # 解密查看SQL #pos值区间 ，写入数据的 194-479 mysqlbinlog --base64-output=decode-rows -vv --skip-gtids --include-gtids=\u0026#39;187299d4-0e2b-11ed-8b0c-000c29463bc7:5\u0026#39; /mysql_log/log_bin_3306/mysql-log-bin.000009 \u0026gt; /tmp/decode_09.txt # 这是要用于恢复的SQL语句 mysqlbinlog --skip-gtids --include-gtids=\u0026#39;187299d4-0e2b-11ed-8b0c-000c29463bc7:5\u0026#39; /mysql_log/log_bin_3306/mysql-log-bin.000009 \u0026gt; /mysql_3306_backup/restore_test_backup_db.sql # 恢复数据的操作 mysql\u0026gt; set sql_log_bin=0; mysql\u0026gt; source /mysql_3306_backup/restore_test_backup_db.sql; mysql\u0026gt; select * from test_backup.test_table; +------+ | id | +------+ | 777 | | 888 | | 999 | +------+ 3 rows in set (0.00 sec) mysql\u0026gt; set sql_log_bin=1; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; # 总结 至此，完成 基于 1. 全量备份的 库、表的恢复 2. 次日刷新的binlog，截取事务区间，恢复的 表数据 场景2：远程数据库的复制，或者重新数据导入 数据库A导出的数据库，导入到 机器B\n3306实例的数据， 导入到新的 3307实例，让它继续开始binlog写入\n正确远程数据导入玩法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 -rw-r--r-- 1 root root 863K Aug 10 10:34 no-gtid-all-db-flush-log.sql 3307数据库，导入进入，看是否可以使用该数据，以及binlog重新记录 # 准备一个新的 初始化数据的 3307实例 # 打开GTID 以及binlog功能，重新记录 事务日志 mysql\u0026gt; source /tmp/no-gtid-all-db-flush-log.sql mysql\u0026gt; select * from kings.cike; +-----------+ | name | +-----------+ | 钟薛高 | | 兰陵王 | | 孙悟空 | +-----------+ 3 rows in set (0.00 sec) 错误的场景\n1 2 3 4 5 6 7 8 9 10 3306 导出的数据，携带了GTID历史记录 SET @@GLOBAL.GTID_PURGED=\u0026#39;187299d4-0e2b-11ed-8b0c-000c29463bc7:1-2\u0026#39;; 3307 实例的GTID 号码 mysqld --initialize-insecure --user=mysql --basedir=/opt/mysql --datadir=/linux0224/mysql_3307 | eba785df-16c3-11ed-9d4f-000c29463bc7:1-276 | 试试 导入3306的SLQ到 3307 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 1. 3307实例，重新初始化，基于GTID启动后，默认有自己的GTID信息 唯一事务ID标识的 mysql\u0026gt; create database 3307_db; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; show master status; +------------------+----------+--------------+------------------+----------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+----------------------------------------+ | mysql-bin.000001 | 322 | | | 68d3d065-185c-11ed-bcd5-000c29463bc7:1 | +------------------+----------+--------------+------------------+----------------------------------------+ 1 row in set (0.00 sec) [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock \u0026lt; /tmp/all-db-flush-log.sql ERROR 1840 (HY000) at line 24: @@GLOBAL.GTID_PURGED can only be set when @@GLOBAL.GTID_EXECUTED is empty. 2. 此时是无法导入3306携带GTID的SQL文件 3. 你可以重置3307的 binlog，重置它的GTID事务信息 reset master; 没有它自己的GTID历史记录了，清空3307自己的GTID事务记录 4. 你就可以正确导入 3306的数据了，且携带GTID的 [root@tech-db-51 /linux0224/mysql_3307]# [root@tech-db-51 /linux0224/mysql_3307]# [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock \u0026lt; /tmp/all-db-flush-log.sql [root@tech-db-51 /linux0224/mysql_3307]# 5. 此时的3307，就从3306的数据开始写入 ","date":"2025-04-14T16:10:17+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/%E5%A4%87%E4%BB%BD%E8%BF%9B%E9%98%B6gtid/","title":"备份进阶（GTID）"},{"content":"1.为什么要备份 运维是干什么的？\n保护服务器数据安全 维护公司运维资产7*24小时运转 企业真实案件：\nhttps://www.leiphone.com/category/sponsor/Isb7Smi17CHBTxVF.html\n企业丢了数据，就等于失去了商机、客户、产品、甚至倒闭。\n在各式各样的数据中，数据库的数据更是核心之核心，当然其他各式各样的如静态文件数据，也很重要，也会通过其他的备份方式来保证安全。\n2.备份恢复的职责 1 2 3 4 5 6 7 8 9 10 11 1. 备份、恢复的策略 备份周期、备份工具、备份方式、数据恢复方式 2.日常备份检查 日志、备份数据 3.定期恢复数据演练 4.数据故障时，利用现有的资源，快速恢复 5.数据迁移，数据库升级。 3.备份工具 物理备份: 直接备份数据库所对应的数据文件基至是整个磁盘。\n逻辑备份: 将数据从数据库中导出, 并将导出的数据进行存档备份。\n类别 物理备份 逻辑备份 备份对象 数据库的物理文件(如数据文件,控制文件,归档日志文件等) 数据库对象(如用户,表,存储过程等) 可移植性 较弱,甚至不可移植 数据库对象级备份,可移植性较强 占用空间 占用空间大 占用空间相对较小 恢复效率 效率高 效率较低 适用场景 大型业务系统或者整系统的容灾恢复、系统级全量备份 主备数据库间的增量数据备份、不同业务系统之间的数据同步、业务不中断升级过程中在线数据迁移 逻辑备份 把数据库、表，以SQL语句的形式，输出为文件的备份过程，这种方式称之为逻辑备份。\n但是这种方式效率并不高，以SQL导出，在海量数据下，例如几十G的场景，备份、恢复的时间都会过长。\n因此还会有其他备份方案。\n1 2 3 4 mysqldump mysqlbinlog mydumper binlog2sql 物理备份 1 2 3 1. 工具使用，https://www.percona.com/software/mysql-database/percona-xtrabackup 2.直接shell+crontab备份整个mysql数据目录 如何选 1 2 100G数据以内，逻辑备份没问题，服务器配置要跟上 100G 以上，建议物理备份 4.mysqldump备份 开始逻辑备份的学习\n只备份某些库 只备份某些表 以及只要表结构，不要表数据 结构，数据都要，全量备份等 1 2 3 4 5 6 7 8 9 10 11 12 mysqldump备份语法 Mysqldump -u用户名 -p密码 参数 数据库名 \u0026gt; 数据备份文件 mysql自带的备份工具，可以实现本地备份，远程备份 mysqldump命令备份过程，实际上是把数据库、表，以SQL语句的形式，输出为文件的备份过程，这种方式称之为逻辑备份。 但是这种方式效率并不高，以SQL导出，在海量数据下，例如几十G的场景，备份、恢复的时间都会过长。 因此还会有其他备份方案。 4.1 mysqldump连接参数 1 2 3 4 5 -u mysql用户名 -p mysql用户密码 -S mysql本地socket文件 -h 指定主机地址 -P 指定mysql端口 4.2 mysqldump备份参数 可以利用如下语句，实现数据库的数据、结构、很实用的技巧。\n全量备份 对当前数据库实例，导出，所有的库，表，以及数据，转储为SQL文件\n对这个文件进行导入执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 --all-databases，-A 转储所有数据库中的所有表。 mysqldump -uroot -plinux3306 --all-databases \u0026gt; /opt/all-3306.sql [root@tech-db-51 ~]#wc -l /opt/all-3306.sql 2030 /opt/all-3306.sql [root@tech-db-51 ~]# [root@tech-db-51 ~]#file /opt/all-3306.sql /opt/all-3306.sql: UTF-8 Unicode text, with very long lines [root@tech-db-51 ~]# # 这个备份的文件，具体步骤就是 # 有几张表示空表，没数据， lock, unlock之间是空的 1. 当前操作某个库， 先基于 if条件 判断，然后create 库 2. 删除库下的某个表，然后create 重建表结构 3. 先 lock 锁住表的数据写入，为了防止恢复出现问题； 恢复数据，insert 插入数据 unlock 解锁表，允许再次写入 mysqldump 逻辑备份，导出的SQL，解读 ，3个流程 1 每学一个备份的玩法，就进行数据导入，查看具体备份，恢复的情况。 准备一个新的数据库实例，模拟数据恢复，查看不同备份命令的数据恢复结果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 准备一个 3307 实例 1. 清空3307的数据 2. 重新初始化3307的数据 [root@tech-db-51 /linux0224/mysql_3307]#mysqld --initialize-insecure --user=mysql --basedir=/opt/mysql --datadir=/linux0224/mysql_3307/ 3.导入3306的数据即可覆盖 # 恢复数据的命令 [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock 3307 \u0026gt; 3306数据 （自建的库表，以及mysql默认得库表） mysql\u0026gt; source /opt/all-3306.sql 重启3307后，会读取所有3306 的数据了 [root@tech-db-51 /linux0224/mysql_3307]#bash /linux0224/3307.sh restart Restarting MySQL... Stoping MySQL... Starting MySQL... 此时3307的数据，完全以3306来了，用的3306的账密认证了。 [root@tech-db-51 /linux0224/mysql_3307]#mysql -uroot -plinux3306 -S /linux0224/mysql_3307/mysql.sock mysql: [Warning] Using a password on the command line interface can be insecure. 指定3306备份某个库下的某个表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 mysqldump -uroot -plinux3306 world city \u0026gt; /opt/world_city.sql 1. 删除city表 2. 创建city表结构 ，定义好字段 3. insert插入数据，city ，一条insert语句写入了所有数据 3307实例单独导入某个表数据 # 方式1，导入数据 mysql\u0026gt; create database test_world; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; use test_world; Database changed mysql\u0026gt; source /opt/world_city.sql # 方式2，命令行，指定库，导入 [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock test_world \u0026lt; /opt/world_city.sql mysql\u0026gt; select * from city where id \u0026lt;5; +----+----------------+-------------+----------+------------+ | ID | Name | CountryCode | District | Population | +----+----------------+-------------+----------+------------+ | 1 | Kabul | AFG | Kabol | 1780000 | | 2 | Qandahar | AFG | Qandahar | 237500 | | 3 | Herat | AFG | Herat | 186800 | | 4 | Mazar-e-Sharif | AFG | Balkh | 127800 | +----+----------------+-------------+----------+------------+ 4 rows in set (0.00 sec) 指定备份库下的多个表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #将3306 world库下的 country countrylanguage 导出为SQL，发给3307导入 [root@tech-db-51 ~]#mysqldump -uroot -plinux3306 world city country countrylanguage \u0026gt; /opt/world_all_tb.sql mysqldump: [Warning] Using a password on the command line interface can be insecure. [root@tech-db-51 ~]# [root@tech-db-51 ~]# [root@tech-db-51 ~]#vim /opt/world_all_tb.sql [root@tech-db-51 ~]# [root@tech-db-51 ~]## 该文件，就是对3张表的 结构，数据，导出 # 恢复数据，到3307实例 [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock test_world \u0026lt; /opt/world_all_tb.sql Database changed mysql\u0026gt; show tables; +----------------------+ | Tables_in_test_world | +----------------------+ | city | | country | | countrylanguage | +----------------------+ 3 rows in set (0.00 sec) # 小结 导出3306 world库下的多个表 恢复导入到了3307实例中 # 3307本身就有 city 表，数据会重复吗？ #不会，/opt/world_all_tb.sql ，先drop删表，create 建表，insert写入数据 指定你要哪些数据库，进行备份 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 --databases，-B 转储几个数据库。 通常情况，mysqldump将命令行中的第1个名字参量看作数据库名，后面的名看作表名。 使用该选项，它将所有名字参量看作数据库名。 -B可以跟上多个数据库名，同时备份多个库 尽量结合gzip命令压缩 # 导出3306的 dev01 库 school_db库 mysqldump -uroot -plinux3306 -B school_db dev01 \u0026gt; /opt/school_db-dev01.sql # 查看sql文件 # 导入到3307实例 mysql\u0026gt; ^DBye [root@tech-db-51 /linux0224/mysql_3307]#mysql -S /linux0224/mysql_3307/mysql.sock \u0026lt; /opt/school_db-dev01.sql 只要表结构，不要数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 有一些服务器，你想拿到这些服务器上的数据库 ，表的结构，字段即可。 框架 拿到这些框架，导入测试服务器， --no-data参数 # 语法 mysqldump -uroot -p 库 该库下的表1 该库下的表2 --no-data # 导出生产服务器 3306实例的 员工库 下，职称表的结构 mysqldump -uroot -plinux3306 --no-data employees titles \u0026gt; /opt/emp_titles_no_data.sql # 看看 sql文件 少一个insert插入数据 # 备份的SQL文件，很简单 1. 删表 2. create 创建表结构 [root@tech-db-51 ~]#grep -Ev \u0026#39;#|\\*|--|^$\u0026#39; /opt/emp_titles_no_data.sql DROP TABLE IF EXISTS `titles`; CREATE TABLE `titles` ( `emp_no` int(11) NOT NULL, `title` varchar(50) NOT NULL, `from_date` date NOT NULL, `to_date` date DEFAULT NULL, PRIMARY KEY (`emp_no`,`title`,`from_date`), CONSTRAINT `titles_ibfk_1` FOREIGN KEY (`emp_no`) REFERENCES `employees` (`emp_no`) ON DELETE CASCADE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 只要表数据，不要结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 # 有一个现成的测试服务器，数据表都有了，但是就没数据 # 只要insert语句，不要 create table语句 --no-create-info，-t 还是遵循mysqldump的 默认语法 库 表1 表2 表3 数据导入，文件，可能比较大，建议压缩 # 导出3306 的 title表数据，以及 salaries mysqldump -uroot -plinux3306 --no-create-info employees titles salaries |gzip \u0026gt; /opt/data_employees_title_salaries.sql.gz # 恢复该数据，导入到 3307实例 # 创建表，导入sql文件 # 创建该2个对应的表结构即可 CREATE TABLE `titles` ( `emp_no` int(11) NOT NULL, `title` varchar(50) NOT NULL, `from_date` date NOT NULL, `to_date` date DEFAULT NULL, PRIMARY KEY (`emp_no`,`title`,`from_date`), CONSTRAINT `titles_ibfk_1` FOREIGN KEY (`emp_no`) REFERENCES `employees` (`emp_no`) ON DELETE CASCADE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 ; CREATE TABLE `salaries` ( `emp_no` int(11) NOT NULL, `salary` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`from_date`), CONSTRAINT `salaries_ibfk_1` FOREIGN KEY (`emp_no`) REFERENCES `employees` (`emp_no`) ON DELETE CASCADE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 导入sql数据 方式1 1. 先解压为普通的sql文件 2. 再学过命令导入 方法2 zcat data_employees_title_salaries.sql.gz | mysql -S /linux0224/mysql_3307/mysql.sock d1 # 验证数据的恢复titles mysql\u0026gt; select * from titles order by emp_no limit 0,5; +--------+-----------------+------------+------------+ | emp_no | title | from_date | to_date | +--------+-----------------+------------+------------+ | 10001 | Senior Engineer | 1986-06-26 | 9999-01-01 | | 10002 | Staff | 1996-08-03 | 9999-01-01 | | 10003 | Senior Engineer | 1995-12-03 | 9999-01-01 | | 10004 | Engineer | 1986-12-01 | 1995-12-01 | | 10004 | Senior Engineer | 1995-12-01 | 9999-01-01 | +--------+-----------------+------------+------------+ 5 rows in set (0.00 sec) # 工资表 mysql\u0026gt; select * from salaries order by emp_no limit 0,5; +--------+--------+------------+------------+ | emp_no | salary | from_date | to_date | +--------+--------+------------+------------+ | 10001 | 60117 | 1986-06-26 | 1987-06-26 | | 10001 | 62102 | 1987-06-26 | 1988-06-25 | | 10001 | 66074 | 1988-06-25 | 1989-06-25 | | 10001 | 66596 | 1989-06-25 | 1990-06-25 | | 10001 | 66961 | 1990-06-25 | 1991-06-25 | +--------+--------+------------+------------+ 5 rows in set (0.00 sec) 备份且压缩数据 对于数据库有大量数据表，以及信息，导出的备份文件，最好是压缩后的，节省磁盘。\n1 2 3 # 压缩数据备份， [root@tech-db-51 ~]#du -h /opt/data_employees_title_salaries.sql.gz 27M\t/opt/data_employees_title_salaries.sql.gz 什么是lock tables 禁止DML相关SQL执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 mysql提供的，基于会话的 锁表，防止他人冲突写入数据。 语法1，单独锁某个表 基于会话的，锁某个表 # 针对其他mysql链接会话的写入动作，锁住。 mysql\u0026gt; lock table world.city write; mysql\u0026gt; unlock tables; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from city order by id desc limit 0,5; +------+------+-------------+----------+------------+ | ID | Name | CountryCode | District | Population | +------+------+-------------+----------+------------+ | 4084 | | | | 0 | | 4083 | | | | 0 | | 4082 | | | | 0 | | 4081 | | | | 0 | | 4080 | | | | 0 | +------+------+-------------+----------+------------+ 5 rows in set (0.00 sec) 语法2，全局读锁，针对普通账号的写入权限。 set global read_only=1; set global read_only=0; 5.日志篇 日志的作用，不说大家应该都知道，可以收集、检测我们程序的健康状况\n默认这些日志，大部分是未开启的，运维小于可以通过命令、配置文件，开启这些日志，以及定义存储路径。\nmysql日志文件的作用：\n1、能记录物理数据页面的修改的信息；\n2、能将数据从逻辑上恢复至事务之前的状态；\n3、能以二进制文件的形式记录了数据库中的操作；\n4、能记录错误的相关信息；\n5、能从主服务器中二进制文件取的事件等等。\n普通日志 记录了服务器接收到的每一个查询或是命令，无论这些查询或是命令是否正确甚至是否包含语法错误，general log 都会将其记录下来 ，记录的格式为 {Time ，Id ，Command，Argument }。\n也正因为mysql服务器需要不断地记录日志，开启General log会产生不小的系统开销。 因此，Mysql默认是把General log关闭的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 产生大量的磁盘IO，导致数据库服务器的磁盘压力，CPU压力。 mysql数据库的特点是 底层的逻辑是 1.先写入数据到磁盘中 2. 记录本次写入动作，记录到日志中 增删改查语句，全部记录下来。 用在银行，证券等公司，需要对每一个SQL语句，做严格的记录，审核，后期的检查。恢复等。 采购高价的SSD超强的CPU，超大的存储磁盘。 二进制日志binlog 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 mysql将你执行的DML相关的SQL操作 insert 插入数据 create 建库，建表 默认会做的事 1. 实质性的创建库表数据，写入磁盘中。 做2件事，维护数据的安全 1. 定时备份 2. binlog二进制日志 将你每次的DML操作，额外开启一个binlog日志功能，记录本次修改数据的操作，写入到日志中 binlog是记录数据库被修改的SQL语句，对数据造成影响了。\n一般是DDL和DML语句，包含\ninsert update delete create drop alter 等关键字 作用 记录mysql数据的增量数据，且用来做增量数据恢复，前面老师已经完整的讲过、全量备份、增量备份的区别，如果不开启binlog，将无法恢复完整的数据。\n以及用在主从数据复制\n二进制binlog索引文件 该文件用于记录binlog的索引号\n1 2 [root@db-51 ~]#cat /linux0224/mysql_3306/logs/mysql-bin.index /linux0224/mysql_3306/logs/mysql-bin.000001 6.binlog日志（重点） binlog是mysql一大重点，Binlog是一个二进制格式的文件，用于记录用户对数据库更新的SQL语句信息\n例如更改数据库库表和更改表内容的SQL语句都会记录到binlog里，但是对库表等内容的查询则不会记录到日志中。\n1 2 3 4 记录 DML，insert update，delete DDL，create drop，alter，truncate DCL，grant revoke binlog的作用 当有数据写入到数据库时，还会同时把更新的SQL语句写入到对应的binlog文件里，这个文件就是上文所说的binlog文件。\n1 2 3 4 5 6 7 8 备注：mysql是先写日志，再写入数据的过程。 insert into city values(); 先后的mysql底层会 1. 先记录到binlog中，这个insert语句 2. 执行该语句，写入磁盘数据 配置log_bin 默认是没开启binlog功能的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 查看mysql关于log_bin的变量参数 查看log_bin的配置信息 mysql\u0026gt; show variables like \u0026#39;%log_bin%\u0026#39;; +---------------------------------+-------+ | Variable_name | Value | +---------------------------------+-------+ | log_bin | OFF | | log_bin_basename | | | log_bin_index | | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | ON | +---------------------------------+-------+ 6 rows in set (0.01 sec) 开启binlog 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 只需要修改配置文件，加入开启 log_bin的参数即可，就是永久生效的了 server_id=100 # 是指二进制日志，具体存储到哪，建议做法是，和mysql数据目录分开 mkdir -p /mysql_log/log_bin_3306/ log_bin=/mysql_log/log_bin_3306/mysql-log-bin # 最终配置 [root@tech-db-51 ~]#cat /etc/my.cnf [mysqld] server_id=100 log_bin=/mysql_log/log_bin_3306/mysql-log-bin character_set_server=utf8mb4 log-error=/linux0224/mysql_3306/logs/3306-err.log port=3306 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3306/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock [root@tech-db-51 ~]# # 重启mysqld mkdir -p /mysql_log/log_bin_3306/ chown -R mysql.mysql /mysql_log/ systemctl restart mysqld # 目前是没有二进制日志文件的，只有发生DML操作后，自动生成 [root@tech-db-51 ~]#cd /mysql_log/log_bin_3306/ [root@tech-db-51 /mysql_log/log_bin_3306]#ll total 0 # 检查mysql，二进制日志的变量配置信息 mysql\u0026gt; show variables like \u0026#39;%log_bin%\u0026#39;; +---------------------------------+---------------------------------------------+ | Variable_name | Value | +---------------------------------+---------------------------------------------+ | log_bin | ON | | log_bin_basename | /mysql_log/log_bin_3306/mysql-log-bin | | log_bin_index | /mysql_log/log_bin_3306/mysql-log-bin.index | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | ON | +---------------------------------+---------------------------------------------+ 6 rows in set (0.01 sec) mysql\u0026gt; 查看具体的日志信息\n1 2 3 4 5 [root@tech-db-51 /mysql_log/log_bin_3306]#ll total 8 -rw-r----- 1 mysql mysql 154 Aug 8 15:04 mysql-log-bin.000001 -rw-r----- 1 mysql mysql 45 Aug 8 15:04 mysql-log-bin.index [root@tech-db-51 /mysql_log/log_bin_3306]# binlog内容的格式 事件event记录方式 也就是binlog日志记录了如下内容，解密后可看。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 1. 事件描述 时间戳 server_id 加密方式 开始位置 start_pos 结束位置 end_pos mysql里面的数据操作，都是事务性，被mysql以 开始-结尾 做了一个记录 create database d1; 从开始 到结束，都被mysql 数字号，记录位置 2.事件内容 修改类的操作，SQL语句，数据行的变化 重点，使用binlog主要关注 start_pos end_pos 事件内容 二进制日志事件内容格式查看 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 查看binlog日志的详细信息 mysql\u0026gt; show variables like \u0026#39;%binlog%\u0026#39;; 这里看到| binlog_format 是ROW 对于DDL、DCL语句，直接将SQL本身记录到binlog中 对于DML : insert、update、delete 受到binlog_format参数控制。 SBR : Statement : 语句模式。之前版本，默认模式 RBR : ROW : 行记录模式。5.7以后，默认模式 MBR : mixed : 混合模式。 # 一句话，5.7版本中 binlog日志，基于行去记录 用户的DML操作 简单说就是，一个insert 语句，记录为一行日志，更新一个pos值 一个delete语句，也事一行日志，更新一个pos值 查看binlog日志文件情况 查看所有日志文件的信息，二进制日志\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [root@tech-db-51 /linux0224/mysql_3306]#ls /mysql_log/log_bin_3306/ mysql-log-bin.000001 mysql-log-bin.index # 查看当前数据库实例，用哪个日志文件记录 SQL中。 show binary logs; mysql\u0026gt; show binary logs; +----------------------+-----------+ | Log_name | File_size | +----------------------+-----------+ | mysql-log-bin.000001 | 154 | +----------------------+-----------+ 1 row in set (0.00 sec) 查看当前日志，记录的事件，最新截止点在哪 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000001 | 154 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) # 只要数据变化 刷新新日志文件 了解该命令即可，不能随便执行。。\n1 2 3 4 5 一般用于数据库恢复，数据库重置时，才会用到。 除非你已经做好了全量备份，次日新增数据时，重新记录新的binlog也行。 flush logs; 不能随便敲 查看当前mysql用哪个日志文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 查看当前mysql，正在用的哪个binlog日志文件 show master status; 显示mysql所有的binlog记录 你当前数据库实例，所有的数据变化，分散记录再了这些日志文件中 mysql\u0026gt; show binary logs; +----------------------+-----------+ | Log_name | File_size | +----------------------+-----------+ | mysql-log-bin.000001 | 557 | | mysql-log-bin.000002 | 328 | +----------------------+-----------+ 2 rows in set (0.00 sec) 模拟binlog记录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 1.写入数据，库，表 2.分别查看binlog记录pos值的变化，确认binlog会记录哪些SQL。 3.确认上述的所有数据创建操作，属于mysql的一个完整事务，到执行commit命令。 4. 当前用的数据库引擎，叫做innodb，默认就是DML操作都是事务性操作。 SQL执行完毕后，默认执行了一个commit提交指令。 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000002 | 508 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; mysql\u0026gt; insert into hei values(\u0026#34;11\u0026#34;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000002 | 783 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; 简单理解什么是mysql的事务 1 2 3 4 5 6 7 可以理解为 你去存钱 1.第一次存500，第二次存800，然后退出银行卡时，本次存钱的动作，永久写入数据库，你的余额永久变化了 2. 你去转账给好兄弟，第一次转了5块，第二次转了10块，这个过程都得你好兄弟的卡里，多了5块，10块，才是正确的，如果哪一方的账号出了问题，导致转账动作异常，数据库都能回退本次操作。 也就是，你不会少5块，对方也不会多5块，数据一致性完全正确。 这是mysql数据库提供的事务性特征。 查看日志事件 具体来看 二进制日志事件截图，看看，日志到底记录了个啥。\n1 2 3 1. binlog是二进制，人类看不懂的 2. 基于mysqlbinlog命令，解读为普通的SQL文件即可 体验binlog流程图解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 导出binlog [root@tech-db-51 /mysql_log/log_bin_3306]#mysqlbinlog mysql-log-bin.000003 \u0026gt; /tmp/mysql-log.txt 154\t建库 明文 325 建表 ,明文 501 插入表数据 at 768 从这开始 插入多条数据 1055 # 解密当前binlog，查看具体的SQL # 基于base64算法，按行解密binlog # -vv 显示日志的详细程度 [root@tech-db-51 /mysql_log/log_bin_3306]#mysqlbinlog --base64-output=decode-rows -vv mysql-log-bin.000003 \u0026gt; /tmp/decode-mysql-log.txt # 再次插入多条数据，pos值变化 mysql\u0026gt; insert into biekun77 values(2),(3),(4),(5),(6); Query OK, 5 rows affected (0.00 sec) Records: 5 Duplicates: 0 Warnings: 0 # 再次解密日志，查看 插入的数据 解密查看binlog日志 解密binlog，其实就是解密出具体的SQL语句，也就看到了具体的数值。\n1 2 3 4 [root@db-51 /mysql_backup]#mysqlbinlog /linux0224/mysql_3306/logs/mysql-bin.000003 [root@db-51 /mysql_backup]#mysqlbinlog --base64-output=decode-rows -vv /linux0224/mysql_3306/logs/mysql-bin.000003 7.binlog日志截取与恢复实践 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 1. 查看当前数据库，都用了哪些binlog mysql\u0026gt; show binary logs; +----------------------+-----------+ | Log_name | File_size | +----------------------+-----------+ | mysql-log-bin.000001 | 557 | | mysql-log-bin.000002 | 1109 | | mysql-log-bin.000003 | 1055 | +----------------------+-----------+ 3 rows in set (0.00 sec) 2. 当前正在用哪个binlog mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000003 | 1055 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 3. 查看binlog的玩法 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000003 | 1055 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 删除数据5 删除动作也是修改，也会提交事务，也会生成新的pos值 mysql\u0026gt; delete from biekun77 where id=5; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000003 | 1322 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) # 解密binlog日志 # 更精确的确认pos值的玩法 起点截止点 show binlog events in \u0026#39;mysql-log-bin.000003\u0026#39; # 恢复数据的命令 # --start-position 从哪个pos值开始 # --stop-positio 到哪个pos值结束 （delete语句之前截止） # 这个命令是，解密binlog，截取日志，只截取写入数据的 部分SQL，丢弃delete语句的部分 # delete删除数据 # 重新insert写入不就得了么 mysqlbinlog --start-position=381 --stop-position=752 mysql-log-bin.000004 \u0026gt; /tmp/restore-lol.sql 误删除数据的恢复思路 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 1. 使用mysql的GTID日志模式 用这个方式，就可以不用考虑POS值的选择麻烦了，目前生产玩法都是它，学习手工pos值的玩法，是为了更好理解GTID的优点。 2. 基于mysqlbinlog的日志提取 3.目前的思路是 - 如果是单行数据的delete 提取日志，解密SQL，然后手工insert插入数据即可 1. 当前的 日志状态 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000004 | 1793 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 2. 手工删除数据，基于日志恢复 # mysql\u0026gt; delete from tb1 where id =2; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000004 | 2049 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) # 当前状态 是 1793 2049截止，是数据删除 # 误删除了一个数据 # 删除的动作，被记录到了 binlog日志了 分析binlog日志，能知道你到底删除了什么 # delete也是被加密的数据 # 误误删除数据，你是不知道，到底删除了什么的 # 这个删除动作，由于开启binlog日志，所以delete动作也被记录下来AI # 提取binlog日志部分信息，解密出了，到底删了什么 mysqlbinlog --start-position=1793 --stop-position=2049 mysql-log-bin.000004 \u0026gt; /tmp/delete-test.sql # 单行恢复，删除了什么 # insert 写入 mysql\u0026gt; select * from data1.tb1; +------+ | id | +------+ | 1 | | 3 | | 4 | +------+ 3 rows in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; insert into data1.tb1 values(2); Query OK, 1 row affected (0.00 sec) - 如果是删库，删表级别的操作。 提取，从建库，到插入数据的部分 模拟练习 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 再来一次，建库，建表，删表，恢复数据 1.刷新日志，从头来 mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000006 | 154 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; create database db06; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; use db06; Database changed mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000006 | 313 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; create table tb06(id int); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000006 | 477 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; insert into tb06 values(66),(77),(88); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql\u0026gt; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000006 | 742 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) # 查看binlog的事件 1. 建库 154 \u0026gt; 313 2. 建表 313 \u0026gt; 477 3. 写入数据 477 \u0026gt; 742 4. 删库 742 \u0026gt; 899 4. 直接干掉这个库 ，db06 drop database db06; 查看 日志状态 show master status; mysql\u0026gt; show master status; +----------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------+----------+--------------+------------------+-------------------+ | mysql-log-bin.000006 | 899 | | | | +----------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 日志事件 2. 恢复数据 你目前所有的操作，都被记录再了日志 mysql-log-bin.000006 - 先看啊看这个日志，完整的SQL记录 mysqlbinlog mysql-log-bin.000006 # 再次查看日志事件，截取，你要的 SQL范围 mysql\u0026gt; show binlog events in \u0026#39;mysql-log-bin.000006\u0026#39;; --start-position --stop-position mysqlbinlog --start-position=154 --stop-position=419 mysql-log-bin.000007 \u0026gt; /tmp/huifu-tb06.sql # 恢复操作 1. 先停止binlog的记录 mysql\u0026gt; set sql_log_bin=0; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show variables like \u0026#39;%log_bin%\u0026#39;; +---------------------------------+---------------------------------------------+ | Variable_name | Value | +---------------------------------+---------------------------------------------+ | log_bin | ON | | log_bin_basename | /mysql_log/log_bin_3306/mysql-log-bin | | log_bin_index | /mysql_log/log_bin_3306/mysql-log-bin.index | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | OFF | +---------------------------------+---------------------------------------------+ 6 rows in set (0.00 sec) 2数据导入 mysql\u0026gt; set sql_log_bin=0; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show variables like \u0026#39;%log_bin%\u0026#39;; +---------------------------------+---------------------------------------------+ | Variable_name | Value | +---------------------------------+---------------------------------------------+ | log_bin | ON | | log_bin_basename | /mysql_log/log_bin_3306/mysql-log-bin | | log_bin_index | /mysql_log/log_bin_3306/mysql-log-bin.index | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | OFF | +---------------------------------+---------------------------------------------+ 6 rows in set (0.00 sec) source /opt/huifu-tb06.sql 恢复binlog set sql_log_bin=1; 今日作业 1 2 3 4 5 6 1.完成mysqldump逻辑备份命令练习 2. 完成binlog日志作用整理，以及数据恢复实践 基于pos值的玩法，恢复数据通过了。 ","date":"2025-04-14T16:07:24+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%97%A5%E5%BF%97mysqldump/","title":"备份与日志（Mysqldump）"},{"content":"02-3-mysql运维核心基础 前置知识回顾\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 mysql多实例登录 mysql c/s模式 ，client server 两端 mysql客户端 机器本地的，/opt/mysql/bin/mysql 命令 windows机器上安装的一个 mysql命令 mysql服务端 10.0.0.51:3306 mysql -uroot -p密码 -h该账户允许登录的网段 -P实例端口 2种链接方式 入口一：基于ip：port的 网络链接形式，入口一 ，链接参数 ，-hlocahost -P3306 端口，窗口提供服务的入口 windows机器，去链接 mysql服务端 本质上是tcp的建立 netstat 查看网络链接情况 # 期望是你windows也装了个mysql，然后去登录 windows命令行： mysql -uroot -p密码 -hlocalhost # 远程链接 # 前提（默认mysql只提供了localhost登录，） # 授权操作，允许root@10.0.0.% 这个网段登录 windows命令行：发请求 10.0.0.1 这个windows的ip发出登录请求 ↓ mysql -uroot -plinux3306 -h10.0.0.51 -P3306 # 完整的登录命令 mysql -uroot -plinux3306 -hlocahost -P3306 入口二，只能在10.0.0.51这个机器上，机器本地，基于进程套接字文件的链接形式 不能用window去用这个方式 #这个命令只能是在10.0.0.51这个机器去执行 mysql -uroot -plinux3306 -S /linux3306/mysql_3306/mysql.sock 10.0.0.51:3307 10.0.0.51:3308 # 作为运维，如何给公司的其他人员配置mysql的权限，权限控制，限制 # 场景一：给开发装了一个linux的mysql服务端，开发只能再自己的机器上，去写代码，读数据库，增删改查测试 # 运维设置账号，先定权限，去远程链接，允许再什么样的网段中去链接，内网，允许再任意地址，只允许某一个ip去登录。 # 场景二：维护的阿里云，测试工程师需要测一份代码，需要有数据库的支撑 # 运维去创建一个测试库，测试账号，给这个测试工程师去用 # 例如ceshi01 ceshi666 123.206.16.61 23306端口 # mysql -uceshi01 -pceshi666 -h123.206.16.61 -P23306 # 把报错，截个图，李经理，帮忙看看吧，连不上了。 1.启动、关闭mysql原理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 systemctl start mysqld systemctl stop mysqld 如果这俩命令，报错了，如何排查 以及你得搞懂mysql启动的进程命令，背后的脚本加载逻辑，执行顺序 管理3306实例的脚本逻辑顺序 ①. 脚本放在了 /etc/init.d/mysqld ②. 可以用多种方式使用该脚本 1.给脚本添加执行权限 /etc/init.d/mysqld start 2. 该方式等于 service mysqld start 3.centos7上建议写法 systemctl start mysqld 4. service和systemctl命令都是去读取 /etc/init.d/目录下的脚本mysqld脚本文件 5.再centos7下的加载方式 /etc/init.d/mysqld ↓ systemctl 去调用 ↓ service 转化为systemctl mysqld_safe和mysqld区别 mysqld_safe作用\n1 2 3 4 5 6 7 先看看mysql的安装主程序目录 先用systemctl启动mysql试试，通过 ps命令 ，可以看到进程运行的完整命令和参数 [root@tech-db-51 ~]#yum install -y psmisc [root@tech-db-51 ~]#pstree -p 1 2 3 4 5 6 7 8 9 10 11 12 13 14 mysqld_safe作用 1. mysql官方启动脚本，是以执行mysqld_safe为入口，其实mysqld_safe也是个shell脚本，调用了myqsld命令启动服务 2.mysqld_safe脚本设置运行环境，如以守护进程运行 3.mysqld_safe检测mysqld运行状态 4.mysqld_safe检测mysqld进程运行信息，写入 mysql实例目录下的hostname.err文件 5.以及mysqld_safe会读取my.cnf配置文件的[mysqld],[mysqld_safe]等配置 mysqld作用 mysqld是mysql的核心程序，用于管理mysql的数据库文件，以及用户执行的SQL请求 mysqld读取my.cnf中 [mysqld]配置 启动命令区别 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 有3个实例 3306 复制mysql的官方脚本 入口 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; /etc/init.d/mysqld ↓ /opt/mysql/bin/mysqld_safe ↓ mysql主程序命令 /opt/mysql/bin/mysqld 3307 3308 [root@tech-db-51 ~]#bash /linux0224/3307.sh start Starting MySQL... [root@tech-db-51 ~]# [root@tech-db-51 ~]# [root@tech-db-51 ~]# [root@tech-db-51 ~]#bash /linux0224/3308.sh start Starting MySQL... [root@tech-db-51 ~]# # 查看3个mysql实例的进程命令 2.关闭mysql 脚本关闭 1 2 3 该实例，用什么脚本起的，就用什么脚本关 停止3307 命令关闭 1 2 3 4 5 6 7 8 更推荐用这个 # 先登录具体实例，然后再关闭 # 3308 mysql\u0026gt; shutdown; Query OK, 0 rows affected (0.00 sec) 特殊情况下，不建议用这个操作 1 2 3 4 5 6 7 8 9 直接用kill pkill killall kill pid # 除非进程卡死，无任何解决办法，再去 kill -9 pid 数据丢失，数据写入，事务提交，确认数据写入到磁盘，写入到日志 pkill 进程名 killall 进程名 直接杀死mysqld的玩法，可能导致下次mysql无法启动，日志会有报错信息 mysql丢失了服务端链接 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 mysql\u0026gt; shutdown; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; select user(); ERROR 2013 (HY000): Lost connection to MySQL server during query mysql\u0026gt; mysql\u0026gt; show databases(); ERROR 2006 (HY000): MySQL server has gone away No connection. Trying to reconnect... ERROR 2003 (HY000): Can\u0026#39;t connect to MySQL server on \u0026#39;127.0.0.1\u0026#39; (111) ERROR: Can\u0026#39;t connect to the server mysql\u0026gt; select user(); No connection. Trying to reconnect... ERROR 2003 (HY000): Can\u0026#39;t connect to MySQL server on \u0026#39;127.0.0.1\u0026#39; (111) ERROR: Can\u0026#39;t connect to the server 1 2 3 4 5 6 7 8 9 10 11 12 13 14 全部实例都挂了 [root@tech-db-51 ~]#systemctl stop mysqld [root@tech-db-51 ~]# [root@tech-db-51 ~]# [root@tech-db-51 ~]# [root@tech-db-51 ~]#!net netstat -tunlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1009/sshd tcp6 0 0 :::22 :::* LISTEN 1009/sshd [root@tech-db-51 ~]# [root@tech-db-51 ~]# 3.自定义mysqld服务管理脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 1.写mysql的运行脚本 1. 如 /linxu0224/3307.sh /linxu0224/3307.sh start /linxu0224/3307.sh stop /linxu0224/3307.sh restart 2. 写入 /etc/init.d/mysqld /etc/init.d/mysqld service systemctl 管理 3. centos7下，写服务管理脚本，参考 ，network脚本等写就行 找到centos7的 system服务脚本在哪，参考语法 #rpm -ql systemd|grep service [root@tech-db-51 ~]#systemctl status sshd ● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled) # 参考sshd脚本，写mysql管理脚本 [root@tech-db-51 ~]#cat /usr/lib/systemd/system/sshd.service [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.service Wants=sshd-keygen.service [Service] Type=notify EnvironmentFile=/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target 4. 参考写法，写一个systemctl 管理mysql的脚本 先关闭 /etc/init.d/mysqld脚本的功能 [root@tech-db-51 ~]#mv /etc/init.d/mysqld /linux0224/mysql_3306/ # 5.写入3306的服务管理脚本 cat \u0026gt; /etc/systemd/system/mysqld.service \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [Unit] Description=mysql server by www.lijinit.cn Documentation=man:mysqld(8) Documentation=https://dev.mysql.com/doc/refman/en/using-systemd.html After=network.target After=syslog.target [Install] WantedBy=multi-user.target [Service] User=mysql Group=mysql ExecStart=/opt/mysql/bin/mysqld --defaults-file=/etc/my.cnf LimitNOFILE=5000 EOF 6. 修改3306的配置文件，加入日志参数 [root@tech-db-51 ~]#mkdir -p /linux0224/mysql_3306/logs [root@tech-db-51 ~]# [root@tech-db-51 ~]#chown -R mysql.mysql /linux0224/ [root@tech-db-51 ~]#cat /etc/my.cnf [mysqld] log-error=/linux0224/mysql_3306/logs/3306-err.log port=3306 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3306/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock 7.启动3306，检测日志 # 重载systemctl 的脚本 systemctl daemon-reload systemctl restart mysqld systemctl stop mysqld # 管理mysql的脚本，方式，4种，具体再生产下遇见哪种，都会玩了 4.配置文件模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [root@db-51 ~]#cat /etc/my.cnf [mysqld] # 服务端标签 port=3306 # 端口 server_id # 主机编号，用于主从复制 user=mysql # 内置运行用户 basedir=/opt/mysql # 软件目录 datadir=/www.lijinit.cn/mysql_3306 # 数据目录 socket=/tmp/mysql.sock # 套接字文件路径 [mysql] socket=/tmp/mysql.sock # mysql客户端连接数据库，默认读取的socket文件路径 配置语法 [server] 服务端读取的配置 [mysqld] mysqld进程读取的配置 [mysqld_safe] mysqld_safe脚本会加载的配置 客户端配置参数 [mysql] 客户端命令读取的设置 [client] 所有本地客户端读取的设置 [mysqldump] 备份命令读取的设置 5.远程连接管理学习grant语句 本地连接 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 授权语句，创建一个用户，只允许本地连接 # 也能实现创建一个用户的作用 grant 权限 on 库.表 to 用户名@\u0026#39;允许登录的网段\u0026#39; identified by \u0026#39;远程登录的用户密码\u0026#39;; # 注意，写localhost 和127.0.0.1是不一样的 /linux0224/mysql_3306/mysql/该实例的用户数据都在这... /linux0224/mysql_3307/mysql/该实例的用户数据都在这... /linux0224/mysql_3308/mysql/该实例的用户数据都在这... # 创建wenjie用户，只允许再机器本地登录mysql 3307实例，给与最大权限，可以增删改查所有库表 # 先登录 [root@tech-db-51 ~]#mysql -uroot -plinux3307 -S /linux0224/mysql_3307/mysql.sock mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.28 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; mysql\u0026gt; grant all privileges on *.* to wenjie@\u0026#39;127.0.0.1\u0026#39; identified by \u0026#39;wenjie666\u0026#39;; 查看mysql的用户表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 查看3307实例 1. 登录 [root@tech-db-51 ~]# -uroot -plinux3307 -S /linux0224/mysql_3307/mysql.sock 2. 先进入mysql库，查看库下的所有表 mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) mysql\u0026gt; use mysql; # 查看当前再哪个库 mysql\u0026gt; select database(); +------------+ | database() | +------------+ | mysql | +------------+ 1 row in set (0.00 sec) # 查看当前库下有哪些表，2个语法 # 完整的 mysql\u0026gt; show tables from mysql; # 简写 mysql\u0026gt; show tables; # 进入mysql库，查看用户表，mysql本身存储的用户，账户密码表 # select 语句，查看表中的数据 大小写提示 数据库基础知识，不难，就是多，要细心做笔记，帮你大脑记忆\n1 2 # 目前数据库是不区分大小写的。。。。。。。。。。。。。。 # 内置的关键字建议大写，自定义的数据，建议小写 1 2 3 4 5 6 7 当前数据库有2个用户可以登录，只能本地登录 select user,host,authentication_string from mysql.user; root localhost wenjie 127.0.0.1 本地账号登录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 文杰 [root@tech-db-51 ~]#mysql -uwenjie -pwenjie666 -h127.0.0.1 -P3307 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 4 Server version: 5.7.28 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) mysql\u0026gt; # wenjie账户有最大的权限 使用mysql套接字登录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 再加一个用户记录，注意用root添加 grant all privileges on *.* to wenjie@\u0026#39;localhost\u0026#39; identified by \u0026#39;wenjie666\u0026#39;; [root@tech-db-51 ~]#mysql -uwenjie -pwenjie666 -S /linux0224/mysql_3307/mysql.sock mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 8 Server version: 5.7.28 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; # 基于自建的账号，走socket文件登录数据库，本地登录 mysql\u0026gt; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;远程连接\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 关于登录的方式选择 1 2 1. 本地登录，建议用socket去链接，或者ip:port也行 2. 远程登录，只能走IP:port了 授权，允许访问的网段 其他机器，登录10.0.0.51的3307的数据库实例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 只允许wenjie用户在 10.0.0.0~255 网段登录，有最大的权限 # 授权语句只能用root去操作 # % 百分号表示一个任意匹配的意思 grant all privileges on *.* to wenjie@\u0026#39;10.0.0.%\u0026#39; identified by \u0026#39;wenjie666\u0026#39;; #查询mysql的用户表的信息，当前mysql实例，有哪些用户信息 select * from mysql.user; # 默认查询所有的字段 select user,host from mysql.user; # 再创建一个用户 songlin01 只允许再内网172网段登录mysql grant all privileges on *.* to songlin01@\u0026#39;172.16.1.%\u0026#39; identified by \u0026#39;songlin666\u0026#39;; mysql\u0026gt; mysql\u0026gt; select user,host from mysql.user; +---------------+------------+ | user | host | +---------------+------------+ | wenjie | 10.0.0.% | | wenjie | 127.0.0.1 | | songlin01 | 172.16.1.% | | mysql.session | localhost | | mysql.sys | localhost | | root | localhost | | wenjie | localhost | +---------------+------------+ 7 rows in set (0.00 sec) mysql\u0026gt; #grant创建， select 查看 试试远程去登录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # wenjie用户，再10网段的机器登录 # 10.0.0.xxx的机器，能和这个 10.0.0.51:3307确保通信就行 # 留作用windows去登录，查看 -------------------------------------------------- # songlin01用户，只允许再172的内网环境登录 #172.16.1.xx 的机器，和 172.16.1.51:3307 # 找一个装有mysql的机器，作为客户端测试即可 ---------------------------------------------------------------------- # 查看mysql 3307 服务端绑定的ip：port [root@tech-db-51 ~]#netstat -tunlp|grep 3307 tcp6 0 0 :::3307 :::* LISTEN 4312/mysqld # 如果你限制mysql只能在内网访问 navicat图形化访问 1 2 3 4 5 6 7 8 玩mysql 2方式 1. mysql -uroot -p登录，纯命令行操作，所有的增删改查，都要输入SQL语句。 2. 所有的操作，全是图形化点点点。navicat工具， wenjie用户，允许再10.0.0.xx网段登录 1 2 3 4 5 至此完成了 1。 再内网环境下的 从 71 \u0026gt; 51 使用songlin01用户 2. 再模拟外网的环境 从windows \u0026gt; 51 ，用的是 wenjie用户 查看mysql的tcp链接 6.mysql用户管理 6.1 用户说明 1 2 3 4 5 6 7 8 9 linux 用户 - 登录系统 - 管理文件 mysql用户 - 登录mysql - 管理mysql的库、表，能管理哪些库，表，以及能做什么梦事 都看grant语句，给的权限了 6.2 远程登录白名单语法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 mysql 用户授权语法 远程登录，不在服务端的机器上去登 服务端 10.0.0.51:3307 10.0.0.7机器，去登 51 用户名@\u0026#39;网段白名单\u0026#39; 语法 lijin@\u0026#39;localhost\u0026#39; lijin可以在本地登录（ip:3306），以及socket lijin@\u0026#39;10.0.0.10\u0026#39; lijin只能在10.0.0.10这个客户端登录 lijin@\u0026#39;10.0.0.%\u0026#39; lijin只能在10.0.0.xx/24网段登录 lijin@\u0026#39;10.0.0.5%\u0026#39; lijin只能在10.0.0.50~59 登录 lijin@\u0026#39;%\u0026#39; lijin可以在任意地址登录该mysql服务端 lijin@\u0026#39;db-51\u0026#39; 基于主机名的登录限制 6.3 用户管理 查看mysql用户列表 1 2 3 4 5 6 7 # 查看mysql库下的user表的数据 # user 用户名 # host 允许登录的网段白名单 # authentication_string 验证字符串，密码的意思（加密显示的） select user,host,authentication_string from mysql.user; # 查询 创建用户 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 创建用户切设置密码 create user lijin02@\u0026#39;localhost\u0026#39; identified by \u0026#39;123\u0026#39;; # 明确区分，关键字和用户数据 CREATE USER xinlin01@\u0026#39;10.0.0.71\u0026#39; IDENTIFIED BY \u0026#39;xinlin666\u0026#39;; Last login: Fri Jul 29 22:15:15 2022 from 10.0.0.1 [root@zabbix-server-71 ~]#mysql -uxinlin01 -pxinlin666 -h10.0.0.51 -P3307 .Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MySQL connection id is 22 Server version: 5.7.28 MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. MySQL [(none)]\u0026gt; MySQL [(none)]\u0026gt; MySQL [(none)]\u0026gt; select user(); +--------------------+ | user() | +--------------------+ | xinlin01@10.0.0.71 | +--------------------+ 1 row in set (0.00 sec) MySQL [(none)]\u0026gt; MySQL [(none)]\u0026gt; 修改用户密码，root去修改 1 2 3 4 5 6 7 8 9 10 # root权限最大的，修改表数据了，修改语法是基于 # 区分关键字用大写给大家表示 # 修改用户xinlin01的密码 为 ，juanwang666 select user,host,authentication_string from mysql.user; ALTER USER xinlin01@\u0026#39;10.0.0.71\u0026#39; IDENTIFIED BY \u0026#39;juanwang666\u0026#39;; 普通用户改自己密码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 注意修改自己的密码，要进行加密处理 # 需求，让wenjie修改自己的密码为 laoliu666 set password=password(\u0026#39;lijin666\u0026#39;); 等于 # 先看这个写法 SET PASSWORD=PASSWORD(\u0026#39;新的密码\u0026#39;) select password(\u0026#39;laoliu666\u0026#39;); # wenjie修改自己的密码 SET PASSWORD=PASSWORD(\u0026#39;laoliu666\u0026#39;) 删除用户 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 用root用户去删除普通用户 # 运维一般创建普通账户，不可能给最大权限 mysql\u0026gt; DROP USER xinlin01@\u0026#39;10.0.0.71\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; select user,host,authentication_string from mysql.user; +---------------+-----------+-------------------------------------------+ | user | host | authentication_string | +---------------+-----------+-------------------------------------------+ | root | localhost | *19A77E0F06928E313B68F2AAB7756D508846258B | | mysql.session | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | | mysql.sys | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | +---------------+-----------+-------------------------------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; # root，清空了所有的无用账号 配置root远程链接 1 2 3 4 5 6 7 8 9 10 11 12 13 mysql\u0026gt; select user,host,authentication_string from mysql.user; +---------------+-----------+-------------------------------------------+ | user | host | authentication_string | +---------------+-----------+-------------------------------------------+ | root | localhost | *19A77E0F06928E313B68F2AAB7756D508846258B | | mysql.session | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | | mysql.sys | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | | root | % | *83F7A15725AF362EF5EAFC16E1F3F97FDAB9B411 | +---------------+-----------+-------------------------------------------+ 4 rows in set (0.00 sec) mysql\u0026gt; #本地链接root密码是 linux3307 远程链接是lijin666 mysql\u0026gt; 7.grant授权管理 权限的作用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 限制mysql的用户，可以执行哪些SQL语句。 使用grant语句可以创建用户且进行权限控制 限制用户，可以用如下哪些语句 show privileges # 查看权限规则语法 create user create database drop 删除语句 alter user 更新数据 [root@tech-db-51 ~]# [root@tech-db-51 ~]#mysql -uroot -plijin666 -h10.0.0.51 -P3307 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 35 Server version: 5.7.28 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; mysql\u0026gt; show privileges # 用于 grant 给与的权限1,权限2,权限3 on 库.表 to 用户名@允许登录的网段规则 indentified by \u0026#39;密码\u0026#39;； 查看授权规则语法 1 2 3 4 5 6 7 grant不会用怎么办？ help grant; 语法如下 grant 给与的权限1,权限2,权限3 on 库.表 to 用户名@允许登录的网段规则 indentified by \u0026#39;密码\u0026#39;； grant授权命令 1 2 查看所有文档 mysql\u0026gt; help grant; 授权实践 root默认不允许远程登录，给与权限，允许远程登录\n1 GRANT ALL PRIVILEGES on *.* to root@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;lijin666\u0026#39;; 给一个普通开发者jiaqiang01的账户权限，只能增删改查基本操作，且限定某个数据库，且只允许在内网环境连接。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 select,update,delete,insert dev01 库 172.16.1.% # 创建数据库 # 运维，使用最大的权限账户， # root@\u0026#39;localhost\u0026#39; # 查看如下权限表的，是最高权限的root用户 mysql\u0026gt; show grants; +---------------------------------------------------------------------+ | Grants for root@localhost | +---------------------------------------------------------------------+ | GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | | GRANT PROXY ON \u0026#39;\u0026#39;@\u0026#39;\u0026#39; TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | +---------------------------------------------------------------------+ 2 rows in set (0.00 sec) CREATE DATABASE dev01; # 创建了jiaqiang01用户，以及授权 # GRANT SELECT,UPDATE,DELETE,INSERT ON dev01.* TO jiaqiang01@\u0026#39;172.16.1.%\u0026#39; IDENTIFIED BY \u0026#39;jiaqiang666\u0026#39;; mysql\u0026gt; select user,host from mysql.user; +---------------+------------+ | user | host | +---------------+------------+ | root | % | | jiaqiang01 | 172.16.1.% | | mysql.session | localhost | | mysql.sys | localhost | | root | localhost | +---------------+------------+ 5 rows in set (0.00 sec) 查看具体用户的权限 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 show grants # 查看当前用户的权限信息 mysql\u0026gt; show grants; +---------------------------------------------------------------------+ | Grants for root@localhost | +---------------------------------------------------------------------+ | GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | | GRANT PROXY ON \u0026#39;\u0026#39;@\u0026#39;\u0026#39; TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | +---------------------------------------------------------------------+ 2 rows in set (0.00 sec) select user,host from mysql.user; show grants for 用户@\u0026#39;网段\u0026#39;; 查询具体用户的权限 # 如何查看jiaqiang01的权限 show grants for jiaqiang01@\u0026#39;172.16.1.%\u0026#39;; mysql\u0026gt; show grants for jiaqiang01@\u0026#39;172.16.1.%\u0026#39;; +--------------------------------------------------------------------------------+ | Grants for jiaqiang01@172.16.1.% | +--------------------------------------------------------------------------------+ | GRANT USAGE ON *.* TO \u0026#39;jiaqiang01\u0026#39;@\u0026#39;172.16.1.%\u0026#39; | | GRANT SELECT, INSERT, UPDATE, DELETE ON `dev01`.* TO \u0026#39;jiaqiang01\u0026#39;@\u0026#39;172.16.1.%\u0026#39; | +--------------------------------------------------------------------------------+ 2 rows in set (0.00 sec) 回收权限 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # grant授权的语句 # 移除jiaqiang01 对dev01库下的所有表的 delete 权限 # 大写语法 REVOKE DELETE ON dev01.* from jiaqiang01@\u0026#39;172.16.1.%\u0026#39; ; # 移除所有权限，针对dev01这个库 REVOKE ALL ON dev01.* from jiaqiang01@\u0026#39;172.16.1.%\u0026#39; ; show grants for jiaqiang01@\u0026#39;172.16.1.%\u0026#39;; # 此时jiaqiang01用户只剩下登录权限了 mysql\u0026gt; mysql\u0026gt; show grants for jiaqiang01@\u0026#39;172.16.1.%\u0026#39;; +-------------------------------------------------+ | Grants for jiaqiang01@172.16.1.% | +-------------------------------------------------+ | GRANT USAGE ON *.* TO \u0026#39;jiaqiang01\u0026#39;@\u0026#39;172.16.1.%\u0026#39; | +-------------------------------------------------+ 1 row in set (0.00 sec) # 使用jiaqiang01用户登录 [root@tech-db-51 ~]#mysql -ujiaqiang01 -pjiaqiang666 -h172.16.1.51 -P3307 只有账户、无任意权限 该账户只能登录\n1 2 3 4 5 6 7 mysql\u0026gt; show grants for jiaqiang01@\u0026#39;172.16.1.%\u0026#39;; +-------------------------------------------------+ | Grants for jiaqiang01@172.16.1.% | +-------------------------------------------------+ | GRANT USAGE ON *.* TO \u0026#39;jiaqiang01\u0026#39;@\u0026#39;172.16.1.%\u0026#39; | +-------------------------------------------------+ 1 row in set (0.00 sec) 作业练习 mysql知识量大，需要记忆的多\n做好笔记，思维脑图\n就能学好了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 1.完成mysql远程连接的命令整理，grant语句整理 2. 实际案例练习 3306实例 创建三个普通账号，授权练习 1. 运维账号给与最大权限，允许远程连接 2.开发账号，只能对开发库有增删改查权限，只允许在10，172两个网段连接 3.测试账号，只能对测试库增，改，查的权限，且只允许在172内网连接。 3307实例，安装jpress博客，且可以navicat远程访问 在阿里云部署mysql5.7.28 ，修改默认端口为23306，防止数据库被恶意扫描，确保可以navicat，和cmd远程访问 ","date":"2025-04-14T16:04:59+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/mysql%E6%9D%83%E9%99%90%E7%AF%87/","title":"MySQL权限篇"},{"content":"03-MySQL基础 一、入门 Navicat图形化\n① 安装：略。\n② 连接MySQL服务器\n二、MySQL命令 SQL命令 概念：MySQL客户端远程操作和管理MySQL服务器里面的数据一种指令（代码）。\n语法规则：\n① 必须以分号结尾，MySQL服务器以分号判定SQL是否结束了。\n② 关键词大小写一样，不敏感。例如：select 和SELECT​，但是数据\u0026rsquo;abc\u0026rsquo; \u0026lsquo;ABC\u0026rsquo;;\n③ 注释使用 \u0026ndash;表示。\n1 -- 说明文字,不算代码，mysql不执行，给程序员给人看的。 数据库管理 (1) 查看当前数据库版本信息\n1 2 select version(); SELECT version(); (2) 查看当前mysql服务器连接的客户端信息\n1 show processlist; 结果说明 MySQL核心概念 例如：学校管理学生信息\n目的：提高数据管理和检索效率。\n1 2 3 4 5 1. 学生信息：鹿晗博 2. 班级：66班 3. 年级：3年级 4. 专业：计算机专业 5. 学校：清华大学 数据库数据管理：row行数据​、table表​、database库​。\n关键词 概念 说明 row​ 行 一条数据。 table​ 表 一个表和包含多row行数据，一个表存数据都是业务含义相似的数据，例如：学生表存学生，老师表存老师，商品表，存商品。 database​ 库 管理table表，一个database管理多个table。一个软件系统的多张表管理在一个database。 primary key​ 主键 唯一标识一条数据，例如：身份证号、卡号、学生号、工号、游戏ID、递增不重复的数字。\ncolumn​ 列 列不属于数据，明确table当前列的数据含义、数据类型。 database管理命令 (1) 创建database\n语法\ncreate database db名字;​\n代码\n1 2 3 4 -- 创建一个 edu的database create database edu; -- 创建一个shop的database create database shop; (2) 查看系统所有database\n语法\nshow databases;​\n(3) 切换database\n语法\nuse db名字;​\n(4) 删除database\n语法\ndrop database db名字;​\n三、 table管理命令 1. 表结构 表名\n列信息：① 列名 ② 数据类型 ③ 约束\n​\n1 2 3 4 5 6 7 1. 表名： 例如：t_product、t_emp、t_user、t_category 命名规范：t_名字 2. 列信息 列名：表名列的含义 命名规范：username、password、product_name、shangping_mingzi 数据类型：该列的所有的值类型是什么：数字、文本、日期。 2.数据类型 总类 类型 说明 整数 int 整数：范围 -2147483648~2147483647 bigint​ 大整数 小数 double(m,n)​ 小数。m表示数字的最大长度，n表示最多小数位。\n例如：double(5,2)，123.45 √ 12.345 x ​ 文本/字符串 char(n) 定长文字类型，n表示最大的字符个数，如果实际给的字符个数少于n，MySQL自动补白。补够n的个数。\n例如：char(1) 最多只能存1个字符，char(11) 最多存11个字符\n注意：char(11),如果只存了10个字符，剩余字符空间自动补白。\n场景：性别、状态、手机号\n优点：查找效率比较高。 varchar(n)​ 可变长文字类型，n表示最大字符个数，如果实际给的个数少于n。\n例如：用户名、商品名、简介、地址。\n优点：节省空间 text``longtext 65,535字符 ≈ 64KB长度字符串\nlongtext 最大 4GB字符\n日期 date 日期，包含信息\n日期date：年月日\n时间time：时分秒\n3. 表管理命令 (1) 建表\n语法\n1 2 3 4 5 create table 表名( 列名1 类型, 列名2 类型, 列名3 类型 ); 案例\n创建一个员工表,包含：工号、姓名、生日、性别(1男 0女 2其他)、手机号、工资、地址\n1 2 3 4 5 6 7 8 9 create table t_emp( emp_id bigint, emp_name varchar(20), sex char(1), birth date, mobile char(11), salary double(10,2), address varchar(100) ); (2) 查看表信息\n查看表结构信息\n语法：\ndesc 表名;​\n(3) 删除表\n语法\ndrop table 表名;​\n(4) 约束\n概念\n建表针对列添加除了类型以外额外数据限制要求,常见：主键、非空、唯一、自增。\n常见约束\n约束 说明 例子 primary key​ 主键：唯一+非空 身份证、工号、学号、游戏ID not null​ 非空，要求该列的值必须给 用户名、手机号、密码\u0026hellip; unique​ 唯一，要求该列的值不能重复 手机号、用户名 auto_increment​ 自增列，该列的值自动有MySQL分配，主键递增。 ID分配 语法\n1 2 3 4 5 create table 表名( 列名1 类型 约束 约束, 列名2 类型 约束, 列名3 类型 约束 ); 案例\n创建一个员工表,包含：工号、姓名、生日、性别(1男 0女 2其他)、手机号、工资、地址\n1 2 3 4 5 6 7 8 9 create table t_emp_check( emp_id bigint primary key auto_increment, emp_name varchar(20) not null unique, sex char(1), birth date, mobile char(11) unique, salary double(10,2) not null, address varchar(100) ); 任务：\n1 2 3 4 5 6 7 8 9 10 11 创建一个学生表： 学号 姓名 班级号 专业名称 性别 出生日期 籍贯 手机号 政治面貌 高考成绩 4. 数据管理 准备一个table表\n1 2 3 4 5 6 7 8 9 10 11 12 -- 创建一个database：baizhi create database baizhi; use baizhi; -- 用户表 create table t_user( id bigint primary key auto_increment, username varchar(20), password varchar(20), age int, birth date, mobile varchar(11) ); 添加数据 场景\n向t_user表添加一条数据：luhanbo、123123、20、1999-9-9、 15533367988\n语法\n1 2 3 4 5 6 分析： ① 表 ② 列... ③ 数据值... 语法： insert into 表名(列名1,列名2,列名3...) values(值1,值2,值3...); 注意：表名后面的列顺序，和values后面值的顺序保持一致。\nSQL\n1 2 insert into t_user(username,password,age,birth,mobile) values(\u0026#39;luhanbo\u0026#39;,\u0026#39;123123\u0026#39;,20,\u0026#39;1999-9-9\u0026#39;,\u0026#39;15533367777\u0026#39;); 批量插入\n1 2 3 4 5 insert into 表名(列名1,列名2,列名3...) values(值1,值2,值3...), (值1,值2,值3...), (值1,值2,值3...), (值1,值2,值3...); 查询数据 场景\n从t_user表查询全部数据\n语法\nselect * from 表名;​\n1 2 select: 指定数据提取那些列 from: 指定数据来源哪张表 SQL\n1 2 3 4 5 -- 查询部分列 select 列1,列1,列1,列1 from 表名; --查询所有列 select * from t_user; 修改数据 场景：\n修改t_user表中悟空，age=800，密码=111111?\n语法\n1 2 3 4 5 6 分析： ① 指定表 ② 指定那条数据 ③ 那些列，新值 update 表名 set 列名=新值,列名=新值 where id = ? SQL\n1 2 3 4 5 update t_user set age=800, password=111111 where id = 2; 删除数据 场景\n删除数据库的luhanbo这条数据？\n语法\n1 2 3 4 5 6 分析： ① 表 ② 那条数据？ 语法： delete from 表 where id=?; SQL\n1 delete from t_user where id = 1; 清空表truncate 将表中全部数据截断（将表数据部分占用空间直接回收），保留表结构。\n方法1：delete删除\ndelete from 表;​ 问题：逐行删除，效率低，数据量越大删除越慢。 方法2：truncate 截断\ntruncate table 表;​ truncate特点\nTRUNCATE不支持WHERE条件 自增长列，TRUNCATE后归1，delete删除的数据占用递增之，不会释放的。 效率高于DELETE 复制表 将表复制一份新的，场景：调试、测试场景。\n仅复制表结构\n针对原表的完整表结构进行复制，包含 所有列、类型、约束。\n语法： 1 CREATE TABLE 待创建的表名 LIKE 已有表名 示例： 1 2 mysql\u0026gt; create table departments like nsd2021.departments; Query OK, 0 rows affected (0.01 sec) 复制表结构及数据\n针对查询语句结果，创建一个表，可以制定要选择的那些数据那些列。作为新表。\n语法： 1 2 CREATE TABLE 待创建的表名 SELECT 字段, ... FROM 已有表名 示例： 1 2 3 4 mysql\u0026gt; create table departments2 -\u0026gt; select * from nsd2021.departments; Query OK, 13 rows affected (0.01 sec) Records: 13 Duplicates: 0 Warnings: 0 四、查询 1、数据准备 (1) 步骤\n① 创建database，名字：edu\ncreate database edu;\n② 进入baizhi\nuse edu;​\n③ 复制课堂案例数据edu员工.sql中所有代码，粘贴到mysql的客户端sql命令中。执行。\n(2) 简介\nt_employees：员工表\n员工ID 名字 姓 邮箱 手机号 入职时间 职位ID 月薪 佣金比例 直属领导ID 部门ID EMPLOYEE_ID FIRST_NAME LAST_NAME EMAIL PHONE_NUMBER HIRE_DATE JOB_ID SALARY COMMISSION_PCT MANAGER_ID DEPARTMENT_ID t_jobs：职位表\nt_departments：部门表\nt_countries：国家信息\nt_locations：分公司事业部所在地址\n2、SQL语句总结(最后) 关键词作用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 1. select 选择提取列 2. from 指定数据来源哪个表 3. where 指定过滤数据的条件 ① and or 连接多个条件 ② between 区间查询：数字 日期 ③ is null | is not null ④ in 枚举选项，满足任何一个即可 ⑤ like模糊查询 4. order by 排序 5. limit 满足查询结果的数据进行截取 6. group by 分组 SQL书写语法\n1 2 3 4 5 6 7 8 9 10 1. 版本1 select 列名1,列名2,列名3 from 表名; 2. 版本2 select 列名1,列名2,列名3 from 表名 where 条件; 3. 版本3 select ... from ... where 条件 order by 排序列 limit start,num; 4. 版本4 SQL的执行顺序\n执行顺序 关键字 作用 1 from​ 明确数据源 2 where​ 过滤表中数据 3 group by​ 对满足where条件的数据进行分组group having​ 对分组后的数据进行过滤。 6 select​ 选择指定的列 7 order by​ 排序 8 limit​ 截取查询结果 3、简单查询 (1) 查询部分列\n场景\n查询t_emp中所有员工的id工号、名字、月薪？\n关键\n1 2 1. select：选择要查看的列。 2. from: 确定数据来源的表 语法\n1 select 列名1,列名2,列名3 from 表名; 案例\n1 2 select employee_id,first_name,salary from t_emp; (2) 查询全部列\n场景\n查询t_emp表所有员工的全部信息：id、名字、月薪、姓、职位、部门id、佣金？\n语法\n1 2 select * from t_employees; (3) 列数学运算\n场景\n查看所有员工的id、名字、月薪、年薪（salary*12）？\n语法\n1 2 3 4 select 列+n,列-n,列*n,列/n from 表名; 注意：列的数据类型必须是数字类型：int 、bigint、double。 案例\n1 2 select employee_id,first_name,salary from t_employees; (4) 列起别名\n场景\n查看所有员工的id、名字、月薪(mon_salary)、年薪(year_salary)？\n说明\nselect查询结果列名，并不一定是表中的列名，由select语句后面的单词决定。\n语法\n1 2 3 4 5 select 列1 as 别名 ,列2 as 别名,列3 as \u0026#34;别名\u0026#34; ... from 表名; 注意： 如果别名中有特殊字符，关键词，空格，需要使用引号，建议使用双引号定义别名。 案例\n1 2 select employee_id,first_name,salary as \u0026#34;mon_salary\u0026#34;,salary*12 as \u0026#34;year_salary\u0026#34; from t_employees; (5) 去重\n场景：\n查询员工t_emp表所有的领导的id编号？\n关键词\ndistinct​\n作用：针对查询结果中重复的数据，进行去重。(只有一行数据中所有列的值都一样，才算做重复数据。distinct作用于后面所有列)\n重复数据定义：看一整行row，一行数据所有的值，都重复。\n语法：\n1 2 select distinct 列名1,列名2,列名3 from 表名; (6) case-when(**)\n场景\n查询所有员工的id、名字、工资、工资等级(10000+:A,8000~10000:B, 6000 ~8000:C, 6000-：D)\n语法\ncase-when是用来生成查询结果的列，书写位置在select后面和其他列同级别。\n1 2 3 4 5 6 7 8 9 10 case when 条件1 then 值1 when 条件2 then 值2 when 条件3 then 值3 else 值4 end 说明： 1. 按照case条件从上开始判断，满足某个条件，则选择then后面的值作为当前列的值，如果不满足，则继续向下判断。 如果都不成立，最后值选择else的值。 代码\n1 2 3 4 5 6 7 8 select employee_id,first_name,salary, case when salary \u0026gt; 10000 then \u0026#39;A\u0026#39; when salary \u0026gt; 8000 then \u0026#39;B\u0026#39; when salary \u0026gt; 6000 then \u0026#39;C\u0026#39; else \u0026#39;D\u0026#39; end from t_employees; 4、where条件查询 场景： 用户选择数据过滤的条件，然后出发查询操作，获得满足过滤条件的数据。\n​\n关键词\nwhere​\n作用：对查询表中的数据进行条件帅选，只有满足where条件的数据才会被客户端查询得到。\n运行机制\n① from表中所有数据，逐条进行where条件判断。\n② 只有满足where条件，才会被保留在查询结果中。\n语法\n1 select 列名1,列名2,列名3 from 表名 where 过滤条件; (1) 单条件\n场景：\n查询工资大于等于10000员工信息：id、名字、工资。\n代码\n1 2 3 select employee_id,first_name,salary from t_employees where salary \u0026gt;= 10000; (2) 多条件\n场景\n查询部门编号90，且工资大于10000的员工信息id、名字、工资？\n分析\n1 2 3 where条件： ① 条件1：department_id = 90 ② 条件2：salary \u0026gt;= 10000 语法\n1 2 3 4 5 6 7 select 列名1,列名2,列名3 from 表名 where 条件1 and|or 条件2 说明： and：且：只有and两边条件都满足，才会作为查询结果。 or：或：数据条件只要满足1个即可作为查询结果。 代码\n1 2 3 4 5 -- 1. 查询部门编号90，且工资大于10000的员工信息id、名字、工资？ select employee_id,first_name,salary,department_id from t_employees where department_id = 90 and salary\u0026gt;= 10000; \u0026ndash; 2. 查询部门编号90，或者 工资大于10000的员工信息id、名字、工资？ select employee_id,first_name,salary,department_id from t_employees where department_id = 90 or salary\u0026gt;= 10000;\n\u0026ndash; 3. 查询工资 8000~10000之间员工信息：id，名字，工资。 select employee_id,first_name,salary from t_employees where salary \u0026gt;= 8000 and salary \u0026lt;=10000;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 (3) 区间 * 场景 查询工资 8000~10000之间员工信息：id，名字，工资。 * 关键 ​`where 列名 between min and max`​ 含义：过滤数据条件在min和max之间的数据。(结果中包含min和max的情况) * 语法 ```sql select 列名1,列名2,列名3 from 表名 where 列名 between 最小值 and 最大值; 代码\n1 2 3 select employee_id,first_name,salary from t_employees where salary between 8000 and 10000; (4) in枚举\n场景\n查询部门编号60 70 80 部门的员工信息：id、名字、工资、部门id？\n关键\nwhere 列 in (值1,值2,值3,值4)​\n含义： 判断列的值否满足in后面括号中任意一个值，如果满足任意一个，即可作为查询结果。\n语法\n1 2 3 select 列名1,列名2,列名3 from 表名 where 列 in (值1,值2,值3,值4) 代码\n1 2 3 select employee_id,first_name,salary,department_id from t_employees where department_id in (60,70,80,90); (5) 空值\n场景\n查询员工信息，没有佣金的员工信息？\n关键词\nwhere 列 is ​​null​​\n含义：判断指定列的值是否是null，如果是null，则作为查询结果。\nwhere 列 is ​​not null​​\n含义：判断指定的值是否是非null(是否有值)。\n代码\n1 2 3 4 -- 查询员工信息，没有佣金的员工信息？ select * from t_employees where comission_pct is null; (6) 模糊查询\n场景：\n查询员工职位名称 以\u0026quot;IT\u0026quot;开头的员工信息？\n语法\nwhere 列名 like '关键词和通配符'​\nSQL通配符：\n序号 符号 含义 1 %​ 任意字符，个数0~n个 2 _​ 任意字符，表示1个 代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- 查询员工职位名称 以\u0026#34;IT\u0026#34;开头的员工信息？ select * from t_employees where job_id like \u0026#39;IT%\u0026#39;; -- 查询名字中以A开头的员工信息？ select * from t_employees where first_name like \u0026#39;A%\u0026#39;; -- 查询员工的名字4个字母的员工信息？ select * from t_employees where first_name like \u0026#39;____\u0026#39;; 5、order排序 场景：为了方便用户查看信息，数据展示往往会提供可以排序的功能。\n​\n关键词\norder by 列名 asc | desc​\norder by可以支持整数、小数、日期类型排序。(可以对字符串排序)\n语法\n1 select ... from ... where ... order by 排序列1 asc|desc,排序列2 asc|desc 说明： order by：基于指定列进行排序,可以指定多个列，且当第一个列的值相同，按照第二列的排序方式进行排序。 asc：升序 默认 desc：降序\n1 2 3 4 5 6 7 8 9 10 11 12 * 代码 ```sql -- 查询员工信息，按照薪资降序排序？ select * from t_employees order by salary desc; -- 查询员工信息，按照信息升序，如果薪资相同按照部门id降序排序？ select * from t_employees order by salary asc,department_id desc; 6、limit截取 场景：往往每次查询返回给用户的数据并不是全部数据，而是进行截取分批查询，分页展示​。\n​\n分析优化：\n1 2 3 1. 实际开发中，数据不会全部查询发送给客户端，用户多了以后不需要的数据也会大量占用MySQL服务器网络带宽，降低查询效率。 结论：不必要查询的数据，就不返回给用户。 2. select后面的列，不需要的数据，就不要给客户端传输。不要使用select *. 语法\nlimit start,count​\n1 2 3 4 limit start,count start: 截取数据，从第几条开始，从 0 开始计数。 count:本次查询，查询多少条。 代码\n1 2 3 4 -- 查询员工的信息，每页显示10条，查询第一页（0,10） select * from t_employees limit 0,10; 五、函数 概念：\nMySQL内置了一些SQL 特定数据处理功能的工具，叫做函数。\n语法\n函数名()​\n函数名(参数)​\n1. 单行函数 概念：\n被单行函数处理的数据，输入n条，输出n个结果。逐条数据进行处理。 总结：单行函数处理的目标数据一行一行，一行数据产生一条结果。\n​\n常见：\n1 2 3 4 5 6 7 8 9 10 11 12 13 1. 获得当前系统时间：(MySQL-Server服务器所在电脑) sysdate() 2. 获得字符串长度： length(列名) 3. 字符串拼接： concat(列,列,列,\u0026#39;abc\u0026#39;) 4. 将字符串格式 \u0026#39;1999年9月9日\u0026#39; 转变成date类型。 str_to_date(参数..) 5. 提取日期中部分数据(日期：年月日 时分秒) date_format(参数..) 6. 其他... 相同单行函数。 (1) sysdate 获得日期\n场景：\n1 2 -- 查看当前系统时间 select 语法：\n1 select sysdate(); (2) length 获得字符串长度\n语法\n1 length(列名) 场景\n1 2 3 4 5 6 7 8 -- 1. 查看所有员工的id，名字，工资，及其名字的长度？ select employee_id,first_name,salary,length(first_name) from t_employees; -- 2. 查看员工的名字长度是5位员工信息？ select * from t_employees where length(first_name) = 5; (3) concat 字符串拼接\n语法\n1 2 3 concat(列名1,列名2) concat(列名1,列名2,列名3...) concat(列名1,\u0026#39;固定字符\u0026#39;) 场景\n1 2 3 4 5 6 -- 查看员工姓名和工资？ select concat(first_name,last_name),salary from t_employees; select concat(first_name,\u0026#39;·\u0026#39;,last_name) as \u0026#34;name\u0026#34;,salary from t_employees; (4) str_to_date 字符串转为date\n语法\n1 str_to_date(\u0026#39;1999年9月9日\u0026#39;,\u0026#39;日期提取格式\u0026#39;) 日期通配符\n格式标识符 含义 **%Y**​ 年（4位） **%m**​ 月，格式为（01~12) **%d**​ 天，格式为（00~31） **%H**​ 小时，格式为（00~23） **%i**​ 分钟，格式为（00~59） **%s**​ 秒，格式为（00~59） 场景\n1 2 3 4 5 -- 将 \u0026#39;1999年9月9日\u0026#39; 转化为日期类型 select str_to_date(\u0026#39;1999年9月9日\u0026#39;,\u0026#39;%Y年%m月%d日\u0026#39;); -- 向t_user表的name和birth添加一条数据\u0026#39;麦克阿瑟\u0026#39; \u0026#39;1999年9月9日\u0026#39; insert into t_user(name,birth) values(\u0026#39;美国五星上将马克阿瑟\u0026#39;,str_to_date(\u0026#39;1999年9月9日\u0026#39;,\u0026#39;%Y年%m月%d日\u0026#39;)); (5) date_format 日期格式化\n作用：提取日期的部分(年 月 日 时 分 秒)信息。\n语法：\n1 2 date_format(date类型列名,\u0026#39;日期格式\u0026#39;) -- 结果是一个字符串类型的结果。 date_format(date类型列名,\u0026#39;%Y-%m\u0026#39;) -- 场景\n1 2 3 4 5 6 7 8 9 -- 1. 查看所有员工的入职日期，精确到年月(1999-9)？ select first_name,date_format(hire_date,\u0026#39;%Y-%m\u0026#39;) from t_employees; -- 2. 查看一下本月生日的员工信息？（假设hire_date就是生日） -- 翻译：hire_date 的月份 = 当前系统时间的月份 select * from t_employees where date_format(hire_date,\u0026#39;%m\u0026#39;) = date_format(sysdate(),\u0026#39;%m\u0026#39;); 2. 组函数 概念：\n对组数据进行处理的，输入n组数据，产生n条结果。\n常见组函数\n1 2 3 4 5 6 1 统计一组的总个数： count(列) 2 统计总和： sum(列) 3. 最大值、最小值、平均值 max(列)\tmin(列) avg(列) 案例\n当sql中没有分组group by 操作，组函数会将原表where过滤之后的数据当成一组来看。\n1 2 3 4 5 6 7 前提：如果针对一张表的数据，统计(没有分组)，一张表直接看做1组。 -- 1. 统计所有员工人数？ select count(employee_id) from t_employees; -- 2. 统计员工的平均工资？ -- 3. 插卡员工最大工资和最小工资？ -- 4. 统计员工月人力成本？ select avg(salary),max(salary),min(salary),sum(salary),fist_name from t_employees; 六、分组 1. 分组group 对from表满足where条件之后的数据进行分组。\n场景\n1 2 3 1. 统计每个部门的平均工资？ 2. 统计每个班级的班级人数？ 3. 统计每种类别的商品平均价格？ 思路\n① 第一步：按照某个列，将数据分成多组。\n② 第二步：对每组数据，进行组函数统计。\n关键词\ngroup by 分组依据列名​\n语法\n1 2 3 4 select ... from ... where ... group by 依据列 代码\n1 2 3 4 -- 1. 统计每个部门的平均工资？(平均工资 部门id) select department_id,avg(salary),max(salary),min(salary) from t_employees group by department_id; 注意：\n表数据一旦经过分组group by后， select后只能出现group by的字段。 select后还能出现组函数处理字段。 2. 分组过滤having 场景：\n查看平均工资高于8000的，部门id，平均工资，人数？\n思路：\n分析(x)\n1 2 3 4 select dept_id,avg(salary),count(emp_id) from t_emp where 部门平均工资\u0026gt;8000 group by 部门id 自以为是的SQL\n1 2 3 4 select department_id,avg(salary),count(employee_id) from t_employees where avg(salary) \u0026gt; 8000 group by department_id; 错误原因：\n① where关键词执行顺序在group分组之前。\n② where语句执行，数据未分组，不能使用组函数。\n关键词\nhaving​\n作用：对分组后的数据进行过滤，可以having中使用组函数处理结果(组函数、分组依据列)\n语法\n1 2 3 4 5 select ... from ... where 分组前的过滤条件 group by 分组依据列 having 分组后过滤条件 代码改写\n1 2 3 4 5 -- 查看平均工资高于8000的，部门id，平均工资，人数？ select department_id,avg(salary),count(employee_id) from t_employees group by department_id having avg(salary) \u0026gt;= 8000; 3. 对比where和having 场景\n统计统计60,80,90部门的平均工资(department_id,平均工资)？\n代码\n1 2 3 4 5 6 7 8 9 10 11 1. 方式1 select department_id,avg(salary) from t_employees group by department_id having department_id in (60,80,90); 2. 方式2 select department_id,avg(salary) from t_employees where department_id in (60,80,90) group by department_id; 总结\n① where是在分组之前过滤。\n② having是在分组之后过滤。\n③ where过滤早于having，但凡可以，优先使用where过滤掉不需要的数据。以免无意义的数据进入后续处理流程，浪费MySQL操作性能。\n七、SQL总结 1. 编写顺序 语法\nselect ... from ... where ... group by ... having ... order by .... limit ...;​\n详细\n1 2 3 4 5 6 7 select 列,列... from 表 where 分组前过滤条件 group by 分组依据列 having 分组后的过滤条件 order by 列 desc|asc,列 desc|asc limit start,total; SQL编写思路\n① 先分析需求，用自己的思路，需要如何操作，1,2,3,4 ？\n② 确定所需的关键词，注意关键词执行顺序。\n③ 补充完每个关键字依据。\n2. 执行顺序 SQL关键词执行顺序\n八、子查询 select查询的from的表，是另一个sql的查询结果，嵌套查询。\n1. 单列单行 总结\n子查询结果单行单列的一个值，通常用在单值条件判断。\n场景\n查询工资大于Nancy工资的员工信息? 查询与Nancy同一部门（department_id）的员工信息 1 2 -- 1. 查询工资大于Nancy工资的员工信息 -- 2. 查询与Nancy同一部门（department_id）的员工信息? 分析1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1. 查询工资大于xSalary的员工信息？ select * from t_employees where salary \u0026gt; xSalary; 2. 查询Nancy的工资xSalary？ select salary from t_employees where first_name = \u0026#39;Nancy\u0026#39;; 3. 组合 将Nancy工资SQL作为子查询，替换xSalary。 select * from t_employees where salary \u0026gt; (select salary from t_employees where first_name = \u0026#39;Nancy\u0026#39;); 分析1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- 查询与Nancy同一部门（department_id）的员工信息 1. 查询员工信息，where department_id = ? select * from t_employees where department_id = XDeptId; 2. 查询Nancy所在部门是？ select deparment_id from t_employees where first_name = \u0026#39;Nancy\u0026#39;;--XDeptId 3. 组合 select * from t_employees where department_id = (select deparment_id from t_employees where first_name = \u0026#39;Nancy\u0026#39;); 2. 单列多行 总结\n查询结果是单列多行的多个值，通常用在in条件语法中。\n场景\n1 -- 查询与名字叫john(多个人同名)同一部门的员工信息？ 分析\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1. 查询员工的信息？where department_id in (x,y,z...) 假设 deptids select * from t_employees where department_id in (deptids) 2. 查询john(重名)所在部门id。-- deptids select department_id from t_employees where first_name = \u0026#39;John\u0026#39;; 3. 组装 select * from t_employees where department_id in (select department_id from t_employees where first_name = \u0026#39;John\u0026#39;); 3. 多列多行 场景\n1 -- 计算工资最高的前5名员工的薪资总和 分析\n1 2 3 4 5 6 7 8 9 10 11 顺序： ① order by排序：order by salary desc分组： ② limit：limit 0,5 ③ 分组函数：sum(salary) 自以为是的SQL： select sum(salary) from t_employees order by salary desc limit 0,5; 思路\n注意：from后面是一个sql子查询的话，需要起别名，然后使用子查询别名表的列：别名.列名​.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1. 先排序+limit select salary,first_name from t_employees order by salary desc limit 0,5; -- t_temp 2. 对上SQL结果，统计sum select sum(salary) from t_temp; 3. 组装 select sum(tb.salary) from (select salary,first_name from t_employees order by salary desc limit 0,5) as tb; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## 六、表连接 \u0026gt; 当查询数据需要的列，来源于多张表的时候，需要将多表合并成1个表，作为from查询。 ### (1) 左外连 * 概念： 在sql的连接操作中，左表为主，右表为辅，连接结果**保留全部左表**数据。 * 场景： 查询员工的信息：工号id、名字、工资、部门名称？ * 语法 ```sql 表1 别名1 left join 表2 别名2 on 别名1.字段 = 别名2.字段 -- 将场景表连接 t_employees as t_emp left join t_departments as t_dept on t_emp.department_id = t_dept.department_id 说明：将2个表合并成一张表。 思路\n代码\n1 2 select e.employee_id,e.first_name,e.salary,d.department_name from t_employees as e left join t_departments as d on e.department_id = d.department_id; 代码2\n1 2 3 4 5 6 7 8 -- 查询员工的信息：工号id、名字、工资、部门名称，职位名字title，职位最大工资，职位最小工资？ 1. 数据来源的表：员工表、部门表、职位表？ select e.EMPLOYEE_ID,e.FIRST_NAME,e.SALARY,d.DEPARTMENT_NAME,j.JOB_TITLE,j.MAX_SALARY,j.MIN_SALARY from t_employees e left join t_departments d on e.department_id = d.department_id left join t_jobs j on e.job_id = j.job_id; (2) 右外连 概念\n以右表为主，左表为辅，保留全部右表数据，左表中只有满足on条件的数据才会保留。\n语法\n表1 right join 表2 on 连接条件;​\n(3) 内连接 概念\n没有主次之分，只保留满足on连接条件的数据。\n语法\n表1 inner join 表2 on 连接条件;​\n(4) 自连接 需要通过表连接，将2个条数据连接成一条数据。借助左外连实现数据连接。如果join2个表都是同一个表的。自连接。\n场景\n查看员工的id、名字、工资、及其上级领导的id、名字、工资?\n代码\n1 2 3 4 5 6 7 1. 2个员工表自连接成1张表 t_employees e1 left join t_employees e2 on e1.manager_id = e2.employee_id 2. SQL select e1.EMPLOYEE_ID,e1.FIRST_NAME,e1.SALARY,e2.EMPLOYEE_ID,e2.FIRST_NAME,e2.SALARY from t_employees e1 left join t_employees e2 on e1.manager_id = e2.employee_id; ","date":"2025-04-14T15:49:32+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/mysql%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","title":"MySQL基础语法"},{"content":"02-2-mysql基础实践 为什么mysql用的这么多 性能强悍，服务稳定，很少因为MySQL自身宕机\n开放源代码，社区很活跃，出了问题可以很快得到解决方案\nMySQL软件体积优化了N次后，安装包也很小，部署简单，配置易懂，文档也多\n历史悠久，MySQL得到了全世界的公司验证，选它没问题\nLAMP,LNMP、都是和MySQL架构\nMySQL便于编程语言，基于API直接获取数据，如java、python、golang等\n版本选择 企业版 MySQL企业版由MySQLAB公司内部专门的人员负责开发及维护,但同时也会吸纳社区人员编写的优秀代码及算法,并且由他们严格按照软件测试流程对这些采纳的代码进行测试,确定没有问题之后才会进行发布。简单地说,MySQL企业版是由MySQL公司内部发布的,它参考了社区版的先进代码功能和算法,是MySQL公司的赢利产品,需要付费才能使用及提供服务支持,稳定性和可靠性无疑都是最好的,当然了,企业腰包得够鼓才能买得起。某知名分类门户网站2008年就购买过MySQL企业版,价格不比那些闭源的商业数据库便宜,也是大几十万。\n社区版 MySQL社区版则是由分散在世界各地的MySQL开发者、爱好者以及用户参与开发与测试的，包括软件代码的管理、测试工作，也是他们在负责。社区也会设立BUG汇报机制，收集用户在使用过程中遇到的BUG情况，相比于企业版，社区版的开发及测试环境没有那么严格。\n选哪个 mysql是成熟产品，企业版和社区版在性能方面区别不大，对于我们学习而言，社区版即可。它们的区别可以如下了解\n企业版对代码的管理、测试更严格、稳定性更好 企业版不遵循GPL开源协议，而社区版遵循，可以免费用 企业版可以购买额外的收费服务，如7*24的技术支持，有钱任性。 社区版的安全性，稳定性，无法像企业版有及时的维护、技术支持。 MySQL特点 支持多种操作系统,Windows、MacOS、Linux等支持多种语言API,如C、C++、Python、PHP、Java等\n支持多线程、充分利用硬件资源支持多种存储引掌\nmysq就是一个基于socket编写的C/S架构的软件\n客户端软件：mysq自带:如mysql命令,mysqldump命令等;python模块:如pymysql\nMySQL服务端-客户端 先看下什么是B/S和C/S架构。\nB/S是Browser/Server指浏览器和服务器端,在客户机不需要装软件,只需要装一个浏览器。\nC/S是Client/Server指客户端和服务器,在客户机端必须装客户端软件及相应环境后,才能访问服务器\nMySQL是基于客户端-服务端的运行模式数据库,服务满负责数据处理,运行在数据库服务器上。\n用户通过发送增删改查等请求,发送给 客户端软件,然后通过网络提交请求给 服务端,服务端接收到请求,再进行处理,然后返回。\n服务端、客户端可以在不同的机器上,也可以在一台机器上。\n这种服务端,客户端,就在生活里很常见,如打游戏时的登录,QQ、微信的登录,MySQL也是一个登录的过程。\nmysql下载选择 了解数据库后，我们可以下载mysql软件了\nhttp://mirrors.sohu.com/mysql/\nmysql安装启动 准备3个新机器，\ndb-51\ndb-52\ndb-53\n我们会用到\n或者自己快照管理\n1.安装全流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 yum 源码编译 rpm包 装和卸载 如何处理依赖关系 都是要掌握的技能 我这里是省事，二进制解压即用 # 确认时间正确 [root@tech-db-51 /opt]#crontab -l * * * * * ntpdate -u ntp.aliyun.com 1 .准备好包 [root@tech-db-51 /opt]#ll total 707688 -rw-r--r-- 1 root root 724672294 Jul 28 19:56 mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz [root@tech-db-51 /opt]# [root@tech-db-51 /opt]# [root@tech-db-51 /opt]#du -h 692M\t. 2. 解压缩 [root@tech-db-51 /opt]## 常见做法，做软连接，便于二进制包的升级，后续的使用路径，用的都是软连接 [root@tech-db-51 /opt]# [root@tech-db-51 /opt]# [root@tech-db-51 /opt]#ln -s /opt/mysql-5.7.38-linux-glibc2.12-x86_64 /opt/mysql [root@tech-db-51 /opt]# [root@tech-db-51 /opt]# [root@tech-db-51 /opt]# [root@tech-db-51 /opt]#ls /opt/ -l total 707688 lrwxrwxrwx 1 root root 40 Jul 28 19:58 mysql -\u0026gt; /opt/mysql-5.7.38-linux-glibc2.12-x86_64 drwxr-xr-x 9 root root 129 Jul 28 19:57 mysql-5.7.38-linux-glibc2.12-x86_64 -rw-r--r-- 1 root root 724672294 Jul 28 19:56 mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz [root@tech-db-51 /opt]# # 3. 配置PATH echo \u0026#39;export PATH=$PATH:/opt/mysql/bin\u0026#39; \u0026gt;\u0026gt; /etc/profile source /etc/profile # 4. 验证mysql版本 [root@tech-db-51 /opt]#mysql -V mysql Ver 14.14 Distrib 5.7.38, for linux-glibc2.12 (x86_64) using EditLine wrapper [root@tech-db-51 /opt]# # 5.删除mariadb的依赖，删除默认的配置文件 yum remove mariadb-libs.x86_64 -y rm -f /etc/my.cnf # 6.装mysql5.7特有的依赖包 yum install libaio-devel -y #7. 创建数据目录， # 准备mysql的数据目录，授权用户 useradd -s /sbin/nologin -M mysql mkdir -p /linux0224/ mkdir -p /linux0224/mysql_3306/ # 授权 chown -R mysql.mysql /linux0224/ chown -R mysql.mysql /linux0224/mysql_3306/ chown -R mysql.mysql /opt/mysql* #检查 ls -ld /linux0224 /linux0224/mysql_3306/ /opt/mysql* [root@tech-db-51 /opt]#ls -ld /linux0224 /linux0224/mysql_3306/ /opt/mysql* # 8.此时自建的mysql目录，没有输数据，mysql 无法使用，初始化生成mysql默认库的数据源 ，用户等信息，即可启动 # mysqld 服务端命令，启动，初始化，都用的这个 # --basedir mysql二进制命令装再哪了，主程序目录 # --datadir 数据目录初始到哪 mysqld --initialize-insecure --user=mysql --basedir=/opt/mysql --datadir=/linux0224/mysql_3306/ 2.配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 初始化完毕后，有配置文件即可正确启动，告诉 my.cnf mysqld的数据源目录在哪，日志写入到哪等 # /etc/my.cnf 默认mysql会去读这个，不指定，也读这个 # [mysqld] 服务端会读取的配置 # [mysql] 再机器本地，执行mysql命令，客户端读取的配置 # socket 本地进程套接字文件，用于mysql客户端再本地区链接 cat \u0026gt;/etc/my.cnf \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [mysqld] port=3306 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3306/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock EOF 3.启动脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 复制自带脚本即可 [root@tech-db-51 /linux0224/mysql_3306]#cp /opt/mysql/support-files/mysql.server /etc/init.d/mysqld [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]#systemctl daemon-reload [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]#systemctl status mysqld ● mysqld.service - LSB: start and stop MySQL Loaded: loaded (/etc/rc.d/init.d/mysqld; bad; vendor preset: disabled) Active: inactive (dead) Docs: man:systemd-sysv-generator(8) 4.登录mysql 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 启动即可 [root@tech-db-51 /linux0224/mysql_3306]#systemctl start mysqld [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]# [root@tech-db-51 /linux0224/mysql_3306]#mysql Welcome to the MySQL monitor. Commands end with ; or /g. Your MySQL connection id is 2 Server version: 5.7.38 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;/h\u0026#39; for help. Type \u0026#39;/c\u0026#39; to clear the current input statement. mysql\u0026gt; mysql多实例管理 前面已经针对MySQL数据库进行了介绍,并说明了为什么选择MySQL数据库,以及MySQL数据库在Linux系统下的多种安装方式,同时以单实例讲解了如何以编译方式安装MySQL和基础安全优化等内容,本章将为大家讲解更为实用的MySQL多实例安装\n百度、淘宝、阿里、新浪等大公司无一例外地都会使用多实例的方式 部署数据库,那么是什么原因促使他们选择多实例数据库的部署方式呢?\n单实例,也就是老师前面是带着大家,在一台Linux上,某个目录下,安装了一个mysql,且启动了这个mysql,这就表示,这个机器上,有单独的一个mysql个体,一个实例。\n什么是多实例 多实例,就是一台Linux上,同时运行多个mysql,当然是区别了不同的端口,例如3306、3307、3308。运行三个mysql数据库\n这三个mysql,就相当于三个独立的卧室,互相没关系,在Linux上的呈现区别就是\n不同的端口 不同的数据目录,不同的配置文件 不同的mysql进程,不同的pid 多实例的好处 可有效利用服务器资源。当单个服务器资源有剩余时,可以充分利用剩余的资源提供更多的服务,且可以实现资源的逻辑隔离。\n节约服务器资源。若公司资金紧张,但是数据库又需要各自尽量独立地提供服务,而且还需要用到主从复制等技术,那么选择多实例就再好不过了。\n例如公司有多个业务,需要用到好几套mysq数据库,都得单独的部著,数据区分开\n多实例的弊端 MySQL多实例有它的好处,也有其弊端,比如,会存在资源互相抢占的问题。当某个数据库实例并发很高或者有SQL慢查询时,整个实例会消耗大量的系统CPU、磁盘1/O等资源,导致服务器上的其他数据库实例提供服务的质量一起下降。\n这就相当于大家住在一个房子的不同卧室中,早展起来上班,都要刷牙、洗脸等,这样卫生间就会长期处于占用状态,其他人则必须要等待。\n不同实例获取的资源是相对独立的,无法像虚拟化一样完全隔离。(毕竞大家都是在同一个文件系统下)\n以后老师教大家学习虚拟化后,就可以实现完全隔离。\n学MySQL多实例用在哪些场景 资金紧张的公司 若公司资金紧张,公司业务访问量不太大,但又希望不同业务的数据库服务各自能够尽量独立地提供服务而互相不受影响,或者,还有需要主从复制等技术提供备份或读写分离服务的需求,那么,多实例就再好不过了\n比如:可以通过3台服务器部署9~15个实例,交叉做主从复制、数据备份及读写分离\n这样就可以等同于9~15台服务器每个只装一个数据库才有的效果。(很省钱了)\n这里需要强调的是,所谓的尽量独立是相对的。\n用户并发访问量不大的业务 当公司业务访问量不太大的时候,服务器的资源基本上都是浪费的,这时就很适合多实例的应用,如果对SQL语句的优化做得比较好,MySQL多实例会是一个很值得使用的技术,即使并发很大,合理分配好系统资源以及搭配好服务,也不会有太大的问题。\n例如某古董、古玩展示的网站,比起电商网站,并发量会小一些,更多追求稳定,而不是高性能、高并发。 大型网站也有用多实例\n大型网站也有用多实例 门户网站通常都会使用多实例,因为配置硬件好的服务器,可以节省IDC机柜空间,同时,运行多实例也会减少硬件资源占用率不满的浪费。\nMySQL多实例部署 图解 创建数据目录 1 2 3 4 5 mkdir -p /linux0224/mysql_3307 mkdir -p /linux0224/mysql_3308 chown -R mysql.mysql /linux0224 初始化2个实例的数据 1 2 3 4 5 6 7 8 9 mysqld --initialize-insecure --user=mysql --basedir=/opt/mysql --datadir=/linux0224/mysql_3307 mysqld --initialize-insecure --user=mysql --basedir=/opt/mysql --datadir=/linux0224/mysql_3308 # 都会默认创建一个账户，链接权限 root 空密码 只允许再localhost登录 至此有3个实例了 1 2 3 4 5 6 7 8 9 10 [root@tech-db-51 /linux0224]#ll total 4 drwxr-xr-x 6 mysql mysql 4096 Jul 28 14:00 mysql_3306 drwxr-xr-x 5 mysql mysql 314 Jul 28 14:37 mysql_3307 drwxr-xr-x 5 mysql mysql 314 Jul 28 14:38 mysql_3308 [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#du -sh * 134M\tmysql_3306 122M\tmysql_3307 122M\tmysql_3308 额外创建俩实例的配置文件 3306 1 2 3 4 5 6 7 8 9 10 11 [root@tech-db-51 /linux0224]#cat /etc/my.cnf [mysqld] port=3306 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3306/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock 3307 区别在参数\n1 2 3 4 5 6 7 8 9 10 11 cat /etc/my.cnf [mysqld] port=3307 user=mysql basedir=/opt/mysql datadir=/linux0224/mysql_3307/ socket=/tmp/mysql.sock [mysql] socket=/tmp/mysql.sock port\ndatadir\nsocket 进程套接字文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 链接mysql的俩方式，找到它 进程 pid 能链接程序的俩方式 1. 通过远程网络的链接形式，效率很低，网络波动， ip:port 10.0.0.51:3306 mysql -uroot -p -h10.0.0.51 -P3306 -------------------------------- -------------------------------- -------------------------------- 2. 通过再机器本地，进程套接字文件去链接，直接是基于内存的链接 程序和程序之间，直接走内存数据，效率极高，遇见一些软件的部署，走socket链接 如nginx的反向代理配置 proxy_pass ip:port; proxy_pass unxi:socket; /linux0224/mysql_3307/mysql.sock # -S 等于 -h -P # 链接3307的进程 mysql -uroot -p密码 -S /linux0224/mysql_3307/mysql.sock mysql -uroot -p密码 -S /linux0224/mysql_3306/mysql.sock mysql -uroot -p密码 -S /linux0224/mysql_3308/mysql.sock log目录\n1 2 3 4 5 6 7 8 9 cat \u0026gt;/etc/mysql_3307.cnf \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [mysqld] port=3307 user=mysql basedir=/opt/mysql/ datadir=/linux0224/mysql_3307/ socket=/linux0224/mysql_3307/mysql.sock log_error=/linux0224/mysql_3307/mysql.log EOF 3308 1 2 3 4 5 6 7 8 9 10 cat \u0026gt;/etc/mysql_3308.cnf \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [mysqld] port=3308 user=mysql basedir=/opt/mysql/ datadir=/linux0224/mysql_3308/ socket=/linux0224/mysql_3308/mysql.sock log_error=/linux0224/mysql_3308/mysql.log EOF 检查配置文件 1 2 3 [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#ls /etc/my* /etc/my.cnf /etc/mysql_3307.cnf /etc/mysql_3308.cnf 多实例脚本 有3个数据目录+ 3个独立的配置文件+ shell脚本 -=====3个运行程序\n提供一个脚本模板，自己区分3个实例的端口，数据目录即可\n生成 3307 和3308即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 cat \u0026gt; /linux0224/3307.sh \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; port=\u0026#34;3307\u0026#34; mysql_user=\u0026#34;mysql\u0026#34; Cmdpath=\u0026#34;/opt/mysql/bin/\u0026#34; # socket用于判断程序是否运行 # 程序运行中，该socket文件存在 # 进程挂了，socket文件自动消失 mysql_sock=\u0026#34;/linux0224/mysql_${port}/mysql.sock\u0026#34; # 定义路径，mysql进程启动后，一个存储该进程pid号码的文件在哪 mysqld_pid_file_path=/linux0224/mysql_${port}/mysqld_${port}.pid # 启动mysqld服务端的入口命令 start(){ if [ ! -e \u0026#34;$mysql_sock\u0026#34; ];then printf \u0026#34;Starting MySQL.../n\u0026#34; # mysql的启动逻辑 # mysqld_safe 脚本 \u0026gt; mysqld 脚本 \u0026gt; 运行mysql进程 /bin/sh ${Cmdpath}/mysqld_safe --defaults-file=/etc/mysql_${port}.cnf --pid-file=$mysqld_pid_file_path 2\u0026gt;\u0026amp;1 \u0026gt; /dev/null \u0026amp; sleep 3 else printf \u0026#34;MySQL is running.../n\u0026#34; exit 1 fi } stop(){ if [ ! -e \u0026#34;$mysql_sock\u0026#34; ];then printf \u0026#34;MySQL is stopped.../n\u0026#34; exit 1 else printf \u0026#34;Stoping MySQL.../n\u0026#34; mysqld_pid=`cat \u0026#34;$mysqld_pid_file_path\u0026#34;` if (kill -0 $mysqld_pid 2\u0026gt;/dev/null) then kill $mysqld_pid sleep 2 fi fi } restart(){ printf \u0026#34;Restarting MySQL.../n\u0026#34; stop sleep 2 start } case \u0026#34;$1\u0026#34; in start) start ;; stop) stop ;; restart) restart ;; *) printf \u0026#34;Usage: /data/${port}/mysql{start|stop|restart}/n\u0026#34; esac EOF 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 cat \u0026gt; /linux0224/3308.sh \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; port=\u0026#34;3308\u0026#34; mysql_user=\u0026#34;mysql\u0026#34; Cmdpath=\u0026#34;/opt/mysql/bin/\u0026#34; # socket用于判断程序是否运行 # 程序运行中，该socket文件存在 # 进程挂了，socket文件自动消失 mysql_sock=\u0026#34;/linux0224/mysql_${port}/mysql.sock\u0026#34; # 定义路径，mysql进程启动后，一个存储该进程pid号码的文件在哪 mysqld_pid_file_path=/linux0224/mysql_${port}/mysqld_${port}.pid # 启动mysqld服务端的入口命令 start(){ if [ ! -e \u0026#34;$mysql_sock\u0026#34; ];then printf \u0026#34;Starting MySQL.../n\u0026#34; # mysql的启动逻辑 # mysqld_safe 脚本 \u0026gt; mysqld 脚本 \u0026gt; 运行mysql进程 /bin/sh ${Cmdpath}/mysqld_safe --defaults-file=/etc/mysql_${port}.cnf --pid-file=$mysqld_pid_file_path 2\u0026gt;\u0026amp;1 \u0026gt; /dev/null \u0026amp; sleep 3 else printf \u0026#34;MySQL is running.../n\u0026#34; exit 1 fi } stop(){ if [ ! -e \u0026#34;$mysql_sock\u0026#34; ];then printf \u0026#34;MySQL is stopped.../n\u0026#34; exit 1 else printf \u0026#34;Stoping MySQL.../n\u0026#34; mysqld_pid=`cat \u0026#34;$mysqld_pid_file_path\u0026#34;` if (kill -0 $mysqld_pid 2\u0026gt;/dev/null) then kill $mysqld_pid sleep 2 fi fi } restart(){ printf \u0026#34;Restarting MySQL.../n\u0026#34; stop sleep 2 start } case \u0026#34;$1\u0026#34; in start) start ;; stop) stop ;; restart) restart ;; *) printf \u0026#34;Usage: /data/${port}/mysql{start|stop|restart}/n\u0026#34; esac EOF 启动多实例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 查看已有的3306实例 [root@tech-db-51 /linux0224]#netstat -tunlp|grep 3306 tcp6 0 0 :::3306 :::* LISTEN 2018/mysqld # 启动3307 [root@tech-db-51 /linux0224]#bash 3307.sh start Starting MySQL... Logging to \u0026#39;/linux0224/mysql_3307/mysql.log\u0026#39;. [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#netstat -tunlp|grep mysql tcp6 0 0 :::3306 :::* LISTEN 2018/mysqld tcp6 0 0 :::3307 :::* LISTEN 12514/mysqld # 启动3308 [root@tech-db-51 /linux0224]#bash 3308.sh start Starting MySQL... Logging to \u0026#39;/linux0224/mysql_3308/mysql.log\u0026#39;. [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#netstat -tunlp|grep mysql tcp6 0 0 :::3306 :::* LISTEN 2018/mysqld tcp6 0 0 :::3307 :::* LISTEN 12514/mysqld tcp6 0 0 :::3308 :::* LISTEN 12700/mysqld 检查3个实例的pid文件，socket文件 1 2 3 4 5 6 7 8 # pid文件 ，3个实例的 [root@tech-db-51 /linux0224]#find . -name \u0026#39;*.pid\u0026#39; ./mysql_3306/tech-db-51.pid ./mysql_3307/mysqld_3307.pid ./mysql_3308/mysqld_3308.pid #socket文件 生产下的暗坑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [root@tech-db-51 /linux0224]#systemctl start mysqld [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#bash /linux0224/3307.sh start Starting MySQL... [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]# [root@tech-db-51 /linux0224]#find / -name \u0026#39;*.sock\u0026#39; |xargs -i ls -l {} srwxrwxrwx 1 mysql mysql 0 Jul 28 15:00 /tmp/mysql.sock srwxrwxrwx 1 mysql mysql 0 Jul 28 15:00 /linux0224/mysql_3307/mysql.sock srwxrwxrwx 1 mysql mysql 0 Jul 28 14:55 /linux0224/mysql_3308/mysql.sock [root@tech-db-51 /linux0224]# 有些程序，不专业的程序员，会清空/tmp下的数据 # mysql的链接有的链接方式是走 sock文件的，因此sock文件不得删除，导致无法链接 # 建议，sock文件，别放入/tmp目录 设置多实例的密码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 3实例， # mysqladmin和mysql一样，也是客户端链接命令 # 精确定位 每一个实例 # ip:port # socket mysqladmin -uroot -p password 新的密码 # ==================3306========= # socket修改 # -u账户 # -p密码 ，啥也没写，会交互式提示让你输入 mysqladmin -uroot -p -S /tmp/mysql.sock password linux0224 # 还要再改3306的密码 # -p后面建议别跟上密码，因为history能看到密码记录 # mysql也给你提示不安全 # mysqladmin -uroot -plinux0224 -S /tmp/mysql.sock password linux3306 mysql -uroot -p mysql\u0026gt; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;123456\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; FLUSH PRIVILEGES; Query OK, 0 rows affected (0.00 sec) # ==================3307========= mysqladmin -uroot -p -S /linux0224/mysql_3307/mysql.sock password linux3307 # ==================3308========= mysqladmin -uroot -p -S /linux0224/mysql_3308/mysql.sock password linux3308 登录多实例 ip:port方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 [root@tech-db-51 /linux0224]#mysql -hlocalhost -P3306 -uroot -plinux3306 -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; mysql: [Warning] Using a password on the command line interface can be insecure. +---------------+-------+ | Variable_name | Value | +---------------+-------+ | port | 3306 | +---------------+-------+ # 3307 ，mysql的用户远程链接，权限问题 [root@tech-db-51 /linux0224]#mysql -uroot -plinux3307 -h127.0.0.1 -P3307 -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; mysql: [Warning] Using a password on the command line interface can be insecure. +---------------+-------+ | Variable_name | Value | +---------------+-------+ | port | 3307 | +---------------+-------+ [root@tech-db-51 /linux0224]#mysql -uroot -plinux3308 -h127.0.0.1 -P3308 -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; mysql: [Warning] Using a password on the command line interface can be insecure. +---------------+-------+ | Variable_name | Value | +---------------+-------+ | port | 3308 | +---------------+-------+ # ip:port有很多种规则 # 授权语法 # locahost, 127.0.0.1 10.0.0.10 sock文件方式 1 2 3 4 5 6 7 8 mysql -uroot -plinux3308 -S /linux0224/mysql_3308/mysql.sock -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; mysql -uroot -plinux3307 -S /linux0224/mysql_3307/mysql.sock -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; mysql -uroot -plinux3306 -S /tmp/mysql.sock -e \u0026#34;show global variables like \u0026#39;port\u0026#39;;\u0026#34; 查看mysql的仨实例进程信息 ","date":"2025-04-14T15:44:19+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/mysql%E5%9F%BA%E7%A1%80%E5%AE%9E%E8%B7%B5/","title":"MySQL基础实践"},{"content":"02-1-数据库基础知识 1 2 今天主要快速入门，学习数据库的核心理论，运维和数据库的关系等 以及安装部署 数据库开篇架构 什么是数据? 1 2 3 数据就是数值,也就是我们通过观察、实验或计算得出的结果。 数据有很多种,最简单的就是数字。 数据也可以是文字、图像、声音等。 1 2 3 4 qq 就是mysql 我们打游戏最怕什么?最怕被盗号,怕自己的账号,密码丢失。 打游戏时候,腾讯为了保护大家的账号安全,提供了密码服务xl 数据存储 很早很早以前，古人是这么存数据的\n结绳、契刻、结珠、石头替代法等等,如今纸张是人们广泛使用的信息载体。但是书籍不便于 询、共享、储藏等缺点。\n计算机去存储，管理数据\n随着计算机的发展,人们将信息转化为二进制数字,存储在磁性存储介质中,也就是磁盘进行 据记录。数据通过文件系统管理,以文件形式显示出来。 但是大量的文件数据,查询内容,还是很不方便。 在这个背景下,一个专门用于数据管理的工具诞生了,它能让我们更简单的管理数据。\n什么是数据库 顾名思义，数据库(DB，database)按照数据结构来组织、存储和管理数据的“仓库”，是一个文件或者一组文件。\n表是数据库中存储数据的基本单位，数据按照分类存储在不同的表中，便于查询。\n数据库可以通过统一的一些指令对数据进行增、删、改、查(Create,Retrive,Updata,Delete)等操作。\n例如财务人员使用Excel统计公司资产信息，进行管理，计算账户\nDBMS Database Management System，数据库管理系统\n数据库管理系统这一软件用于创建和操作数据库。\n主流数据库软件,如Mysql(免费),Oracle(收费,甲骨文公司),MicrosoftSQLServer、SQLite(轻型)等。\nmysq主要用于大型门户,例如搜狗、新浪等,它主要的优势就是开放源代码,因为开放源代码这个数据库是免费的,他现在是甲骨文公司的产品。\noracle主要用于银行、铁路、飞机场等。该数据库功能强大,软件费用高。也是甲骨文公司的产品\nsqlserver是微软公司的产品,主要应用于大中型企业,如联想、方正等。\n数据库基础知识 首先mysql前面超哥已经多少带着大家接触过，安装过、使用过，大家心中有一个基础的认识。\n运维和数据库 说白了，数据库就是存数据的，是一款软件，用专门的数据库语言，增删改查数据。\n数据库的形式\n自己再inux上,直接安装,例如上图,数据都在inux机器磁盘上,运维自己管理 云服务器RDS产品(数据库安装在阿里巴巴的服务器上,我们通过账号密码,远程使用) 数据库类别 目前主流数据库软件，分为两种\n关系型数据库 非关系型数据库 关系型数据库 关系型数据库模型可将复杂的数据结构归结为简单的二元关系（即二维表格形式）\n数据库的操作建立在一个、或者多个关系表格上,通过对这些表格进行分类、合并、连接等查询方式,来找 到我们想要的数据。\n最常见的数据库里是MySQL和Oracle,\n图解数据库概念 数据库\u0026ndash;文件夹…文件夹名字(luffy_dev) 数据库里的数据表\u0026ndash;文件夹里的table数据表\u0026ndash;数据表的名字 数据表里的数据…-文件中的数据\u0026ndash;例如一个excel里的数据 什么是表 在 MySQL 中，表是数据库中的基本存储结构，用于组织和存储数据。表由行和列组成，每个表都有一个名称，用于标识和访问。\n什么是列 列是表中的一个垂直部分，代表数据的一个属性或字段。每列都有一个名称和数据类型，用于定义该列可以存储的数据类型（如整数、字符串等）。\n什么是行 行是表中的一个水平部分，代表一条完整的数据记录。每行包含多个列的值，每个值对应于表中定义的一个列。\n什么是主键 主键是表中一列或多列的组合，其值唯一标识表中的每一行。主键约束确保没有两行具有相同的主键值，通常用于快速检索数据和建立表之间的关系。\n什么是外键 外键是数据库表中的一个约束，用于建立和维护两个表之间的数据关联。它是一个或多个列，其值引用另一表的主键。外键约束确保数据的一致性和完整性，防止无效数据插入。通过外键，可以在不同表之间建立关系，实现数据的关联性和完整性。\n运维要学的：什么是SQL SQL是结构化查询语言的缩写,读作S-Q-L或者sequel,全称是(Structured QueryLanguage),是一种专用来与数据库交流的语言。\nSQL语法主要是\n查询语言:select 操作语言:insert、update、delete 事务处理:begintransaction、commit、rolback 权限控制:grant、revoke 数据库管理:create、drop 以上语法不区分大小写\n什么是mariadb、mysql MySQL是一个开源的中小型关系型数据库管理系统,被应用于大、中、小型网站。由于其具有体积小、速度快、总体拥有成本低,且开放源码等特点,因此许多大中小型网站选择它作为网站数据库,从而降低网站总体拥有成本,甚至国内知名的淘宝网也选择弃用Oracle而更换成更为开放的MySQL。\nMySQL数据库的应用范围主要包括互联网领域、大中小型网站、游戏公司、电商平台等,因用户广泛,其产生了很多高并发的成熟解决方案,因此传统企业的用户也在逐渐增多。\nMariaDB mariadb是mysq数据库的一个分支,主要由开源社区维护,采用GPL授权许可。 开发这个MariaDB数据库分支的可能原因之一是:Oracle公司收购了MySQL之后,有将MySQL闭源的潜在风险,因此MySQL开源社区采用分支的方式来避开这个风险。开发MariaDB数据库的目的是完全兼容MySQL数据库,包括APl和命令行,使之能够轻松地成为MySQL的替 代品。在存储引擎方面,它使用XtraDB来代替MySQL的InnoDB。MariaDB由MySQL的创始人Michael Widenius主导开发,他早前普以10亿美元的价格,将自己创建的公司MySQLAB卖给Sun,此后,随着Sun被甲骨文收购,MySQL的所有权也落入Oracle的手中。MariaDB数据库的名称来自MySQL的创始人Michael Widenius的女儿Maria的名字 MariaDB基于事务的Maria存储引擎,替换了MySQL的MyiSAM存储引擎,使用Percona的XtraDB替换了MySQL的innoDB存储引攀。\nMariaDB数据库的早期版本,均依照MySQL的版本发行。因此,使用MariaDB的人都会从MySQL中了解到MariaDB的相关功能,学习MySQL数据库的人,也可以轻松上手掌握MariaDB数据库。\n1 2 3 4 5 6 7 8 9 目前市面上用的最多的，是mysql 5.7系列 一些最新的公司，用的是mysql8.0 传统行业，mysql更低的版本 或者其他数据库软件如 oracle，sql server等 本次学习mysql 5.7系列 其他关系型数据库 这里大家只需要了解有该数据库即可\nMicrosoft SQL Server Microsoft Access PostgreSQL DB2 Sysbase Informix 数据库具体应用场景 相亲网 譬如网站的注册登录功能，正确流程是，注册成功-\u0026gt;可以登录。\n工程师就要检测在注册成功后，检查数据库是否正确保留了信息。\n游戏数据库 如下是英雄联盟所有的英雄数据库，列出了所有英雄数据\n总结 数据库方面知识，主要以运维、开发分为两个方向，不同的方向所重点学习的内容不一样\n运维人员，主要是对数据库架构、设计、维护 单实例、多实例 SQL语句基础CURD学习、权限管理 字符集、数据库引擎 备份方案 复制方案 高可用方案 开发人员，主要是对数据进行设计、开发 针对业务进行数据库设计、表结构设计 高性能索引 视图 存储过程 函数 ","date":"2025-04-14T15:41:38+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/mysql%E6%A0%B8%E5%BF%83%E5%85%A5%E9%97%A8/","title":"MySQL核心入门"},{"content":"开篇前言 第二阶段：综合架构篇 学习前言 第一阶段总结 1 2 3 4 5 6 7 8 9 10 第一阶段 1.死记硬背 2.多敲命令，多做练习题 3.学的东西的确特别多，但是工作里日常用的其实反复就那几个，参数也就那几个 关于学习方法的理解 1.在不知道网站是如何搭建的时候（没做过这件事，会很难，LNMP LAMP，wordpress，discuz）刚开始，没有思路是最难的 2.在尝试实践过后，有了思路过后，后面的工作就是反复的重复，成为熟练工了 3.为什么新人是万事开头难 4.你会发现领导都是不干活，都是写写文案，出方案，写写PPT，年入50万（人家曾经也辛苦过10年时间） 第二阶段开始，学习思路的转变 更多的是架构的理解，而不是太多的操作\n1 2 3 4 5 6 7 大家都一样装软件，nginx 修改配置 修改端口的参数 修改网站html根目录的参数 启动 启动玩了之后有日志 你得去看日志，看大量的屏幕的英文输出，是正确启动，还是错误？ 主动的思考\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 第二阶段 1.和第一阶段完全不一样，更多的是理解 （你千万不能死记硬背操作，否则换一个场景，你又不知道自己在干什么） - 主动的通过自己的思考，想出每一题的解决方案，转化为你所理解的正则符号- 自己主动再去找更多的练习，不会的和老师交流 2.第二阶段会频繁的使用第一阶段的命令 3.第二阶段大多数是使用软件(ftp,ssh,rsync,nginx)，修改配置文件，那配置文件，好几百、几千行，你根本无法背诵 背死在固定的某一行，某些参数 - 理解你要做什么，去修改什么软件的配置文件，修改的参数是什么意思 4.做好笔记（帮你理解如何修改配置，如何使用软件，的流程） 盖房子一样，流程性很重，以及盖房子之间，cad图纸得画好 （架构图要画好，从前端，到后端，到数据库，之间所有涉及服务，如何去理解，他们之间如何相互调用，通信） 比如同样的安装nginx高可用，集群\n1 2 3 4 5 6 7 8 9 10 11 第一、你先理解原理，心中有了架构思维，这是最重要的 第二、具体nginx集群的安装部署，这其实就很简单了，你笔记做好，以后用到，拿出来复制粘贴即可。 第三、这也是为什么，你会发现，越牛逼的大佬，具体干的活越少，而是写方案，出架构图，因为这是一个有含金量的东西， 当然，人家架构师也是从普通运维，一步步锻炼，反复安装部署软件几千次，敲打几万次命令， 心中早已有无数方案，踩过无数的坑，因此才能独当一面，见招拆招。 500台机器，维护几万的日活 维护了5万台机器，维护过几十亿的日活 小白成长记 也是你未来很长一段时间要走的路线..\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 小白（2月24进班级之前，连电脑都不太会玩） \u0026gt; 初级运维（很多的命令，服务搭建，配置，权限，等等等。。。。） \u0026gt; 运维熟练工 （通过不断的学习各种软件，反复的安装yum，编译，修改配置，刚开始是vim手动去修改，sed修改配置文件,启动systemctl，自己写启动脚本，得看进程，看端口，不断的去练习 ps ，netstat，ss，lsof） 学了2月过去， 网站集群，数据库，shell编程，监控 \u0026gt; 高级运维开发 linux+python \u0026gt; 架构师 linux+python+安全+全栈==架构师 你在教室，每一天的学习强度，上班之后，一下子降低70% 每天的学习，输入大量的知识，自己看看书， 你现在的学习环境，类似于公司的测试环境，机器配置都是最低的，服务安装也是单机的配置也不复杂 小白 \u0026gt; 新人 linux命令会用了 \u0026gt; 初级运维 各种运维工具熟练安装、配置、搭建 \u0026gt; 中高级运维 运维+编程，完成高级运维自动化开发工作 \u0026gt; 高级运维、运维开发 最后、架构师 -实实在在维护过五年以上的linux服务器，从小公司，中型公司，大公司 -解决过太多问题，写过太多笔记、运维博客（博客园等，找运维大佬，写了有10年以上，linux命令基础，到服务部署，到xxx 所有运维都是围绕着k8s去转） -扛得住大公司的大并发架构，复杂运维架构，在阿里，卷累了，不想卷了 -也能在小公司独当一面，一个人就能扛起公司所有的运维工作 -解决方案架构师（架构在心中，出几个PPT，月入几万，全球技术峰会，全球devops技术大佬会，公司也会有技术分享会，运维，给开发同事分享k8s的技术，linux基础都不会，docker，k8s,jenkins，领导是给钱，打绩效的， 500/课，2000/课) -高级运维工程师（熟练操作sed、awk、grep、linux、nginx、mysql、jenkins、redis、kafka、zookeeper、hadoop、oracle、docker、kubernetes、prometheus，等一堆工具，维护过千台服务器，维护过日活一亿的网站，起步50k+） 小白 \u0026gt; 工地新人 \u0026gt; 熟练小推车、铁锹 、和水泥 \u0026gt; 学会了工地图纸设计、造价方案 \u0026gt; 学会了和领导喝酒 \u0026gt; 自己成为了当初最讨厌的那个人（老板，月入百万） 如何学好第二阶段 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1.画图、架构图（一图胜千言、无图言*） 画图工具 https://www.processon.com/ https://excalidraw.com/ 2.理解流程、架构先后关系，如软件安装的先后关系，服务启动的先后关系 3. nginx mysql 运行了 程序一定会有日志输出，开发，运维，都通过这个日志，去掌握程序运行的状态 因此你后面的学习，工作生涯，会和大量的英文接触 所以，请你从此安装机器，再也别用中文了 程序崩溃，无法运行，这个信息，毫无意义，你得通过程序反馈的英文报错，日志，去搜索，去理解它的含义 学会看日志 学会看日志 学会看日志， 无论新人，还是20年架构师，干活都是在看日志 （程序运行了，正常，还是故障，只能去看运行日志！） 提问的艺术 错误的提问 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 傻蛋的提问 - 在吗? 我在 - 有人知道nginx吗？ 大量的死群，qq群，微信群，学习交流群 我知道，nginx是一个服务器 - 我遇到问题了 - 服务起不来了 - 什么问题？ - nginx报错了？ - 什么报错？ - 怎么看？ 。。。我tm想给你一锤子 ============================================================================================ 如果有同学加过各种学习群，你就会见到各种这样的提问 有人知道centos吗？ nginx报错了怎么看？ 然后群里永远是死群，无人回答，你让人家怎么回。。 正确的提问 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 正确的提问艺术 架构搭建中，没人能简单服务为什么没启动、请求为什么没转发成功，自己要捋顺流程，再告诉别人大概你做了什么事 lnmp的部署 linux 最小化安装，系统的基础依赖会有区别 nginx安装 装在了哪里 mysql php,python 如 各位大佬们打扰了，我部署LNMP时出错了，我做了如下的操作 1.怎么装的nginx 2.配置文件在哪，日志目录在哪 3.我改了什么操作，才导致报错的 nginx启动不了，看nginx的日志 4.如果你这些流程自己很清晰，其实你几乎已经快找到问题所在了，只不过经验欠缺，可能还无法解决问题 我已经尝试了这些解决方案，但是还是不行（这样大佬知道你做了什么事，是不是方案错了） 1. 2. 3. 以下是nginx的日志报错，有大佬懂的话可以指点以下，感谢 图1 图2 这样的提问，试问，如果是你，你愿不愿意回答一下？是不是好多了？ 笔记的重要性 1 2 3 4 部署搭建过程，务必记录好步骤，你如果部署出错了，记录下出错的日志,也给记下来 这样你有问题喊老师、同学来看看，大家才知道你做了什么，哪出错了 否则，神仙也不知道你做了什么事，你的问题也无法得到解决，耽误你我时间。 搜索工具的重要性 1 2 你能遇见的绝大多数错误，搜索引擎上，都会有人曾经搜索过，查询过 也有人发布过类似问题的解决方案，合理利用它，能解决你大部分问题。 学点英语 1 2 3 4 5 6 做IT避免不了和英语打交道 运维部署，会反复和大量的英文日志打交道，看日志、看日志、要学会怎么看、提取重点部分信息 无论是去翻译，还是去搜索 都要反复积累英文单词的理解、否则一直看不懂日志，那肯定做不好 AI工具 1 GPT、天工大模型、KIM I等 分享两本书 淘宝的十年\n大型网站架构\n大型网站架构特点(淘宝网) 和传统企业应用系统相比，大型网站系统具备如下特点： ·高并发，大流量：需要扛得住高并发，大流量的用户访问。Google日均PV数35亿，日均IP访问数3亿；腾讯QQ同时在线用户数过亿；淘宝双11当天活动交易额过百亿，活动开始的第一分钟独立访问用户数 达千万 ·高可用：网站系统需要7*24小时不间断提供服务，大型网站的宕机事件通常都会成为新闻焦点，例如百度域名曾被黑客劫持无法访问。 ·海量数据，高可用数据库：需要存储，管理海量数据，使用大量的服务器 ·世界各地用户分布广泛，网络环境复杂：大型网站都是为全球用户提供服务，全球各地网络环境千差万 别，即使国内也有多个运营商网络互通难的问题，面对海外用户还得假设海外数据中心。 ·服务器安全问题：互联网的开放性，很容易受到黑客攻击，需要保护服务器安全，保证数据安全。 ·需求快速变更，发布频繁：和传统应用比较不同，互联网产品为了快速满足市场需求，产品发布率很 高，一天内网站发布几十次已是正常。 ·渐进式发展：即使是世界级大型网站，也都是由小型架构慢慢演变而来，如阿里巴巴本是在马云家中客厅诞生。\n基本架构名词 在介绍架构演进之前，你需要先有一些基本的名词理解\n单体应用架构 单机就是所有的业务全部写在一个项目中，部署服务到一台服务器上，所有的请求业务都由这台服务器处 理，无论是开发代码、还是运维部署、都比较简单粗暴，重启搞定一切。 显然，当业务增长到一定程度的时候，服务器的硬件会无法满足业务需求。自然而然地想到一个程序不行就 部署多个喽，就是集群。\n集群架构 单机处理到达瓶颈的时候，你就把单机复制几份，这样就构成了一个“集群”。 集群中每台服务器就叫做这个集群的一个“节点”,所有节点构成了一个集群。 每个节点都提供相同的服务，那么这样系统的处理能力就相当于提升了好几倍(有几个节点就相当于提升了 几倍)。 集群中的一个节点掉线时，也不会影响到整体的集群业务。\n负载均衡 但问题是用户的请求究竟由哪个节点来处理呢?最好能够让此时此刻负载较小的节点来处理，这样使得每个 节点的压力都比较平均。 要实现这个功能，就需要在所有节点之前增加一个“调度者”的角色，用户的所有请求都先交给它，然后它根 据当前所有节点的负载情况，决定将这个请求交给哪个节点处理。 这个“调度者”有个牛逼了名字——负载均衡服务器。 负载均衡：协调集群里的每个节点均衡地接受业务请求。 通俗的讲就是服务A和服务B相同时间段内处理的同类业务请求数量是相似的。\n高可用 集群系统中部分节点失效时，其他节点能够接替它继续提供服务，则可认为系统具有高可用性。\n淘宝网的十年架构演进 大型网站都是由小型网站发展而来，网站架构也是一样，从小网站逐步演化，最开始小网站访问人数很少，一台服务器即可完成工作。\n此时应用程序，数据库，文件等所有资源都在一台服务器，也就是我们常见的LAMP、LNMP单机，使用各种开源软件和一台普通的服务器即可运行网站。\n单机架构 以淘宝作为例子。在网站最初时，应用数量与用户数都较少，可以把Tomcat(后端)和数据库部署在同一台服务器上。\n浏览器往www.taobao.com发起请求时，首先经过DNS服务器（域名系统）把域名转换为实际IP地址10.102.4.1，浏览器转而访问该IP对应的Tomcat。\n随着用户数的增长，Tomcat和数据库之间竞争资源，单机性能不足以支撑业务\n第一次升级、tomcat和数据库分开了 因为tomcat是java写的，非常占内存资源，总是和数据库抢占磁盘资源、内存资源，导致服务器压力过大，网站解析、处理整体能力都很差。\n因此让tomcat和数据库分开两台机器，显著提升各自的运行性能。\n应用服务和数据库分离 随着网站业务的发展，用户量增多，一台服务器逐渐支撑不住，越来越多的用户访问导致网站响应速度变慢，越来越多的数据，导致存储空间不足。这时候应该把应用和数据分离，使用三台服务器的架构，分别运行应用服务器、文件服务器、数据库服务器。\n这三台机器对硬件资源要求各不同，\n应用服务器需要处理大量的业务逻辑，需要更强大，更快的CPU处理器 数据库服务器需要更快速的读写数据，因此需要更强大的磁盘和大内存 文件服务器要存储大量用户上传的文件，因此需要更大容量的硬盘。 应用和数据分离后，不同作用的服务器承担不同的服务角色，各司其职，网站的并发处理能力和存储空间都得到了很大的改善，进一步支持网站业务。\n但是随着公司发展，用户持续增长，网站此时架构又一次面临挑战，数据库压力太大，导致用户访问延迟，用户体验变差，老板又要拍板骂人了，需要对网站架构进一步优化。\n1 2 3 4 5 6 7 8 9 10 mysql是磁盘性数据库，和机械硬盘，固态硬盘的读写速度挂钩 如果硬盘太差，速度速度从物理上就慢 其他的软件技术都是白扯 数据库，读写速度很快？ 内存读写速度，比磁盘块的多的多 市面上主流的磁盘数据库，mysql 内存性数据，redis，直接数据写入到内存中 第二次升级、引入本地缓存、分布式缓存 1 数据放在内存中，这就叫做缓存（数据写入到内存中，读写都是和内存交互） 网站访问特点也逃不掉现实世界的二八定律：80%的业务访问集中在20%的商品数据上。\n例如淘宝的用户最关注的都是成交量多，评价较好的商品；\n很明显，对于网站的数据，就有热数据，冷数据之分，大部分的业务集中在一小部分数据上，那么如果把热门的数据缓存再内存中，是不是可以减轻数据库的访问压力，提高网站的整体访问效果呢，当然是可以。\nPS：内存的I/O速度是远超于磁盘的\n网站的缓存主要分两种：\n缓存再应用服务器上的本地缓存（内存） 缓存放在专门的分布式缓存服务器上（单独的一台大内存服务器） 本地缓存的弊端 1 2 3 4 5 6 7 第一种缓存，利用程序本身提供的缓存功能（还未引入第二种内存数据库，） php java python 本身这个程序，可以将部分数据，直接写入到内存里，读取时候，也去读取内存的数据 这个叫做程序的本身缓存，本地缓存 比如修改tomcat的参数、添加JVM缓存参数、或者在应用服务器部署memcached缓存数据库，也都可以。\n本地缓存的访问更快，没有网络延时，但是应用服务器的内存有限，缓存的数据量有限制，而且会有缓存和应用程序争夺内存的情况。\n分布式缓存的优点 远程分布式缓存可以采用集群的方案，部署较大内存的服务器作为专门的缓存服务器，可以在理论上实现内存不受限的扩容服务。当然这需要有成本代价。\n新的问题又来了\n使用缓存后，数据库的访问压力得到有效的缓解，但是应用服务器在后续也有了瓶颈；\n缓存抗住了绝大多数的访问请求，但是随着淘宝网的崛起，用户越来越多，并发压力更大了，网站的压力就集中在了tomcat这样的应用服务器上；\n后端服务器解析速度越来越慢；\n主要使用负载均衡集群方式改善。\n1 2 第二种缓存，需要引入独立的产品，独立的软件 引入一个新的数据库，叫做redis数据库 第三次升级、引入反向代理、负载均衡 关于反向代理的概念\n反向代理，以房东 \u0026gt; 中介 \u0026gt; 租客 正向代理， 用户浏览器 \u0026gt; vpn \u0026gt; facebook 使用集群是网站解决高并发，海量请求的常见手段，俗话说三个臭皮匠，胜过诸葛亮。\n一台服务器的处理能力，存储空间都会有瓶颈，此时压根不要企图再去换一个更强大的服务器，对于大型网站而言，无论多么强大的服务器，都满足不了业务增长的需求，此时你的做法应该是再增加一个臭皮匠，也就是增加一台服务器，去分担原有服务器的压力。\n对于网站架构而言，通过增加机器的形式改善负载压力，就可以持续不断的改善系统性能，实现系统的可伸缩性。\n在很多台机器上，都部署tomcat、使用反向代理软件nginx，把请求均匀的分发给每一个tomcat。\n假设tomcat本身最多支持1000个并发（1000个用户同时在线）；\nNginx最多支持50000个并发（支持5万个用户同时连接）；\n那么nginx只要把5万个并发请求，转发给50个tomcat服务器就能扛得住这个流量；\n通过负载均衡调度服务器，将用户的请求分发到应用服务器集群中的任何一台机器上，根据用户访问量，来决定增/删集群中的服务器，以此来解决应用服务器的压力。\n涉及技术、nginx、haproxy、lvs等\n问题又来了\n既然理论上，只要不断增加负载均衡的节点，应用服务器的数量，后端就必然能扛得住更多的用户流量；\n此时的压力就落到了谁身上？\n数据库，此时数据库mysql、依然是单机，读写性能达到瓶颈。\n第四次升级、数据库读写分离 数据库优化技术，读写分离\n网站在使用缓存后，使得大部分数据的读取操作，不通过数据库就可以访问完成，但是也会有一部分的读取操作（例如缓存未命中，缓存过期）和全部的写入操作需要访问数据库，在网站达到一定规模之后，数据库因为负载压力过高而成为网站瓶颈。\n主从复制 目前主流的数据库软件都提供了主从热备功能 ，配置两台数据库的主从关系，可以将一台数据库的数据，同步更新到另一台机器上。\n网站利用该功能，可以实现数据读写分离，减轻数据库负载压力。\n读写分离 数据库规划为读库（从库）；写库（主库）；\n应用服务器进行写入操作的时候，访问主数据库，主数据库通过主从复制机制将数据更新同步到从数据库，这样当\n应用服务器读取数据的时候，可以通过从库获取数据，以此实现数据读写分离；\n针对不同的网站业务，读，写的操作比率，也是不一样的。\n如电商类站点，用户浏览商品居多，读取居多；\n博客类站点，用户写入数据居多，需要依次进行不同的优化调整。\n读库可以有多个，通过主从同步技术把写库的数据，同步到所有的读库；\n对于需要读取最新数据的场景，可以再从写库，同步到缓存中，确保可以通过缓存也能拿到最新数据；\n这里的数据库拆分、主要是DBA的专业数据库运维工作内容，以及开发工程师要根据业务的拆分涉及，系统运维主要以配置数据库复制为主。\n问题又来了 依然是随着淘宝网的发展，不仅是用户量、并发量更大了、业务复杂性也更高了\n业务越来越多、不同业务之间的访问量、访问频率相差也太大，甚至有业务会对数据库竞争，相互影响性能，因此数据库瓶颈依然是个问题。\n后续就是DBA级别的数据库优化架构了，主要是\n数据库按业务分为多个数据库 数据表拆分 这就不在网站架构的讨论范畴了，因此不做讲解了\n第五次升级、负载均衡升级 假设nginx能够支撑5万的用户并发，但是此时的淘宝网已经有50万的用户了，也就是入口的nginx也扛不住这个请求压力了，瓶颈此时出现在了nginx。\n因此依然是采用负载均衡的理念，运行多个nginx来分摊这个集中式的请求压力；\n入口此时发现被修改为了叫做LVS、或是F5这样的软件，它俩也是提供负载均衡能力的软件，但是性能上比nginx更强悍，支持更高的并发，单机的F5就能扛得住支持几十万的用户请求，但是价格昂贵，是一台硬件负载均衡设备，需要企业估值成本；\n成本不允许，则可以使用开源技术，LVS替代F5、性能也足够强悍，也是提供负载均衡的能力。\n但是LVS是软件负载均衡，也就是linux上运行的一个程序而已，如果lvs服务器宕机了，会导致网站入口直接就挂了，因此需要实现高可用，常见的方案就是keepalived；\n第六次升级、DNS负载均衡 1 2 3 4 5 6 7 提示，服务器理论上，最大并发数是 \u0026gt;\u0026gt;\u0026gt; 2**48 281474976710656 每一条连接都是要消耗系统资源的，所以实际中可能会设置最大并发数来保证服务器的安全和稳定，所以这个理论最大并发数是不可能达到的。 实际中并发数和业务是直接相关的，服务器支持几十万连接是没问题的 由于LVS这套软件负载均衡技术，虽说并发数能达到几十万，但是淘宝实在是太挣钱了，老百姓花钱的能力太强了，淘宝网的用户已经达到千万、上亿级别了。\n并且此时的服务器架构，已经是在全国不同的地区，有很多的机房了，并且用户也是分散在全国不同的地区，和服务器的距离各不相同；\n新疆的用户访问淘宝网，请求如果是发给了杭州的淘宝服务器，那这个过程显然是太慢太慢了。。\n你得让新疆的用户，访问淘宝网，这个请求发给了新疆周边的淘宝服务器、或者说找到一个离新疆最近的淘宝服务器（前提是，淘宝在新疆地区周边部署了机房），要不只能通过网络去找其他地区的服务器了。\n以阿里云官网提供的资料来看，如果是新疆的用户，离得最近的就是呼和浩特这个机房。\nDNS负载均衡 在DNS服务器中可以配置一个域名、解析到多个IP地址，每个IP地址对应不同地区的机房服务器IP。\n用户在不同的地区访问www.taobao.com时，DNS服务器会自动判断该用户所在地区，然后选择离他最近的淘宝服务器，返回其IP地址提供访问。\n因此实现了DNS负载均衡，让用户可以访问离自己最近的淘宝网服务器，这样的话，只要增加机房，扩大服务器规模，无论你是千万、千亿级别的并发量，都可以负载均衡、分发给在全国各地的机房了，因此网站入口的并发再也不是问题。\n问题又来了 此时流量入口，不是什么大问题了，难题依然是在业务的复杂度上、业务发展、数据越来越恐怖，后续的优化、又是在数据库角度了\n第N次升级 引入NoSQL数据库，redis 引入搜索引擎技术，ElasticSearch 代码架构升级、大功能拆为小功能，如淘宝网首页，业务拆分为 淘宝网代码 天猫超市代码 聚划算代码 \u0026hellip; 复杂的功能抽象成微服务、置于淘宝网首页的诸多功能 淘宝网代码 天猫超市代码 聚划算代码 这些等等子系统都有一些共同的功能，如 用户数据管理系统 订单管理系统 支付系统 物流系统 \u0026hellip; 这些系统在多个应用中都存在，代码没必要重复的运行、重复的单独写、维护，因此可以抽象为一个公共的服务来关系，这就是微服务的概念，此时多个应用，都可以统一使用这些公共的微服务。 这些微服务系统，都交给专门的团队去维护即可，目前市面上的微服务以阿里的Dubbo、SpringCLoud框架为主流。 当业务以微服务模式运行后、不仅开发工作更细化了、运维部署也更加频繁，且细化了 容器时代 目前市面上最主流的就是通过docker容器技术管理微服务应用，每一个微服务也就是一个个应用程序，全部运行在docker容器里，当容器数量过多后，你必须进行容器编排管理。\n目前最主流的docker管理平台肯定是Kubernetes了。\n以云平台承载系统 到这里，就不是关乎于网站架构的性能问题了，而是成本问题，机器的运行、管理成本，服务器很贵的，部门每个月都有支出预算，这个月服务器费用是50万，如何降低个10万？是不是需要合理的去规划机器的硬件配置，以及不用的机器，是否要回收，关机？\n机房的电费也是很贵的。。\n问题它又来了 使用容器化技术后服务动态扩缩容问题得以解决，但是物理机器还是需要公司自身来管理\n在非大促的时候，还是需要闲置着大量的机器资源来应对大促，机器自身成本和运维成本都极高，资源利用率低\n现在的企业，要么是用公有云（阿里、腾讯、华为云等），部署运行自己的应用；\n要么就是自己有机房、搭建私有云平台，管理虚拟机。\n核心都是在与系统部署在云平台上，利用云平台的海量机器资源，以及可以动态伸缩机器资源，可以在如大促的时候申请更多的机器硬件，结合docker、k8s快速部署业务；\n在大促结束之后，在降低、释放资源，真正做到按需付费，资源利用率提高了，也很大的降低了运营成本。\n云平台是什么 所谓的云平台，就是把海量机器资源，通过统一的资源管理，抽象为一个资源整体，在之上可按需动态申请硬件资源（如CPU、内存、网络等），并且之上提供通用的操作系统，提供常用的技术组件（如Hadoop技术栈，MPP数据库等）供用户使用，甚至提供开发好的应用，用户不需要关系应用内部使用了什么技术，就能够解决需求（如音视频转码服务、邮件服务、个人博客等）。\n在云平台中会涉及如下几个概念：\n**IaaS：**基础设施即服务。对应于上面所说的机器资源统一为资源整体，可动态申请硬件资源的层面； **PaaS：**平台即服务。对应于上面所说的提供常用的技术组件方便系统的开发和维护； **SaaS：**软件即服务。对应于上面所说的提供开发好的应用或服务，按功能或性能要求付费。 架构师原则 N+1设计。系统中的每个组件都应做到没有单点故障；\n回滚设计。确保系统可以向前兼容，在系统升级时应能有办法回滚版本；\n禁用设计。应该提供控制具体功能是否可用的配置，在系统出现故障时能够快速下线功能；\n监控设计。在设计阶段就要考虑监控的手段；\n多活数据中心设计。若系统需要极高的高可用，应考虑在多地实施数据中心进行多活，至少在一个机房断电的情况下系统依然可用；\n采用成熟的技术。刚开发的或开源的技术往往存在很多隐藏的bug，出了问题没有商业支持可能会是一个灾难；\n资源隔离设计。应避免单一业务占用全部资源；\n架构应能水平扩展。系统只有做到能水平扩展，才能有效避免瓶颈问题；\n非核心则购买。非核心功能若需要占用大量的研发资源才能解决，则考虑购买成熟的产品；\n使用商用硬件。商用硬件能有效降低硬件故障的机率；\n快速迭代。系统应该快速开发小功能模块，尽快上线进行验证，早日发现问题大大降低系统交付的风险；\n无状态设计。服务接口应该做成无状态的，当前接口的访问不依赖于接口上次访问的状态。\n综合架构图 ![屏幕截图 2024-09-04 090012](D:/desktop/myblog/myblog/content/post/Linux综合架构/assets/屏幕截图 2024-09-04 090012.png)\n![屏幕截图 2024-09-04 090215](D:/desktop/myblog/myblog/content/post/Linux综合架构/assets/屏幕截图 2024-09-04 090215.png)\n![](D:/desktop/myblog/myblog/content/post/Linux综合架构/assets/屏幕截图 2024-09-04 150442.png)\n今日任务 创建虚拟机，为实验环境做准备\n1 2 3 4 5 6 7 1.今天学习的知识就是理解架构图，理解网站架构演进，升级的历程， 绘制同样的图，去理解架构 2.创建虚拟机，为了我们的运维架构部署做准备 -创建模板机，设置双网卡，主机名，静态ip地址 - 克隆该机器，克隆9台，且 根据文档，设置好主机名，ip地址 架构图中的服务组件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 1.用户、顾客（浏览器） 访问网站的用户请求 2.防火墙、保安（iptables） 设定防火墙策略、防火墙规则，请求的进入、响应的出口，针对ip、port的流量控制 3.负载均衡服务器、迎宾服务员（nginx） 对用户的请求进行调度、纷发 4.web服务器，点餐前台服务员（nginx） 接收用户请求、处理、响应用户请求，返回服务器资料 5.数据库服务器、厨房后厨仓库（mysql） 存储网站的动态数据、提供读写数据功能 6.存储服务器、粮仓仓库（nfs） 存储图片、音频、视频、各种附件等容量较大的静态资源 7.备份服务器、粮仓仓库二号（rsync+crond定时备份、rsync+inotify实时备份） 二次备份所有数据，存储图片、音频、视频、各种附件等容量较大的静态资源 8.缓存服务器、自助取餐（redis） 数据存储在内存里，提供内存的高速数据读写 以及减轻mysql服务器的读写压力 9.ansible服务器、调度总台（ansible） 批量化管理所有的服务器 服务器环境规划 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 服务器作用 主机名 外网地址 内网地址 运行软件 管理机 master-61 10.0.0.61 172.16.1.61 Ansible/zabbix/jumpserver/openvpn 负载均衡服务器 slb-5 10.0.0.5 172.16.1.5 nginx/keepalived 负载均衡服务器 slb-6 10.0.0.6 172.16.1.6 nginx/keepalived web服务器 web-7 10.0.0.7 172.16.1.7 nginx/php web服务器 web-8 10.0.0.8 172.16.1.8 nginx/tomcat web服务器 web-9 10.0.0.9 172.16.1.9 nginx/php 存储服务器 nfs-31 10.0.0.31 172.16.1.31 nfs/rsyncd/lsyncd 备份服务器 rsync-41 10.0.0.41 172.16.1.41 nfs/rsyncd/lsyncd 数据库服务器 db-51 10.0.0.51 172.16.1.51 mysql/redis 注意去理解架构图，生产环境下、只有最外层的负载均衡设备，才能对接到公网流量，因此需要配置公网ip地址； 其他功能的服务器，只需要单网卡，内网IP即可； 外网地址 - 模拟互联网的公网ip - 你可以直接使用windows，ping通该地址，（xshell）ssh连接该地址（服务器） 内网地址 - 模拟服务器的内网，局域网环境 - 无法直接通过xshell连接该服务器 综合架构实践 1.关闭你之前旧的所有虚拟机，甚至删除也行，别开机，因为你之前修改过网络设置\n2.你这里要修改新的网络设置，需要修改vmware的虚拟网络编辑器（实测要关闭dhcp功能，反正我们都是用静态ip）\n1.创建新虚拟机（模板机） 1 2 3 4 5 6 系统 centos7 内存 至少2G/1c（特殊情况，给1c/1g也够了） 网卡 eth0，使用NAT、模拟外网环境 ，网段是10.0.0.xx eth1，使用LAN区段，模拟内网环境，网段是172.16.1.xx 硬盘容量，40G 再添加另一块网卡（充当内网环境的网卡）\n1 2 3 4 提示，常见的LAN和WAN是什么？ WAN接口，也就是广域网（WAN，Wide Area Network）的缩写，也称之为远程网（long haul network ）。 而LAN接口，也就是局域网（Local Area Network，LAN）的缩写，它是指在某一区域内由多台计算机互联成的计算机组。 图解双网卡的配置\n2.安装centos7 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 1.进入内核选择界面时，按上下方向键，取消自动选择 2.输入tab键，复制粘贴进去如下代码，以下代码的作用是禁用基于硬件设备的命名风格，使网卡的命名风格回退到eth0、eth1的形式： net.ifnames=0 biosdevname=0 3.输入回车，启动 4.请注意，必须是英文，以后再也别用中文了，因为你要看日志 5.只需要修改亚洲上海时区,其他全部默认 6.网络设置、修改静态ip地址、设置主机名 模板机，主机名 lj-template-100 ip，10.0.0.100 网关，10.0.0.254 网络配置\n3.登录该机器\n1 ssh root@10.0.0.100 3.简化网卡配置文件 友情提醒，sed是一个双刃剑\n用好了、高效修改配置文件\n用坏了，可能不小心会清空你的配置文件\n所以自己看着来，细心是第一位，做好备份是第一位\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 1.删除网卡配置文件中关于ipv4、ipv6的行 [root@lj-template-100 ~]# sed -i \u0026#39;/ipv[46]/Id\u0026#39; /etc/sysconfig/network-scripts/ifcfg-eth0 2.再删除如下四行 proxy_method browser_only defroute uuid sed -r -i \u0026#39;/(proxy_method|browser_only|uuid|defroute)/Id\u0026#39; /etc/sysconfig/network-scripts/ifcfg-eth0 3.上述俩语句，你也可以一行搞定 确保最终的配置如下，和我一样即可 [root@lj-template-100 network-scripts]# sed -ri \u0026#39;/(proxy_method|browser_only|uuid|defroute)/Id\u0026#39; /etc/sysconfig/network-scripts/ifcfg-eth0 [root@lj-template-100 network-scripts]# [root@lj-template-100 network-scripts]# cat ifcfg-eth0 TYPE=Ethernet BOOTPROTO=none NAME=eth0 DEVICE=eth0 ONBOOT=yes IPADDR=10.0.0.100 PREFIX=24 GATEWAY=10.0.0.254 DNS1=223.5.5.5 4.如果你不这么做，你后续克隆虚拟机，会导致无法上网，必须要删除网卡配置文件的uuid 还得编辑eth1内网网卡配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 [root@lj-template-100 network-scripts]# sed -r -e \u0026#39;s#eth0#eth1#g\u0026#39; -e \u0026#39;s#10.0.0.100#172.16.1.100#g\u0026#39; -e \u0026#39;s#10.0.0.254#172.16.1.254#g\u0026#39; ifcfg-eth0 \u0026gt;ifcfg-eth1 [root@lj-template-100 network-scripts]# cat ifcfg-eth1 TYPE=Ethernet BOOTPROTO=none NAME=eth1 DEVICE=eth1 ONBOOT=yes IPADDR=172.16.1.100 PREFIX=24 GATEWAY=172.16.1.254 DNS1=223.5.5.5 如果sed用的不熟，实在不行，vim去手动改也一样 最后重启网络服务，确保ip正常\n1 2 3 4 5 6 7 [root@lj-template-100 network-scripts]# systemctl restart network [root@lj-template-100 network-scripts]# ip addr show |grep -E \u0026#39;eth0|eth1\u0026#39; 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 inet 10.0.0.100/24 brd 10.0.0.255 scope global noprefixroute eth0 3: eth1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 inet 172.16.1.100/24 brd 172.16.1.255 scope global noprefixroute eth1 最后用你的windows、验证这两块网卡\n5.系统初始化优化 关闭NetworkManager【注意！】 NetworkManager 服务是一个用于管理和配置网络连接的后台守护进程。它的主要目的是简化网络配置，特别是在动态环境中（如笔记本电脑或移动设备），所以如果你的网络环境是WIFI，请不要关闭该服务\n1 2 [root@lj-template-100 ~]# systemctl stop NetworkManager [root@lj-template-100 ~]# systemctl disable NetworkManager 关闭防火墙、selinux 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [root@lj-template-100 ~]# systemctl stop firewalld [root@lj-template-100 ~]# systemctl disable firewalld [root@lj-template-100 ~]# sed -i \u0026#39;/^SELINUX=/c SELINUX=disabled\u0026#39; /etc/selinux/config [root@lj-template-100 ~]# grep -i \u0026#39;selinux=\u0026#39; /etc/selinux/config # SELINUX= can take one of these three values: SELINUX=disabled [root@lj-template-100 ~]# setenforce 0 [root@lj-template-100 ~]# getenforce Permissive [root@lj-template-100 ~]# iptables -F [root@lj-template-100 ~]# iptables -X [root@lj-template-100 ~]# iptables -Z 最后检查 [root@lj-template-100 ~]# iptables -L [root@lj-template-100 ~]# systemctl is-enabled firewalld NetworkManager disabled disabled 加速ssh连接 修改如下2个参数\n1 2 3 4 5 [root@lj-template-100 yum.repos.d]# grep -Ei \u0026#39;^(usedns|gssapiauth)\u0026#39; /etc/ssh/sshd_config GSSAPIAuthentication no UseDNS no [root@lj-template-100 yum.repos.d]# systemctl restart sshd.service 优化PS1变量 1 echo \u0026#39;export PS1=\u0026#34;[\\[\\e[34;1m\\]\\u@\\[\\e[0m\\]\\[\\e[32;1m\\]\\H\\[\\e[0m\\] \\[\\e[31;1m\\]\\w\\[\\e[0m\\]]\\\\$\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/profile yum源优化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 1.备份旧的默认repo [root@lj-template-100 ~]# cd /etc/yum.repos.d/ [root@lj-template-100 yum.repos.d]# mkdir bakrepo [root@lj-template-100 yum.repos.d]# mv *.repo bakrepo/ 2.下载新的repo curl https://mirrors.aliyun.com/repo/Centos-7.repo \u0026gt; /etc/yum.repos.d/centos-base.repo curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 或 wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 3.清楚旧的yum缓存 生成新的缓存 yum clean all \u0026amp;\u0026amp; yum makecache 安装基础软件 1 yum install -y tree wget bash-completion bash-completion-extras lrzsz net-tools sysstat iotop iftop htop unzip telnet ntpdate lsof vim 关闭邮件告警 1 2 3 你所有的操作，都会被linux内置的邮件服务器记录，不断的写入 /var/log下的日志文件，可能会占用多余的磁盘 [root@lj-template-100 ~]# echo \u0026#39;unset mailcheck\u0026#39; \u0026gt;\u0026gt; /etc/profile [root@lj-template-100 ~]# source /etc/profile 配置hosts解析 1 2 3 4 5 6 7 8 9 10 11 12 cat \u0026gt; /etc/hosts \u0026lt;\u0026lt;EOF # 外网地址 内网地址 主机名 10.0.0.61 172.16.1.61 master-61 10.0.0.5 172.16.1.5 slb-5 10.0.0.6 172.16.1.6 slb-6 10.0.0.7 172.16.1.7 web-7 10.0.0.8 172.16.1.8 web-8 10.0.0.9 172.16.1.9 web-9 10.0.0.31 172.16.1.31 nfs-31 10.0.0.41 172.16.1.41 rsync-41 10.0.0.51 172.16.1.51 db-51 EOF 时间同步 1 2 3 4 5 6 7 8 systemctl status crond crontab -e * * * * * /usr/sbin/ntpdate time1.aliyun.com \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 #检查 [root@template-linux01 ~]#crontab -l 关闭swap 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 取消swap的功能，不适用这个从磁盘获取而来的部分内存容量，因为效率太差，企业里的服务器内存都巨大 [root@lj-template-100 ~]# swapoff -a [root@lj-template-100 ~]# free -m total used free shared buff/cache available Mem: 1982 97 1409 9 475 1699 Swap: 0 0 0 [root@lj-template-100 ~]# vim /etc/fstab [root@lj-template-100 ~]# cat /etc/fstab # # /etc/fstab # Created by anaconda on Mon Apr 18 01:03:08 2022 # # Accessible filesystems, by reference, are maintained under \u0026#39;/dev/disk\u0026#39; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=16dbd4b1-60b3-4770-b20a-4d0b59b39e4a /boot xfs defaults 0 0 6.修改ip的脚本 至此，上述所有的初始化操作，已经针对模板机修改好了，然后克隆该机器，也自动有了所有的配置\n未读需要修改的就是ip地址、主机名，每一个机器都不一样，因此你可设置一个简单脚本。\nnetwork_init.sh\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/bin/bash read -p \u0026#34;请输入IP主机位：\u0026#34; my_ip read -p \u0026#34;请输入主机名：\u0026#34; host_name echo \u0026#39;正在修改网卡配置文件eth0\u0026#39; sed -i \u0026#34;/IPADDR/s#100#${my_ip}#g\u0026#34; /etc/sysconfig/network-scripts/ifcfg-eth0 echo \u0026#39;正在修改网卡配置文件eth1\u0026#39; sed -i \u0026#34;/IPADDR/s#100#${my_ip}#g\u0026#34; /etc/sysconfig/network-scripts/ifcfg-eth1 echo \u0026#39;网卡配置文件修改完毕\u0026#39; echo \u0026#39;正在修改主机名\u0026#39; hostnamectl set-hostname ${host_name} echo \u0026#34;==========================\u0026#34; echo \u0026#34;此时的eth0配置是：\u0026#34; `cat /etc/sysconfig/network-scripts/ifcfg-eth0` echo \u0026#34;==========================\u0026#34; echo \u0026#34;此时的eth1配置是：\u0026#34; `cat /etc/sysconfig/network-scripts/ifcfg-eth1` echo \u0026#34;当前的主机名是：\u0026#34; `hostname` echo \u0026#39;重启network服务中\u0026#39; systemctl restart network 7.拍摄快照 8.克隆新的虚拟机 新虚拟机，克隆完毕后\n检查一下初始化的配置是否正确 ip、主机名是否正确，按照规划的来 是否可以ssh 是否可以上网 全部做好首次的快照 循环操作，完成9台机器的创建\n","date":"2025-04-14T15:40:04+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux%E7%BB%BC%E5%90%88%E6%9E%B6%E6%9E%84/","title":"Linux综合架构"},{"content":"数据备份的重要性 数据备份方案 企业网站和应用都得有完全的数据备份方案确保数据不丢失，通常企业有如下的数据备份方案\n定时任务定期备份 需要周期性备份的数据可以分两类：\n后台程序代码、运维配置文件修改，一般会定时任务执行脚本进行文件备份，然后配置Rsync工具推送到远程服条器备份 对于数据库文件用定时任务脚本配合数据库提供的备份工具，定时生成备份文件，配合Rsync备份到远端 为什么要用实时同步服务 因为定时任务有缺陷，一分钟以内的数据无法进行同步，容易造成数据丢失\n实时复制方案 实施复制是最适合企业备份重要数据的方式，用于用户提交的数据备份，对于用户提交的普通文件(jpg、 tar、zip、MP4、txt,html)等待，都可以用Inofity+Rsync实时备份方案。 对于数据文件，还有更复杂的分布式存储方案，把数据同时备份成多份，如FastDFS、GlusterFS等 对于提交到数据库中的数据，还可以用数据库的主从复制(如MySQL),这是软件自带的实时备份。 图解备份方式 实时同步结合NFS 实时同步的难点 1.什么条件下开始同步 2.同步哪些文件夹 3.多长时间同一次? 4.用什么工具同步?\ninotify隆重出场 Inotify是一个强大的，细粒度的，异步的文件系统事件监控机制。 事件是指如文件的增删改查都是事件。\nLinux2.6.13开始就引入了inotify这个功能，用于监控文件系统的增删改查等事件。\n1 2 3 4 查看内核 uname -a 升级系统(包括内核) yum upgrade 第三方软件能实现监控文件内容变化，其实是因为linux提供了这个inotify机制功能。\nInofity-tools+Rsync实施复制实战 先准备rsyncd服务环境 部署拓扑图 Backup服务器（rsync服务端） 1 2 3 4 5 6 7 1.恢复了快照，重新安装rsync服务端 2.快速的部署rsyncd服务端 [root@rsync-41 ~]#vim instal_rsync.sh 3.执行脚本部署服务端的rsync [root@rsync-41 ~]#bash instal_rsync.sh dev服务器部署（rsync客户端） 1 [root@nfs-31 ~]#yum install rsync -y 准备部署inotify-tools软件（nfs-31机器） 内核检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 [root@nfs-31 ~]#uname -r 3.10.0-862.el7.x86_64 还有内核参数检查， 本质上是linux支持inotify机制 在性能还可以优化，支持更高的文件并发数 检测多少个文件 ，文件内容大量的发生变化，inotify机制能同时检测多少文件 这个参数的优化，就是调整linux的几个文件 [root@nfs-31 ~]#ls -l /proc/sys/fs/inotify/ total 0 -rw-r--r-- 1 root root 0 Apr 20 20:08 max_queued_events -rw-r--r-- 1 root root 0 Apr 20 20:08 max_user_instances -rw-r--r-- 1 root root 0 Apr 20 20:08 max_user_watches 系统文件解释 max_user_watches: 设置inotifywait或inotifywatch命令可以监视的文件数量（单进程） 默认只能监控8192个文件 max_user_instances: 设置每个用户可以运行的inotifywait或inotifywatch命令的进程数 默认每个用户可以开启inotify服务128个进程 max_queued_events: 设置inotify实例事件（event）队列可容纳的事件数量 默认监控事件队列长度为16384 inotify-tools 系统自带的比较low的工具 sersync 金山云的运维通过c++开发的工具 lsyncd三个工具 最新的，目前有人在用，适用于大规模服务器环境的工具 这些工具就3件事 1.优化，调整了这3文件的参数 2.检测某个目录 3.触发rsync命令 安装inotifty-tools工具 1 2 3 4 5 6 7 需要配置好epel源，才可以安装 [root@nfs-31 ~]# yum install inotify-tools -y 检查生成的软件命令 [root@nfs-31 ~]# rpm -ql inotify-tools |head -2 /usr/bin/inotifywait /usr/bin/inotifywatch 1 2 3 4 上述操作我们安装好了Inotify-tools软件，生成2个重要的命令 inotifywait：在被监控的目录等待特定文件系统事件（open、close、delete等事件），执行后处于阻塞状态，适合在Shell脚本中使用，是实现监控的关键 Inotifywatch：收集被监控的文件系统使用的统计数据（文件系统事件发生的次数统计） inotifywait实践 所有事件，任意的linux命令，只要对该目录的数据 对文件发生了修改动作，都会被检测到\n1 2 3 4 5 6 7 8 9 10 11 12 [root@nfs-31 ~]#mkdir /nfs-data [root@nfs-31 ~]#inotifywait -mrq --timefmt \u0026#39;%T\u0026#39; --format \u0026#34;%T----%w------%f 捕获到的事件是：%e\u0026#34; /nfs-data 12:27:56----/nfs-data/------ 捕获到的事件是：CLOSE_NOWRITE,CLOSE,ISDIR 12:27:56----/nfs-data/------ 捕获到的事件是：OPEN,ISDIR 12:27:56----/nfs-data/------ 捕获到的事件是：CLOSE_NOWRITE,CLOSE,ISDIR 参数解释： -m:即“-monitor”表示始终保持事件监听状态。 -r:即“-recursive”表示递归查询目录 -q:即“-quiet”表示打印出监控事件 -e:即“-event”,通过此参数可以指定要监控的 需要指定检测事件的名字 1 2 3 4 5 6 7 8 9 10 11 Events 含义 access 文件或目录被读取 modify 文件或目录内容被修改 attrib 文件或目录属性被改变 close 文件或目录封闭，无论读/写模式 open 文件或目录被打开 moved_to 文件或目录被移动至另外一个目录 move 文件或目录被移动到另一个目录或从另一个目录移动至当前目录 create 文件或目录被创建在当前目录 delete 文件或目录被删除 umount 文件系统被卸载 Create、delete 检测，创建，删除两个时间，只有你执行了对应的linux命令，才会生成日志\n1 2 3 4 5 6 7 8 -e events 事件名 [root@nfs-31 ~]#inotifywait -mrq --timefmt \u0026#39;%T\u0026#39; --format \u0026#34;%T----%w------%f 捕获到的事件是：%e\u0026#34; -e delete,create /nfs-data 12:29:46----/nfs-data/------hehe.log 捕获到的事件是：CREATE 12:30:24----/nfs-data/------aoligei.log 捕获到的事件是：CREATE 12:31:03----/nfs-data/------hehe.log 捕获到的事件是：DELETE move事件 1 2 3 4 5 6 7 8 9 10 11 [root@nfs-31 ~]# [root@nfs-31 ~]#inotifywait -mrq --timefmt \u0026#39;%T\u0026#39; --format \u0026#34;%T----%w------%f 捕获到的事件是：%e\u0026#34; -e move /nfs-data 12:31:48----/nfs-data/------xixi.log 捕获到的事件是：MOVED_FROM 12:31:48----/nfs-data/------xixi.png 捕获到的事件是：MOVED_TO 12:32:17----/nfs-data/------xixi.png 捕获到的事件是：MOVED_FROM 12:32:54----/nfs-data/------xixi.png 捕获到的事件是：MOVED_TO close_write事件 1 [root@nfs-31 ~]#inotifywait -mrq --timefmt \u0026#39;%T\u0026#39; --format \u0026#34;%T----%w------%f 捕获到的事件是：%e\u0026#34; -e close_write /nfs-data 总结inotify-wait命令 1 2 3 1.该命令，在大量文件生成的时候，需要检测，性能会骤然下降，以及会丢失数据，有部分的文件，会无法被检测到，也就是无法被后续的动作抓取到 适用于数据量不大的情况下，你用也没问题 基于sersync工具同步（了解） 检测文件事件的工具，条件\n某些文件不检测 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 1.下载安装 https://code.google.com/archive/p/sersync/ cd /opt \u0026amp;\u0026amp; wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz [root@nfs-31 /opt]#tar -zxvf sersync2.5.4_64bit_binary_stable_final.tar.gz 修改名字 [root@nfs-31 /opt]#mv GNU-Linux-x86/ sersync254 2.修改配置文件 找到需要检测的目录配置段，修改为你的机器环境即可 检测nfs-31 /nfs-data目录 修改如下部分配置 23 \u0026lt;sersync\u0026gt; 24 \u0026lt;localpath watch=\u0026#34;/nfs-data\u0026#34;\u0026gt; 25 \u0026lt;remote ip=\u0026#34;172.16.1.41\u0026#34; name=\u0026#34;backup\u0026#34;/\u0026gt; 26 \u0026lt;/localpath\u0026gt; 27 \u0026lt;rsync\u0026gt; 28 \u0026lt;commonParams params=\u0026#34;-az\u0026#34;/\u0026gt; 29 \u0026lt;auth start=\u0026#34;true\u0026#34; users=\u0026#34;rsync_backup\u0026#34; passwordfile=\u0026#34;/etc/rsync.pwd\u0026#34;/\u0026gt; 3.启动服务 [root@nfs-31 /nfs-data]#/opt/sersync254/sersync2 -r -d -o /opt/sersync254/confxml.xml 3.1 发现报错了，如何看日志，解决问题，咱们当前得问题是 1.没有密码文件 2.密码文件权限不对 [root@nfs-31 /nfs-data]#echo \u0026#34;bz666\u0026#34; \u0026gt; /etc/rsync.pwd [root@nfs-31 /nfs-data]#chmod 600 /etc/rsync.pwd 4.使用工具 必须先确认sersync帮你生成的rsync命令，能正确的执行 5.查看sersync是否帮你做了同步 你必须确保，rsync可以手动，sersync才能帮你同步！！！ 排查错误的经验所在 lsyncd工具（推荐使用） 注意，当你做了很多的实验，机器上，可能会同时运行很多个rsync数据同步程序，为了保证工具的准确性，注意只保留一个即可\n1 2 3 4 5 6 7 8 https://github.com/lsyncd/lsyncd Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。 我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。 另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。 lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。 实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 0.干掉sersync工具 1.下载安装 [root@nfs-31 /nfs-data]#yum install lsyncd -y 2.修改配置文件,（只检测一个目录） [root@nfs-31 /data]#cat /etc/lsyncd.conf settings { logfile =\u0026#34;/var/log/lsyncd/lsyncd.log\u0026#34;, statusFile =\u0026#34;/var/log/lsyncd/lsyncd.status\u0026#34;, inotifyMode = \u0026#34;CloseWrite\u0026#34;, maxProcesses = 8, } sync { default.rsync, source = \u0026#34;/nfs-data\u0026#34;, target = \u0026#34;rsync_backup@172.16.1.41::backup\u0026#34;, delete= true, exclude = {\u0026#34;.*\u0026#34;}, delay=1, rsync = { binary = \u0026#34;/usr/bin/rsync\u0026#34;, archive = true, compress = true, verbose = true, password_file=\u0026#34;/etc/rsync.pas\u0026#34;, _extra={\u0026#34;--bwlimit=200\u0026#34;} } } 3.启动服务 [root@nfs-31 /nfs-data]#systemctl start lsryncd [root@nfs-31 /nfs-data]# [root@nfs-31 /nfs-data]#systemctl start lsyncd [root@nfs-31 /nfs-data]# [root@nfs-31 /nfs-data]#systemctl status lsyncd 4.使用工具 [root@nfs-31 /nfs-data]#for i in {1..100};do echo ${i} \u0026gt; ${i}.log;sleep 0.1;done 实战小项目 三台机器（回快照）\nweb-7 （1.web-7的网页根目录数据来自于nfs共享目录/nfs-nginx-data/ ，要求该目录下的所有用户映射为www（uid=11111），允许读写） （整理为脚本）\n1 2 3 4 5 6 7 1.安装软件 yum install -y nginx yum install -y rsync yum install nfs-utils rpcbind -y 2.创建挂载点 mkdir -p /test-nfs [root@nfs-31 ~]#mount -t nfs 172.16.1.31:/nfs-nginx-data /test-nfs nfs-31 （2.在web-7的nginx网站根目录下创建首页文件后，触发实时同步，备份到rsync-41机器上） （整理为脚本）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 1.因为我现在啥软件也没有，所以现在先安装软件 [root@nfs-31 ~]#yum install -y nginx [root@nfs-31 ~]#yum install -y rsync [root@nfs-31 ~]yum install nfs-utils rpcbind -y 2.接下来要把nfs-31上的数据共享到web-7目录下 先创建共享目录 [root@nfs-31 ~]#mkdir /nfs-nginx-data 修改配置文件 cat \u0026gt; /etc/rsyncd.conf \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; uid = www gid = www port = 873 fake super = yes use chroot = no max connections = 200 timeout = 600 ignore errors read only = false list = false auth users = rsync_backup secrets file = /etc/rsync.passwd log file = /var/log/rsyncd.log ##################################### [backup] comment = this is first backup dir path = /backup [data] comment = this is second backup dir,to website data.. path = /data EOF 再创建用户 useradd -u 11111 -M -s /sbin/nologin www 修改权限 [root@nfs-31 ~]#chown -R www:www /data/ [root@nfs-31 ~]#chown -R www:www /backup/ [root@nfs-31 ~]#ll -d /data /backup/ drwxr-xr-x 2 www www 6 3月 11 22:39 /backup/ drwxr-xr-x 2 www www 6 3月 11 22:39 /data .创建密码文件，写入账户和密码，用于和客户端连接时候的认证 [root@nfs-31 ~]#vim /etc/rsync.passwd 2.写入账户密码 [root@nfs-31 ~]#cat /etc/rsync.passwd rsync_backup:szm666 3.这一步，非常重要，rsync要求降低密码文件的权限，且必须是600 [root@nfs-31 ~]#chmod 600 /etc/rsync.passwd [root@nfs-31 ~]#ll /etc/rsync.passwd -rw------- 1 root root 23 Apr 20 11:36 /etc/rsync.passwd [root@nfs-31 ~]#systemctl start rpcbind.service [root@nfs-31 ~]#systemctl start rpcbind.socket [root@nfs-31 ~]#systemctl start nfs nfs配置文件修改或，无需重启，使用重新加载，方式NFS端口号再次变化[root@nfs-31 ~]#systemctl reload nfs rsync-41 （3.数据备份服务器） （整理为脚本）\n1 [root@rsync-41 ~]#yum install rsync ","date":"2025-04-14T15:38:22+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/","title":"实时同步"},{"content":"nfs前言 用于Linux之间进行文件共享则是用NFS服务(Network FileSystem) 目的在于让不同的机器，不同的操作系统可以彼此分享各自的文件数据 NFS服务可以将远程Linux系统上的文件共享资源挂载到本地机器的目录上 NFS很像Windows系统的网络共享、安全功能、网络驱动器映射 一般情况下，中小型网站集群架构后端通常用 NFS数据共享，如果大型网络集群，还会用更复杂的文件系统，如GlusterFS、FastDFS等。 NFS系统已有30年发展历史，代表了一个稳定的网络文件系统，具备可扩展，高性能等特点。 由于网络速度的加快和延迟的减少，NFS系统一直是通过网络提供文件系统的不错的选择，特别是在中小型互联网企业用的广泛。 NFS在企业的应用架构 在企业集群架构的工作场景中，NFS网络文件系统一般被用来存储共享视频、图片、静态文件，通常网站用 户上传的文件也都会放在NFS共享里，例如BBS产品(论坛)产生的图片、附件、头像等，然后前端所有的节 点访问静态资源时都会读取NFS存储上的资源。 阿里云等公有云平台的NAS就是云版的NFS服务应用。 这个奔驰官网，需要展示大量的图片，动态图，html网页文件，这些都是存储在服务器上的。 企业生产集群为什么需要共享存储 先看一下如果没有共享存储的问题\nA用户上传图片到web01服务器，然后用户B访该图片，结果B的请求被负载均衡分发到了Web02,但是由于 没有配置共享存储，web02没有该图片，导致用户B看不到该资源，用户心理很不爽呀。\n那么如果配置了共享存储，无论A用户上传的图片是发给了web01还是其他，最终都会存储到共享存储上， 用户B再访问该图片的时候，无论请求被负载均衡发给了web01,web02、web03最终都会去共享存储上寻 找资源，这样也就能够访问到资源了。\n这个共享存储对于中小企业，也就是使用服务器配置NFS网络文件共享系统实现。\n任务：用NFS完成网站共享存储 什么是NFS共享存储 1 2 3 4 5 6 7 8 9 10 11 network file system 网络文件系统 NFS主要使用在局域网下，让不同的主机之间可以共享文件、或者目录数据 主要用于linux系统上实现文件共享的一种协议，其客户端主要是Linux 没有用户认证机制，且数据在网络上传送的时候是明文传送，一般只能在局域网中使用 不需要输入账号密码，在配置文件中，定义好可访问该NFS的机器，ip地址即可，如果需要进行安全认证， 还得借助其他用户认证的插件，结合NFS，提高安全性 支持多节点同时挂载及并发写入 NFS服务架构(NFS原理) NFS程序运行后，产生如下组件 RPC(Remote Procedure Call Protocol):远程过程调用协议，它是一种通过网络从远程计算机程序 上请求服务，不需要了解底层网络技术的协议。 rpcbind//负责NFS的数据传输，远程过程调用tcpludp协议端口11 nfs-utils //控制共享哪些文件，权限管理 什么是RPC RPC(Remote Procedure Call)远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需 要了解底层网络技术的协议。 下类个简单的例子来理解RPC： 1 2 3 4 5 6 7 远程过程调用，相对应的就是，本地过程调用。 rpc一般是开发中的网络编程知识 1.本地写好了一个代码文件，如hello-world.py ，本地运行该程序，这就是本地过程调用（执行程序，拿到结果） 2.远程过程调用 将代码文件放在远程服务器上，在自己笔记本上，远程调用、执行该代码文件，执行结果会通过网络把数据发回来，这就是远程过程调用 NFS和RPC关系 我们已知NFS是通过网络来进行数据传输(网络文件系统),因此NFS会使用 一些port来传输数据。 关键点： 但是NFS在传输数据的时，使用的端口是随机选择(可以重启NFS服务查看 端口)。 既然NFS是随机端口选择(好比银行的取钱窗口总发生变化，你知道几号窗口 是取钱业务吗?) 那么NFS在传输数据的时候，怎么知道NFS服务器使用的端口是哪个呢? 答案就是NFS使用的RPC(Remote Procedure Call,就是远程过程调用) 协议来实现的。 NFS结合rpcbind通信原理 1 2 3 4 5 6 7 8 1.NFS服务端启动后、将自己的端口信息，注册到rpcbind服务中 2.NFS客户端通过TCP/IP的方式，连接到NFS服务端提供的rpcbind服务，并且从该服务中获取具体的端口信息 3.NFS客户端拿到具体端口信息后，将自己需要执行的函数，通过网络发给NFS服务端对应的端口 4.NFS服务端接收到请求后，通过rpc.nfsd进程判断该客户端是否有权限连接 5.NFS服务端的rpc.mount进程判断客户端是否有对应的操作权限 6.最终NFS服务端会将客户端请求的函数，识别为本地可以执行的命令，传递给内核、最终内核驱动硬件 结论:nfs的客户端、服务端之间的通信基于rpc协议，且必须运行rpcbind服务 rpcbind服务 该服务是用于，nfs启动后，将端口号，注册到这个rpcbind服务中\n图解NFS工作原理 nfs工作流程图原理 NFS服务端部署 机器准备\n1 2 3 4 5 6 nfs服务端 nfs-31 多个nfs客户端 web-7 最终完成效果: 让web-7 可以读写 nfs共享的静态文件数据 安装nfs服务，需要安装如下软件包: ·nfs-utils:NFS服务的主程序，包括了rpc.nfsd、rpc.mountd这两个守护进 程以及相关文档，命令 ·rpcbind:是centos7/6环境下的RPC程序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 1.准备好nfs服务端机器 2.安装nfs工具包 [root@nfs-31 ~]#yum install nfs-utils rpcbind -y 3.修改配置文件，填写为你需要的共享参数即可 先学学该软件的配置文件语法，每一个软件的配置文件语法，可能都不相同 [root@nfs-31 ~]#cat /etc/exports 需要你填入如下配置，定义共享文件，以及限定访问的ip主机，以及共享的参数，权限设置 4. 设置一个共享 /nfs-data文件夹，运行172.16.1.0局域网内的用户可以访问，权限是只读 [root@nfs-31 ~]#mkdir /nfs-data [root@nfs-31 ~]#vim /etc/exports /nfs-data 172.16.1.0/24(ro) 5.注意要先启动rpcbind服务 确保如下2个进程都运行，rpc服务才正常，如果想停止rpc服务，也是关闭这俩进程 rpcbind.service rpcbind.socket [root@nfs-31 ~]#systemctl start rpcbind.service 一定要先启动rpc服务 [root@nfs-31 ~]#systemctl start rpcbind.socket [root@nfs-31 ~]#netstat -tunlp 6.运行nfs服务 ，每次重启nfs，nfs端口号，不断变化中 [root@nfs-31 ~]#systemctl start nfs 7.检查nfs共享的情况 [root@nfs-31 ~]#showmount -e 172.16.1.31 Export list for 172.16.1.31: /nfs-data 172.16.1.0/24 创建测试数据 [root@nfs-31 ~]#touch /nfs-data/123.txt 8.客户端可以去挂载使用了 9.修改服务端的nfs配置文件，允许读写操作 这里需要添加参数，让挂载后的客户端，身份改为匿名用户，降低权限，以及设置对应的读写权限 root_squash 这个参数，就是将客户端机器在nfs中创建的数据，用于改为nfsnobody [root@nfs-31 ~]#cat /etc/exports /nfs-data 172.16.1.0/24(rw,root_squash) 还需要修改该共享文件夹的权限 [root@nfs-31 ~]#chown -R nfsnobody:nfsnobody /nfs-data 10.nfs配置文件修改或，无需重启，使用重新加载，方式NFS端口号再次变化 方法1 [root@nfs-31 ~]#systemctl reload nfs 方法2，更新nfs的配置文件设置 [root@nfs-31 ~]#exportfs -r 配置文件默认语法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 默认配置文件路径是/etc/exports exports配置文件语法 NFS共享目录 NFS客户端地址(参数1、参数2...) 客户点地址2（参数1、参数2...） 例如 / hostname1(rw) hostname2(rw,no_root_squash) /pub *(rw) /home/chao 123.206.16.61(ro) 参数解释 1.NFS共享目录：为NFS服务器要共享的实际目录，必须绝对路径，注意目录的本地权限，如果要读写共享，要让本地目录可以被NFS客户端的(nfsnobody)读写 2.NFS客户端地址，也就是NFS服务器端授权可以访问共享目录的客户端地址，详见下表 3.权限参数，对授权的NFS客户端访问权限设置，见下表 nfs客户端地址说明 客户端地址 具体地址 说明 单一客户端 192.168.178.142 用的少 整个网段 192.168.178.0/24 24表示子网掩码255.255.255.0，指定网段，用的较多192.168.178.1~ 192.168.178.254 授权域名客户端 nfs.cn 弃用 授权整个域名客户端 *.cn 弃用 关于nfs挂载参数所有解释 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 ro 只读 rw 读写 root_squash 当nfs客户端以root访问时，它的权限映射为NFS服务端的匿名用户，它的用户ID/GID会变成nfsnobody no_root_squash 同上，但映射客户端的root为服务器的root，不安全，避免使用 all_squash 所有nfs客户端用户映射为匿名用户，生产常用参数，降低用户权限，增大安全性。 sync 数据同步写入到内存与硬盘，优点数据安全，缺点性能较差 async 数据写入到内存，再写入硬盘，效率高，但可能内存数据会丢 /etc/exports man 5 exports 共享目录 共享选项 /nfs/share *(ro,sync) 共享主机： * ：代表所有主机 192.168.0.0/24：代表共享给某个网段 192.168.0.0/24(rw) 192.168.1.0/24(ro) :代表共享给不同网段 192.168.0.254：共享给某个IP *.yuchaoit.cn:代表共享给某个域下的所有主机 共享选项： ro：只读，不常用 rw：读写 sync：实时同步，直接写入磁盘 async：异步，先缓存在内存再同步磁盘 anonuid：设置访问nfs服务的用户的uid，uid需要在/etc/passwd中存在 anongid：设置访问nfs服务的用户的gid root_squash ：默认选项 root用户创建的文件的属主和属组都变成nfsnobody,其他人nfs-server端是它自己，client端是nobody。 no_root_squash：root用户创建的文件属主和属组还是root，其他人server端是它自己uid，client端是nobody。 all_squash： 不管是root还是其他普通用户创建的文件的属主和属组都是nfsnobody 说明： 请用如下的参数，即可，生产环境用这个 anonuid和anongid参数和all_squash一起使用。 all_squash表示不管是root还是其他普通用户从客户端所创建的文件在服务器端的拥有者和所属组都是nfsnobody；服务端为了对文件做相应管理，可以设置anonuid和anongid进而指定文件的拥有者和所属组 NFS客户端部署 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 1.查看机器的挂载情况 mount -l 2. 查看磁盘分区挂载情况 df -h 3.挂载nfs，查看nfs [root@web-7 ~]#yum install nfs-utils -y [root@web-7 ~]#mount -t nfs 172.16.1.31:/nfs-data /test-nfs [root@web-7 ~]#df -h 4.尝试读写数据 [root@web-7 ~]#ls /test-nfs touch /test-nfs/hello.log # 发现没有权限 5.更新nfs服务端的读写权限后，再次测试数据操作 [root@web-7 ~]# [root@web-7 ~]#touch /test-nfs/456.txt [root@web-7 ~]# [root@web-7 ~]#ll /test-nfs/ total 0 -rw-r--r-- 1 nfsnobody nfsnobody 0 Apr 22 10:58 123.txt -rw-r--r-- 1 nfsnobody nfsnobody 0 Apr 22 11:12 456.txt [root@web-7 ~]#echo \u0026#34;今天又是氪金的一天\u0026#34; \u0026gt;\u0026gt; /test-nfs/123.txt [root@web-7 ~]#cat /test-nfs/123.txt 今天又是氪金的一天 [root@web-7 ~]#cat /test-nfs/123.txt 今天又是氪金的一天 冲他个十万吧 勇士 NFS结合nginx实现共享存储 安装部署nfs服务端\n生产环境下的参数rw,sync,all_squash,anonuid,anongid\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 rw,sync, all_squash ,将web-7的任意用户root,bob01,，在该共享目录下的操作，全部改为nfsnobody以实现权限控制 web-7 /test-nfs 172.16.1.31:/nfs-data 无论是root去读写 、/test-nfs 还是bob01读写 /test-nfs 创建的数据，都会被改为user，group都是 默认的nfsnobody anonuid=id号 anongid= 集合这俩参数，就可以限制在 该nfs共享目录下的所有用户操作，统一被限制为了某个指定的用户 需求说明 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 任务需求 1.nginx的启动用户必须是www，uid是 1500，不允许登录 [root@web-7 ~]#useradd www -u 1500 -M -s /sbin/nologin 1.0 安装nginx [root@web-7 ~]#yum install nginx -y 1.1 修改nginx配置文件，指定是www用户运行 [root@web-7 ~]#vim /etc/nginx/nginx.conf 修改如下 user www; 1.2 启动nginx [root@web-7 ~]#systemctl start nginx 1.3 检查nginx进程 [root@web-7 ~]#ps -ef|grep nginx root 5038 1 0 12:07 ? 00:00:00 nginx: master process /usr/sbin/nginx www 5040 5038 0 12:07 ? 00:00:00 nginx: worker process 2.nfs共享存储用户也是www，uid是 1500，不允许登录，允许读写 修改nfs配置文件如下，限定客户端在该目录中的操作，权限都被转化为www用户 限制nginx机器才能访问 [root@nfs-31 ~]#mkdir /nfs-nginx [root@nfs-31 ~]#useradd www -u 1500 -M -s /sbin/nologin 修改配置文件 [root@nfs-31 ~]#cat /etc/exports /nfs-data *(rw,all_squash) /nfs-nginx 172.16.1.7(rw,sync,all_squash,anonuid=1500,anongid=1500) 3.重新加载nfs（reload是针对已经有进程在运行了，重新读取配置文件） 你是新安装的机器nfs，还能reload吗？ [root@nfs-31 ~]#systemctl reload nfs 4.修改共享目录的属主、属组为www [root@nfs-31 /nfs-nginx]#chown -R www.www /nfs-nginx/ [root@nfs-31 /nfs-nginx]#ll -d /nfs-nginx/ drwxr-xr-x 2 www www 6 Apr 22 12:09 /nfs-nginx/ 3.nginx网站可以正常读写共享存储资料 先挂载nfs mount -t nfs 172.16.1.31:/nfs-nginx /usr/share/nginx/html/ [root@web-7 ~]#df -h |grep nginx 172.16.1.31:/nfs-nginx 17G 1.6G 16G 10% /usr/share/nginx/html 客户端生成网页，和图片等静态资源，查看是否写入到NFS服务端 [root@web-7 ~]#vim /usr/share/nginx/html/index.html 模拟用普通用户，到该nginx目录下，生成一个数据图片 [client01@web-7 /usr/share/nginx/html]$wget -O /usr/share/nginx/html/liyunlong.jpg https://inews.gtimg.com/newsapp_bt/0/8823765779/1000 4.修改nginx网页，加载该用户自己创建的图片信息吗 [client01@web-7 /usr/share/nginx/html]$cat index.html \u0026lt;meta charset=utf-8\u0026gt; 把我李云龙的意大利炮拿来 \u0026lt;img src=\u0026#39;./liyunlong.jpg\u0026#39;\u0026gt; 5.模拟用户访问该nginx网站 http://10.0.0.7/ NFS故障案例 1.客户端未挂载NFS\n1 2 3 4 5 6 7 [root@web-7 ~]# [root@web-7 ~]#umount /usr/share/nginx/html [root@web-7 ~]# 重新挂载 mount -t nfs 172.16.1.31:/nfs-nginx /usr/share/nginx/html/ 2.服务端出问题，。nfs挂了\n导致nginx页面卡死，nginx网页目录操作也都卡死\n此时明确了共享存储出问题了\n去共享存储NFS服务器上找原因\n1 2 发现nfs挂了，重启即可 systemctl restart nfs 3.nfs修复后，客户端的挂载可以恢复\n4.如果真的nfs死机了，且暂时无法恢复，你还得快速恢复网站的业务，可以强制取消挂载\n1 2 3 4 5 6 7 8 使用强制卸载参数 ，先看看挂载了什么 mount -l |grep nfs umount -fl 挂载点 # 取消挂载即可 然后最终还是要以恢复NFS为主 ","date":"2025-04-14T15:36:22+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/nfs%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"NFS学习笔记"},{"content":"第1章 Rsync介绍 备份是太常见、且太重要的一个日常工作了。\n备份源码、文档、数据库、等等。\n类似cp命令拷贝，但是支持服务器之间的网络拷贝，且保证安全性。\nRsync是一款开源的、快速的、多功能的、可实现全量及增量的本地或远程数据同步备份的优秀工具。并且 可以不进行改变原有数据的属性信息，实现数据的备份迁移特性。\nRsync软件适用于unix/linux/windows等多种操作系统平台。\nRsync是一个快速和非常通用的文件复制工具。它能本地复制，远程复制，或者远程守护进程方式复制。\n它提供了大量的参数来控制其行为的各个方面，并且允许非常灵活的方式来实现文件的传输复制。它以其 delta-transfer算法闻名。减少通过网络数据发送数量，利用只发送源文件和目标文件之间的差异信息，从而 实现数据的增量同步复制。\nRsync被广泛用于数据备份和镜像，并且作为一种改进后的复制命令用于日常运维。\nRsync具备使本地和远程两台主机之间的数据快速复制，远程备份的功能，Rsync命令本身即可实现异地主机 复制数据，功能类似scp又优于scp,scp每次都是全量备份，rsync可以实现增量拷贝(和scp一样都是基于 ssh服务传输),Rsync软件还支持配置守护进程，实现异机数据复制。\n增量复制是Rsync—特点，优于scp,cp命令。\nRsync实现如下功能\n本地数据同步复制，效果如cp 远程数据同步复制，如scp 本地数据删除，如rm 远程数据查看，如ls 1.rsync三种工作模式 本地模式，类似cp 远程模式，常用，类似scp,不同的机器之间，通过网络拷贝数据 后台服务模式，常用，用于实时数据同步，安全性更高 2.rsync的备份方式 全量备份\n就是完全备份，所有指定的客户端的数据，全部被备份到server01机器上(效率太低，重复性备份文件)\n增量备份\nrsync自动检测，只会将新增加的文件，备份到server01下，而不会重复备份已存在的数据，备份效率高\n3.rsync的备份架构 第2章 Rsync本地模式和远程模式 1.命令说明 单纯通过rsync的命令，来实现数据目录A 拷贝到数据目录B\n也就是模拟cp的用法 很简单\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 rsync [选项] 源数据 目的数据 1.安装 [root@rsync-41 ~]#yum install rsync -y 2.命令语法，分几个模式 - 本地模式 rsync 参数 源路径 目标路径 rsync -xxxxx /var/log /tmp - 远程模式，推送方式，把自己的数据推送到另一台机器上（上传） 语法1 ，rsync默认走ssh协议 rsync 参数 源路径 user@ip:目标路径 [root@rsync-41 ~]#rsync -avzP /var/log/ root@10.0.0.31:/tmp/ 语法2 rsync 参数 源路径 user@ip::目标路径 - 远程模式，拉取方式，拉取别人机器的数据到自己的机器上（下载） rsync 参数 user@ip:源路径 目标路径 rsync 参数 user@ip::源路径目标路径 [root@rsync-41 ~]#rsync -avzP root@10.0.0.31:/var/log/ /tmp/ 参数解释 -v 详细模式输出 -a 归档模式，递归的方式传输文件，并保持文件的属性，等同于 -rlptgoD -r 递归拷贝目录 -l 保留软链接 -p 保留原有权限 -t 保留原有时间（修改） -g 保留属组权限 -o 保留属主权限 -D 等于--devices --specials 表示支持b,c,s,p类型的文件 -R 保留相对路径 -H 保留硬链接 -A 保留ACL策略 -e 指定要执行的远程shell命令 -E 保留可执行权限 -X 保留扩展属性信息 a属性 比较常用的组合参数 rsync -avzP -a 保持文件原有属性 -v 显示传输细节情况 -z 对传输数据压缩传输 -P 显示文件传输的进度信息 2.本地模式 linux机器本身，数据来回发送\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 对文件同步 把本地的的/var/log/messages 文件 拷贝到/opt下 拷贝单个文件 [root@rsync-41 ~]#rsync -avzP /var/log/messages /opt sending incremental file list messages 985,500 100% 56.79MB/s 0:00:00 (xfr#1, to-chk=0/1) sent 123,300 bytes received 35 bytes 246,670.00 bytes/sec total size is 985,500 speedup is 7.99 拷贝单个大文件，拷贝大文件时，要注意限速，否则占用磁盘IO太多，以及如果是网络传输的话，占用网络带宽，会导致其他程序受影响所以rsync这样的备份服务，都是在夜里，凌晨操作，尽量不影响其他程序 先生成一个5G文件 [root@rsync-41 ~]#dd bs=100M count=50 if=/dev/zero of=/var/log/my_self.log [root@rsync-41 ~]#rsync -avzP /var/log/my_self.log /opt 查看磁盘的读写IO情况 [root@rsync-41 ~]#iotop `借助--bwlimit=xx（单位MB）限制单个大文件的传输，速度只给他20M每秒` [root@rsync-41 ~]#rsync -avzP --bwlimit=20 /var/log/my_self.log /opt sending incremental file list my_self.log 393,117,696 7% 20.14MB/s 0:03:55 扩展\ndd: 是一个用于复制和转换文件命令\nif=/dev/zero: 指定输入文件（input file）为 /dev/zero。/dev/zero 是一个特殊的设备文件，它只生成空字符（null bytes，即值为 0 的字节）。 of=ceshi.txt: 指定输出文件（output file）为 ceshi.txt。这意味着 dd 命令将把从 /dev/zero 读取的数据写入到 ceshi.txt 文件中 count=1: 表示只复制 1 个块（block）的数据。 bs=10M: 设置块大小（block size）为 10 兆字节（Megabytes） 这种操作通常用于快速生成一个指定大小的文件，尤其是当你需要一个大文件来进行某种测试或填充磁盘空间时。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 对目录同步（注意语法的区别） 拷贝后的数据，会携带该目录本身 [root@rsync-41 ~]#rsync -avzP /var/log /opt 不拷贝该目录本身，仅拷贝目录下的数据 [root@rsync-41 ~]#rsync -avzP /var/log/ /opt 测试文件夹的增量拷贝 [root@rsync-41 ~]#rsync -avzP /test1/ /test2 sending incremental file list sent 118 bytes received 12 bytes 260.00 bytes/sec total size is 0 speedup is 0.00 [root@rsync-41 ~]#echo \u0026#34;123\u0026#34; \u0026gt;/test1/1.png [root@rsync-41 ~]#rsync -avzP /test1/ /test2 sending incremental file list 1.png 4 100% 0.00kB/s 0:00:00 (xfr#1, to-chk=4/6) sent 175 bytes received 35 bytes 420.00 bytes/sec total size is 4 speedup is 0.02 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 无差异化拷贝 使用--delete参数 将目标目录的数据清空，保证完全和源目录的数据一致 [root@rsync-41 /test2]#rsync -azvP --delete /test1/ /test2/ sending incremental file list deleting 行者孙.png ./ 白龙马.png 0 100% 0.00kB/s 0:00:00 (xfr#1, to-chk=0/12) sent 269 bytes received 55 bytes 648.00 bytes/sec total size is 4 speedup is 0.01 [root@rsync-41 /test2]#ls /test1/ 1.png 2.png 3.png 4.png 5.png 孙悟空1 孙悟空2 孙悟空3 孙悟空4 孙悟空5 白龙马.png [root@rsync-41 /test2]#ls /test2 1.png 2.png 3.png 4.png 5.png 孙悟空1 孙悟空2 孙悟空3 孙悟空4 孙悟空5 白龙马.png 3.远程模式 1 2 把rsync-41 /root下的数据 拷贝到 nfs-31 /tmp下 1 2 3 4 5 6 7 8 9 PUSH 推送模式，上传模式 把rsync-41 /root下的数据，拷贝到 nfs-31 /tmp下 登录rsync41 用ip形式、再用主机名形式 添加无差异化参数，该参数，慎用！搞清楚了你在做什么！ [root@rsync-41 ~]#rsync -avzP --delete /root/ root@172.16.1.31:/tmp/ 1 2 3 4 5 6 PULL 拉取模式（你要琢磨，数据最终放在了哪） 把rsync-41 /root下的数据，拷贝到 nfs-31 /tmp下 [root@nfs-31 ~]#rsync -avzP root@172.16.1.41:/root/ /tmp/ 拉取rsync41的/etc/passwd文件到 nfs-31的/opt下，使用主机名通信 [root@nfs-31 ~]#rsync -avzP root@rsync-41:/etc/passwd /opt/ 1 2 3 4 5 传输整个目录,包含目录本身 [root@nfs-31 ~]#rsync -avzP root@172.16.1.41:/root /tmp/ 只传输目录下的文件,不包含目录本身 [root@nfs-31 ~]#rsync -avzP root@172.16.1.41:/root/ /tmp/ 1 2 3 4 不同主机之间同步数据 --delete [root@nfs-31 ~]#rsync -avzP --delete root@172.16.1.41:/root /tmp/ 注意:如果/和一个空目录进行完全同步,那么效果和删根目录一样 1 2 3 4 5 6 7 注意:传输过程不限速导致带宽被占满 ,--bwlimit=50 远程传输 nfs-31下的 /tmp/2G.log 备份到 rsync-41的/opt下 [root@nfs-31 ~]#dd bs=100M count=20 if=/dev/zero of=/tmp/2G.log [root@nfs-31 ~]#rsync -avzP /tmp/2G.log root@172.16.1.41:/opt 1 2 远程备份文件，且改名 [root@nfs-31 /tmp]#rsync -avzP /tmp/2G.log root@172.16.1.41:/opt/2G.logggggggggggggggggggggg 1 2 3 4 远程传输 nfs-31下的 /tmp/2G.log 备份到 rsync-41的/opt下，且是无差异化备份 等于清空原有/opt下的数据 [root@nfs-31 ~]#rsync -avzP --delete /tmp/2G.log root@172.16.1.41:/opt/2G.log 第3章 Rsync服务模式-服务端配置 0.为什么需要服务模式 ​\tRsync 借助 SSH 协议同步数据存在的缺陷: ​\t1.使用系统用户（不安全） /etc/passwd ​\t2.使用普通用户（会导致权限不足情况） ​\t3.守护进程传输方式: rsync 自身非常重要的功能(不使用系统用户，更加安全)\n1.安装rsync 1 [root@rsync-41 ~]#yum install rsync -y 2.修改配置文件 复制粘贴如下代码即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [root@rsync-41 ~]#cat \u0026gt; /etc/rsyncd.conf \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; uid = www gid = www port = 873 fake super = yes use chroot = no max connections = 200 timeout = 600 ignore errors read only = false list = false auth users = rsync_backup secrets file = /etc/rsync.passwd log file = /var/log/rsyncd.log ##################################### [backup] comment = this is first backup dir path = /backup [data] comment = this is second backup dir,to website data.. path = /data EOF 配置信息说明：\n3.创建用户以及数据目录 1 2 3 4 5 6 7 8 9 10 11 12 13 根据你的配置文件中定义的信息，创建对应的用户，备份的目录 该无法登录的用户，只是用于运行进程的账户 [root@rsync-41 ~]#useradd -u 1000 -M -s /sbin/nologin www 创建配置文件中定义的2个备份目录 [root@rsync-41 ~]#mkdir -p /data/ /backup/ 修改备份目录的权限 [root@rsync-41 ~]#chown -R www:www /data/ [root@rsync-41 ~]#chown -R www:www /backup/ [root@rsync-41 ~]#ll -d /data /backup/ drwxr-xr-x 2 www www 6 Apr 20 11:34 /backup/ drwxr-xr-x 2 www www 6 Apr 20 11:34 /data 4.创建rsync专用的账户密码（这一步很重要，有错基本也是来这排查） 1 2 3 4 5 6 7 8 9 10 11 1.创建密码文件，写入账户和密码，用于和客户端连接时候的认证 [root@rsync-41 ~]#vim /etc/rsync.passwd 2.写入账户密码 [root@rsync-41 ~]#cat /etc/rsync.passwd rsync_backup:lj666 3.这一步，非常重要，rsync要求降低密码文件的权限，且必须是600 [root@rsync-41 ~]#chmod 600 /etc/rsync.passwd [root@rsync-41 ~]#ll /etc/rsync.passwd -rw------- 1 root root 23 Apr 20 11:36 /etc/rsync.passwd 5.加入开机自启动 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 设置rsyncd服务，运行，且开机自启 [root@rsync-41 ~]#systemctl start rsyncd 检查rsyncd服务是否运行，以及该服务的运行日志 [root@rsync-41 ~]#systemctl status rsyncd ● rsyncd.service - fast remote file copy program daemon Loaded: loaded (/usr/lib/systemd/system/rsyncd.service; disabled; vendor preset: disabled) Active: active (running) since Wed 2022-04-20 11:46:57 CST; 4s ago Main PID: 6078 (rsync) CGroup: /system.slice/rsyncd.service └─6078 /usr/bin/rsync --daemon --no-detach Apr 20 11:46:57 rsync-41 systemd[1]: Started fast remote file copy program daemon. Apr 20 11:46:57 rsync-41 systemd[1]: Starting fast remote file copy program daemon... Apr 20 11:46:57 rsync-41 rsyncd[6078]: params.c:Parameter() - Ignoring badly formed line in config file: ignore errors Apr 20 11:46:57 rsync-41 rsyncd[6078]: rsyncd version 3.1.2 starting, listening on port 873 6.检查服务是否运行 1 2 3 4 5 6 7 8 9 10 11 12 [root@rsync-41 ~]#systemctl status rsyncd # 无论是学习期间还是上班了，都养成好习惯 # 给别人启动了某程序后，给自己启动某程序 务必去检查，验证是否正确 [root@rsync-41 ~]#ps -ef|grep \u0026#39;rsync\u0026#39; | grep -v \u0026#39;grep\u0026#39; root 6078 1 0 11:46 ? 00:00:00 /usr/bin/rsync --daemon --no-detach [root@rsync-41 ~]#netstat -tunlp|grep rsync tcp 0 0 0.0.0.0:873 0.0.0.0:* LISTEN 6078/rsync tcp6 0 0 :::873 :::* LISTEN 6078/rsync 第4章 Rsync服务模式-客户端配置 安装rsync\n1 [root@nfs-31 ~]#yum install rsync -y 第5章 操作服务端rsync-41的数据 推送，备份，发送nfs-31的数据发给rsync-41 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 把客户端的数据，发送给服务端的backup备份模块下 把客户端的 /tmp/200M.log 备份，发送到rsync-41机器上的 backup模块下 rsync -avzP /tmp/200M.log 账户@主机名::模块名 默认无密码变量，也无密码文件，需要你自己输入该rsync_backup虚拟用户的密码 需要交互式的输入密码，无法再脚本中使用rsync同步命令 rsync基本都是和脚本结合使用 [root@nfs-31 ~]#rsync -avzP /tmp/200M.log rsync_backup@rsync-41::backup 非交互式密码的操作，如下2个方法 1. 生成密码文件，每次连接都指定这个密码文件（在客户端生成） [root@nfs-31 ~]#echo \u0026#39;lj666\u0026#39; \u0026gt; /etc/my_rsync.pwd 还必须降低密码文件的权限才行，必须是600 [root@nfs-31 ~]#chmod 600 /etc/my_rsync.pwd 此时可以传输数据了，往data模块下传输 [root@nfs-31 ~]#rsync -avzP --password-file=/etc/my_rsync.pwd /tmp/200M.log rsync_backup@rsync-41::data 如果是脚本中的话，去掉vP显示过程的参数去掉 [root@nfs-31 ~]#rsync -az --password-file=/etc/my_rsync.pwd /tmp/200M.log rsync_backup@rsync-41::data 2. 生成密码变量，让当前系统中存在叫做 RSYNC_PASSWORD 这个变量，以及变量的值，是配置文件中的密码即可 [root@nfs-31 ~]#export RSYNC_PASSWORD=\u0026#39;lj666\u0026#39; [root@nfs-31 ~]#rsync -avzP /tmp/200M.log rsync_backup@rsync-41::backup 上传过程中文件改名 [root@nfs-31 ~]#rsync -avzP /tmp/200M.log rsync_backup@rsync-41::backup/11111.log 下载备份服务器的数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 rsync -avzP 账户@主机名::模块名 下载的目标路径 如果需要输入密码，则可以撤销这个密码变量 [root@nfs-31 ~]#unset RSYNC_PASSWORD 或者重新登录，只要密码变量失效，就必须得输入密码了，或者使用密码文件 [root@nfs-31 ~]#rsync -avzP rsync_backup@rsync-41::backup /tmp/ 非交互式的密码认证方式 1，使用密码变量 [root@nfs-31 ~]#export RSYNC_PASSWORD=\u0026#39;lj666\u0026#39; 2.指定密码文件 [root@nfs-31 ~]#rsync -avzP --password-file=/etc/my_rsync.pwd rsync_backup@rsync-41::backup /tmp/ 下载过程中文件改名 [root@nfs-31 ~]#rsync -avzP --password-file=/etc/my_rsync.pwd rsync_backup@rsync-41::backup/222222222.log /tmp/ 第6章 关于rsync的常见错误 rsync由于配置步骤比较细节，比较坑比较多，你可能会遇见各种错误\nRsync服务端排错思路 1.检查rsync服务端的配置文件路径是否正确：/etc/rsyncd.conf 2.查看配置文件的host allow ,host deny允许的ip网段是否允许客户端访问 3.查看配置文件中的path参数路径是否存在，权限是否正确(和配置文件的UUID参数对应) 4.查看rsync服务是否启动，端口、进程是否存活 5.查看iptables防火墙、selinux是否允许rsync服务通过，或是关闭 6.查看服务端rsync配置文件的密码文件，权限是否600,格式，语法是否正确，且和配置文件的secrect files参数对应 7.如果是推送数据，要查看配置rsyncd.conf中的用户对该rsync模块下的文件是否可以读取\nRsync客户端排错 1.查看rsync客户端配置的密码文件权限是否600,密码文件格式是否正确，是否和服务端的密码一致 2.尝试telnet连接rsync服务端的873端口，检测服务是否可以连接 3.客户端执行命令语法要检查，细心\n","date":"2025-04-14T15:26:03+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/rsync%E6%9C%8D%E5%8A%A1/","title":"Rsync服务"},{"content":"文件共享服务 文件共享服务方案有很多，了解即可\nftp（简单文件传输服务）\n提供用户认证机制 可以输入账号密码 python -m SimpleHTTPServer\n1 2 平时，简易的快速进行文件下载，下载服务器上的资料 python -m SimpleHTTPServer nginx也提供了文件下载的功能\n提供用户认证机制 反向代理，负载均衡 web服务器，静态文件服务器的作用 如ftp服务器的作用 samba(linux和windows之间共享数据)\n提供用户认证机制 nfs（实际工作中主要用这个）\n搭建ftp服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 1.需要安装vsftpd服务 yum install vsftpd -y 2.修改ftp配置文件，设置账号密码，登录ftp服务器，可以查看某文件夹下的数据资料（共享文件夹） 3.创建一个linux的用户（ftp使用linux的用户信息，不靠谱） useradd ops01 设置该用户密码 [root@nfs-31 ~]#echo \u0026#39;123456\u0026#39; | passwd --stdin ops01 Changing password for user ops01. passwd: all authentication tokens updated successfully. 4.修改ftp配置文件，设置用于共享的目录 [root@nfs-31 ~]#rpm -ql vsftpd |grep \u0026#39;.conf$\u0026#39; /etc/vsftpd/vsftpd.conf 4.1 关闭所有的匿名用户功能，不安全 找出和匿名用户相关的配置参数 [root@nfs-31 ~]#grep \u0026#39;^anonymous\u0026#39; /etc/vsftpd/vsftpd.conf anonymous_enable=NO 4.2添加自定义的共享文件夹配置参数，笔记的解释，别写入linux中，写笔记上，否则可能会导致编码不识别，程序出错 直接在文件最低下，添加如下配置 # 配置解释 # local_root=/data/kefu 指定本地用户的默认数据根目录 # chroot_local_user=YES 禁锢本地用户的默认数据目录（禁止用户切换到其他目录） # allow_writeable_chroot=YES 允许ftp用户登录后，可以创建数据 你只需要修改如下三个参数即可 # ftp用户，ops01登录ftp之后，只能看到/test_0224这个文件夹下的数据 ## by myself local_root=/test_0224/ chroot_local_user=YES allow_writeable_chroot=YES 5.创建用于共享的文件夹 mkdir /test_0224/ touch /test_0224/wenjie.png 别忘记修改文件夹的权限，否则无法读取了，修改为刚才自定义的用户 chown -R ops01:ops01 /test_0224/ [root@nfs-31 ~]#ll -d /test_0224/ drwxr-xr-x 2 ops01 ops01 24 Apr 19 14:53 /test_0224/ 6.此时可以重启vsftpd服务 [root@nfs-31 ~]#systemctl restart vsftpd [root@nfs-31 ~]#ps -ef|grep vsftpd root 2221 1 0 15:01 ? 00:00:00 /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf root 2226 1168 0 15:02 pts/0 00:00:00 grep --color=auto vsftpd 使用客户端，验证ftp的登录，数据查看 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 你可以用另一台机器，安装ftp程序，登录vsftpd服务端 yum install ftp -y 登录ftp设备的命令 ftp 机器的ip地址 如 ftp 172.16.1.31 输入账号密码 ops01 123456 进入之后，输入? 查看ftp提供的命令帮助 ftp\u0026gt; pwd 查看当前的ftp目录位置 257 \u0026#34;/\u0026#34; ftp提供的上传下载 下载功能 ftp\u0026gt; get (remote-file) 文杰.png (local-file) 文杰1.png local: 文杰1.png remote: 文杰.png 227 Entering Passive Mode (10,0,0,31,149,223). 150 Opening BINARY mode data connection for 文杰.png (0 bytes). 226 Transfer complete. ftp\u0026gt; 上传功能 ftp\u0026gt; ftp\u0026gt; put (local-file) /opt/4111111.jpg (remote-file) 4444444.jpg local: /opt/4111111.jpg remote: 4444444.jpg 227 Entering Passive Mode (10,0,0,31,185,67). 150 Ok to send data. 226 Transfer complete. windows的ftp客户端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 windows访问ftp 命令行操作 C:\\Users\\lj\u0026gt;ftp ftp\u0026gt; bye C:\\Users\\lj\u0026gt;ftp 10.0.0.31 连接到 10.0.0.31。 220 (vsFTPd 3.0.2) 200 Always in UTF8 mode. 用户(10.0.0.31:(none)): ops01 331 Please specify the password. 密码: 230 Login successful. ftp\u0026gt; ls 200 PORT command successful. Consider using PASV. 150 Here comes the directory listing. 41.png 4444444.jpg 佳强.png 文杰.png 226 Directory send OK. ftp: 收到 48 字节，用时 0.00秒 48000.00千字节/秒。 ftp\u0026gt; 图形化连接ftp设备: 指定协议语法 ftp://10.0.0.31/ ","date":"2025-04-14T15:25:11+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/ftp%E6%9C%8D%E5%8A%A1/","title":"FTP服务"},{"content":"Linux-磁盘管理 1. 磁盘管理工具 (1)硬盘概念结构 机械硬盘：依赖于磁盘上的磁性材料记录数据，内部构造包括磁盘盘片、磁头和主轴电机等。在读写数据时，磁头通过高速旋转的盘片记录或读取磁性信息。由于机械部件的存在，HDD在工作时会产生噪音‌。\n固态硬盘：基于闪存技术（通常是NAND闪存）存储数据，没有任何机械结构。数据通过电子传输直接读写，因此读取速度比HDD快得多，且更为安静‌。\n​\n💡硬盘接口类型：IDE、SATA、SCSI、FC\n磁盘接口类型 说明 IDE（Integrated Device Electronics:电子集成驱动器） 最初硬盘的通用标准，任何电子集成驱动器都属于IDE，甚至包括SCSI； SATA（Serial-ATA：串行ATA） SATA的出现将ATA和IDE区分开来，而IDE则属于Parallel-ATA(并行ATA)。所以，一般来说，IDE称为并口，SATA称为串口。 SCSI（Small Computer System Interface：小型计算机系统专用接口） SCSI硬盘就是采用这种接口的硬盘。SAS(Serial Attached SCSI)就是串口的SCSI接口。一般服务器硬盘采用这两类接口，其性能比上述两种硬盘要高，稳定性更强，支持热插拔，但是价格高，容量小，噪音大。 FC（FibreChannel） 使光纤通道能够直接作为硬盘连接接口，为高吞度吐量性能密集型系统的设计者开辟了一条提高I/O性能水平的途径。 (2)使用 fdisk 分区工具 查看分区表\n1 fdisk -l /dev/sda 硬盘分区\n主分区：也称为主磁盘分区，主分区中不能再划分其他类型的分区，因此每个主分区都相当于一个逻辑磁盘。\n逻辑分区：扩展分区与逻辑分区是为了突破分区表中只能保存4个分区的限制而出现的，扩展分区不能直接使用，需要在扩展分区内划分一个或多个逻辑分区后才能使用。\n扩展分区：在扩展分区上面，可以创建多个逻辑分区，硬逻辑分区是盘上一块连续的区域，它是扩展分区的组成部分。 1 2 3 4 # 通常所说的“硬盘分区”就是指修改磁盘分区表，注意以下情况： 1 考虑到磁盘的连续性，一般建议将扩展分区放在最后面的柱面内。 2 一个硬盘只有一个扩展分区，除去主分区，其它空间都分配给扩展分区。 3 硬盘容量=主分区+扩展分区；扩展分区容量=各个逻辑分区容量之和 修改硬盘的分区表\n1 2 3 4 5 6 7 8 9 10 11 [root@localhost ~]# fdisk /dev/sdb n 创建新的分区-----\u0026gt;分区类型 回车-----\u0026gt;分区编号 回车----\u0026gt;起始扇区 回车-----\u0026gt;在last结束时 +2G p 查看分区表 n 创建新的分区-----\u0026gt;分区类型 回车-----\u0026gt;分区编号 回车----\u0026gt;起始扇区 回车-----\u0026gt;在last结束时 +1G w 保存并退出 [root@localhost ~]# lsblk [root@localhost ~]# ls /dev/sdb[1-2] 常用交互指令：\nm 列出指令帮助\np 查看现有的分区表\nn 新建分区\nd 删除分区\nq 放弃更改并退出\nw 保存更改并退出\n(3)格式化分区 常用的格式化工具 mkfs 工具集\nmkfs.ext3 分区设备路径\nmkfs. ext4 分区设备路径\nmkfs.xfs 分区设备路径\nmkfs.vfat 分区设备路径\n格式化：赋予空间文件系统类型过程\n文件系统：空间存储数据的规则\nWindows常见文件系统：NTFS、FAT、FAT32\nLinux常见文件系统: ext4(RHEL6)、XFS(RHEL7)\n1 2 3 4 5 [root@localhost ~]# mkfs.ext4 /dev/sdb1 [root@localhost ~]# blkid /dev/sdb1 #查看文件系统类型 [root@localhost ~]# mkfs.xfs /dev/sdb2 [root@localhost ~]# blkid /dev/sdb2 #查看文件系统类型 挂载使用 1 2 3 4 5 6 7 [root@localhost ~]# mkdir /mypart1 [root@localhost ~]# mount /dev/sdb1 /mypart1 [root@localhost ~]# df -h #查看当前系统正在挂载设备 [root@localhost ~]# mkdir /mypart2 [root@localhost ~]# mount /dev/sdb2 /mypart2 [root@localhost ~]# df -h #查看当前系统正在挂载设备 开机自动挂载 /etc/fstab 格式：设备路径 挂载点 类型 参数 备份标记 检测顺序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@localhost ~]# blkid /dev/sdb1 #查看文件系统类型 [root@localhost ~]# blkid /dev/sdb2 #查看文件系统类型 [root@localhost ~]# vim /etc/fstab /dev/sdb1 /mypart1 ext4 defaults 0 0 /dev/sdb2 /mypart2 xfs defaults 0 0 [root@localhost ~]# umount /mypart1 [root@localhost ~]# umount /mypart2 [root@localhost ~]# df -h | grep sdb [root@localhost ~]# mount -a 检测/etc/fstab开机自动挂载配置文件,格式是否正确 检测/etc/fstab中,书写完成,但当前没有挂载的设备,进行挂载 [root@localhost ~]# df -h | grep sdb /etc/fstab书写错误：\n输入root的密码（输入的内容不显示）\n继续编辑/etc/fstab内容进行修复 vim /etc/fstab\n(4)综合分区 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@localhost ~]# fdisk /dev/sdb p 查看分区表 n 创建主分区-----\u0026gt;回车-----\u0026gt;回车----\u0026gt;回车-----\u0026gt;在last结束时 +2G p 查看分区表 n 创建扩展分区 -----\u0026gt;回车----\u0026gt;起始回车-----\u0026gt;结束回车 将所有空间给扩展分区 p 查看分区表 n 创建逻辑分区-----\u0026gt;起始回车------\u0026gt;结束+2G n 创建逻辑分区-----\u0026gt;起始回车------\u0026gt;结束+2G n 创建逻辑分区-----\u0026gt;起始回车------\u0026gt;结束+2G p 查看分区表 w 保存并退出 [root@localhost ~]# partprobe #刷新分区表 Warning: 无法以读写方式打开 /dev/sr0 (只读文件系统)。/dev/sr0 已按照只读方式打开。 [root@localhost ~]# lsblk 总结：\n1.识别硬盘 lsblk\n2.分区规划 fdisk 分区模式MBR\n3.刷新分区表 partprobe\n4.格式化 mkfs.ext4 mkfs.xfs blkid\n5.挂载使用 mount /etc/fstab mount -a df -h\n(5) GPT分区模式 添加全新的硬盘，为GPT分区模式准备 关闭虚拟机\n1 [root@localhost ~]# poweroff 添加一块5硬盘\n查看系统识别的硬盘\n1 [root@localhost ~]# lsblk GPT分区模式，分区进阶 全局唯一标识分区表\n突破固定大小64字节的分区表限制\n最多可支持128个主分区，最大支持18EB容量\n1 EB = 1024 PB = 1024 x 1024 TB\nparted常用分区指令（专门划分GPT分区模式）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 [root@localhost ~]# parted /dev/sdc (parted) mktable gpt #指定分区模式为GPT (parted) mkpart #划分新的分区 分区名称？ []? Haha #分区的名字，随意起名 文件系统类型？ [ext2]? ext4 #文件系统类型，随意写 起始点？ 0 #起始点 结束点？ 4G #结束点 忽略/Ignore/放弃/Cancel? Ignore #忽略分区表占用的空间 (parted) print (parted) unit GB #采用GB作为单位 (parted) print (parted) mkpart 分区名称？ []? haha 文件系统类型？ [ext2]? ext4 起始点？ 4G 结束点？ 100% #全部空间 (parted) print (parted) quit 2. 交换空间（虚拟内存） 利用硬盘的空间，充当真正内存\n作用：当物理内存不够时候，暂时将物理内存中的数据，放到交换空间中，缓解真实物理内存的不足\nCPU\u0026mdash;\u0026ndash;\u0026gt;内存\u0026mdash;\u0026mdash;\u0026gt;硬盘\n(1）方式一 利用未使用的分区空间制作交换空间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ]# ls /dev/sdc1 ]# mkswap /dev/sdc1 #格式化交换文件系统 ]# blkid /dev/sdc1 #查看文件系统 ]# swapon /dev/sdc1 #启用交换分区 ]# swapon #查看组成交换空间的成员信息 ]# free -m #查看交换空间总共的大小 ]# swapoff /dev/sdc1 #停用交换分区 ]# swapon #查看组成交换空间的成员信息 ]# free -m #查看交换空间总共的大小 ]# vim /etc/fstab #开机自动启用交换分区 /dev/sdc1 swap swap defaults 0 0 ]# swapon ]# swapon -a #专门用于检测交换分区 ]# swapon (2）方式二 利用一个文件，进行制作交换空间 生成一个2G的文件\ndd if=源设备 of=目标设备 bs=块大小 count=次数\n1 2 3 ]# ls /dev/zero #永远产生数据 ]# dd if=/dev/zero of=/opt/swap.txt bs=1M count=2048 ]# du -sh /opt/swap.txt #查看占用磁盘空间大小 利用文件占用空间，充当交换空间\n1 2 3 4 ]# mkswap /opt/swap.txt #格式化交换文件系统 ]# swapon /opt/swap.txt #启用交换文件 swapon: /opt/swap.txt：不安全的权限 0644，建议使用 0600。 ]# swapon #查看交接空间组成的成员信息 3. 逻辑卷管理 (1）什么是 LVM？ 💡逻辑卷管理（Logical Volume Management, LVM）是一种灵活的磁盘管理机制，允许动态调整磁盘空间。\n优点:\n动态调整分区大小。 支持在线扩展和缩减。 支持快照功能，便于备份和恢复。 (2）LVM 核心概念 物理卷 (Physical Volume, PV): 物理硬盘或分区。 卷组 (Volume Group, VG): 由一个或多个物理卷组成的存储池。 逻辑卷 (Logical Volume, LV): 从卷组中划分出的虚拟分区，可格式化和挂载使用。 ​\n（3）主要命令语法 1 2 3 4 5 6 # 语法格式 pvcreate 设备名1 [设备名2 … …] #创建物理卷 vgcreate 卷组名 物理卷名1 物理卷名2 #创建卷组 lvcreate -L 容量大小 -n 逻辑卷名 卷组名 #创建逻辑卷 lvextend -L +大小 /dev/卷组名/逻辑卷名 #扩展逻辑卷 lvreduce -L -大小 /dev/卷组名/逻辑卷名 #缩减逻辑卷 （4）配置案例 创建和管理物理卷 1 2 3 4 5 6 [root@centos ~]#fdisk /dev/sdb 进行分区 注意：分区类型一定要改成8e（lvm类型） [root@centos ~]#pvcreate /dev/sdb1 /dev/sdb2 把1和2创建成物理卷 [root@centos ~]#pvscan 扫描物理卷 [root@centos ~]#pvdisplay 显示物理卷（查看物理卷） [root@centos ~]# pvremove /dev/sdb2 删除物理卷 创建和管理卷组 1 2 3 4 5 6 [root@centos ~]# vgscan ---扫描卷组 [root@centos ~]# vgcreate hb2022 /dev/sdb1 /dev/sdb2 /dev/sdc1 ----创建卷组名称为hb2022 把物理卷sdb1、sdb2、sdc1加入到组内 [root@centos ~]# vgdisplay hb2022 ---查看卷组名字为hb2022的卷组的详细信息 [root@centos ~]# vgextend hb2022 /dev/sdc2 ---扩展卷组大小，把物理卷sdc2加入到卷组 [root@centos ~]# vgreduce hb2022 /dev/sdc2 ----缩小卷组大小，把物理卷sdc2减掉 [root@centos ~]# vgremove hb2022 ----移除卷组 创建和管理逻辑卷 1 2 3 4 5 6 [root@centos ~]# lvscan ----扫描逻辑卷 [root@centos ~]# lvcreate -L 20G -n benet hb2022 ---创建逻辑卷空间为20G，名称为benet，所占用的卷组为hb2022 [root@centos ~]# lvdisplay hb2022—查看逻辑卷详细信息 [root@centos ~]# lvextend -L +9G /dev/hb2022/benet ---扩展逻辑卷的大小，增加9G [root@centos ~]# lvreduce -L -9G /dev/hb2022/benet ---扩展逻辑卷的大小，减少9G（需要y的确认） [root@centos ~]# lvremove /dev/hb2022/benet ------删除逻辑卷 逻辑卷格式化 1 [root@centos ~]# mkfs -t xfs /dev/hb2022/benet ---把逻辑卷benet格式为xfs 挂载逻辑卷 1 2 3 [root@centos ~]# mkdir benet ---在宿主目录创建一个benet目录（作为挂载点） [root@centos ~]# mount /dev/hb2022/benet /root/benet ----挂载benet逻辑卷到宿主目录下benet目录（挂载点） [root@centos ~]# df -Th ---查看挂载情况 永久挂载逻辑卷 1 2 3 4 [root@centos ~]# vi /etc/fstab ---修改永久挂载 /dev/hb2022/benet /root/benet xfs defaults 0 0 或者 /dev/mapper/hb2022-benet /root/benet xfs defaults 0 0 ‍\n","date":"2025-04-14T15:03:08+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux-%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/","title":"Linux 磁盘管理"},{"content":"Linux-网络配置与防火墙 一、Linux网络配置 （1）配置永久主机名 1 2 3 4 5 6 7 8 9 10 11 [root@localhost ~]# echo svr7.tedu.cn \u0026gt; /etc/hostname [root@localhost ~]# cat /etc/hostname svr7.tedu.cn [root@localhost ~]# hostname svr7.tedu.cn #修改当前 [root@localhost ~]# hostname svr7.tedu.cn 开启一个新的终端查看提示符的变化\n（2）查看网络接口信息 1 [root@centos ~]# ifconfig ​\n（3）配置网卡IP地址、子网掩码、网关地址 设置网卡相关参数\n1 2 3 4 5 6 7 8 9 10 11 ]# vi /etc/sysconfig/network-scripts/ifcfg-ens33 #不同版本操作系统网卡命名规则不同，可到/etc/sysconfig/network-scripts/目录下查看网卡具体名称 TYPE=Ethernet ----设置网卡类型，Ethernet表示以太网。 BOOTPROTO=static ----网络接口配置方式。Static为静态，dhcp为动态获取。 DEVICE=ens33 ----设置网络接口名称 ONBOOT=yes ----系统启动时是否激活 IPADDR=192.168.4.11 ----ip地址 NETMASK=255.255.255.0 ----子网掩码 GATEWAY=192.168.4.1 ----网关 DNS1=8.8.8.8 ----NDS地址 DNS2=114.114.114.114 ----NDS地址 重启网络服务，令配置命令生效 1 2 [root@svr7 ~]# systemctgl restart network [root@svr7 ~]# ipconfig #查看结果 （4）配置DNS服务器地址 DNS服务器：负责域名解析的机器，将域名解析为IP地址\n1 2 3 4 5 [root@svr7 ~]# echo nameserver 8.8.8.8 \u0026gt; /etc/resolv.conf [root@svr7 ~]# cat /etc/resolv.conf nameserver 8.8.8.8 （5）设置路由route 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #添加到指定网段的路由记录 语法：route add -net 网段地址 gw IP地址 例子：[root@centos ~]# route add -net 192.168.10.0/24 gw 192.168.4.1 #删除到指定网段的路由记录 语法：route del -net 网段地址 例子：[root@centos ~]# route del -net 192.168.10.0/24 #删除路由表中的默认网关记录 语法：route del default gw IP地址 例子：[root@centos ~]# route del default gw 192.168.137.2 #向路由表中添加默认网关记录 语法：route add default gw IP地址 例子：[root@centos ~]# route add default gw 192.168.137.2 （6）常用网络测试工具 测试网络连接 ping\n1 2 3 4 ping命令 测试网络连通性 [root@centos ~]# ping www.baidu.com 按Ctrl+C中止测试 跟踪数据包 traceroute\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 测试从当前主机到目的主机之间经过的网络节点 traceroute 目标主机地址 无法响应的主机会显示* [root@centos ~]# traceroute www.baidu.com 通过最多 30 个跃点跟踪 到 www.baidu.com [110.242.68.3] 的路由: 1 23 ms 27 ms 19 ms bogon [192.168.20.1] 2 12 ms 7 ms 10 ms dns1.online.tj.cn [111.162.92.1] 3 * * * 请求超时。 4 * * * 请求超时。 5 * * * 请求超时。 6 * 15 ms * 110.242.66.178 7 34 ms 32 ms 22 ms 221.194.45.134 8 * * * 请求超时。 9 * * * 请求超时。 10 * * * 请求超时。 11 18 ms 189 ms 297 ms 110.242.68.3 跟踪完成。 域名解析 nslookup\n1 2 3 测试DNS域名解析 nslookup 目标主机地址 [DNS服务器地址] [root@centos ~]# nslookup www.baidu.com 二、物理机与虚拟机的通信 （1）VMware网络连接常用的三种方式 桥接模式：将虚拟机直接连接到物理网络，虚拟机会获得与主机相同的网络中的独立 IP 地址，就像一台独立的物理设备。 1 2 3 4 5 6 7 8 #特点 * 虚拟机与主机处于同一局域网。 * 虚拟机可以访问外部网络（如互联网），也可以被同一局域网中的其他设备访问。 * 虚拟机的 IP 地址由局域网中的 DHCP 服务器分配，或手动配置。 #使用场景 * 需要虚拟机作为独立设备运行，并与局域网中的其他设备通信。 * 需要虚拟机对外提供服务（如 Web 服务器、数据库服务器）。 NAT模式：通过主机的网络连接共享外部网络访问权限。虚拟机通过主机的 IP 地址与外部网络通信。 1 2 3 4 5 6 7 8 #特点 * 虚拟机可以访问外部网络（如互联网），但外部网络无法直接访问虚拟机。 * 虚拟机的 IP 地址由 VMware 虚拟网络中的 DHCP 服务器分配。 * 主机充当虚拟机的网关。 #使用场景 * 需要虚拟机访问外部网络，但不希望虚拟机暴露在局域网中。 * 适合个人开发、测试环境。 仅主机模式：将虚拟机与主机连接到一个私有网络中，虚拟机只能与主机通信，无法访问外部网络。 1 2 3 4 5 6 7 8 #特点 * 虚拟机与主机之间可以互相通信。 * 虚拟机无法访问外部网络（如互联网）。 * 虚拟机的 IP 地址由 VMware 虚拟网络中的 DHCP 服务器分配。 #使用场景 * 需要虚拟机与主机之间进行隔离通信。 * 适合测试和开发环境，尤其是需要隔离外部网络的场景。 特性 桥接模式 NAT 模式 仅主机模式 网络访问 可以访问外部网络 可以访问外部网络 无法访问外部网络 外部访问虚拟机 可以 不可以 不可以 IP 地址来源 局域网 DHCP 或手动配置 VMware 虚拟网络 DHCP VMware 虚拟网络 DHCP 虚拟机与主机通信 可以 可以 可以 适用场景 虚拟机作为独立设备运行 虚拟机访问外部网络 虚拟机与主机隔离通信 （2）查看物理机虚拟网卡 💡物理机网络连接中可以看到用于与虚拟机连接的虚拟网卡，其中vmnet1虚拟网卡用于仅主机模式，vmnet8用于NAT模式，vmnet0没有显示出来，用于桥接模式的连接。\n​\n1 2 3 虚拟机需要与外网通信，可以使用桥接模式，NAT模式这两种网络连接方式 桥接模式需要设置局域网同段地址，会引起地址冲突问题，设置IP地址前需要通过ping命令测试改地址是否有人使用 为避免冲突，建议使用NAT模式设置网络连接（创建虚拟机网卡时选择该模式或在虚拟机设置——网络适配器中选择该模式） （3）查看VMnet8的网络信息 NAT模式网段信息\n1 ‍VMware虚拟机依次点击菜单栏编辑——虚拟网络编辑器——VMnet8，可以看到当前默认的网段信息，如需更改网段，在下方子网IP处进行修改。 NAT模式网关的查看\n1 2 点击NAT设置按钮，可以看到该网段默认的网关地址 注意：查看到网段及网关信息，在虚拟机网卡设置中未使用DHCP自动获取方式，通过手工静态方式设置，那么就要使用该网段及网关进行设置 ​\n（4）测试通信 ping命令测试网络联通性\n1 2 ping -c 3 192.168.91.2 #测试与网关之间的联通 ping -c 3 www.baidu.com #测试与外网之间的联通，前提需要配置好DNS地址 （5）课堂练习 1 2 3 1、创建一台CentOS主机，要求能够访问外网，可以分别尝试桥接、NAT这两种不同的模式来实现 2、创建两台CentOS主机，不仅要求能够访问外网，彼此之间要求能够相互访问 三、远程管理(Linux与Linux) 软件包的安装\n1 2 3 4 5 6 7 [root@svr7 /]# rpm -qa | grep openssh openssh-7.4p1-16.el7.x86_64 openssh-server-7.4p1-16.el7.x86_64 openssh-clients-7.4p1-16.el7.x86_64 远程登录工具 ssh\n虚拟机A：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [root@svr7 /]# \u0026gt; /etc/resolv.conf [root@svr7 /]# ssh root@192.168.4.207 ………necting (yes/no)? yes root@192.168.4.207\u0026#39;s password: #输入密码 [root@pc207 ~]# touch /root/hahaxixi.txt [root@pc207 ~]# exit 登出 Connection to 192.168.4.207 closed. [root@svr7 /]# cat /root/.ssh/known_hosts #记录曾经远程管理的机器 实现ssh远程管理无密码验证\n虚拟机A：\n1.生成公钥(锁)与私钥(钥匙)进行验证\n1 2 3 4 5 6 7 8 9 10 11 [root@svr7 ~]# ssh-keygen #一路回车 …….save the key (/root/.ssh/id_rsa): #保存位置 ……..assphrase): #设置密码为空 …….. again: #设置密码为空 [root@svr7 ~]# ls /root/.ssh/ id_rsa(私钥) id_rsa.pub(公钥) known_hosts 2.将公钥(锁)传递给虚拟机B\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [root@svr7 ~]# ssh-copy-id root@192.168.4.207 [root@svr7 ~]# ssh root@192.168.4.207 #测试无密码 [root@pc207 ~]# exit 登出 Connection to 192.168.4.207 closed. [root@svr7 ~]# 虚拟机B [root@pc207 ~]# ls /root/.ssh/ authorized_keys(别的机器传递过来的公钥) known_hosts [root@pc207 ~]# 安全复制工具 scp=ssh+cp\n– scp [-r] 用户名@服务器:路径 本地路径\n– scp [-r] 本地路径 用户名@服务器:路径\n虚拟机A：\n1 2 3 4 5 ]# scp /etc/passwd root@192.168.4.207:/root ]# scp -r /home root@192.168.4.207:/root/ ]# scp root@192.168.4.207:/etc/passwd /mnt/ 虚拟机B：\n1 ]# ls /root 四、Linux防火墙 （1）防火墙 作用：隔离，严格过滤入站，放行出站\n硬件防火墙：保护一个网络中所有机器\n软件防火墙：保护本机\n1 2 3 4 5 6 7 8 9 10 11 • 管理工具：firewall-cmd(命令)、firewall-config(图形工具) • 根据所在的网络场所区分，预设保护规则集 • public：仅允许访问本机的ssh、dhcp、ping服务 • trusted：允许任何访问 • block：拒绝任何来访请求，有明确的回应 • drop：丢弃任何来访的数据包，没有明确的回应 （2） 防火墙判定的规则： 1.查看请求中源IP地址，查看自己所有区域，哪个区域有该源IP地址规则，则进入哪个区域 2.进入默认区域（默认情况下为public） （3）修改默认区域 虚拟机A：\n1 2 3 [root@svr7 ~]# rpm -q firewalld #防火墙软件 firewalld-0.4.4.4-14.el7.noarch 虚拟机A：\n1 ]# firewall-cmd --get-default-zone #查看默认区域 虚拟机B\n1 2 3 [root@pc207 /]# ping -c 2 192.168.4.7 #成功 [root@pc207 /]# curl http://192.168.4.7 #失败 虚拟机A：\n1 ]# firewall-cmd --set-default-zone=trusted #修改默认区域 虚拟机B\n1 2 3 [root@pc207 /]# ping -c 2 192.168.4.7 #成功 [root@pc207 /]# curl http://192.168.4.7 #成功 （4）区域中添加允许的协议 虚拟机A：\n1 2 3 4 5 6 7 8 9 ]# firewall-cmd --set-default-zone=public #修改默认区域 ]# firewall-cmd --get-default-zone #查看默认区域 ]# firewall-cmd --zone=public --list-all #查看区域规则 ]# firewall-cmd --zone=public --add-service=http #添加协议 ]# firewall-cmd --zone=public --list-all #查看区域规则 虚拟机B\n1 2 3 4 5 [root@pc207 /]# curl http://192.168.4.7 #访问成功 hahaxixihehelele哈哈嘻嘻 [root@pc207 /]# （5）永久规则 永久（\u0026ndash;permanent）\n默认区域的修改，默认就是永久的\n1 2 3 4 5 6 7 8 9 10 11 12 13 ]# firewall-cmd --reload #重新加载防火墙永久的配置 ]# firewall-cmd --zone=public --list-all #查看区域规则 ]# firewall-cmd --permanent --zone=public --add-service=http #永久规则 ]# firewall-cmd --zone=public --list-all #查看区域规则 ]# firewall-cmd --reload #重新加载防火墙永久的配置 ]# firewall-cmd --zone=public --list-all #查看区域规则 （6）单独拒绝192.168.4.207所有访问，允许其他机器 防火墙判定的规则: 1.查看请求中源IP地址，查看自己所有区域，哪个区域有该源IP地址规则，则进入哪个区域\n2.进入默认区域（默认情况下为public）\n虚拟机A\n.添加源IP地址规则\n1 2 3 4 5 ]# firewall-cmd --zone=block --add-source=192.168.4.207 ]# firewall-cmd --get-default-zone #查看默认区域 public 虚拟机B\n1 ]# curl http://192.168.4.7 #访问失败 ‍\n","date":"2025-04-14T14:32:32+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E4%B8%8E%E9%98%B2%E7%81%AB%E5%A2%99/","title":"Linux 网络配置与防火墙"},{"content":"Linux-文件系统与权限管理 一、文件系统 1、文件系统概述 💡文件系统是操作系统用于明确存储设备或分区上的文件的方法和数据结构；即在存储设备上组织文件的方法。操作系统中负责管理和存储文件信息的软件机构称为文件管理系统，简称文件系统。\n2、文件系统类型及使用场景 常见文件类型 使用场景 FAT windows9X系统使用的文件系统，包括FAT16，FAT32 NTFS NTFS文件系统是一个基于安全性的文件系统，是Windows NT所采用的独特的文件系统结构，Win 2000采用了更新版本的NTFS文件系统NTFS 5.0 NFS 网络文件系统，用于在UNIX系统间通过网络进行文件共享 RAW RAW文件系统是一种磁盘未经处理或者未经格式化产生的文件系统 Ext GNU/Linux系统中标准的文件系统，其特点为存取文件的性能极好，对于中小型的文件更显示出优势，包括Ext2，Ext3，Ext4 XFS 一种高性能的日志文件系统，最早于1993年，由Silicon Graphics为他们的IRIX操作系统而开发，之后被移植到Linux内核上，特别擅长处理大文件，同时提供平滑的数据传输。 ISO 9600 该文件系统中光盘所使用的标准文件系统，Linux对该文件系统也有很好的支持，不仅能读取光盘和光盘ISO映像文件，而且还支持在Linux环境中刻录光 3、系统交换分区 💡Linux系统交换空间（swap）就是磁盘上的一块区域，可以是一个分区，也可以是一个文件，简单的说就是当物理内存资源紧张时，将内存中不常访问的资源保存到预先设定的硬盘上的交换空间，来释放该资源占用的内存，这样系统就有更多的物理内存为各个进程服务，而当系统需要访问swap上存储的内容时，再将swap上的数据加载到内存中。\nRAM大小 推荐的交换空间 ≤ 2GB 2X RAM 2GB – 8GB = RAM \u0026gt;8GB 8GB 二、权限管理 基本权限 – 读取：允许查看内容-read 利用r表示\n– 写入：允许修改内容-write 利用w表示\n– 可执行：允许运行和切换-excute 利用x表示\n对于文本文件 读取权限(r)：cat、head、tail、less、grep\n写入权限(w)：vi（保存退出）、\u0026gt;、\u0026gt;\u0026gt;\n可执行权限(x)：Shell脚本、Python脚本\n归属关系 – 所有者：拥有此文件/目录的用户-user 利用u表示\n– 所属组：拥有此文件/目录的组-group 利用g表示\n– 其他用户：除所有者、所属组以外的用户-other 利用o表示\n执行 ls -l或ls -ld命令查看文件/目录权限 以-开头：表示文本文件\n以d开头：表示目录\n以l开头:快捷方式或者链接文件\n1 2 3 4 5 6 [root@A ~]# ls -l /etc/shadow [root@A ~]# ls -l /etc/passwd [root@A ~]# ls -ld /etc/ [root@A ~]# ls -ld /root [root@A ~]# ls -ld /home/zhangsan [root@A ~]# ls -ld /tmp #默认具备附加权限的目录 修改权限 chmod命令 – 格式：chmod [ugoa] [+-=] [rwx] 文件\u0026hellip;\n常用命令选项 – -R：递归修改权限\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 [root@A /]# mkdir /nsd01 [root@A /]# ls -ld /nsd01 [root@A /]# chmod u-w /nsd01 #修改所有者权限 [root@A /]# ls -ld /nsd01 [root@A /]# chmod u+w /nsd01 #修改所有者权限 [root@A /]# ls -ld /nsd01 [root@A /]# chmod g=rwx /nsd01 #修改所属组权限 [root@A /]# ls -ld /nsd01 [root@A /]# chmod u=rwx,g=rx,o=--- /nsd01 [root@A /]# ls -ld /nsd01 [root@A /]# chmod a=rwx /nsd01 #赋予所有人rwx权限 [root@A /]# ls -ld /nsd01 [root@A /]# mkdir -p /opt/aaa/bbb/ccc [root@A /]# ls -R /opt/aaa [root@A /]# chmod -R o=--- /opt/aaa #递归设置权限 [root@A /]# ls -ld /opt/aaa [root@A /]# ls -ld /opt/aaa/bbb/ [root@A /]# ls -ld /opt/aaa/bbb/ccc/ Linux 判断用户具备的权限 1.首先判断，用户对于该数据，处于的身份(角色)\n2.查看数据，相应身份的权限位置，权限内容\n• 用户对于目录具备权限\n读取权限(r)：可以查看目录内容\n写入权限(w)：可以新建、删除、改名,目录的内容，对目录本身没有修改权限\n可执行权限(x)：可以进入切换到该目录下(一位用户能否切换到一个目录只和x执行权限有关)\n案例1：设置基本权限 1）以root身份新建/nsddir1/目录，在此目录下新建readme.txt文件 1 2 3 4 5 [root@localhost ~]# mkdir /nsddir1 [root@localhost ~]# echo 123456 \u0026gt; /nsddir1/readme.txt [root@localhost ~]# cat /nsddir1/readme.txt 2）使用户zhangsan能够修改readme.txt文件内容 1 [root@localhost ~]# chmod o+w /nsddir1/readme.txt 3）使用户zhangsan不可以修改readme.txt文件内容 1 [root@localhost ~]# chmod o-w /nsddir1/readme.txt 4）使用户zhangsan能够在此目录下创建/删除子目录 1 2 3 [root@localhost ~]# chmod o+w /nsddir1/ [root@localhost ~]# ls -ld /nsddir1/ 5）调整此目录的权限，使任何用户都不能进入，然后测试用户zhangsan是否还能修改readme.txt（测试结果不能，对父目录没有权限） 1 [root@localhost ~]# chmod a-x /nsddir1/ 6）为此目录及其下所有文档设置权限 rwxr-x\u0026mdash; 1 [root@localhost ~]# chmod -R u=rwx,g=rx,o=--- /nsddir1/ 权限位的8进制数表示 r、w、x分别对应4、2、1，后3组分别求和\n分组 User权限 Group权限 Other权限 字符 r w x r - x r - x 数字 4 2 1 4 0 1 4 0 1 求和 7 5 5 1 2 3 4 5 6 7 8 9 10 [root@A /]# mkdir /nsd03 [root@A /]# ls -ld /nsd03 [root@A /]# chmod 700 /nsd03 [root@A /]# ls -ld /nsd03 [root@A /]# chmod 007 /nsd03 [root@A /]# ls -ld /nsd03 [root@A /]# chmod 750 /nsd03 [root@A /]# ls -ld /nsd03 新建文件/目录的默认权限 – 一般文件默认均不给 x 执行权限\n– 其他取决于 ​umask​​ 设置\n– 目录默认的权限为755，文件的默认权限为644\n1 2 3 4 5 6 7 8 9 [root@A /]# umask 0022 [root@A /]# umask 077 #修改umask值 [root@A /]# umask 0077 [root@A /]# mkdir /nsd05 [root@A /]# ls -ld /nsd05 drwx------. 2 root root 6 9月 8 14:17 /nsd05 [root@A /]# umask 022 修改归属关系 chown命令 – chown 属主 文件\u0026hellip;\n– chown 属主:属组 文件\u0026hellip;\n– chown :属组 文件\u0026hellip;\n常用命令选项 – -R：递归修改归属关系\n1 2 3 4 5 6 7 8 9 10 11 [root@A /]# mkdir /nsd07 [root@A /]# ls -ld /nsd07 [root@A /]# groupadd tmooc #创建tmooc组 [root@A /]# chown zhangsan:tmooc /nsd07 [root@A /]# ls -ld /nsd07 [root@A /]# chown lisi /nsd07 #单独修改所有者 [root@A /]# ls -ld /nsd07 [root@A /]# chown :root /nsd07 #单独修改所属组 [root@A /]# ls -ld /nsd07 Linux 判断用户具备的权限 匹配即停止原则 1.用户对于该数据处于的身份(角色) 所有者 \u0026gt; 所属组 \u0026gt;其他人\n2.查看数据，相应身份的权限位置，权限内容\n案例2：归属关系练习 1）利用root的身份新建/tarena目录，并进一步完成下列操作 1 [root@localhost ~]# mkdir /tarena 2）将/tarena属主设为gelin01，属组设为tmooc组 1 2 3 4 5 [root@localhost ~]# useradd gelin01 [root@localhost ~]# groupadd tmooc [root@localhost ~]# chown gelin01:tmooc /tarena 3）使用户gelin01对此目录具有rwx权限，除去所有者与所属组之外的用户对此目录无任何权限 1 [root@localhost ~]# chmod o=--- /tarena 4）使用户gelin02能进入、查看此目录 1 2 3 [root@localhost ~]# useradd gelin02 [root@localhost ~]# gpasswd -a gelin02 tmooc 5）将gelin01加入tmooc组，将tarena目录的权限设为450，测试gelin01用户能否进入此目录 1 2 3 [root@localhost ~]# gpasswd -a gelin01 tmooc [root@localhost ~]# chmod 450 /tarena 案例3： 实现lisi用户可以读取/etc/shadow文件内容，您有几种办法？ 利用其他人 1 [root@A /]# chmod o+r /etc/shadow 利用所属组 1 2 3 [root@A /]# chown :lisi /etc/shadow [root@A /]# chmod g+r /etc/shadow 利用所有者 1 2 3 [root@A /]# chown lisi /etc/shadow [root@A /]# chmod u+r /etc/shadow 利用ACL策略 1 [root@A /]# setfacl -m u:lisi:r /etc/shadow 附加权限（特殊权限） 粘滞位，Sticky Bit 权限 – 占用其他人（Other）的 x 位\n– 显示为 t 或 T，取决于其他人是否有 x 权限\n– 适用于目录，用来限制用户滥用写入权\n– 在设置了粘滞位的文件夹下，即使用户有写入权限，也不能删除或改名其他用户文档\n1 2 3 4 5 6 [root@A /]# mkdir /home/public [root@A /]# chmod 777 /home/public [root@A /]# ls -ld /home/public [root@A /]# chmod o+t /home/public [root@A /]# ls -ld /home/public SGID 权限 – 占用属组（Group）的 x 位\n– 显示为 s 或 S，取决于属组是否有 x 权限\n– 对目录有效\n– 在一个具有SGID权限的目录下，新建 的文档会自动继承此目录的属组身份\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@A /]# mkdir /nsd10 [root@A /]# ls -ld /nsd10 [root@A /]# chown :tmooc /nsd10 [root@A /]# ls -ld /nsd10 [root@A /]# mkdir /nsd10/abc01 [root@A /]# ls -ld /nsd10/abc01 [root@A /]# chmod g+s /nsd10 #赋予SetGID权限 [root@A /]# ls -ld /nsd10 [root@A /]# mkdir /nsd10/abc02 [root@A /]# ls -ld /nsd10/abc02 [root@A /]# touch /nsd10/1.txt [root@A /]# ls -l /nsd10/1.txt ACL策略管理（ACL权限） acl 访问策略 – \u0026lt;u\u0026gt;​能够对个别用户、个别组设置独立的权限**​ \u0026lt;/u\u0026gt;\n– 大多数挂载的EXT3/4、XFS文件系统默认已支持\n• setfacl命令\n– 格式：setfacl [选项] u:用户名:权限 文件\u0026hellip;\nsetfacl [选项] g:组名:权限 文件\u0026hellip;\n• 常用命令选项\n– -m：定义一条ACL策略\n– -x：清除指定的ACL策略\n– -b：清除所有已设置的ACL策略\n– -R：递归设置ACL策略\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@A /]# mkdir /nsd11 [root@A /]# chmod 770 /nsd11 [root@A /]# ls -ld /nsd11 [root@A /]# su - lisi [lisi@A ~]$ cd /nsd11 -bash: cd: /nsd11: 权限不够 [lisi@A ~]$ exit [root@A /]# setfacl -m u:lisi:rx /nsd11 #设置ACL策略 [root@A /]# getfacl /nsd11 #查看ACL策略 [root@A /]# su - lisi [lisi@A ~]$ cd /nsd11 [lisi@A nsd11]$ pwd [lisi@A nsd11]$ exit [root@A /]# 将某个用户拉黑（制作黑名单） 1 2 3 [root@A /]# ls -ld /home/public/ drwxrwxrwt. 2 root root 41 9月 8 15:53 /home/public/ [root@A /]# setfacl -m u:lisi:--- /home/public setfacl 命令练习 1 2 3 4 5 6 7 8 9 10 11 [root@A /]# mkdir /nsd12 [root@A /]# setfacl -m u:dc:rwx /nsd12 [root@A /]# setfacl -m u:zhangsan:rx /nsd12 [root@A /]# setfacl -m u:lisi:rwx /nsd12 [root@A /]# setfacl -m u:tom:rwx /nsd12 [root@A /]# getfacl /nsd12 #查看ACL策略 [root@A /]# setfacl -x u:zhangsan /nsd12 #删除指定ACL [root@A /]# getfacl /nsd12 [root@A /]# setfacl -b /nsd12 #清除所有ACL策略 [root@A /]# getfacl /nsd12 -R : 递归设置 ACL 策略 1 2 3 4 5 6 7 8 9 10 [root@A /]# ls -R /opt/aaa /opt/aaa: bbb /opt/aaa/bbb: ccc /opt/aaa/bbb/ccc: [root@A /]# setfacl -Rm u:lisi:rx /opt/aaa [root@A /]# getfacl /opt/aaa [root@A /]# getfacl /opt/aaa/bbb [root@A /]# getfacl /opt/aaa/bbb/ccc 课后习题 案例1：chmod权限设置 1）以root用户新建/nsddir/目录，在该目录下新建文件readme.txt\n1 2 [root@Localhost ~]# mkdir /nsddir/ [root@Localhost ~]# touch /nsddir/readme.txt 2）使用户zhangsan能够在/nsddir/目录下创建/删除子目录\n1 2 3 4 5 6 [root@Localhost ~]# useradd zhangsan [root@Localhost ~]# chmod o+w /nsddir/ [root@localhost ~]# su -zhangsan [zhangsan@localhost ~]$ mkdir /nsddir/zhangsan [zhangsan@localhost ~]$ ls /nsddir [zhangsan@localhost ~]$ exit 3）使用户zhangsan能够修改/nsddir/readme.txt文件的容\n1 2 3 4 [root@Localhost ~]# chmod o+w /nsddir/readme.txt [zhangsan@localhost ~]$ echo xixi \u0026gt;\u0026gt; /nsddir/readme.txt [zhangsan@localhost ~]$ cat /nsddir/readme.txt [zhangsan@localhost ~]$ exit 案例2：chown归属设置 1）新建/tarena1目录\na）将属主设为gelin01，属组设为tarena组 1 2 3 4 [root@Localhost ~]# mkdir /tarena1 [root@Localhost ~]# useradd gelin01 [root@Localhost ~]# groupadd tarena [root@Localhost ~]# chown gelin01:tarena /tarena1 b）使用户gelin01对此目录具有rwx权限，其他人对此目录无任何权限 1 2 3 [root@Localhost ~]# ls -ld /tarena1 [root@Localhost ~]# chmod o=--- /tarena1 [root@Localhost ~]# ls -ld /tarena1 2）使用户gelin02能进入、查看/tarena1文件夹（提示：将gelin02加入所属组）\n1 2 3 4 5 6 7 [root@Localhost ~]# useradd gelin02 [root@Localhost ~]# gpasswd -a gelin02 tarena [root@Localhost ~]# id gelin02 [root@Localhost ~]# su-gelin02 [gelin02@Localhost ~]# cd /tarena1 [gelin02@Localhost ~]# ls [gelin02@Localhost ~]# exit 3）新建/tarena2目录\na）将属组设为tarena 1 2 [root@Localhost ~]# mkdir /tarena2 [root@Localhost ~]# chown :tarena /tarena2 b）使tarena组的任何用户都能在此目录下创建、删除文件 1 2 3 4 5 6 7 8 [root@Localhost ~]# chmod g+w /tarena2 [root@Localhost ~]# useradd ceshi [root@Localhost ~]# gpasswd -a ceshi tarena [root@Localhost ~]# id ceshi [root@Localhost ~]# su -ceshi [ceshi@Localhost ~]# mkdir /tarena2/ceshi [ceshi@Localhost ~]# ls /tarena2 [ceshi@Localhost ~]# exit 4）新建/tarena/public目录\na）使任何用户对此目录都有rwx权限 1 2 [root@Localhost ~]# mkdir -p /tarena/public [root@Localhost ~]# chmod 777 /tarena/public b）拒绝zhangsan进入此目录，对此目录无任何权限（提示ACL黑名单） 1 2 3 4 5 6 7 [root@Localhost ~]# ls -ld /tarena/public [root@Localhost ~]# setfacl -m u:zhangsan:--- /tarena/public [root@Localhost ~]# useradd zhangsan [root@Localhost ~]# su -zhangsan [zhangsan@Localhost ~]# ls /tarena/public [zhangsan@Localhost ~]# cd /tarena/public [zhangsan@Localhost ~]# exit 案例3:权限设置 1、创建文件夹/data/test,设置目录的访问权限，使所有者和所属组具备读写执行的权限；其他人无任何权限。\n1 2 3 [root@Localhost ~]# mkdir -p /data/test [root@Localhost ~]# chmod u=rwx,g=rwx,o=--- /data/test 或者 chmod 770 /data/test [root@Localhost ~]# ls -ld /data/test 2、递归修改文件夹/data/test的归属使所有者为zhangsan，所属组为tarena。\n1 2 [root@Localhost ~]# chown -R zhangsan:tarena /data/test [root@Localhost ~]# ls -ld /data/test 3、请实现在test目录下，新建的所有子文件或目录的所属组都会是tarena。\n1 2 3 [root@Localhost ~]# chmod g+s /data/test [root@Localhost ~]# mkdir /data/test/abc [root@Localhost ~]# ls -ld /data/test/abc 4、为lisi创建ACL访问权限，使得lisi可以查看/etc/shadow文件\n1 2 3 4 5 [root@Localhost ~]# useradd lisi [root@Localhost ~]# setfacl -m u:liai:r /etc/shadow [root@Localhost ~]# getfacl /etc/shadow [root@Localhost ~]# su-lisi [lisi@Localhost ~]# cat /etc 案例4:虚拟机 上操作 将文件 /etc/fstab 拷贝为 /var/tmp/fstab，并调整文件 /var/tmp/fstab权限\n满足以下要求：\n– 此文件的拥有者是 root\n– 此文件对任何人都不可执行\n– 用户 natasha 能够对此文件执行读和写操作\n– 用户 harry 对此文件既不能读，也不能写\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@Localhost ~]# mkdir -p /var/tmp/fstab [root@Localhost ~]# cp /etc/fstab /var/tmp/fstab [root@Localhost ~]# ls -l /var/tmp/fstab [root@Localhost ~]# chmod a-x /var/tmp/fstab [root@Localhost ~]# setfacl -m u:natasha:rw /var/tmp/fstab [root@Localhost ~]# getfacl /var/tmp/fstab [root@Localhost ~]# su -natasha [natasha@Localhost ~]# cat /var/tmp/fstab [natasha@Localhost ~]# echo ceshi \u0026gt;\u0026gt; /var/tmp/fstab [natasha@Localhost ~]# cat /var/tmp/fstab [natasha@Localhost ~]# exit [root@Localhost ~]# setfacl -m u:harry:--- /var/tmp/fstab [root@Localhost ~]# getfacl /var/tmp/fstab [root@Localhost ~]# su-harry [harry@Localhost ~]# cat /var/tmp/fstab [harry@Localhost ~]# echo ceshi \u0026gt;\u0026gt; /var/tmp/fstab [harry@Localhost ~]# exit 案例5:虚拟机上操作 创建一个共用目录 /home/admins，要求如下：\n– 此目录的所属组是 adminuser – adminuser 组的成员对此目录有读写和执行的权限，并且其他用户没有任何权限 – 在此目录中创建的文件，其所属组会自动设置为 属于 adminuser 组 1 2 3 4 5 6 7 8 9 10 [root@Localhost ~]# mkdir /home/admins [root@Localhost ~]# groupadd adminuser [root@Localhost ~]# chown :adminuser /home/admins [root@Localhost ~]# ls -ld /home/admins [root@Localhost ~]# chmod g:rwx,o:--- /home/admins [root@Localhost ~]# chown g+s /home/admins [root@Localhost ~]# ls -ld /home/admins [root@Localhost ~]# mkdir /home/admins/ceshi [root@Localhost ~]# ls -ld/home/admins/ceshi ‍\n","date":"2025-04-14T14:27:42+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/","title":"Linux 文件系统与权限管理"},{"content":"Linux-进程管理与服务管理 一、Linux进程管理 进程\n💡处于运行状态的任务(程序)，叫做计算机的一个进程。\n常见进程\nSSHD进程：远程连接程序 chronyd进程: 负责管理系统日期时间 network: 管理操作系统网络ip地址，网卡，网关，网络连接状态。 firewalld:防火墙，定制有选择性拦截非法的网络连接。(默认 22端口 放开)，其他所有端口都是不被本机以外计算机访问。 其他程序：MySQL、Tomcat、Nginx、自开发程序。 查看进程\n1 2 3 4 5 6 7 # 命令 ps [-参数] # 参数 -a：显示 当前窗口 下的进程 -u：显示 当前用户 下的进程 -x：显示 当前主机 下的所有进程 命令结果含义 1 2 3 PID(进程号) TTY TIME CMD(该程序进程对应那个命令) 2405 pts/0 00:00:00 bash 2427 pts/0 00:00:00 ps 关闭进程\n1 2 3 4 5 6 7 8 9 # 命令 kill [-参数] 进程id 说明：默认情况kill，只能关闭闲置的进程，没有人正在使用。 # 参数 -9 ：强制退出（小心使用：强制杀死程序，不管有没有人正在使用。） -18 ：继续 -19 ：暂停 程序：静态没有运行的代码 占用硬盘空间\n进程：正在运行的代码 占用CPU与内存的资源\n进程唯一标识 : PID\n父进程与子进程 树型结构\nsystemd：所有进程的父进程 上帝进程\n查看进程 pstree — Processes Tree\n格式：pstree [选项] [PID或用户名]\n• 常用命令选项\n-a：显示完整的命令行\n-p：列出对应PID编号\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@localhost ~]# pstree #查看正在运行的进程信息 [root@localhost ~]# useradd lisi [root@localhost ~]# pstree lisi 未发现进程。 [root@localhost ~]# pstree lisi #登录lisi用户，查看进程 bash───vim [root@localhost ~]# pstree -p lisi #显示进程的PID bash(6838)───vim(6874) [root@localhost ~]# pstree -a lisi #显示完成的命令 bash └─vim a.txt 查看进程\nps aux 操作（显示的信息非常详细）\n列出正在运行的所有进程\n用户 进程ID %CPU %内存 虚拟内存 固定内存 终端 状态 起始时间 CPU时间 程序指令\n1 2 3 4 5 6 7 8 9 10 11 [root@localhost ~]# wc -l /etc/passwd 43 /etc/passwd [root@localhost ~]# ps aux | wc -l [root@localhost ~]# ps -elf | wc -l [root@localhost ~]# find /etc -name \u0026#34;*.conf\u0026#34; [root@localhost ~]# find /etc -name \u0026#34;*.conf\u0026#34; | wc -l ps -elf 操作（可以显示进程的父进程PID）\n进程动态排名top 交互式工具\n格式：top [-d 刷新秒数] [-U 用户名]\n1 2 3 4 5 6 7 [root@localhost ~]# top 输入P(大写)，按照CPU进行排序 输入M(大写)，按照内存进行排序 输入q退出 检索进程pgrep — Process Grep\n用途：pgrep [选项]\u0026hellip; 查询条件\n常用命令选项\n-l：输出进程名，而不仅仅是 PID\n-U：检索指定用户的进程\n-x：精确匹配完整的进程名\n1 2 3 [root@localhost ~]# pgrep -l a [root@localhost ~]# pgrep -l c 进程的前后台调度\n• Ctrl + z 组合键\n挂起当前进程（暂停当前的进程并转入后台）\n• jobs 命令\n查看后台任务列表\n• fg 命令\n将后台任务恢复到前台运行\n• bg 命令\n激活后台被挂起的任务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@localhost /]# sleep 3600 \u0026amp; #进程正在运行的状态放入后台 [root@localhost /]# firefox \u0026amp; [root@localhost ~]# sleep 3600 ^Z #按ctrl +z 暂停放入后台 [1]+ 已停止 sleep 3600 [root@localhost ~]# jobs #查看后台进程的信息 [1]+ 已停止 sleep 3600 [root@localhost ~]# bg 1 #将后台编号为1 的进程恢复运行 [1]+ sleep 3600 \u0026amp; [root@localhost ~]# jobs [1]+ 运行中 sleep 3600 \u0026amp; [root@localhost ~]# fg 1 #将后台编号为1的进程恢复到前台\nsleep 3600\n^C #按ctrl +c 结束进程\n[root@localhost ~]#\n杀死进程\n干掉进程的不同方法\nCtrl+c 组合键，中断当前命令程序\nkill [-9] PID\u0026hellip; 、kill [-9] %后台任务编号\nkillall [-9] 进程名\u0026hellip;\npkill [-9] 查找条件，包含就可以\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@localhost ~]# sleep 3600 \u0026amp; [root@localhost ~]# sleep 3600 \u0026amp; [root@localhost ~]# sleep 3600 \u0026amp; [root@localhost ~]# jobs -l #显示后台进程信息，显示PID [1] 8618 运行中 sleep 3600 \u0026amp; [2]- 8625 运行中 sleep 3600 \u0026amp; [3]+ 8632 运行中 sleep 3600 \u0026amp; [root@localhost ~]# kill 8618 #按照PID杀死 [1] 已终止 sleep 3600 [root@localhost ~]# jobs -l [root@localhost ~]# killall sleep 3600 #杀死所有sleep 3600进程 杀死一个用户开启的所有进程（强制踢出一个用户）\n1 [root@localhost ~]# killall -9 -u lisi 二、Linux服务管理 💡服务可以理解成软件程序​，特点是运行和系统可以绑定​。\n1 2 3 4 5 6 # 常见服务 sshd 远程连接 NetworkManager 网络管理器 chronyd 时钟 firewalld 防火墙 mysqld 数据库 1 2 3 4 5 1. 查看服务状态 systemctl status 服务名 说明： inactive 不可用 active 正在运行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 2. 启动服务 systemctl start 服务名 3. 重启服务 systemctl restart 服务名 4. 关闭服务 systemctl stop 服务名 例子： 关闭防火墙 systemctl stop firewalld 5. 设置开启自启动 systemctl enable 服务名 例子： 关闭防火墙 6. 关闭开机自启动 systemctl disabled 服务名 ‍\n","date":"2025-04-14T14:20:58+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E4%B8%8E%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/","title":"Linux 进程管理与服务管理"},{"content":" Linux-基础命令与操作 一、 Linux系统 1. Linux系统 💡开源的，免费的类Unix企业服务常用的操作系统，支持多用户，多任务，多处理器。\n1 2 3 Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统 ​Linux也继承了Unix的文件设计思想，一切皆文件(文件夹也是文件)​ Linux之父是“托瓦斯林纳斯” 开源 免费​\n开源：开放Linux操作系统源代码，任何人可以免费使用，且对Linux代码定制升级。\n最安全\n最稳定\n性能效率对比较高\n2.版本说明 💡Linux由于是开源的，所以有很多公司在Linux内核程序基础上开发了自己的有特别功能的程序(工具)，然后，再命令为一个新的版本，因此Linux有众多的版本型号。\n1 总结：严格来讲，Linux操作系统指的是“linux内核+各种软件”. 商业公司维护的发型版本 社区组织维护的发行版本 3.虚拟机的安装 💡通过软件技术，虚拟出一套计算机硬件设备：CPU、内存、硬盘、网卡、显示器。\n版本\nVMware​ 收费 virtrubox​ 免费 Oracle公司 企业虚拟机​ 云服务器​ （1）VMware的安装 VMware17安装包\n1 VMware17激活码:JU090-6039P-08409-8J0QH-2YR7F （2）虚拟创建一个计算机设备​ （3）安装CentOS操作系统 系统盘\n保存了操作系统文件的光盘\n虚拟镜像光盘：CentOS-7-x86_64-DVD-1804.iso​\n安装过程\n2. 安装CentOS7.zip\n（4）命令行界面 CentoS安装好以后，命令行界面，没有图形化操作界面。\n① 原因节省服务器CPU和内存资源。\n② 命令行操作效率，速度，远超过图形化界面。\n（5）vmware使用 开关机 虚拟机路径 快照 克隆 二 、Linux基础命令与操作 1. Linux远程连接 （1）linux工作环境 实际工作中，不会直接触碰服务器，会通过Linux远程连接工具服务器。\n（2）SSH工具 ① 查看Linux的ip地址\nip addr​\n② SecureCRT连接linux\n1 2 3 4 5 6 1. linux的ip 192.168.199.131 2. 用户名 root 3. 密码 admins （3）Windows的ssh（了解）\n1 2 3 1. 打开windows的cmd命令行 2. 输入命令 ssh root@linux的ip地址 ​\n2. 命令行介绍 （1）Linux终端 终端terminal​（命令行客户端） 1 2 3 4 5 6 7 1. 概念：用来连接和操作linux系统的接口，存在于用户和计算机之间沟通的桥梁。 2. 终端快捷键 ① tab ：命令自动补全。 例如： da+tab ② ctrl+c： 强行中断 停止退出当前程序命令。 ③ ↑ ↓ ：直接找到回显之前执行过历史命令。 Linux命令 1 2 3 4 5 1. 命令是一种操作Linux系统的一种指令。 2. linux命令区分大小写。 3. linux命令结构 linux命令 参数 其中多个参数可以组合使用。 （2）命令行提示符 1 2 3 4 5 6 7 [root@baizhi-centos ~]# root ：当前登录系统的用户 @：无意义，仅分隔符 baizhi-centos：计算机名字 ~ ： 当前命令所在的 目录路径 ，home #或者$: 表示当前用户超级管理员，$表示普通用户。 （3）基本命令 查看ip 1 2 3 4 5 1. 完整命令 ip address 2. 简化命令 ip addr 网络ping 1 2 3 4 5 6 7 8 9 10 11 # 命令 ping ip地址 # 参数 -c 次数：设置ping发送数据包次数。 # 案例 本机内部网络是否联通。 ping 127.0.0.1 ping localhost # 案例 ping -c 5 192.168.199.131 清屏 1 clear 关机 序号 命令 备注 1 init 0​ 立刻关机，只有管理员可以使用 2 poweroff​ 立刻关机 3 shutdown​ 立刻或定时关机 重启 序号 命令 备注 1 reboot​ 立即重启 操作系统信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 场景： 同时拿到10个服务器，判断10个服务器操作系统版本环境是否一致。 # 命令 uname # 参数 -s 输出 内核名称 (默认) -n 输出网络节点上的主机名 -r 输出内核版本 -v 输出内核的构建容器和版本信息 -m 输出主机的硬件架构名称 -p 输出处理器类型或\u0026#34;unknown\u0026#34; -i 输出硬件平台或\u0026#34;unknown\u0026#34; -o 输出操作系统名称 -a 以如下次序输出所有信息。其中若-p和-i的结果不可知则省略 也可以 --all # 注意 多个参数可以合并使用 例如： uname -svr 磁盘信息 1 2 3 1. 查看物理磁盘空间 df是一个用于显示文件系统磁盘空间使用情况的命令行工具，它可以帮助用户查看磁盘分区的总空间、已用空间、可用空间以及挂载点等信息。 df -h 磁盘使用空间 1 2 3 4 5 6 7 8 9 10 11 1. 查看文件或目录的大小 du #语法 du [-ahs] [文件名|目录] #参数 -a 显示子文件的大小 -h 以易读的方式显示 KB,MB,GB等 -s summarize 统计总占有量 说明： -s和-a不能同时使用 例如： du -h 配置硬件信息 1 2 3 4 5 1. 查看CPU信息 lscpu 2. 查看内存 free -h 系统程序的资源占用情况 1 2 3 4 5 6 7 8 9 10 11 12 13 1. 实时查看 #命令： top #快捷键： ↑ ： 上翻 ↓ ：下翻 q ：退出 2. 场景 ① 服务器卡顿 DDOS攻击 中毒 查看原因：top 主机名 1 2 3 4 5 1. 查看主机名 hostname 2. 修改主机名 hostnamectl set-hostname 新主机名 ​\n系统时间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # 命令 date \u0026#39;+参数\u0026#39; 说明： 一个日期包含信息：年 月 日 星期 时 分秒 毫秒 纳秒 时区 # 参数 1. 日期格式 %c : 直接显示日期与时间 (2023年10月08日 星期日 15时57分35秒) %x : 直接显示日期 (YYYY-mm-dd) %D : 直接显示日期 (mm/dd/yy) %X : 相当于 %H:%M:%S %T : 直接显示时间 (24 小时制) %r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M) 2. 提取详细日期属性 %Y : 完整年份 (0000..9999) %y : 年份的最后两位数字 (00.99) %m : 月份 (01..12) %d : 日 (01..31) %H : 小时(00..23) %M : 分钟(00..59) %S : 秒 %n : 下一行 %t : 跳格 tab %p : 显示本地 AM 或 PM 3. 其他日期属性（了解） %Z : 显示时区 %w : 一周中的第几天 (0..6)。说明每星期第0天是周日。 %a : 星期几 (Sun..Sat) %A : 星期几 (Sunday..Saturday) %b : 月份 (Jan..Dec) %B : 月份 (January..December) %s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数 计算机对于日期信息统计方式：时钟从1970年开始计算过去了多少秒，内部底层存储日期(数字秒) %n : 下一行 %t : 跳格 tab 1 2 # 案例: 获取日期格式显示：xxxx-xx-xx xx:xx:xx date \u0026#39;+%Y-%m-%d %H:%M:%S\u0026#39; 3. 文件管理 （1）Linux文件系统(了解) ① Linux文件系统没有C​ D​ E​ 盘，顶级目录是/​ ② Linux文件类型：目录、文件、符号链接文件​ （2）Inode元数据 1 2 3 4 5 6 7 8 9 1. Linux文件管理 数据 空间： 存放 数据 本身，100MB 10GB 文件本身所在位置。 元空间： 文件 描述信息(元数据) (文件名 大小 日期 用户 类型 文件所在地址)---Inode。 2.场景： Linux文件查找 ① 先在元空间中，找到文件描述信息。速度快。（元空间小），得到文件地址。 ② 如果需要得到文件内容，通过地址直接定位到对应位置即可。--- 寻道过程。 元数据 ​Inode​​ 数据 ​data​​ 概念 文件的描述信息(文件名 大小 类型 权限 日期等等) 文件内真正存储的数据内容 容量 非常小，且不同大小的文件的元数据信息大小相同 256B字节 大小不等：KB MB GB TB等 位置 元空间**（内存+硬盘）​** 数据空间**（硬盘）​** 类比 公安局档案信息、学生档案信息、生死簿 人、学生、鬼 （3）路径命令 命令 作用 常用选项 用法 示例 pwd​ 查看当前命令所在目录 — cd​ 切换目录 — cd [目录]​ cd /home​ ls​ 查看目录中的文件和目录 -a 显示所有文件含隐藏\n-l 显示文件完整描述元数据\n-R 显示指定目录分支内各子目录中的文件清单\nls [选项] [目录]​ `ls -al /root ls -alR /root ls -al \u0026gt; a.txt` 1 2 3 4 5 6 7 8 9 10 11 # 路径特殊字符 1 / : 顶级目录 2 . : 当前路径位置 通常使用相对路径使用 例如：切换到当前目录下的class目录 cd ./class 3 .. : 上一级路径 常用在相对路径。 4 ~ :当前用户所在的home目录， 例如baizhi用户的目录对应 /home/baizhi 例如root用户所在目录，特殊 /root 1 2 3 4 5 6 7 8 9 10 11 # 绝对路径和相对路径 1 绝对路径：是从根目录（/）开始的完整路径，用于定位文件系统中的任何文件或目录。 例如： /home/user/documents/file.txt就是一个绝对路径，它直接指向根目录下的home目录中的user目录下的documents目录中的file.txt文件。 2 相对路径：是相对于当前工作目录的路径。 例如： 如果你在/home/user目录中，要访问documents目录中的file.txt文件，你可以使用相对路径documents/file.txt。 相对路径让你不需要知道文件的完整路径，只需要知道它与当前工作目录的位置关系。 # 理解和正确使用这两种路径类型对于在Linux系统中高效地导航和操作文件至关重要。 ls文件元数据详解1 1 2 3 # 文件类型 d： 目录 -：普通文件 （4）文件操作命令 命令 作用 常用选项 用法 示例 ​touch​​ 创建一个空文件 — touch [文件名.后缀名]​ touch a.txt​ ​mkdir​​ 创建目录 -p 如果父目录不存在则创建 mkdir [选项] [目录名]​ `mkdir test mkdir -p test/user` ​rm​​ 删除文件或目录 -f 删除文件，不需要确认。\n-r 删除目录\n-fr 强制删除目录，不需要确认 rm ``[选项]`` [目录]​ cd /home​ ​cp​​ 复制文件或目录 -r 复制目录（含文件） cp [选项] [源文件] [拷贝后文件]​ `cp a/abc.txt b/bcd.txt cp a/abc.text b cp -r a b cp -r a/* b` ​mv​​ 移动文件 — mv [源文件] [目标目录]​ 参考cp ​find​​ 查找某个文件所在位置 -name 指定搜索的关键词\n说明：关键词可以使用*进行通配符匹配 find [搜索范围目录] [选项] [关键字]​ `find . find / -name \u0026ldquo;a\u0026rdquo; find / -name \u0026ldquo;a.txt\u0026rdquo; find /root -name \u0026ldquo;a.txt\u0026rdquo; find /root -name \u0026quot; *.txt\u0026quot;` 1 2 3 4 1. 课堂案例命令 2. 作业题目 3. 整理笔记（面试题+命令） 4(尝试). 没讲过的命令 试试。 （5）文件读取命令 命令 作用 常用选项 用法 示例 ​cat​​ 一次性读取整个文件，适合查看小文件 — cat [文件路径]​ cat a.txt​ ​less​​ 文件阅读器，可控制翻页，适合查看大文件 — less [文件路径]​\n↑ ：上翻1行\n↓：下翻1行\n空格 ：向下翻页，\nb：向上翻页\nq退出 less a.txt​ ​head​​ 查看文件前几行 -n 行数 head [文件路径] [选项] 行数​ head a.txt -n 2​ ​tail​​ 查看文件后几行，实时跟踪查看\n常用在服务日志文件 -n 行数\n-f 不断刷新实时更新 tail [文件路径] [选项] 行数​ tail -f a.txt -n 5​ ​grep​​ 在文件中搜索关键字，结果获得关键词所在一行文本提取。 -n 显示行号 grep [选项] 关键字 文件路径​ grep -n local a.txt​ ​echo​​ 用于展示一行/打印一行文字到控制台 — echo 字符串|环境变量名​ echo you are best ​ （6）压缩解压 💡将多个文件打包成一个文件。\n作用：\n① 方便管理和移动。把一些备份数据压缩。\n② 将文件空间占用变小，节约磁盘空间。\n③ 将大量小文件，合并成单个压缩文件，将文件在磁盘存放由随机存放转为顺序存放，访问（移动还是拷贝）文件对文件读取由随机读取变成顺序读取。效率快。\nlinux系统下常用的压缩文件格式有 tar.gz​\n1 2 3 4 5 windows系统：rar，zip。 linux压缩格式： 1. tar 2. tar.gz 压缩/解压tar.gz文件\n1 2 3 4 5 6 7 8 9 10 11 1. 压缩文件操作命令： # 命令 tar -cf 压缩文件名 被压缩文件或者目录路径 # 参数 -c 创建压缩文件 -x 解压压缩文件 -f 执行压缩文件名 -v 显示压缩过程的信息。 -z 主要针对tar.gz压缩格式操作需要 # 第二参数 -C 指定文件解压后所在目录。 案例 压缩 tar -zcvf 压缩后文件名.tar.gz 被压缩文件路径 解压缩 默认解压到当前目录下 tar -zxvf 被解压文件名.tar.gz tar -zxvf 被解压文件名.tar.gz -C 解压后文件存放位置路径 （7）帮助指令 💡man指令：查看指定命令的帮助文档。\n1 2 3 4 5 6 7 语法： man 指令 例子: man ls man pwd man cd 💡\u0026ndash;help参数：大部分Linux命令都支持\u0026ndash;help参数，用于显示该命令的简要帮助信息。\n1 2 3 语法： 指令 --help cd --help 4. vi编辑器 💡编辑文本文件的软件程序，例如：txt文件、xx.ini、xxx.py、xxx.xml、xxx.conf。\n所有的类Unix系统中都会内置vi文本编辑器\n启动命令：vi 文件名​\nvi命令的工作模式：\n1 2 3 1. 命令模式（Command mode）：启动vi编辑器时进入的模式，该模式下可以进行复制、粘贴、删除等操作。 2. 输入模式（Insert mode）：在命令模式下按\u0026#34;i\u0026#34;键进入输入模式，该模式下可以修改文本内容。 3. 底线模式（Last line mode）：在命令模式下按下“:”键进入底线命令模式，该模式下可以对文件内容进行替换、保存、或退出编辑。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 三种模式的切换 ![](https://p.sda1.dev/23/310b9c21fbb6dfdc9b00019294b41c7b/image_ZTx1Aay6G2-20240424161452-kttqch7.png) * 各模式下的操作： | 模式名称 | 快捷键/命令 | 支持的操作 | | ------------ | ----------- | ------------------------------------------- | | **命令模式** | `i`​ | 进入输入模式，在光标前插入insert | | | | | | | `o`​ | 进入输入模式，在光标位置下新建一行输入 | | | `: `​ | 进入底线模式 | | | gg | 定位到第一行 | | | G | 定位到最后一行 | | | nyy | n为整数，`复制`​n行，从光标位置向下复制n行。 | | | p | 粘贴到光标的下一行。 | | | ndd | n为整数，删除n行，从光标向下数n行。 | | **底线模式** | set nu | 显示行号 | | | set nonu | 取消行号 | | | `q`​ | 退出不保存 | | | `q!`​ | 强制退出不保存 | | | `w`​ | 保存内容 | | | `wq`​ | 保存退出 | | | `wq!`​ | 强制保存退出 | 注意事项： 1. vi编辑模式，最好不要编写中文。 2. 如果可以，大量内容编写，可以使用外部文本编辑器 mobaxterm外部工具。 ### 5. Linux软件安装 #### （1）RPM软件 \u0026gt; 💡linux中软件包的一种格式，类似windows(exe msi)。 1. 作用：用于在Linux系统中管理（`安装`​、`卸载`​、`查看`​）.rpm程序包。 2. 常用命令参数： * 命令的格式 ```bash rpm [-参数] rpm软件的文件名。 命令参数 作用 pql​ 显示rpm软件包内部文件 i [软件全名]​ 安装应用程序 e [软件名]​ 卸载应用程序 v​ 显示安装过程信息 h ​ 线程进度条 qa 显示所有已安装的程序包 案例：安装tree命令\n1 2 3 4 5 # 安装 rpm -ivh tree文件名.rpm # 卸载 rpm -evh tree关键名 （2）Yum软件包管理器 Yum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE、CentOS中的Shell前端软件包管理器。\n基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，\n无须繁琐地一次次下载、安装。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## 列出所有可以安装的软件包 yum list ## 安装软件 yum install -y 软件名 # 安装tree yum install -y tree yum install -y vim ## 卸载软件 yum remove 软件名 ## 更新软件(了解) yum update 软件名 ## 查找软件包 yum search all 软件名 # 例如安装vim [root@one ~]# yum install -y vim 常用的工具 1 2 3 4 5 6 7 8 9 10 11 12 # VIM 编辑器 功能类似vi，比vi增加了关键词高亮效果，便于阅读和编写。 安装：yum install -y vim # wget 下载器 安装： yum install -y wget 命令： wget url地址 [参数] 参数： -P 下载文件的保存路径：指定下载文件所存放的路径。 6.管道命令 概念：\n1 管道 就是可以将两个或者多个命令（程序或者进程）连接到一起，把一个命令的输出作为下一个命令的输入，以这种方式连接的两个或者多个命令就形成了管道（pipe） 管道符：|\n语法\n1 command1 | command2 .... ① 连接多个命令 ② 执行顺序，从左至右，会将前一个命令得输出结果，作为后一个命令输入内容。 例：\n1 2 3 4 5 6 # 查询名字包含ssh的进程 ps -aux | grep ssh # 获取ls -al 输出的前5行 ls -al | head -n 5 # 获取ls -al 输出的前5行，查找是否含有关键字a ls -al | head -n 5 | grep a 7.用户与用户组 （1）用户配置文件 /etc/passwd​：存储用户信息。\n格式：用户名:密码占位符:UID:GID:描述信息:家目录:默认Shell​\n示例：\n1 root:x:0:0:root:/root:/bin/bash /etc/shadow​：存储用户密码信息（加密）。\n格式：用户名:加密密码:最后修改时间:最小间隔:最大间隔:警告时间:失效时间:保留字段​\n示例：\n1 root:$6$randomsalt$encryptedpassword:19180:0:99999:7::: （2）用户管理命令 useradd​：创建用户。\n示例：\n1 useradd -m -s /bin/bash username 常用选项：\n-m​：创建家目录。 -s​：指定默认 Shell。 -u​：指定 UID。 -g​：指定主用户组。 -G​：指定附加用户组。 usermod​：修改用户信息。\n示例：\n1 usermod -aG groupname username 常用选项：\n-aG​：将用户添加到附加用户组。 -s​：修改默认 Shell。 -L​：锁定用户。 -U​：解锁用户。 userdel​：删除用户。\n示例：\n1 userdel -r username 常用选项：\n-r​：删除用户及其家目录。 passwd​：修改用户密码。\n示例：\n1 passwd username （3）查看用户信息 id​：查看用户 UID、GID 和所属组。\n示例：\n1 id username whoami​：查看当前登录用户。\nw​：查看当前登录用户及其活动。\n（4）用户组配置文件 /etc/group​：存储用户组信息。\n格式：组名:组密码占位符:GID:组成员​\n示例：\n1 developers:x:1001:user1,user2 （5）用户组管理命令 groupadd​：创建用户组。\n示例：\n1 groupadd groupname groupmod​：修改用户组信息。\n示例：\n1 groupmod -n newgroupname oldgroupname groupdel​：删除用户组。\n示例：\n1 groupdel groupname （6）查看用户组信息 groups​：查看当前用户所属组。\n示例：\n1 groups username （7）其他相关命令 su​：切换用户。\n示例：\n1 su - username sudo​：以超级用户权限执行命令。\n示例：\n1 sudo command visudo​：编辑 /etc/sudoers​ 文件，配置用户权限。\n（8）常用操作示例 创建用户并添加到组 1 2 useradd -m -s /bin/bash user1 usermod -aG developers user1 查看用户所属组 1 groups user1 修改文件权限 1 2 chmod 755 script.sh chown user1:developers script.sh 切换用户 1 su - user1 ","date":"2025-04-12T22:28:22+08:00","permalink":"https://ZackMoel.github.io/xiaoshi/p/linux%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E4%B8%8E%E6%93%8D%E4%BD%9C/","title":"Linux相关基础与操作"}]